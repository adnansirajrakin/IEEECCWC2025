saving to [DIR]/
creating model vgg_small_1w1a
model structure: VGG_SMALL_1W1A(
  (conv0): BinarizeConv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): BinarizeConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (nonlinear): Hardtanh(min_val=-1.0, max_val=1.0, inplace=True)
  (conv2): BinarizeConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): BinarizeConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): BinarizeConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): BinarizeConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc): bilinear(in_features=8192, out_features=10, bias=True)
)
number of parameters: 4663696
Files already downloaded and verified
Files already downloaded and verified
criterion: CrossEntropyLoss()
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f398b791fd0>
EVALUATING - Epoch: [0][0/79]	Time 0.931 (0.931)	Data 0.313 (0.313)	Loss 2.3780 (2.3780)	Prec@1 7.031 (7.031)	Prec@5 44.531 (44.531)
lr: 0.02
TRAINING - Epoch: [0][0/391]	Time 1.694 (1.694)	Data 0.342 (0.342)	Loss 2.3611 (2.3611)	Prec@1 11.719 (11.719)	Prec@5 56.250 (56.250)
TRAINING - Epoch: [0][100/391]	Time 0.061 (0.079)	Data 0.000 (0.004)	Loss 2.1846 (2.1951)	Prec@1 28.125 (28.728)	Prec@5 85.938 (78.048)
TRAINING - Epoch: [0][200/391]	Time 0.061 (0.070)	Data 0.000 (0.002)	Loss 2.1880 (2.2788)	Prec@1 32.031 (29.345)	Prec@5 80.469 (78.778)
TRAINING - Epoch: [0][300/391]	Time 0.063 (0.068)	Data 0.000 (0.001)	Loss 2.1678 (2.3247)	Prec@1 38.281 (29.952)	Prec@5 82.812 (79.480)
EVALUATING - Epoch: [0][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 2.3672 (2.3672)	Prec@1 30.469 (30.469)	Prec@5 83.594 (83.594)
Time cost: 00:28	Time of Finish: 2022-03-24 22:40:53

 Epoch: 1	Training Loss 2.3568 	Training Prec@1 30.284 	Training Prec@5 79.694 	Validation Loss 2.4054 	Validation Prec@1 33.640 	Validation Prec@5 82.350 

lr: 0.04
TRAINING - Epoch: [1][0/391]	Time 0.941 (0.941)	Data 0.354 (0.354)	Loss 2.6862 (2.6862)	Prec@1 19.531 (19.531)	Prec@5 71.094 (71.094)
TRAINING - Epoch: [1][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 3.1412 (3.1051)	Prec@1 30.469 (27.491)	Prec@5 78.906 (77.761)
TRAINING - Epoch: [1][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 2.7488 (3.1839)	Prec@1 32.812 (27.289)	Prec@5 79.688 (77.433)
TRAINING - Epoch: [1][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 2.7359 (3.1160)	Prec@1 32.031 (28.177)	Prec@5 81.250 (78.013)
EVALUATING - Epoch: [1][0/79]	Time 0.398 (0.398)	Data 0.374 (0.374)	Loss 2.1074 (2.1074)	Prec@1 35.938 (35.938)	Prec@5 81.250 (81.250)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:38

 Epoch: 2	Training Loss 2.9649 	Training Prec@1 28.858 	Training Prec@5 78.664 	Validation Loss 2.1641 	Validation Prec@1 34.270 	Validation Prec@5 83.160 

lr: 0.06000000000000001
TRAINING - Epoch: [2][0/391]	Time 0.909 (0.909)	Data 0.345 (0.345)	Loss 2.3721 (2.3721)	Prec@1 26.562 (26.562)	Prec@5 77.344 (77.344)
TRAINING - Epoch: [2][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 1.9341 (2.0204)	Prec@1 33.594 (32.797)	Prec@5 84.375 (82.433)
TRAINING - Epoch: [2][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 1.6180 (1.8996)	Prec@1 43.750 (34.701)	Prec@5 90.625 (83.718)
TRAINING - Epoch: [2][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 1.6985 (1.8489)	Prec@1 34.375 (35.577)	Prec@5 89.062 (84.583)
EVALUATING - Epoch: [2][0/79]	Time 0.387 (0.387)	Data 0.362 (0.362)	Loss 1.6141 (1.6141)	Prec@1 46.875 (46.875)	Prec@5 85.938 (85.938)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:00

 Epoch: 3	Training Loss 1.8223 	Training Prec@1 36.168 	Training Prec@5 84.858 	Validation Loss 1.7076 	Validation Prec@1 40.830 	Validation Prec@5 85.270 

lr: 0.08
TRAINING - Epoch: [3][0/391]	Time 0.939 (0.939)	Data 0.379 (0.379)	Loss 1.7641 (1.7641)	Prec@1 35.156 (35.156)	Prec@5 85.156 (85.156)
TRAINING - Epoch: [3][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 1.5978 (1.8004)	Prec@1 38.281 (35.357)	Prec@5 90.625 (84.785)
TRAINING - Epoch: [3][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.7404 (1.7727)	Prec@1 35.938 (36.466)	Prec@5 84.375 (85.724)
TRAINING - Epoch: [3][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 1.5799 (1.7671)	Prec@1 40.625 (36.690)	Prec@5 91.406 (85.735)
EVALUATING - Epoch: [3][0/79]	Time 0.359 (0.359)	Data 0.339 (0.339)	Loss 1.5520 (1.5520)	Prec@1 46.875 (46.875)	Prec@5 89.844 (89.844)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 4	Training Loss 1.7587 	Training Prec@1 37.036 	Training Prec@5 85.950 	Validation Loss 1.6935 	Validation Prec@1 39.590 	Validation Prec@5 87.880 

lr: 0.1
TRAINING - Epoch: [4][0/391]	Time 0.923 (0.923)	Data 0.353 (0.353)	Loss 1.9114 (1.9114)	Prec@1 28.906 (28.906)	Prec@5 77.344 (77.344)
TRAINING - Epoch: [4][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 1.7635 (1.8048)	Prec@1 31.250 (35.311)	Prec@5 89.844 (85.002)
TRAINING - Epoch: [4][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 1.6696 (1.7772)	Prec@1 38.281 (35.969)	Prec@5 90.625 (85.770)
TRAINING - Epoch: [4][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 1.7110 (1.7682)	Prec@1 32.812 (36.246)	Prec@5 86.719 (86.039)
EVALUATING - Epoch: [4][0/79]	Time 0.393 (0.393)	Data 0.372 (0.372)	Loss 1.6634 (1.6634)	Prec@1 38.281 (38.281)	Prec@5 85.938 (85.938)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:26

 Epoch: 5	Training Loss 1.7539 	Training Prec@1 36.714 	Training Prec@5 86.322 	Validation Loss 1.7084 	Validation Prec@1 39.500 	Validation Prec@5 87.050 

lr: 0.1000017411147667
TRAINING - Epoch: [5][0/391]	Time 0.971 (0.971)	Data 0.358 (0.358)	Loss 1.8210 (1.8210)	Prec@1 35.938 (35.938)	Prec@5 84.375 (84.375)
TRAINING - Epoch: [5][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 1.6094 (1.6990)	Prec@1 38.281 (38.212)	Prec@5 92.188 (88.165)
TRAINING - Epoch: [5][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 1.5817 (1.6825)	Prec@1 43.750 (39.381)	Prec@5 85.938 (88.227)
TRAINING - Epoch: [5][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 1.4897 (1.6630)	Prec@1 46.875 (40.049)	Prec@5 89.062 (88.499)
EVALUATING - Epoch: [5][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 1.5262 (1.5262)	Prec@1 49.219 (49.219)	Prec@5 83.594 (83.594)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 6	Training Loss 1.6501 	Training Prec@1 40.464 	Training Prec@5 88.764 	Validation Loss 1.6804 	Validation Prec@1 41.640 	Validation Prec@5 87.730 

lr: 0.10000298478054478
TRAINING - Epoch: [6][0/391]	Time 0.918 (0.918)	Data 0.368 (0.368)	Loss 1.5711 (1.5711)	Prec@1 48.438 (48.438)	Prec@5 87.500 (87.500)
TRAINING - Epoch: [6][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 1.5727 (1.6133)	Prec@1 42.969 (41.236)	Prec@5 89.062 (89.542)
TRAINING - Epoch: [6][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 1.5805 (1.5914)	Prec@1 42.969 (42.133)	Prec@5 92.969 (90.003)
TRAINING - Epoch: [6][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 1.6031 (1.5702)	Prec@1 52.344 (43.106)	Prec@5 87.500 (90.280)
EVALUATING - Epoch: [6][0/79]	Time 0.357 (0.357)	Data 0.336 (0.336)	Loss 1.5487 (1.5487)	Prec@1 46.094 (46.094)	Prec@5 85.938 (85.938)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:30

 Epoch: 7	Training Loss 1.5616 	Training Prec@1 43.502 	Training Prec@5 90.438 	Validation Loss 1.5784 	Validation Prec@1 43.340 	Validation Prec@5 89.530 

lr: 0.10000373098496097
TRAINING - Epoch: [7][0/391]	Time 0.953 (0.953)	Data 0.380 (0.380)	Loss 1.4217 (1.4217)	Prec@1 45.312 (45.312)	Prec@5 92.969 (92.969)
TRAINING - Epoch: [7][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 1.5272 (1.5160)	Prec@1 44.531 (45.483)	Prec@5 92.969 (91.352)
TRAINING - Epoch: [7][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.4404 (1.5057)	Prec@1 50.000 (45.892)	Prec@5 92.969 (91.402)
TRAINING - Epoch: [7][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 1.3452 (1.4932)	Prec@1 51.562 (46.421)	Prec@5 93.750 (91.541)
EVALUATING - Epoch: [7][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 1.3944 (1.3944)	Prec@1 51.562 (51.562)	Prec@5 88.281 (88.281)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:30

 Epoch: 8	Training Loss 1.4869 	Training Prec@1 46.482 	Training Prec@5 91.636 	Validation Loss 1.5835 	Validation Prec@1 43.790 	Validation Prec@5 91.380 

lr: 0.1
TRAINING - Epoch: [8][0/391]	Time 0.925 (0.925)	Data 0.368 (0.368)	Loss 1.5055 (1.5055)	Prec@1 46.875 (46.875)	Prec@5 92.188 (92.188)
TRAINING - Epoch: [8][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 1.4796 (1.4430)	Prec@1 46.875 (47.084)	Prec@5 92.969 (92.381)
TRAINING - Epoch: [8][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.4635 (1.4312)	Prec@1 48.438 (48.111)	Prec@5 92.969 (92.409)
TRAINING - Epoch: [8][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 1.3641 (1.4129)	Prec@1 53.125 (49.003)	Prec@5 94.531 (92.678)
EVALUATING - Epoch: [8][0/79]	Time 0.384 (0.384)	Data 0.360 (0.360)	Loss 1.2422 (1.2422)	Prec@1 59.375 (59.375)	Prec@5 92.969 (92.969)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:37

 Epoch: 9	Training Loss 1.3973 	Training Prec@1 49.638 	Training Prec@5 92.878 	Validation Loss 1.3622 	Validation Prec@1 52.460 	Validation Prec@5 93.670 

lr: 0.0999997512742683
TRAINING - Epoch: [9][0/391]	Time 0.912 (0.912)	Data 0.354 (0.354)	Loss 1.2495 (1.2495)	Prec@1 53.125 (53.125)	Prec@5 92.969 (92.969)
TRAINING - Epoch: [9][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 1.1997 (1.3190)	Prec@1 60.938 (52.885)	Prec@5 92.969 (94.005)
TRAINING - Epoch: [9][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 1.2655 (1.3103)	Prec@1 57.812 (53.125)	Prec@5 94.531 (93.991)
TRAINING - Epoch: [9][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 1.1007 (1.2975)	Prec@1 60.938 (53.613)	Prec@5 95.312 (94.134)
EVALUATING - Epoch: [9][0/79]	Time 0.349 (0.349)	Data 0.325 (0.325)	Loss 1.1711 (1.1711)	Prec@1 53.125 (53.125)	Prec@5 95.312 (95.312)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 10	Training Loss 1.2890 	Training Prec@1 54.048 	Training Prec@5 94.220 	Validation Loss 1.2993 	Validation Prec@1 54.010 	Validation Prec@5 94.500 

lr: 0.09999900509954777
TRAINING - Epoch: [10][0/391]	Time 0.924 (0.924)	Data 0.364 (0.364)	Loss 1.1856 (1.1856)	Prec@1 55.469 (55.469)	Prec@5 92.188 (92.188)
TRAINING - Epoch: [10][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 1.3635 (1.2369)	Prec@1 50.781 (55.817)	Prec@5 96.094 (94.632)
TRAINING - Epoch: [10][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 1.1575 (1.2376)	Prec@1 59.375 (55.803)	Prec@5 94.531 (94.706)
TRAINING - Epoch: [10][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 1.1137 (1.2230)	Prec@1 56.250 (56.302)	Prec@5 96.094 (94.871)
EVALUATING - Epoch: [10][0/79]	Time 0.376 (0.376)	Data 0.358 (0.358)	Loss 1.2004 (1.2004)	Prec@1 58.594 (58.594)	Prec@5 93.750 (93.750)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:38

 Epoch: 11	Training Loss 1.2069 	Training Prec@1 56.930 	Training Prec@5 95.022 	Validation Loss 1.2505 	Validation Prec@1 56.510 	Validation Prec@5 94.620 

lr: 0.09999776148326214
TRAINING - Epoch: [11][0/391]	Time 0.962 (0.962)	Data 0.368 (0.368)	Loss 1.3384 (1.3384)	Prec@1 49.219 (49.219)	Prec@5 91.406 (91.406)
TRAINING - Epoch: [11][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 1.0358 (1.1737)	Prec@1 64.062 (58.377)	Prec@5 95.312 (95.467)
TRAINING - Epoch: [11][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.1534 (1.1393)	Prec@1 54.688 (59.729)	Prec@5 95.312 (95.736)
TRAINING - Epoch: [11][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 1.1168 (1.1374)	Prec@1 64.062 (59.915)	Prec@5 96.094 (95.751)
EVALUATING - Epoch: [11][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.9917 (0.9917)	Prec@1 66.406 (66.406)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:37

 Epoch: 12	Training Loss 1.1258 	Training Prec@1 60.356 	Training Prec@5 95.814 	Validation Loss 1.1675 	Validation Prec@1 59.730 	Validation Prec@5 95.590 

lr: 0.09999602043778419
TRAINING - Epoch: [12][0/391]	Time 0.924 (0.924)	Data 0.355 (0.355)	Loss 0.9969 (0.9969)	Prec@1 64.062 (64.062)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [12][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 1.0356 (1.0627)	Prec@1 64.844 (62.701)	Prec@5 96.094 (96.303)
TRAINING - Epoch: [12][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.0645 (1.0655)	Prec@1 60.938 (62.380)	Prec@5 96.875 (96.245)
TRAINING - Epoch: [12][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 1.0568 (1.0581)	Prec@1 61.719 (62.832)	Prec@5 95.312 (96.198)
EVALUATING - Epoch: [12][0/79]	Time 0.380 (0.380)	Data 0.357 (0.357)	Loss 0.9366 (0.9366)	Prec@1 69.531 (69.531)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:28

 Epoch: 13	Training Loss 1.0487 	Training Prec@1 63.216 	Training Prec@5 96.282 	Validation Loss 1.0181 	Validation Prec@1 64.470 	Validation Prec@5 96.610 

lr: 0.0999937819804356
TRAINING - Epoch: [13][0/391]	Time 0.902 (0.902)	Data 0.345 (0.345)	Loss 1.0697 (1.0697)	Prec@1 60.156 (60.156)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [13][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 1.1166 (1.0140)	Prec@1 63.281 (64.039)	Prec@5 95.312 (96.597)
TRAINING - Epoch: [13][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 1.2121 (1.0103)	Prec@1 54.688 (64.599)	Prec@5 97.656 (96.615)
TRAINING - Epoch: [13][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7322 (1.0005)	Prec@1 74.219 (64.839)	Prec@5 99.219 (96.787)
EVALUATING - Epoch: [13][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.9104 (0.9104)	Prec@1 67.969 (67.969)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 14	Training Loss 0.9901 	Training Prec@1 65.352 	Training Prec@5 96.798 	Validation Loss 1.0869 	Validation Prec@1 62.500 	Validation Prec@5 96.570 

lr: 0.09999104613348687
TRAINING - Epoch: [14][0/391]	Time 0.936 (0.936)	Data 0.363 (0.363)	Loss 0.9262 (0.9262)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [14][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.7338 (0.9663)	Prec@1 76.562 (66.515)	Prec@5 96.875 (96.952)
TRAINING - Epoch: [14][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.9784 (0.9530)	Prec@1 63.281 (66.667)	Prec@5 96.875 (97.038)
TRAINING - Epoch: [14][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.9157 (0.9414)	Prec@1 70.312 (67.182)	Prec@5 97.656 (97.129)
EVALUATING - Epoch: [14][0/79]	Time 0.359 (0.359)	Data 0.336 (0.336)	Loss 1.0058 (1.0058)	Prec@1 61.719 (61.719)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:36

 Epoch: 15	Training Loss 0.9412 	Training Prec@1 67.212 	Training Prec@5 97.098 	Validation Loss 1.1298 	Validation Prec@1 62.080 	Validation Prec@5 96.250 

lr: 0.09998781292415702
TRAINING - Epoch: [15][0/391]	Time 0.910 (0.910)	Data 0.357 (0.357)	Loss 0.9524 (0.9524)	Prec@1 62.500 (62.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [15][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.8752 (0.8945)	Prec@1 68.750 (68.735)	Prec@5 96.094 (97.192)
TRAINING - Epoch: [15][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.8908 (0.9079)	Prec@1 70.312 (68.043)	Prec@5 97.656 (97.221)
TRAINING - Epoch: [15][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.8684 (0.9019)	Prec@1 68.750 (68.405)	Prec@5 97.656 (97.301)
EVALUATING - Epoch: [15][0/79]	Time 0.377 (0.377)	Data 0.353 (0.353)	Loss 0.8730 (0.8730)	Prec@1 70.312 (70.312)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:19:33

 Epoch: 16	Training Loss 0.9020 	Training Prec@1 68.454 	Training Prec@5 97.298 	Validation Loss 0.9780 	Validation Prec@1 66.290 	Validation Prec@5 97.050 

lr: 0.09998408238461337
TRAINING - Epoch: [16][0/391]	Time 0.920 (0.920)	Data 0.355 (0.355)	Loss 0.8502 (0.8502)	Prec@1 65.625 (65.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [16][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.7585 (0.8727)	Prec@1 76.562 (69.585)	Prec@5 100.000 (97.478)
TRAINING - Epoch: [16][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.7770 (0.8681)	Prec@1 71.094 (69.632)	Prec@5 96.875 (97.571)
TRAINING - Epoch: [16][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7936 (0.8669)	Prec@1 74.219 (69.692)	Prec@5 98.438 (97.610)
EVALUATING - Epoch: [16][0/79]	Time 0.367 (0.367)	Data 0.344 (0.344)	Loss 0.6890 (0.6890)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:11

 Epoch: 17	Training Loss 0.8609 	Training Prec@1 69.844 	Training Prec@5 97.662 	Validation Loss 0.9369 	Validation Prec@1 67.530 	Validation Prec@5 97.630 

lr: 0.09997985455197111
TRAINING - Epoch: [17][0/391]	Time 0.958 (0.958)	Data 0.395 (0.395)	Loss 0.6831 (0.6831)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [17][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.8724 (0.8228)	Prec@1 67.969 (71.442)	Prec@5 96.875 (97.842)
TRAINING - Epoch: [17][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.8276 (0.8218)	Prec@1 69.531 (71.552)	Prec@5 99.219 (97.831)
TRAINING - Epoch: [17][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.7824 (0.8347)	Prec@1 78.125 (70.826)	Prec@5 96.875 (97.778)
EVALUATING - Epoch: [17][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 0.8267 (0.8267)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:38

 Epoch: 18	Training Loss 0.8347 	Training Prec@1 70.930 	Training Prec@5 97.772 	Validation Loss 0.9694 	Validation Prec@1 67.090 	Validation Prec@5 97.690 

lr: 0.09997512946829312
TRAINING - Epoch: [18][0/391]	Time 1.011 (1.011)	Data 0.377 (0.377)	Loss 0.7702 (0.7702)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [18][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.8780 (0.8119)	Prec@1 70.312 (71.813)	Prec@5 99.219 (97.842)
TRAINING - Epoch: [18][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.6823 (0.8092)	Prec@1 78.906 (71.805)	Prec@5 97.656 (97.866)
TRAINING - Epoch: [18][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.8667 (0.8049)	Prec@1 65.625 (71.852)	Prec@5 97.656 (97.918)
EVALUATING - Epoch: [18][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.8165 (0.8165)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:54

 Epoch: 19	Training Loss 0.8043 	Training Prec@1 71.906 	Training Prec@5 97.938 	Validation Loss 0.8879 	Validation Prec@1 70.190 	Validation Prec@5 97.590 

lr: 0.09996990718058936
TRAINING - Epoch: [19][0/391]	Time 0.944 (0.944)	Data 0.361 (0.361)	Loss 0.7409 (0.7409)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [19][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.7590 (0.7922)	Prec@1 74.219 (72.664)	Prec@5 96.875 (98.097)
TRAINING - Epoch: [19][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 1.0747 (0.7923)	Prec@1 64.844 (72.388)	Prec@5 95.312 (98.045)
TRAINING - Epoch: [19][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.7775 (0.7942)	Prec@1 71.875 (72.340)	Prec@5 100.000 (98.097)
EVALUATING - Epoch: [19][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.5977 (0.5977)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:18

 Epoch: 20	Training Loss 0.7992 	Training Prec@1 72.220 	Training Prec@5 98.072 	Validation Loss 0.9279 	Validation Prec@1 68.660 	Validation Prec@5 97.410 

lr: 0.09996418774081654
TRAINING - Epoch: [20][0/391]	Time 0.950 (0.950)	Data 0.380 (0.380)	Loss 0.7028 (0.7028)	Prec@1 70.312 (70.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [20][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.8323 (0.7805)	Prec@1 71.094 (73.097)	Prec@5 97.656 (98.113)
TRAINING - Epoch: [20][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.7673 (0.7845)	Prec@1 74.219 (72.889)	Prec@5 96.094 (98.053)
TRAINING - Epoch: [20][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.8301 (0.7774)	Prec@1 70.312 (73.225)	Prec@5 99.219 (98.126)
EVALUATING - Epoch: [20][0/79]	Time 0.337 (0.337)	Data 0.316 (0.316)	Loss 0.6747 (0.6747)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:37

 Epoch: 21	Training Loss 0.7759 	Training Prec@1 73.118 	Training Prec@5 98.148 	Validation Loss 0.8090 	Validation Prec@1 72.340 	Validation Prec@5 97.850 

lr: 0.09995797120587754
TRAINING - Epoch: [21][0/391]	Time 0.971 (0.971)	Data 0.387 (0.387)	Loss 0.5859 (0.5859)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [21][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.7161 (0.7444)	Prec@1 75.781 (74.072)	Prec@5 98.438 (98.337)
TRAINING - Epoch: [21][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.6654 (0.7435)	Prec@1 78.125 (74.366)	Prec@5 100.000 (98.395)
TRAINING - Epoch: [21][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.7332 (0.7508)	Prec@1 75.000 (74.112)	Prec@5 97.656 (98.360)
EVALUATING - Epoch: [21][0/79]	Time 0.357 (0.357)	Data 0.337 (0.337)	Loss 0.8755 (0.8755)	Prec@1 71.875 (71.875)	Prec@5 94.531 (94.531)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:05

 Epoch: 22	Training Loss 0.7490 	Training Prec@1 74.154 	Training Prec@5 98.356 	Validation Loss 1.0469 	Validation Prec@1 66.610 	Validation Prec@5 95.900 

lr: 0.09995125763762085
TRAINING - Epoch: [22][0/391]	Time 0.935 (0.935)	Data 0.386 (0.386)	Loss 0.6274 (0.6274)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [22][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5937 (0.7390)	Prec@1 80.469 (74.497)	Prec@5 99.219 (98.345)
TRAINING - Epoch: [22][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.7066 (0.7373)	Prec@1 76.562 (74.448)	Prec@5 98.438 (98.368)
TRAINING - Epoch: [22][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5285 (0.7379)	Prec@1 77.344 (74.349)	Prec@5 100.000 (98.367)
EVALUATING - Epoch: [22][0/79]	Time 0.351 (0.351)	Data 0.332 (0.332)	Loss 0.7334 (0.7334)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:40

 Epoch: 23	Training Loss 0.7379 	Training Prec@1 74.414 	Training Prec@5 98.332 	Validation Loss 0.9215 	Validation Prec@1 69.270 	Validation Prec@5 97.560 

lr: 0.09994404710283995
TRAINING - Epoch: [23][0/391]	Time 0.895 (0.895)	Data 0.345 (0.345)	Loss 0.6622 (0.6622)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [23][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.6826 (0.7178)	Prec@1 75.000 (75.085)	Prec@5 98.438 (98.407)
TRAINING - Epoch: [23][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6879 (0.7149)	Prec@1 71.875 (75.268)	Prec@5 98.438 (98.449)
TRAINING - Epoch: [23][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.8104 (0.7129)	Prec@1 72.656 (75.369)	Prec@5 97.656 (98.458)
EVALUATING - Epoch: [23][0/79]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 0.6843 (0.6843)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:32

 Epoch: 24	Training Loss 0.7150 	Training Prec@1 75.358 	Training Prec@5 98.472 	Validation Loss 0.9044 	Validation Prec@1 71.450 	Validation Prec@5 96.750 

lr: 0.09993633967327266
TRAINING - Epoch: [24][0/391]	Time 0.915 (0.915)	Data 0.351 (0.351)	Loss 0.6316 (0.6316)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [24][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.7566 (0.6926)	Prec@1 75.781 (76.067)	Prec@5 97.656 (98.515)
TRAINING - Epoch: [24][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5575 (0.7024)	Prec@1 79.688 (75.917)	Prec@5 100.000 (98.422)
TRAINING - Epoch: [24][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.7766 (0.7096)	Prec@1 74.219 (75.649)	Prec@5 99.219 (98.422)
EVALUATING - Epoch: [24][0/79]	Time 0.355 (0.355)	Data 0.334 (0.334)	Loss 0.5780 (0.5780)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:26

 Epoch: 25	Training Loss 0.7134 	Training Prec@1 75.534 	Training Prec@5 98.430 	Validation Loss 0.7965 	Validation Prec@1 73.560 	Validation Prec@5 98.170 

lr: 0.09992813542560042
TRAINING - Epoch: [25][0/391]	Time 0.932 (0.932)	Data 0.354 (0.354)	Loss 0.6629 (0.6629)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [25][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.6640 (0.6874)	Prec@1 76.562 (76.709)	Prec@5 99.219 (98.453)
TRAINING - Epoch: [25][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6392 (0.6968)	Prec@1 77.344 (76.127)	Prec@5 98.438 (98.422)
TRAINING - Epoch: [25][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5648 (0.6991)	Prec@1 80.469 (75.958)	Prec@5 99.219 (98.448)
EVALUATING - Epoch: [25][0/79]	Time 0.348 (0.348)	Data 0.324 (0.324)	Loss 0.5281 (0.5281)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:24

 Epoch: 26	Training Loss 0.6917 	Training Prec@1 76.208 	Training Prec@5 98.554 	Validation Loss 0.7804 	Validation Prec@1 74.630 	Validation Prec@5 98.150 

lr: 0.09991943444144753
TRAINING - Epoch: [26][0/391]	Time 0.919 (0.919)	Data 0.365 (0.365)	Loss 0.7778 (0.7778)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [26][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.7631 (0.6905)	Prec@1 78.906 (76.207)	Prec@5 99.219 (98.530)
TRAINING - Epoch: [26][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5767 (0.6814)	Prec@1 80.469 (76.528)	Prec@5 100.000 (98.585)
TRAINING - Epoch: [26][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.8303 (0.6869)	Prec@1 72.656 (76.492)	Prec@5 96.875 (98.588)
EVALUATING - Epoch: [26][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.7015 (0.7015)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:01

 Epoch: 27	Training Loss 0.6841 	Training Prec@1 76.514 	Training Prec@5 98.624 	Validation Loss 0.8072 	Validation Prec@1 73.810 	Validation Prec@5 98.030 

lr: 0.09991023680738036
TRAINING - Epoch: [27][0/391]	Time 0.904 (0.904)	Data 0.355 (0.355)	Loss 0.6091 (0.6091)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [27][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6093 (0.6578)	Prec@1 78.906 (77.498)	Prec@5 99.219 (98.538)
TRAINING - Epoch: [27][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.8183 (0.6695)	Prec@1 70.312 (77.134)	Prec@5 99.219 (98.609)
TRAINING - Epoch: [27][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6566 (0.6748)	Prec@1 76.562 (76.921)	Prec@5 98.438 (98.536)
EVALUATING - Epoch: [27][0/79]	Time 0.334 (0.334)	Data 0.313 (0.313)	Loss 0.6282 (0.6282)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:41

 Epoch: 28	Training Loss 0.6744 	Training Prec@1 76.950 	Training Prec@5 98.512 	Validation Loss 0.7985 	Validation Prec@1 73.400 	Validation Prec@5 98.300 

lr: 0.09990054261490638
TRAINING - Epoch: [28][0/391]	Time 0.906 (0.906)	Data 0.347 (0.347)	Loss 0.6070 (0.6070)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [28][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.7686 (0.6670)	Prec@1 71.094 (77.197)	Prec@5 98.438 (98.693)
TRAINING - Epoch: [28][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.6468 (0.6683)	Prec@1 78.125 (77.064)	Prec@5 99.219 (98.748)
TRAINING - Epoch: [28][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.6688 (0.6628)	Prec@1 78.906 (77.271)	Prec@5 96.875 (98.656)
EVALUATING - Epoch: [28][0/79]	Time 0.354 (0.354)	Data 0.331 (0.331)	Loss 0.7720 (0.7720)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:26	Time of Finish: 2022-03-24 22:14:48

 Epoch: 29	Training Loss 0.6689 	Training Prec@1 77.010 	Training Prec@5 98.590 	Validation Loss 0.8606 	Validation Prec@1 72.050 	Validation Prec@5 97.650 

lr: 0.09989035196047345
TRAINING - Epoch: [29][0/391]	Time 0.908 (0.908)	Data 0.346 (0.346)	Loss 0.5514 (0.5514)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [29][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4966 (0.6577)	Prec@1 85.938 (77.823)	Prec@5 98.438 (98.492)
TRAINING - Epoch: [29][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6713 (0.6673)	Prec@1 75.000 (77.208)	Prec@5 98.438 (98.507)
TRAINING - Epoch: [29][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.5122 (0.6628)	Prec@1 79.688 (77.256)	Prec@5 100.000 (98.578)
EVALUATING - Epoch: [29][0/79]	Time 0.363 (0.363)	Data 0.340 (0.340)	Loss 0.7185 (0.7185)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 30	Training Loss 0.6607 	Training Prec@1 77.228 	Training Prec@5 98.630 	Validation Loss 0.8664 	Validation Prec@1 71.870 	Validation Prec@5 97.500 

lr: 0.0998796649454687
TRAINING - Epoch: [30][0/391]	Time 0.926 (0.926)	Data 0.365 (0.365)	Loss 0.6318 (0.6318)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [30][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5234 (0.6352)	Prec@1 79.688 (78.396)	Prec@5 98.438 (98.677)
TRAINING - Epoch: [30][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6792 (0.6458)	Prec@1 76.562 (77.865)	Prec@5 99.219 (98.721)
TRAINING - Epoch: [30][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6449 (0.6488)	Prec@1 78.125 (77.852)	Prec@5 97.656 (98.772)
EVALUATING - Epoch: [30][0/79]	Time 0.356 (0.356)	Data 0.334 (0.334)	Loss 0.5881 (0.5881)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 31	Training Loss 0.6495 	Training Prec@1 77.844 	Training Prec@5 98.798 	Validation Loss 0.8300 	Validation Prec@1 73.320 	Validation Prec@5 97.960 

lr: 0.09986848167621751
TRAINING - Epoch: [31][0/391]	Time 0.906 (0.906)	Data 0.340 (0.340)	Loss 0.5995 (0.5995)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [31][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.5688 (0.6371)	Prec@1 80.469 (78.496)	Prec@5 98.438 (98.847)
TRAINING - Epoch: [31][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6298 (0.6391)	Prec@1 78.906 (78.187)	Prec@5 99.219 (98.733)
TRAINING - Epoch: [31][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6576 (0.6435)	Prec@1 79.688 (78.133)	Prec@5 98.438 (98.700)
EVALUATING - Epoch: [31][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.6879 (0.6879)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:09

 Epoch: 32	Training Loss 0.6478 	Training Prec@1 78.006 	Training Prec@5 98.672 	Validation Loss 0.8855 	Validation Prec@1 71.290 	Validation Prec@5 97.460 

lr: 0.09985680226398258
TRAINING - Epoch: [32][0/391]	Time 0.917 (0.917)	Data 0.344 (0.344)	Loss 0.7216 (0.7216)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [32][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.6517 (0.6322)	Prec@1 78.125 (78.024)	Prec@5 99.219 (98.778)
TRAINING - Epoch: [32][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5155 (0.6450)	Prec@1 83.594 (77.670)	Prec@5 100.000 (98.690)
TRAINING - Epoch: [32][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.8122 (0.6488)	Prec@1 71.875 (77.575)	Prec@5 99.219 (98.679)
EVALUATING - Epoch: [32][0/79]	Time 0.367 (0.367)	Data 0.347 (0.347)	Loss 0.6601 (0.6601)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:43

 Epoch: 33	Training Loss 0.6492 	Training Prec@1 77.590 	Training Prec@5 98.694 	Validation Loss 0.8884 	Validation Prec@1 72.080 	Validation Prec@5 97.390 

lr: 0.0998446268249627
TRAINING - Epoch: [33][0/391]	Time 0.917 (0.917)	Data 0.355 (0.355)	Loss 0.4472 (0.4472)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [33][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5729 (0.6310)	Prec@1 78.125 (78.682)	Prec@5 99.219 (98.685)
TRAINING - Epoch: [33][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6732 (0.6353)	Prec@1 78.906 (78.451)	Prec@5 97.656 (98.729)
TRAINING - Epoch: [33][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.7031 (0.6412)	Prec@1 72.656 (78.216)	Prec@5 100.000 (98.710)
EVALUATING - Epoch: [33][0/79]	Time 0.396 (0.396)	Data 0.372 (0.372)	Loss 0.8012 (0.8012)	Prec@1 67.969 (67.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:56

 Epoch: 34	Training Loss 0.6405 	Training Prec@1 78.240 	Training Prec@5 98.694 	Validation Loss 0.8911 	Validation Prec@1 71.480 	Validation Prec@5 97.550 

lr: 0.0998319554802917
TRAINING - Epoch: [34][0/391]	Time 0.912 (0.912)	Data 0.348 (0.348)	Loss 0.6772 (0.6772)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [34][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.8023 (0.6136)	Prec@1 76.562 (79.355)	Prec@5 97.656 (98.685)
TRAINING - Epoch: [34][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4844 (0.6164)	Prec@1 83.594 (79.248)	Prec@5 100.000 (98.787)
TRAINING - Epoch: [34][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.8918 (0.6298)	Prec@1 75.000 (78.738)	Prec@5 94.531 (98.697)
EVALUATING - Epoch: [34][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.5871 (0.5871)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:13

 Epoch: 35	Training Loss 0.6331 	Training Prec@1 78.564 	Training Prec@5 98.718 	Validation Loss 0.7676 	Validation Prec@1 74.670 	Validation Prec@5 98.080 

lr: 0.09981878835603715
TRAINING - Epoch: [35][0/391]	Time 0.910 (0.910)	Data 0.344 (0.344)	Loss 0.5068 (0.5068)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [35][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5666 (0.6273)	Prec@1 80.469 (78.349)	Prec@5 98.438 (98.925)
TRAINING - Epoch: [35][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5265 (0.6261)	Prec@1 80.469 (78.494)	Prec@5 99.219 (98.884)
TRAINING - Epoch: [35][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5407 (0.6270)	Prec@1 78.125 (78.374)	Prec@5 100.000 (98.881)
EVALUATING - Epoch: [35][0/79]	Time 0.390 (0.390)	Data 0.366 (0.366)	Loss 0.6842 (0.6842)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:50

 Epoch: 36	Training Loss 0.6264 	Training Prec@1 78.322 	Training Prec@5 98.852 	Validation Loss 0.7305 	Validation Prec@1 76.010 	Validation Prec@5 98.550 

lr: 0.09980512558319914
TRAINING - Epoch: [36][0/391]	Time 0.939 (0.939)	Data 0.352 (0.352)	Loss 0.6811 (0.6811)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [36][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.6703 (0.6171)	Prec@1 77.344 (78.775)	Prec@5 99.219 (98.693)
TRAINING - Epoch: [36][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4878 (0.6080)	Prec@1 79.688 (78.972)	Prec@5 100.000 (98.752)
TRAINING - Epoch: [36][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7004 (0.6124)	Prec@1 81.250 (79.031)	Prec@5 96.875 (98.754)
EVALUATING - Epoch: [36][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.5023 (0.5023)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:27

 Epoch: 37	Training Loss 0.6124 	Training Prec@1 79.006 	Training Prec@5 98.774 	Validation Loss 0.6830 	Validation Prec@1 76.820 	Validation Prec@5 98.620 

lr: 0.09979096729770899
TRAINING - Epoch: [37][0/391]	Time 0.934 (0.934)	Data 0.342 (0.342)	Loss 0.6870 (0.6870)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [37][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.8030 (0.5953)	Prec@1 75.000 (79.440)	Prec@5 97.656 (99.072)
TRAINING - Epoch: [37][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6883 (0.5980)	Prec@1 76.562 (79.660)	Prec@5 99.219 (99.017)
TRAINING - Epoch: [37][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.6198 (0.5993)	Prec@1 78.125 (79.612)	Prec@5 99.219 (98.962)
EVALUATING - Epoch: [37][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.6470 (0.6470)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:34

 Epoch: 38	Training Loss 0.6042 	Training Prec@1 79.438 	Training Prec@5 98.938 	Validation Loss 0.7817 	Validation Prec@1 74.450 	Validation Prec@5 98.400 

lr: 0.09977631364042792
TRAINING - Epoch: [38][0/391]	Time 0.984 (0.984)	Data 0.362 (0.362)	Loss 0.5688 (0.5688)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [38][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4069 (0.5808)	Prec@1 86.719 (79.780)	Prec@5 98.438 (98.956)
TRAINING - Epoch: [38][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.6206 (0.5902)	Prec@1 75.781 (79.641)	Prec@5 97.656 (98.927)
TRAINING - Epoch: [38][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.4855 (0.6022)	Prec@1 82.031 (79.225)	Prec@5 99.219 (98.897)
EVALUATING - Epoch: [38][0/79]	Time 0.354 (0.354)	Data 0.332 (0.332)	Loss 0.8792 (0.8792)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:30:08

 Epoch: 39	Training Loss 0.6067 	Training Prec@1 79.122 	Training Prec@5 98.884 	Validation Loss 0.8713 	Validation Prec@1 72.060 	Validation Prec@5 98.240 

lr: 0.09976116475714561
TRAINING - Epoch: [39][0/391]	Time 0.927 (0.927)	Data 0.349 (0.349)	Loss 0.6434 (0.6434)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [39][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.4885 (0.5864)	Prec@1 82.031 (80.005)	Prec@5 99.219 (99.025)
TRAINING - Epoch: [39][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3844 (0.5972)	Prec@1 87.500 (79.513)	Prec@5 99.219 (98.951)
TRAINING - Epoch: [39][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6429 (0.5965)	Prec@1 75.781 (79.521)	Prec@5 98.438 (98.993)
EVALUATING - Epoch: [39][0/79]	Time 0.375 (0.375)	Data 0.352 (0.352)	Loss 0.7560 (0.7560)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:12

 Epoch: 40	Training Loss 0.6043 	Training Prec@1 79.414 	Training Prec@5 98.972 	Validation Loss 0.8420 	Validation Prec@1 73.450 	Validation Prec@5 98.160 

lr: 0.0997455207985787
TRAINING - Epoch: [40][0/391]	Time 0.972 (0.972)	Data 0.374 (0.374)	Loss 0.4847 (0.4847)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [40][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.5369 (0.5875)	Prec@1 78.125 (79.455)	Prec@5 100.000 (99.002)
TRAINING - Epoch: [40][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3968 (0.5992)	Prec@1 85.156 (79.256)	Prec@5 100.000 (98.939)
TRAINING - Epoch: [40][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.6141 (0.6012)	Prec@1 82.812 (79.405)	Prec@5 98.438 (98.840)
EVALUATING - Epoch: [40][0/79]	Time 0.380 (0.380)	Data 0.359 (0.359)	Loss 0.6070 (0.6070)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:29

 Epoch: 41	Training Loss 0.6065 	Training Prec@1 79.276 	Training Prec@5 98.840 	Validation Loss 0.6852 	Validation Prec@1 76.800 	Validation Prec@5 98.550 

lr: 0.09972938192036941
TRAINING - Epoch: [41][0/391]	Time 0.988 (0.988)	Data 0.364 (0.364)	Loss 0.4798 (0.4798)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [41][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.6438 (0.5880)	Prec@1 80.469 (80.090)	Prec@5 98.438 (98.847)
TRAINING - Epoch: [41][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.7086 (0.5970)	Prec@1 75.000 (79.571)	Prec@5 99.219 (98.830)
TRAINING - Epoch: [41][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5909 (0.5993)	Prec@1 82.812 (79.464)	Prec@5 96.875 (98.848)
EVALUATING - Epoch: [41][0/79]	Time 0.360 (0.360)	Data 0.341 (0.341)	Loss 0.5683 (0.5683)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:46

 Epoch: 42	Training Loss 0.6049 	Training Prec@1 79.344 	Training Prec@5 98.852 	Validation Loss 0.7795 	Validation Prec@1 74.500 	Validation Prec@5 98.470 

lr: 0.09971274828308392
TRAINING - Epoch: [42][0/391]	Time 0.967 (0.967)	Data 0.370 (0.370)	Loss 0.7887 (0.7887)	Prec@1 76.562 (76.562)	Prec@5 96.094 (96.094)
TRAINING - Epoch: [42][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.6718 (0.5837)	Prec@1 78.906 (79.958)	Prec@5 98.438 (98.994)
TRAINING - Epoch: [42][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5506 (0.5715)	Prec@1 82.031 (80.360)	Prec@5 98.438 (98.962)
TRAINING - Epoch: [42][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6358 (0.5832)	Prec@1 76.562 (79.960)	Prec@5 100.000 (98.980)
EVALUATING - Epoch: [42][0/79]	Time 0.358 (0.358)	Data 0.337 (0.337)	Loss 0.6680 (0.6680)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:54

 Epoch: 43	Training Loss 0.5858 	Training Prec@1 79.812 	Training Prec@5 98.984 	Validation Loss 0.8225 	Validation Prec@1 73.840 	Validation Prec@5 98.070 

lr: 0.09969562005221076
TRAINING - Epoch: [43][0/391]	Time 0.933 (0.933)	Data 0.345 (0.345)	Loss 0.8534 (0.8534)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [43][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.6340 (0.5956)	Prec@1 79.688 (80.105)	Prec@5 98.438 (99.087)
TRAINING - Epoch: [43][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.6173 (0.6068)	Prec@1 79.688 (79.583)	Prec@5 99.219 (98.974)
TRAINING - Epoch: [43][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.6297 (0.6038)	Prec@1 79.688 (79.607)	Prec@5 99.219 (98.938)
EVALUATING - Epoch: [43][0/79]	Time 0.365 (0.365)	Data 0.342 (0.342)	Loss 0.6610 (0.6610)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:26

 Epoch: 44	Training Loss 0.6033 	Training Prec@1 79.606 	Training Prec@5 98.906 	Validation Loss 0.7530 	Validation Prec@1 75.400 	Validation Prec@5 97.990 

lr: 0.09967799739815922
TRAINING - Epoch: [44][0/391]	Time 0.941 (0.941)	Data 0.342 (0.342)	Loss 0.5153 (0.5153)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [44][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.4560 (0.5591)	Prec@1 83.594 (81.126)	Prec@5 98.438 (98.948)
TRAINING - Epoch: [44][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5828 (0.5835)	Prec@1 81.250 (80.333)	Prec@5 99.219 (98.993)
TRAINING - Epoch: [44][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.5322 (0.5827)	Prec@1 78.906 (80.165)	Prec@5 99.219 (98.985)
EVALUATING - Epoch: [44][0/79]	Time 0.383 (0.383)	Data 0.362 (0.362)	Loss 0.4773 (0.4773)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:56

 Epoch: 45	Training Loss 0.5797 	Training Prec@1 80.316 	Training Prec@5 98.970 	Validation Loss 0.7315 	Validation Prec@1 76.600 	Validation Prec@5 98.430 

lr: 0.09965988049625758
TRAINING - Epoch: [45][0/391]	Time 0.989 (0.989)	Data 0.367 (0.367)	Loss 0.4198 (0.4198)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [45][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.4493 (0.5713)	Prec@1 85.156 (80.546)	Prec@5 100.000 (99.041)
TRAINING - Epoch: [45][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.6852 (0.5809)	Prec@1 75.781 (80.177)	Prec@5 97.656 (98.993)
TRAINING - Epoch: [45][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7129 (0.5781)	Prec@1 75.000 (80.357)	Prec@5 98.438 (98.985)
EVALUATING - Epoch: [45][0/79]	Time 0.368 (0.368)	Data 0.344 (0.344)	Loss 0.6750 (0.6750)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:10

 Epoch: 46	Training Loss 0.5756 	Training Prec@1 80.464 	Training Prec@5 99.008 	Validation Loss 0.8556 	Validation Prec@1 72.870 	Validation Prec@5 98.350 

lr: 0.09964126952675145
TRAINING - Epoch: [46][0/391]	Time 0.903 (0.903)	Data 0.347 (0.347)	Loss 0.6279 (0.6279)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [46][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5052 (0.5533)	Prec@1 83.594 (81.165)	Prec@5 100.000 (99.080)
TRAINING - Epoch: [46][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3739 (0.5651)	Prec@1 89.844 (80.958)	Prec@5 98.438 (99.028)
TRAINING - Epoch: [46][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5905 (0.5736)	Prec@1 81.250 (80.547)	Prec@5 99.219 (98.990)
EVALUATING - Epoch: [46][0/79]	Time 0.375 (0.375)	Data 0.355 (0.355)	Loss 0.7245 (0.7245)	Prec@1 75.781 (75.781)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:50

 Epoch: 47	Training Loss 0.5803 	Training Prec@1 80.304 	Training Prec@5 98.960 	Validation Loss 0.7973 	Validation Prec@1 73.730 	Validation Prec@5 98.480 

lr: 0.0996221646748019
TRAINING - Epoch: [47][0/391]	Time 0.910 (0.910)	Data 0.342 (0.342)	Loss 0.5570 (0.5570)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [47][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4857 (0.5590)	Prec@1 85.156 (80.894)	Prec@5 100.000 (99.080)
TRAINING - Epoch: [47][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.6892 (0.5612)	Prec@1 75.000 (80.741)	Prec@5 98.438 (99.036)
TRAINING - Epoch: [47][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5734 (0.5746)	Prec@1 82.031 (80.349)	Prec@5 98.438 (98.977)
EVALUATING - Epoch: [47][0/79]	Time 0.344 (0.344)	Data 0.320 (0.320)	Loss 0.7828 (0.7828)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:01

 Epoch: 48	Training Loss 0.5768 	Training Prec@1 80.352 	Training Prec@5 98.974 	Validation Loss 1.0048 	Validation Prec@1 70.070 	Validation Prec@5 97.570 

lr: 0.09960256613048364
TRAINING - Epoch: [48][0/391]	Time 0.897 (0.897)	Data 0.340 (0.340)	Loss 0.5888 (0.5888)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [48][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5022 (0.5699)	Prec@1 79.688 (80.670)	Prec@5 97.656 (99.049)
TRAINING - Epoch: [48][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6818 (0.5747)	Prec@1 74.219 (80.302)	Prec@5 100.000 (99.032)
TRAINING - Epoch: [48][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.5598 (0.5748)	Prec@1 82.812 (80.396)	Prec@5 97.656 (98.998)
EVALUATING - Epoch: [48][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.9822 (0.9822)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:47

 Epoch: 49	Training Loss 0.5815 	Training Prec@1 80.192 	Training Prec@5 98.994 	Validation Loss 1.0077 	Validation Prec@1 69.710 	Validation Prec@5 96.940 

lr: 0.0995824740887832
TRAINING - Epoch: [49][0/391]	Time 0.928 (0.928)	Data 0.377 (0.377)	Loss 0.5109 (0.5109)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [49][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6415 (0.5842)	Prec@1 74.219 (80.012)	Prec@5 97.656 (99.056)
TRAINING - Epoch: [49][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4885 (0.5914)	Prec@1 79.688 (79.866)	Prec@5 99.219 (98.881)
TRAINING - Epoch: [49][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.5737 (0.5852)	Prec@1 81.250 (80.134)	Prec@5 99.219 (98.962)
EVALUATING - Epoch: [49][0/79]	Time 0.347 (0.347)	Data 0.323 (0.323)	Loss 0.9847 (0.9847)	Prec@1 69.531 (69.531)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:36

 Epoch: 50	Training Loss 0.5890 	Training Prec@1 80.002 	Training Prec@5 98.958 	Validation Loss 1.1872 	Validation Prec@1 65.620 	Validation Prec@5 96.990 

lr: 0.09956188874959684
TRAINING - Epoch: [50][0/391]	Time 0.914 (0.914)	Data 0.355 (0.355)	Loss 0.6040 (0.6040)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [50][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5327 (0.5762)	Prec@1 82.031 (80.631)	Prec@5 98.438 (98.871)
TRAINING - Epoch: [50][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5694 (0.5688)	Prec@1 80.469 (80.791)	Prec@5 98.438 (99.036)
TRAINING - Epoch: [50][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.5649 (0.5804)	Prec@1 78.125 (80.425)	Prec@5 99.219 (98.972)
EVALUATING - Epoch: [50][0/79]	Time 0.391 (0.391)	Data 0.368 (0.368)	Loss 0.6591 (0.6591)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:25

 Epoch: 51	Training Loss 0.5822 	Training Prec@1 80.390 	Training Prec@5 98.976 	Validation Loss 0.7330 	Validation Prec@1 76.390 	Validation Prec@5 98.500 

lr: 0.09954081031772875
TRAINING - Epoch: [51][0/391]	Time 0.902 (0.902)	Data 0.340 (0.340)	Loss 0.7043 (0.7043)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [51][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5934 (0.5729)	Prec@1 76.562 (80.407)	Prec@5 100.000 (99.041)
TRAINING - Epoch: [51][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5392 (0.5775)	Prec@1 83.594 (80.251)	Prec@5 98.438 (99.079)
TRAINING - Epoch: [51][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6669 (0.5744)	Prec@1 75.000 (80.391)	Prec@5 100.000 (99.097)
EVALUATING - Epoch: [51][0/79]	Time 0.360 (0.360)	Data 0.341 (0.341)	Loss 0.7837 (0.7837)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:39

 Epoch: 52	Training Loss 0.5731 	Training Prec@1 80.404 	Training Prec@5 99.056 	Validation Loss 0.9019 	Validation Prec@1 72.390 	Validation Prec@5 97.980 

lr: 0.09951923900288887
TRAINING - Epoch: [52][0/391]	Time 0.908 (0.908)	Data 0.356 (0.356)	Loss 0.5222 (0.5222)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [52][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.5132 (0.5441)	Prec@1 85.156 (81.644)	Prec@5 98.438 (99.072)
TRAINING - Epoch: [52][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5185 (0.5509)	Prec@1 84.375 (81.320)	Prec@5 99.219 (99.028)
TRAINING - Epoch: [52][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4824 (0.5628)	Prec@1 82.031 (80.866)	Prec@5 99.219 (99.003)
EVALUATING - Epoch: [52][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.5760 (0.5760)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:19:53

 Epoch: 53	Training Loss 0.5690 	Training Prec@1 80.730 	Training Prec@5 98.984 	Validation Loss 0.7416 	Validation Prec@1 76.490 	Validation Prec@5 98.460 

lr: 0.09949717501969077
TRAINING - Epoch: [53][0/391]	Time 0.926 (0.926)	Data 0.380 (0.380)	Loss 0.5756 (0.5756)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [53][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.5357 (0.5653)	Prec@1 78.906 (80.593)	Prec@5 100.000 (98.956)
TRAINING - Epoch: [53][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4902 (0.5640)	Prec@1 83.594 (80.725)	Prec@5 100.000 (98.951)
TRAINING - Epoch: [53][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.5291 (0.5672)	Prec@1 83.594 (80.612)	Prec@5 99.219 (98.975)
EVALUATING - Epoch: [53][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.8334 (0.8334)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:57

 Epoch: 54	Training Loss 0.5655 	Training Prec@1 80.708 	Training Prec@5 98.980 	Validation Loss 0.9952 	Validation Prec@1 70.230 	Validation Prec@5 96.740 

lr: 0.09947461858764975
TRAINING - Epoch: [54][0/391]	Time 0.904 (0.904)	Data 0.345 (0.345)	Loss 0.6318 (0.6318)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [54][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3832 (0.5628)	Prec@1 87.500 (80.554)	Prec@5 100.000 (99.095)
TRAINING - Epoch: [54][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6700 (0.5617)	Prec@1 80.469 (80.873)	Prec@5 97.656 (99.024)
TRAINING - Epoch: [54][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5546 (0.5625)	Prec@1 78.906 (80.881)	Prec@5 98.438 (99.029)
EVALUATING - Epoch: [54][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.5750 (0.5750)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:55

 Epoch: 55	Training Loss 0.5577 	Training Prec@1 81.002 	Training Prec@5 99.040 	Validation Loss 0.7677 	Validation Prec@1 75.350 	Validation Prec@5 98.350 

lr: 0.09945156993118039
TRAINING - Epoch: [55][0/391]	Time 0.907 (0.907)	Data 0.340 (0.340)	Loss 0.5270 (0.5270)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [55][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5361 (0.5663)	Prec@1 79.688 (81.072)	Prec@5 98.438 (98.902)
TRAINING - Epoch: [55][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5890 (0.5576)	Prec@1 82.812 (81.161)	Prec@5 99.219 (98.978)
TRAINING - Epoch: [55][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.6129 (0.5581)	Prec@1 78.125 (81.092)	Prec@5 100.000 (98.998)
EVALUATING - Epoch: [55][0/79]	Time 0.351 (0.351)	Data 0.328 (0.328)	Loss 0.7158 (0.7158)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:38

 Epoch: 56	Training Loss 0.5641 	Training Prec@1 80.814 	Training Prec@5 98.998 	Validation Loss 0.9343 	Validation Prec@1 71.240 	Validation Prec@5 97.790 

lr: 0.0994280292795944
TRAINING - Epoch: [56][0/391]	Time 0.919 (0.919)	Data 0.361 (0.361)	Loss 0.7302 (0.7302)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [56][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.7725 (0.5544)	Prec@1 76.562 (81.366)	Prec@5 97.656 (99.033)
TRAINING - Epoch: [56][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4855 (0.5671)	Prec@1 82.812 (80.869)	Prec@5 98.438 (99.098)
TRAINING - Epoch: [56][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.6659 (0.5602)	Prec@1 77.344 (80.964)	Prec@5 98.438 (99.107)
EVALUATING - Epoch: [56][0/79]	Time 0.362 (0.362)	Data 0.344 (0.344)	Loss 0.5984 (0.5984)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:35

 Epoch: 57	Training Loss 0.5618 	Training Prec@1 80.928 	Training Prec@5 99.116 	Validation Loss 0.7787 	Validation Prec@1 75.260 	Validation Prec@5 98.330 

lr: 0.09940399686709847
TRAINING - Epoch: [57][0/391]	Time 0.890 (0.890)	Data 0.338 (0.338)	Loss 0.7532 (0.7532)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [57][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4873 (0.5792)	Prec@1 84.375 (80.252)	Prec@5 100.000 (99.095)
TRAINING - Epoch: [57][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.7002 (0.5696)	Prec@1 77.344 (80.527)	Prec@5 99.219 (99.098)
TRAINING - Epoch: [57][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5381 (0.5669)	Prec@1 80.469 (80.560)	Prec@5 100.000 (99.128)
EVALUATING - Epoch: [57][0/79]	Time 0.356 (0.356)	Data 0.334 (0.334)	Loss 0.5908 (0.5908)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 58	Training Loss 0.5626 	Training Prec@1 80.734 	Training Prec@5 99.122 	Validation Loss 0.6819 	Validation Prec@1 78.120 	Validation Prec@5 98.510 

lr: 0.09937947293279176
TRAINING - Epoch: [58][0/391]	Time 0.896 (0.896)	Data 0.335 (0.335)	Loss 0.5626 (0.5626)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [58][100/391]	Time 0.061 (0.070)	Data 0.000 (0.003)	Loss 0.5538 (0.5387)	Prec@1 84.375 (81.644)	Prec@5 98.438 (99.180)
TRAINING - Epoch: [58][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.4842 (0.5535)	Prec@1 84.375 (81.254)	Prec@5 98.438 (99.110)
TRAINING - Epoch: [58][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4818 (0.5498)	Prec@1 82.812 (81.312)	Prec@5 99.219 (99.138)
EVALUATING - Epoch: [58][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.5244 (0.5244)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:16:17

 Epoch: 59	Training Loss 0.5548 	Training Prec@1 81.172 	Training Prec@5 99.102 	Validation Loss 0.6435 	Validation Prec@1 78.770 	Validation Prec@5 98.660 

lr: 0.09935445772066359
TRAINING - Epoch: [59][0/391]	Time 0.935 (0.935)	Data 0.339 (0.339)	Loss 0.7269 (0.7269)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [59][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5612 (0.5338)	Prec@1 78.906 (81.853)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [59][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6355 (0.5466)	Prec@1 76.562 (81.464)	Prec@5 98.438 (99.188)
TRAINING - Epoch: [59][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4868 (0.5422)	Prec@1 83.594 (81.556)	Prec@5 100.000 (99.208)
EVALUATING - Epoch: [59][0/79]	Time 0.361 (0.361)	Data 0.340 (0.340)	Loss 0.5594 (0.5594)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:58

 Epoch: 60	Training Loss 0.5465 	Training Prec@1 81.402 	Training Prec@5 99.174 	Validation Loss 0.7653 	Validation Prec@1 75.520 	Validation Prec@5 98.440 

lr: 0.09932895147959105
TRAINING - Epoch: [60][0/391]	Time 0.916 (0.916)	Data 0.350 (0.350)	Loss 0.6009 (0.6009)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [60][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4398 (0.5358)	Prec@1 86.719 (81.745)	Prec@5 98.438 (98.979)
TRAINING - Epoch: [60][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.5492 (0.5346)	Prec@1 82.812 (81.856)	Prec@5 99.219 (99.094)
TRAINING - Epoch: [60][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5906 (0.5417)	Prec@1 78.906 (81.743)	Prec@5 100.000 (99.071)
EVALUATING - Epoch: [60][0/79]	Time 0.356 (0.356)	Data 0.330 (0.330)	Loss 0.8772 (0.8772)	Prec@1 76.562 (76.562)	Prec@5 95.312 (95.312)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:59

 Epoch: 61	Training Loss 0.5436 	Training Prec@1 81.644 	Training Prec@5 99.044 	Validation Loss 1.0129 	Validation Prec@1 70.840 	Validation Prec@5 97.000 

lr: 0.09930295446333648
TRAINING - Epoch: [61][0/391]	Time 0.944 (0.944)	Data 0.375 (0.375)	Loss 0.7084 (0.7084)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [61][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5333 (0.5556)	Prec@1 83.594 (81.706)	Prec@5 96.875 (99.103)
TRAINING - Epoch: [61][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4826 (0.5488)	Prec@1 82.812 (81.646)	Prec@5 99.219 (99.137)
TRAINING - Epoch: [61][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.5407 (0.5489)	Prec@1 82.812 (81.543)	Prec@5 99.219 (99.149)
EVALUATING - Epoch: [61][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 1.3472 (1.3472)	Prec@1 66.406 (66.406)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:19:12

 Epoch: 62	Training Loss 0.5525 	Training Prec@1 81.320 	Training Prec@5 99.160 	Validation Loss 1.3008 	Validation Prec@1 63.910 	Validation Prec@5 96.590 

lr: 0.09927646693054495
TRAINING - Epoch: [62][0/391]	Time 0.944 (0.944)	Data 0.354 (0.354)	Loss 0.6942 (0.6942)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [62][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.7031 (0.5460)	Prec@1 77.344 (81.907)	Prec@5 99.219 (99.203)
TRAINING - Epoch: [62][200/391]	Time 0.066 (0.068)	Data 0.000 (0.002)	Loss 0.5745 (0.5415)	Prec@1 82.031 (81.849)	Prec@5 96.094 (99.133)
TRAINING - Epoch: [62][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7215 (0.5441)	Prec@1 77.344 (81.759)	Prec@5 99.219 (99.138)
EVALUATING - Epoch: [62][0/79]	Time 0.357 (0.357)	Data 0.333 (0.333)	Loss 0.7438 (0.7438)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:13

 Epoch: 63	Training Loss 0.5455 	Training Prec@1 81.640 	Training Prec@5 99.098 	Validation Loss 0.7610 	Validation Prec@1 76.140 	Validation Prec@5 98.490 

lr: 0.09924948914474171
TRAINING - Epoch: [63][0/391]	Time 0.946 (0.946)	Data 0.369 (0.369)	Loss 0.5895 (0.5895)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [63][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.5639 (0.5316)	Prec@1 78.125 (81.985)	Prec@5 98.438 (99.095)
TRAINING - Epoch: [63][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6113 (0.5310)	Prec@1 84.375 (81.814)	Prec@5 100.000 (99.164)
TRAINING - Epoch: [63][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5857 (0.5423)	Prec@1 81.250 (81.442)	Prec@5 98.438 (99.086)
EVALUATING - Epoch: [63][0/79]	Time 0.367 (0.367)	Data 0.346 (0.346)	Loss 0.8372 (0.8372)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:27

 Epoch: 64	Training Loss 0.5418 	Training Prec@1 81.552 	Training Prec@5 99.082 	Validation Loss 0.8117 	Validation Prec@1 74.590 	Validation Prec@5 98.370 

lr: 0.09922202137432953
TRAINING - Epoch: [64][0/391]	Time 0.918 (0.918)	Data 0.367 (0.367)	Loss 0.8085 (0.8085)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [64][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.7793 (0.5336)	Prec@1 77.344 (81.776)	Prec@5 98.438 (99.095)
TRAINING - Epoch: [64][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3982 (0.5291)	Prec@1 85.938 (82.062)	Prec@5 100.000 (99.149)
TRAINING - Epoch: [64][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4095 (0.5438)	Prec@1 82.031 (81.611)	Prec@5 100.000 (99.094)
EVALUATING - Epoch: [64][0/79]	Time 0.347 (0.347)	Data 0.324 (0.324)	Loss 0.7842 (0.7842)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:40

 Epoch: 65	Training Loss 0.5448 	Training Prec@1 81.610 	Training Prec@5 99.116 	Validation Loss 0.8050 	Validation Prec@1 75.180 	Validation Prec@5 98.280 

lr: 0.09919406389258606
TRAINING - Epoch: [65][0/391]	Time 0.911 (0.911)	Data 0.346 (0.346)	Loss 0.8874 (0.8874)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [65][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5126 (0.5396)	Prec@1 85.156 (81.683)	Prec@5 98.438 (99.134)
TRAINING - Epoch: [65][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.8708 (0.5349)	Prec@1 75.000 (81.930)	Prec@5 97.656 (99.149)
TRAINING - Epoch: [65][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5370 (0.5345)	Prec@1 83.594 (81.847)	Prec@5 100.000 (99.193)
EVALUATING - Epoch: [65][0/79]	Time 0.359 (0.359)	Data 0.338 (0.338)	Loss 0.7378 (0.7378)	Prec@1 75.000 (75.000)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:29

 Epoch: 66	Training Loss 0.5308 	Training Prec@1 81.948 	Training Prec@5 99.158 	Validation Loss 0.8566 	Validation Prec@1 75.060 	Validation Prec@5 96.740 

lr: 0.09916561697766112
TRAINING - Epoch: [66][0/391]	Time 0.915 (0.915)	Data 0.357 (0.357)	Loss 0.5605 (0.5605)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [66][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5847 (0.5370)	Prec@1 78.125 (81.528)	Prec@5 99.219 (99.049)
TRAINING - Epoch: [66][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4559 (0.5332)	Prec@1 85.156 (81.775)	Prec@5 100.000 (99.106)
TRAINING - Epoch: [66][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5821 (0.5319)	Prec@1 83.594 (81.883)	Prec@5 97.656 (99.094)
EVALUATING - Epoch: [66][0/79]	Time 0.339 (0.339)	Data 0.319 (0.319)	Loss 0.6740 (0.6740)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:38

 Epoch: 67	Training Loss 0.5321 	Training Prec@1 81.860 	Training Prec@5 99.112 	Validation Loss 0.8383 	Validation Prec@1 74.760 	Validation Prec@5 97.940 

lr: 0.09913668091257388
TRAINING - Epoch: [67][0/391]	Time 0.923 (0.923)	Data 0.352 (0.352)	Loss 0.4393 (0.4393)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [67][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4969 (0.5261)	Prec@1 82.031 (82.209)	Prec@5 100.000 (99.172)
TRAINING - Epoch: [67][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4519 (0.5279)	Prec@1 84.375 (82.035)	Prec@5 100.000 (99.234)
TRAINING - Epoch: [67][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4255 (0.5271)	Prec@1 81.250 (81.886)	Prec@5 100.000 (99.219)
EVALUATING - Epoch: [67][0/79]	Time 0.378 (0.378)	Data 0.355 (0.355)	Loss 0.5954 (0.5954)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 68	Training Loss 0.5274 	Training Prec@1 81.972 	Training Prec@5 99.232 	Validation Loss 0.9607 	Validation Prec@1 71.700 	Validation Prec@5 98.000 

lr: 0.09910725598521011
TRAINING - Epoch: [68][0/391]	Time 0.937 (0.937)	Data 0.374 (0.374)	Loss 0.6428 (0.6428)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [68][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4286 (0.5095)	Prec@1 88.281 (83.106)	Prec@5 99.219 (99.188)
TRAINING - Epoch: [68][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5882 (0.5205)	Prec@1 81.250 (82.463)	Prec@5 100.000 (99.219)
TRAINING - Epoch: [68][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5282 (0.5211)	Prec@1 79.688 (82.410)	Prec@5 99.219 (99.180)
EVALUATING - Epoch: [68][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.5108 (0.5108)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 69	Training Loss 0.5228 	Training Prec@1 82.288 	Training Prec@5 99.200 	Validation Loss 0.6685 	Validation Prec@1 78.260 	Validation Prec@5 98.820 

lr: 0.09907734248831929
TRAINING - Epoch: [69][0/391]	Time 0.936 (0.936)	Data 0.374 (0.374)	Loss 0.3616 (0.3616)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [69][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5243 (0.5123)	Prec@1 82.812 (82.441)	Prec@5 100.000 (99.381)
TRAINING - Epoch: [69][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4916 (0.5136)	Prec@1 82.812 (82.389)	Prec@5 98.438 (99.289)
TRAINING - Epoch: [69][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4657 (0.5226)	Prec@1 86.719 (82.125)	Prec@5 100.000 (99.234)
EVALUATING - Epoch: [69][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.5321 (0.5321)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 70	Training Loss 0.5275 	Training Prec@1 81.964 	Training Prec@5 99.214 	Validation Loss 0.6732 	Validation Prec@1 78.790 	Validation Prec@5 98.840 

lr: 0.09904694071951164
TRAINING - Epoch: [70][0/391]	Time 0.930 (0.930)	Data 0.368 (0.368)	Loss 0.3841 (0.3841)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [70][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4018 (0.5222)	Prec@1 87.500 (82.194)	Prec@5 99.219 (99.234)
TRAINING - Epoch: [70][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5274 (0.5182)	Prec@1 81.250 (82.319)	Prec@5 100.000 (99.184)
TRAINING - Epoch: [70][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.7933 (0.5169)	Prec@1 72.656 (82.343)	Prec@5 98.438 (99.193)
EVALUATING - Epoch: [70][0/79]	Time 0.387 (0.387)	Data 0.365 (0.365)	Loss 0.7533 (0.7533)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:41

 Epoch: 71	Training Loss 0.5200 	Training Prec@1 82.344 	Training Prec@5 99.168 	Validation Loss 0.7209 	Validation Prec@1 76.550 	Validation Prec@5 98.430 

lr: 0.09901605098125527
TRAINING - Epoch: [71][0/391]	Time 0.927 (0.927)	Data 0.343 (0.343)	Loss 0.6086 (0.6086)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [71][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.4454 (0.5222)	Prec@1 85.938 (82.410)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [71][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6348 (0.5256)	Prec@1 79.688 (82.035)	Prec@5 97.656 (99.238)
TRAINING - Epoch: [71][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5606 (0.5317)	Prec@1 80.469 (81.831)	Prec@5 100.000 (99.185)
EVALUATING - Epoch: [71][0/79]	Time 0.395 (0.395)	Data 0.373 (0.373)	Loss 0.6140 (0.6140)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:01

 Epoch: 72	Training Loss 0.5363 	Training Prec@1 81.754 	Training Prec@5 99.158 	Validation Loss 0.8582 	Validation Prec@1 74.500 	Validation Prec@5 97.910 

lr: 0.09898467358087308
TRAINING - Epoch: [72][0/391]	Time 0.913 (0.913)	Data 0.343 (0.343)	Loss 0.3270 (0.3270)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [72][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.4531 (0.5457)	Prec@1 81.250 (81.691)	Prec@5 100.000 (99.041)
TRAINING - Epoch: [72][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.3859 (0.5328)	Prec@1 85.156 (81.930)	Prec@5 99.219 (99.075)
TRAINING - Epoch: [72][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5349 (0.5288)	Prec@1 82.031 (82.078)	Prec@5 100.000 (99.097)
EVALUATING - Epoch: [72][0/79]	Time 0.378 (0.378)	Data 0.354 (0.354)	Loss 0.6762 (0.6762)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:18:57

 Epoch: 73	Training Loss 0.5262 	Training Prec@1 82.158 	Training Prec@5 99.138 	Validation Loss 0.6452 	Validation Prec@1 78.980 	Validation Prec@5 98.840 

lr: 0.09895280883053975
TRAINING - Epoch: [73][0/391]	Time 0.930 (0.930)	Data 0.358 (0.358)	Loss 0.5305 (0.5305)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [73][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5783 (0.5120)	Prec@1 84.375 (82.843)	Prec@5 99.219 (99.196)
TRAINING - Epoch: [73][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3671 (0.5004)	Prec@1 86.719 (83.065)	Prec@5 99.219 (99.195)
TRAINING - Epoch: [73][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5014 (0.5073)	Prec@1 79.688 (82.711)	Prec@5 100.000 (99.195)
EVALUATING - Epoch: [73][0/79]	Time 0.350 (0.350)	Data 0.328 (0.328)	Loss 0.5155 (0.5155)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:39

 Epoch: 74	Training Loss 0.5086 	Training Prec@1 82.708 	Training Prec@5 99.170 	Validation Loss 0.6097 	Validation Prec@1 80.320 	Validation Prec@5 98.760 

lr: 0.09892045704727861
TRAINING - Epoch: [74][0/391]	Time 0.936 (0.936)	Data 0.339 (0.339)	Loss 0.4853 (0.4853)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [74][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.6416 (0.4989)	Prec@1 78.125 (82.874)	Prec@5 98.438 (99.087)
TRAINING - Epoch: [74][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4955 (0.5084)	Prec@1 83.594 (82.432)	Prec@5 99.219 (99.157)
TRAINING - Epoch: [74][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5181 (0.5119)	Prec@1 82.812 (82.530)	Prec@5 99.219 (99.154)
EVALUATING - Epoch: [74][0/79]	Time 0.373 (0.373)	Data 0.349 (0.349)	Loss 0.6399 (0.6399)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:04

 Epoch: 75	Training Loss 0.5193 	Training Prec@1 82.256 	Training Prec@5 99.172 	Validation Loss 0.7528 	Validation Prec@1 76.960 	Validation Prec@5 98.060 

lr: 0.09888761855295852
TRAINING - Epoch: [75][0/391]	Time 0.918 (0.918)	Data 0.345 (0.345)	Loss 0.4844 (0.4844)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [75][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4814 (0.5176)	Prec@1 83.594 (82.511)	Prec@5 99.219 (99.265)
TRAINING - Epoch: [75][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5856 (0.5188)	Prec@1 83.594 (82.533)	Prec@5 98.438 (99.207)
TRAINING - Epoch: [75][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.6613 (0.5196)	Prec@1 78.125 (82.467)	Prec@5 98.438 (99.206)
EVALUATING - Epoch: [75][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.6079 (0.6079)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:51

 Epoch: 76	Training Loss 0.5181 	Training Prec@1 82.462 	Training Prec@5 99.244 	Validation Loss 0.7222 	Validation Prec@1 77.580 	Validation Prec@5 98.200 

lr: 0.0988542936742906
TRAINING - Epoch: [76][0/391]	Time 0.895 (0.895)	Data 0.338 (0.338)	Loss 0.4776 (0.4776)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [76][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4628 (0.4955)	Prec@1 85.156 (82.890)	Prec@5 99.219 (99.196)
TRAINING - Epoch: [76][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5249 (0.5018)	Prec@1 79.688 (82.871)	Prec@5 98.438 (99.160)
TRAINING - Epoch: [76][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.5311 (0.5064)	Prec@1 81.250 (82.672)	Prec@5 100.000 (99.193)
EVALUATING - Epoch: [76][0/79]	Time 0.370 (0.370)	Data 0.349 (0.349)	Loss 0.7707 (0.7707)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:23

 Epoch: 77	Training Loss 0.5118 	Training Prec@1 82.558 	Training Prec@5 99.204 	Validation Loss 0.8735 	Validation Prec@1 73.610 	Validation Prec@5 97.810 

lr: 0.09882048274282504
TRAINING - Epoch: [77][0/391]	Time 0.917 (0.917)	Data 0.352 (0.352)	Loss 0.5865 (0.5865)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [77][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3534 (0.5064)	Prec@1 87.500 (82.379)	Prec@5 100.000 (99.165)
TRAINING - Epoch: [77][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4321 (0.5139)	Prec@1 87.500 (82.369)	Prec@5 99.219 (99.254)
TRAINING - Epoch: [77][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5879 (0.5189)	Prec@1 78.906 (82.322)	Prec@5 100.000 (99.276)
EVALUATING - Epoch: [77][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.7118 (0.7118)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:56

 Epoch: 78	Training Loss 0.5192 	Training Prec@1 82.280 	Training Prec@5 99.278 	Validation Loss 0.8258 	Validation Prec@1 75.050 	Validation Prec@5 97.390 

lr: 0.0987861860949478
TRAINING - Epoch: [78][0/391]	Time 0.956 (0.956)	Data 0.351 (0.351)	Loss 0.4511 (0.4511)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [78][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.5932 (0.5025)	Prec@1 79.688 (83.052)	Prec@5 98.438 (99.327)
TRAINING - Epoch: [78][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.5011 (0.5106)	Prec@1 78.906 (82.700)	Prec@5 98.438 (99.199)
TRAINING - Epoch: [78][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5721 (0.5131)	Prec@1 82.031 (82.626)	Prec@5 98.438 (99.206)
EVALUATING - Epoch: [78][0/79]	Time 0.351 (0.351)	Data 0.332 (0.332)	Loss 0.6948 (0.6948)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:49

 Epoch: 79	Training Loss 0.5141 	Training Prec@1 82.612 	Training Prec@5 99.176 	Validation Loss 0.7947 	Validation Prec@1 75.730 	Validation Prec@5 98.170 

lr: 0.09875140407187721
TRAINING - Epoch: [79][0/391]	Time 0.929 (0.929)	Data 0.354 (0.354)	Loss 0.4589 (0.4589)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [79][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4851 (0.4992)	Prec@1 82.812 (82.851)	Prec@5 99.219 (99.172)
TRAINING - Epoch: [79][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4570 (0.5035)	Prec@1 85.156 (83.022)	Prec@5 100.000 (99.234)
TRAINING - Epoch: [79][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4713 (0.5179)	Prec@1 84.375 (82.628)	Prec@5 100.000 (99.193)
EVALUATING - Epoch: [79][0/79]	Time 0.391 (0.391)	Data 0.368 (0.368)	Loss 0.7353 (0.7353)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:53

 Epoch: 80	Training Loss 0.5208 	Training Prec@1 82.516 	Training Prec@5 99.172 	Validation Loss 0.8662 	Validation Prec@1 72.940 	Validation Prec@5 98.310 

lr: 0.09871613701966067
TRAINING - Epoch: [80][0/391]	Time 0.906 (0.906)	Data 0.346 (0.346)	Loss 0.5276 (0.5276)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [80][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4511 (0.5287)	Prec@1 86.719 (82.325)	Prec@5 98.438 (99.203)
TRAINING - Epoch: [80][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5193 (0.5277)	Prec@1 83.594 (82.389)	Prec@5 100.000 (99.227)
TRAINING - Epoch: [80][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5280 (0.5283)	Prec@1 81.250 (82.244)	Prec@5 100.000 (99.206)
EVALUATING - Epoch: [80][0/79]	Time 0.345 (0.345)	Data 0.321 (0.321)	Loss 0.6098 (0.6098)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:52

 Epoch: 81	Training Loss 0.5245 	Training Prec@1 82.440 	Training Prec@5 99.218 	Validation Loss 0.6958 	Validation Prec@1 77.600 	Validation Prec@5 98.670 

lr: 0.0986803852891711
TRAINING - Epoch: [81][0/391]	Time 0.929 (0.929)	Data 0.367 (0.367)	Loss 0.4040 (0.4040)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [81][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6903 (0.4957)	Prec@1 76.562 (83.207)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [81][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4463 (0.5091)	Prec@1 87.500 (82.692)	Prec@5 99.219 (99.254)
TRAINING - Epoch: [81][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5993 (0.5148)	Prec@1 78.906 (82.662)	Prec@5 98.438 (99.227)
EVALUATING - Epoch: [81][0/79]	Time 0.360 (0.360)	Data 0.339 (0.339)	Loss 0.5433 (0.5433)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:58

 Epoch: 82	Training Loss 0.5184 	Training Prec@1 82.474 	Training Prec@5 99.196 	Validation Loss 0.7397 	Validation Prec@1 77.760 	Validation Prec@5 98.120 

lr: 0.0986441492361035
TRAINING - Epoch: [82][0/391]	Time 0.913 (0.913)	Data 0.342 (0.342)	Loss 0.5564 (0.5564)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [82][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3630 (0.5173)	Prec@1 87.500 (82.550)	Prec@5 99.219 (99.118)
TRAINING - Epoch: [82][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6109 (0.5211)	Prec@1 78.906 (82.257)	Prec@5 100.000 (99.118)
TRAINING - Epoch: [82][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.6399 (0.5194)	Prec@1 75.781 (82.345)	Prec@5 99.219 (99.185)
EVALUATING - Epoch: [82][0/79]	Time 0.343 (0.343)	Data 0.324 (0.324)	Loss 0.8483 (0.8483)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:14

 Epoch: 83	Training Loss 0.5216 	Training Prec@1 82.210 	Training Prec@5 99.190 	Validation Loss 0.8625 	Validation Prec@1 73.910 	Validation Prec@5 97.760 

lr: 0.09860742922097143
TRAINING - Epoch: [83][0/391]	Time 0.929 (0.929)	Data 0.344 (0.344)	Loss 0.5600 (0.5600)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [83][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5338 (0.4999)	Prec@1 82.031 (83.106)	Prec@5 100.000 (99.281)
TRAINING - Epoch: [83][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5787 (0.5020)	Prec@1 78.906 (83.019)	Prec@5 97.656 (99.242)
TRAINING - Epoch: [83][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.5039 (0.5152)	Prec@1 84.375 (82.613)	Prec@5 99.219 (99.211)
EVALUATING - Epoch: [83][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.5082 (0.5082)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:17

 Epoch: 84	Training Loss 0.5173 	Training Prec@1 82.458 	Training Prec@5 99.192 	Validation Loss 0.6341 	Validation Prec@1 79.310 	Validation Prec@5 98.540 

lr: 0.0985702256091034
TRAINING - Epoch: [84][0/391]	Time 0.898 (0.898)	Data 0.336 (0.336)	Loss 0.4684 (0.4684)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [84][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4099 (0.5066)	Prec@1 86.719 (82.727)	Prec@5 99.219 (99.180)
TRAINING - Epoch: [84][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5562 (0.5018)	Prec@1 79.688 (82.828)	Prec@5 100.000 (99.234)
TRAINING - Epoch: [84][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5174 (0.5094)	Prec@1 83.594 (82.579)	Prec@5 99.219 (99.177)
EVALUATING - Epoch: [84][0/79]	Time 0.326 (0.326)	Data 0.306 (0.306)	Loss 0.6973 (0.6973)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:36

 Epoch: 85	Training Loss 0.5144 	Training Prec@1 82.376 	Training Prec@5 99.172 	Validation Loss 0.7883 	Validation Prec@1 74.970 	Validation Prec@5 98.050 

lr: 0.09853253877063924
TRAINING - Epoch: [85][0/391]	Time 0.943 (0.943)	Data 0.353 (0.353)	Loss 0.6761 (0.6761)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [85][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4025 (0.5046)	Prec@1 86.719 (82.712)	Prec@5 100.000 (99.250)
TRAINING - Epoch: [85][200/391]	Time 0.066 (0.068)	Data 0.000 (0.002)	Loss 0.5682 (0.5038)	Prec@1 81.250 (82.832)	Prec@5 98.438 (99.234)
TRAINING - Epoch: [85][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.4035 (0.5076)	Prec@1 85.156 (82.805)	Prec@5 100.000 (99.234)
EVALUATING - Epoch: [85][0/79]	Time 0.351 (0.351)	Data 0.328 (0.328)	Loss 0.6164 (0.6164)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:12

 Epoch: 86	Training Loss 0.5137 	Training Prec@1 82.608 	Training Prec@5 99.196 	Validation Loss 0.7400 	Validation Prec@1 76.230 	Validation Prec@5 98.740 

lr: 0.09849436908052638
TRAINING - Epoch: [86][0/391]	Time 0.908 (0.908)	Data 0.346 (0.346)	Loss 0.4242 (0.4242)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [86][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.6623 (0.5229)	Prec@1 77.344 (81.985)	Prec@5 99.219 (99.165)
TRAINING - Epoch: [86][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3389 (0.5381)	Prec@1 87.500 (81.740)	Prec@5 100.000 (99.137)
TRAINING - Epoch: [86][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5720 (0.5317)	Prec@1 78.125 (82.073)	Prec@5 99.219 (99.151)
EVALUATING - Epoch: [86][0/79]	Time 0.369 (0.369)	Data 0.346 (0.346)	Loss 0.7352 (0.7352)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:57

 Epoch: 87	Training Loss 0.5305 	Training Prec@1 82.056 	Training Prec@5 99.156 	Validation Loss 0.8660 	Validation Prec@1 73.690 	Validation Prec@5 98.080 

lr: 0.09845571691851622
TRAINING - Epoch: [87][0/391]	Time 0.918 (0.918)	Data 0.346 (0.346)	Loss 0.5524 (0.5524)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [87][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4231 (0.5032)	Prec@1 84.375 (83.037)	Prec@5 100.000 (99.273)
TRAINING - Epoch: [87][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.5113 (0.5082)	Prec@1 79.688 (82.754)	Prec@5 99.219 (99.227)
TRAINING - Epoch: [87][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4970 (0.5120)	Prec@1 84.375 (82.665)	Prec@5 99.219 (99.198)
EVALUATING - Epoch: [87][0/79]	Time 0.368 (0.368)	Data 0.343 (0.343)	Loss 0.6879 (0.6879)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:13

 Epoch: 88	Training Loss 0.5077 	Training Prec@1 82.774 	Training Prec@5 99.190 	Validation Loss 0.7285 	Validation Prec@1 77.170 	Validation Prec@5 98.690 

lr: 0.09841658266916022
TRAINING - Epoch: [88][0/391]	Time 0.933 (0.933)	Data 0.339 (0.339)	Loss 0.5522 (0.5522)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [88][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5101 (0.4811)	Prec@1 81.250 (83.710)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [88][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5749 (0.4929)	Prec@1 78.125 (83.147)	Prec@5 98.438 (99.296)
TRAINING - Epoch: [88][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6240 (0.4973)	Prec@1 80.469 (83.134)	Prec@5 99.219 (99.286)
EVALUATING - Epoch: [88][0/79]	Time 0.349 (0.349)	Data 0.326 (0.326)	Loss 0.4679 (0.4679)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 89	Training Loss 0.4998 	Training Prec@1 83.084 	Training Prec@5 99.252 	Validation Loss 0.6470 	Validation Prec@1 78.940 	Validation Prec@5 98.630 

lr: 0.0983769667218062
TRAINING - Epoch: [89][0/391]	Time 0.920 (0.920)	Data 0.360 (0.360)	Loss 0.4033 (0.4033)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [89][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6200 (0.4959)	Prec@1 79.688 (83.114)	Prec@5 98.438 (99.335)
TRAINING - Epoch: [89][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5273 (0.5005)	Prec@1 81.250 (83.081)	Prec@5 98.438 (99.296)
TRAINING - Epoch: [89][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5850 (0.5019)	Prec@1 79.688 (82.914)	Prec@5 98.438 (99.281)
EVALUATING - Epoch: [89][0/79]	Time 0.360 (0.360)	Data 0.335 (0.335)	Loss 0.7806 (0.7806)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:23

 Epoch: 90	Training Loss 0.5013 	Training Prec@1 82.862 	Training Prec@5 99.280 	Validation Loss 0.8346 	Validation Prec@1 75.250 	Validation Prec@5 98.290 

lr: 0.09833686947059436
TRAINING - Epoch: [90][0/391]	Time 0.918 (0.918)	Data 0.343 (0.343)	Loss 0.5914 (0.5914)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [90][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5484 (0.4735)	Prec@1 83.594 (84.073)	Prec@5 96.875 (99.281)
TRAINING - Epoch: [90][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4599 (0.4819)	Prec@1 85.938 (83.804)	Prec@5 98.438 (99.273)
TRAINING - Epoch: [90][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4684 (0.4905)	Prec@1 83.594 (83.441)	Prec@5 99.219 (99.250)
EVALUATING - Epoch: [90][0/79]	Time 0.348 (0.348)	Data 0.328 (0.328)	Loss 0.6934 (0.6934)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:44

 Epoch: 91	Training Loss 0.4993 	Training Prec@1 83.122 	Training Prec@5 99.210 	Validation Loss 0.7590 	Validation Prec@1 76.840 	Validation Prec@5 98.430 

lr: 0.09829629131445343
TRAINING - Epoch: [91][0/391]	Time 0.947 (0.947)	Data 0.345 (0.345)	Loss 0.3840 (0.3840)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [91][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.5246 (0.4902)	Prec@1 80.469 (83.571)	Prec@5 99.219 (99.288)
TRAINING - Epoch: [91][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.5559 (0.4951)	Prec@1 78.906 (83.322)	Prec@5 100.000 (99.296)
TRAINING - Epoch: [91][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5390 (0.4991)	Prec@1 79.688 (83.233)	Prec@5 98.438 (99.333)
EVALUATING - Epoch: [91][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.5802 (0.5802)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 92	Training Loss 0.5033 	Training Prec@1 83.050 	Training Prec@5 99.328 	Validation Loss 0.6427 	Validation Prec@1 78.900 	Validation Prec@5 98.870 

lr: 0.09825523265709668
TRAINING - Epoch: [92][0/391]	Time 0.893 (0.893)	Data 0.341 (0.341)	Loss 0.5281 (0.5281)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [92][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4364 (0.4885)	Prec@1 85.156 (83.230)	Prec@5 99.219 (99.273)
TRAINING - Epoch: [92][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.7139 (0.4919)	Prec@1 81.250 (83.298)	Prec@5 99.219 (99.273)
TRAINING - Epoch: [92][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4532 (0.4996)	Prec@1 85.938 (83.038)	Prec@5 99.219 (99.273)
EVALUATING - Epoch: [92][0/79]	Time 0.371 (0.371)	Data 0.351 (0.351)	Loss 0.6035 (0.6035)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:29

 Epoch: 93	Training Loss 0.5037 	Training Prec@1 82.902 	Training Prec@5 99.258 	Validation Loss 0.7814 	Validation Prec@1 75.870 	Validation Prec@5 98.380 

lr: 0.09821369390701791
TRAINING - Epoch: [93][0/391]	Time 0.907 (0.907)	Data 0.336 (0.336)	Loss 0.4829 (0.4829)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [93][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5754 (0.4966)	Prec@1 79.688 (83.029)	Prec@5 99.219 (99.381)
TRAINING - Epoch: [93][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4577 (0.4971)	Prec@1 88.281 (83.022)	Prec@5 100.000 (99.269)
TRAINING - Epoch: [93][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5415 (0.5009)	Prec@1 79.688 (82.888)	Prec@5 99.219 (99.227)
EVALUATING - Epoch: [93][0/79]	Time 0.356 (0.356)	Data 0.335 (0.335)	Loss 0.4984 (0.4984)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:05

 Epoch: 94	Training Loss 0.4981 	Training Prec@1 82.978 	Training Prec@5 99.230 	Validation Loss 0.6639 	Validation Prec@1 78.640 	Validation Prec@5 98.720 

lr: 0.09817167547748731
TRAINING - Epoch: [94][0/391]	Time 0.929 (0.929)	Data 0.373 (0.373)	Loss 0.3130 (0.3130)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [94][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.5550 (0.4751)	Prec@1 79.688 (83.718)	Prec@5 98.438 (99.319)
TRAINING - Epoch: [94][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4757 (0.4873)	Prec@1 85.156 (83.462)	Prec@5 99.219 (99.246)
TRAINING - Epoch: [94][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.7105 (0.4897)	Prec@1 78.125 (83.376)	Prec@5 96.875 (99.242)
EVALUATING - Epoch: [94][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.6922 (0.6922)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:17:55

 Epoch: 95	Training Loss 0.4917 	Training Prec@1 83.240 	Training Prec@5 99.230 	Validation Loss 0.7860 	Validation Prec@1 74.780 	Validation Prec@5 98.240 

lr: 0.0981291777865475
TRAINING - Epoch: [95][0/391]	Time 0.893 (0.893)	Data 0.336 (0.336)	Loss 0.4905 (0.4905)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [95][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3638 (0.4919)	Prec@1 85.156 (83.462)	Prec@5 100.000 (99.366)
TRAINING - Epoch: [95][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3645 (0.5032)	Prec@1 87.500 (82.879)	Prec@5 99.219 (99.316)
TRAINING - Epoch: [95][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4812 (0.5031)	Prec@1 85.938 (82.971)	Prec@5 98.438 (99.289)
EVALUATING - Epoch: [95][0/79]	Time 0.344 (0.344)	Data 0.320 (0.320)	Loss 0.8363 (0.8363)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:16

 Epoch: 96	Training Loss 0.5063 	Training Prec@1 82.892 	Training Prec@5 99.252 	Validation Loss 0.8096 	Validation Prec@1 74.730 	Validation Prec@5 98.380 

lr: 0.09808620125700927
TRAINING - Epoch: [96][0/391]	Time 0.933 (0.933)	Data 0.362 (0.362)	Loss 0.3913 (0.3913)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [96][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.4862 (0.5153)	Prec@1 85.156 (82.596)	Prec@5 96.875 (99.110)
TRAINING - Epoch: [96][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4634 (0.5123)	Prec@1 82.812 (82.696)	Prec@5 100.000 (99.157)
TRAINING - Epoch: [96][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5364 (0.5081)	Prec@1 85.156 (82.729)	Prec@5 98.438 (99.206)
EVALUATING - Epoch: [96][0/79]	Time 0.401 (0.401)	Data 0.380 (0.380)	Loss 0.5179 (0.5179)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:38

 Epoch: 97	Training Loss 0.5070 	Training Prec@1 82.722 	Training Prec@5 99.242 	Validation Loss 0.7761 	Validation Prec@1 77.170 	Validation Prec@5 97.970 

lr: 0.09804274631644733
TRAINING - Epoch: [97][0/391]	Time 0.908 (0.908)	Data 0.349 (0.349)	Loss 0.5469 (0.5469)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [97][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.6045 (0.5082)	Prec@1 81.250 (82.990)	Prec@5 98.438 (99.273)
TRAINING - Epoch: [97][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6205 (0.5004)	Prec@1 82.031 (83.166)	Prec@5 96.094 (99.223)
TRAINING - Epoch: [97][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4789 (0.4950)	Prec@1 82.812 (83.186)	Prec@5 100.000 (99.229)
EVALUATING - Epoch: [97][0/79]	Time 0.348 (0.348)	Data 0.323 (0.323)	Loss 0.8073 (0.8073)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:40

 Epoch: 98	Training Loss 0.4990 	Training Prec@1 83.052 	Training Prec@5 99.248 	Validation Loss 0.8122 	Validation Prec@1 75.510 	Validation Prec@5 98.160 

lr: 0.09799881339719617
TRAINING - Epoch: [98][0/391]	Time 0.943 (0.943)	Data 0.376 (0.376)	Loss 0.5675 (0.5675)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [98][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5366 (0.4835)	Prec@1 82.031 (83.625)	Prec@5 97.656 (99.327)
TRAINING - Epoch: [98][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6969 (0.4904)	Prec@1 77.344 (83.512)	Prec@5 96.094 (99.269)
TRAINING - Epoch: [98][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3527 (0.4887)	Prec@1 87.500 (83.531)	Prec@5 100.000 (99.260)
EVALUATING - Epoch: [98][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.7468 (0.7468)	Prec@1 75.000 (75.000)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:10

 Epoch: 99	Training Loss 0.4923 	Training Prec@1 83.438 	Training Prec@5 99.280 	Validation Loss 0.8113 	Validation Prec@1 75.360 	Validation Prec@5 98.030 

lr: 0.0979544029363457
TRAINING - Epoch: [99][0/391]	Time 0.897 (0.897)	Data 0.347 (0.347)	Loss 0.4538 (0.4538)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [99][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2964 (0.4964)	Prec@1 89.062 (83.045)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [99][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4498 (0.5013)	Prec@1 85.156 (82.727)	Prec@5 100.000 (99.378)
TRAINING - Epoch: [99][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4793 (0.4941)	Prec@1 83.594 (82.924)	Prec@5 99.219 (99.364)
EVALUATING - Epoch: [99][0/79]	Time 0.351 (0.351)	Data 0.329 (0.329)	Loss 0.8897 (0.8897)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:53

 Epoch: 100	Training Loss 0.4940 	Training Prec@1 82.984 	Training Prec@5 99.342 	Validation Loss 0.9259 	Validation Prec@1 73.840 	Validation Prec@5 97.740 

lr: 0.09790951537573689
TRAINING - Epoch: [100][0/391]	Time 0.905 (0.905)	Data 0.332 (0.332)	Loss 0.3720 (0.3720)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [100][100/391]	Time 0.064 (0.071)	Data 0.000 (0.003)	Loss 0.5944 (0.4961)	Prec@1 77.344 (82.890)	Prec@5 98.438 (99.281)
TRAINING - Epoch: [100][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4656 (0.4910)	Prec@1 82.812 (83.123)	Prec@5 100.000 (99.254)
TRAINING - Epoch: [100][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5087 (0.4942)	Prec@1 85.156 (83.202)	Prec@5 99.219 (99.276)
EVALUATING - Epoch: [100][0/79]	Time 0.355 (0.355)	Data 0.335 (0.335)	Loss 0.6255 (0.6255)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:39

 Epoch: 101	Training Loss 0.4933 	Training Prec@1 83.242 	Training Prec@5 99.288 	Validation Loss 0.8538 	Validation Prec@1 74.970 	Validation Prec@5 98.460 

lr: 0.09786415116195736
TRAINING - Epoch: [101][0/391]	Time 0.894 (0.894)	Data 0.335 (0.335)	Loss 0.4008 (0.4008)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [101][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.6020 (0.5075)	Prec@1 82.031 (82.898)	Prec@5 99.219 (99.273)
TRAINING - Epoch: [101][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5408 (0.4949)	Prec@1 81.250 (83.263)	Prec@5 97.656 (99.300)
TRAINING - Epoch: [101][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.5187 (0.4995)	Prec@1 85.156 (83.098)	Prec@5 99.219 (99.276)
EVALUATING - Epoch: [101][0/79]	Time 0.346 (0.346)	Data 0.322 (0.322)	Loss 0.5256 (0.5256)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:45

 Epoch: 102	Training Loss 0.4980 	Training Prec@1 83.142 	Training Prec@5 99.262 	Validation Loss 0.6593 	Validation Prec@1 79.050 	Validation Prec@5 98.790 

lr: 0.09781831074633705
TRAINING - Epoch: [102][0/391]	Time 0.938 (0.938)	Data 0.354 (0.354)	Loss 0.6430 (0.6430)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [102][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.5394 (0.4773)	Prec@1 85.156 (83.872)	Prec@5 98.438 (99.404)
TRAINING - Epoch: [102][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4301 (0.4921)	Prec@1 85.938 (83.462)	Prec@5 100.000 (99.351)
TRAINING - Epoch: [102][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5151 (0.5015)	Prec@1 82.031 (83.080)	Prec@5 99.219 (99.289)
EVALUATING - Epoch: [102][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.7442 (0.7442)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:31

 Epoch: 103	Training Loss 0.5013 	Training Prec@1 83.130 	Training Prec@5 99.268 	Validation Loss 0.7675 	Validation Prec@1 75.670 	Validation Prec@5 98.620 

lr: 0.09777199458494357
TRAINING - Epoch: [103][0/391]	Time 0.923 (0.923)	Data 0.339 (0.339)	Loss 0.4074 (0.4074)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [103][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.6451 (0.4765)	Prec@1 77.344 (83.648)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [103][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5740 (0.4792)	Prec@1 81.250 (83.660)	Prec@5 100.000 (99.401)
TRAINING - Epoch: [103][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4945 (0.4950)	Prec@1 85.938 (83.137)	Prec@5 99.219 (99.299)
EVALUATING - Epoch: [103][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 0.6388 (0.6388)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 104	Training Loss 0.4992 	Training Prec@1 83.032 	Training Prec@5 99.280 	Validation Loss 0.7252 	Validation Prec@1 77.470 	Validation Prec@5 98.460 

lr: 0.09772520313857778
TRAINING - Epoch: [104][0/391]	Time 0.921 (0.921)	Data 0.349 (0.349)	Loss 0.4157 (0.4157)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [104][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4773 (0.4934)	Prec@1 84.375 (83.130)	Prec@5 98.438 (99.242)
TRAINING - Epoch: [104][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4486 (0.4947)	Prec@1 85.938 (83.116)	Prec@5 97.656 (99.203)
TRAINING - Epoch: [104][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3308 (0.4901)	Prec@1 89.062 (83.295)	Prec@5 100.000 (99.219)
EVALUATING - Epoch: [104][0/79]	Time 0.355 (0.355)	Data 0.335 (0.335)	Loss 0.5817 (0.5817)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:07

 Epoch: 105	Training Loss 0.4872 	Training Prec@1 83.396 	Training Prec@5 99.226 	Validation Loss 0.8681 	Validation Prec@1 75.260 	Validation Prec@5 98.420 

lr: 0.09767793687276916
TRAINING - Epoch: [105][0/391]	Time 0.895 (0.895)	Data 0.337 (0.337)	Loss 0.5509 (0.5509)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [105][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5190 (0.4833)	Prec@1 81.250 (83.586)	Prec@5 98.438 (99.343)
TRAINING - Epoch: [105][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5001 (0.4977)	Prec@1 83.594 (83.236)	Prec@5 100.000 (99.242)
TRAINING - Epoch: [105][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.6044 (0.4991)	Prec@1 82.812 (83.212)	Prec@5 97.656 (99.240)
EVALUATING - Epoch: [105][0/79]	Time 0.373 (0.373)	Data 0.350 (0.350)	Loss 1.0539 (1.0539)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 106	Training Loss 0.4979 	Training Prec@1 83.228 	Training Prec@5 99.262 	Validation Loss 0.9976 	Validation Prec@1 70.980 	Validation Prec@5 97.660 

lr: 0.09763019625777113
TRAINING - Epoch: [106][0/391]	Time 0.905 (0.905)	Data 0.350 (0.350)	Loss 0.3600 (0.3600)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [106][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.4952 (0.4811)	Prec@1 84.375 (83.586)	Prec@5 99.219 (99.373)
TRAINING - Epoch: [106][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5723 (0.4924)	Prec@1 81.250 (83.318)	Prec@5 99.219 (99.335)
TRAINING - Epoch: [106][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4876 (0.4988)	Prec@1 81.250 (83.140)	Prec@5 99.219 (99.317)
EVALUATING - Epoch: [106][0/79]	Time 0.371 (0.371)	Data 0.352 (0.352)	Loss 1.0729 (1.0729)	Prec@1 70.312 (70.312)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:26

 Epoch: 107	Training Loss 0.4961 	Training Prec@1 83.196 	Training Prec@5 99.284 	Validation Loss 1.0388 	Validation Prec@1 71.140 	Validation Prec@5 97.910 

lr: 0.0975819817685565
TRAINING - Epoch: [107][0/391]	Time 0.944 (0.944)	Data 0.385 (0.385)	Loss 0.6149 (0.6149)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [107][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4464 (0.4767)	Prec@1 80.469 (83.818)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [107][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.4533 (0.4824)	Prec@1 85.156 (83.535)	Prec@5 98.438 (99.308)
TRAINING - Epoch: [107][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3407 (0.4920)	Prec@1 87.500 (83.275)	Prec@5 100.000 (99.268)
EVALUATING - Epoch: [107][0/79]	Time 0.335 (0.335)	Data 0.317 (0.317)	Loss 0.5607 (0.5607)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 108	Training Loss 0.4944 	Training Prec@1 83.234 	Training Prec@5 99.234 	Validation Loss 0.7119 	Validation Prec@1 77.530 	Validation Prec@5 98.200 

lr: 0.09753329388481262
TRAINING - Epoch: [108][0/391]	Time 0.959 (0.959)	Data 0.381 (0.381)	Loss 0.3976 (0.3976)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [108][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5394 (0.4801)	Prec@1 82.812 (83.764)	Prec@5 100.000 (99.327)
TRAINING - Epoch: [108][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4471 (0.4708)	Prec@1 83.594 (84.033)	Prec@5 99.219 (99.328)
TRAINING - Epoch: [108][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5002 (0.4776)	Prec@1 77.344 (83.760)	Prec@5 99.219 (99.297)
EVALUATING - Epoch: [108][0/79]	Time 0.356 (0.356)	Data 0.332 (0.332)	Loss 0.4286 (0.4286)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 109	Training Loss 0.4769 	Training Prec@1 83.806 	Training Prec@5 99.270 	Validation Loss 0.6631 	Validation Prec@1 78.360 	Validation Prec@5 98.410 

lr: 0.09748413309093668
TRAINING - Epoch: [109][0/391]	Time 0.933 (0.933)	Data 0.372 (0.372)	Loss 0.3808 (0.3808)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [109][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.4510 (0.4628)	Prec@1 85.156 (83.950)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [109][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4809 (0.4740)	Prec@1 86.719 (83.660)	Prec@5 98.438 (99.339)
TRAINING - Epoch: [109][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4295 (0.4749)	Prec@1 82.812 (83.734)	Prec@5 99.219 (99.328)
EVALUATING - Epoch: [109][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.7361 (0.7361)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:27

 Epoch: 110	Training Loss 0.4821 	Training Prec@1 83.502 	Training Prec@5 99.322 	Validation Loss 0.7389 	Validation Prec@1 76.650 	Validation Prec@5 97.940 

lr: 0.09743449987603084
TRAINING - Epoch: [110][0/391]	Time 0.913 (0.913)	Data 0.344 (0.344)	Loss 0.5847 (0.5847)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [110][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5966 (0.5071)	Prec@1 77.344 (83.006)	Prec@5 100.000 (99.296)
TRAINING - Epoch: [110][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4435 (0.4960)	Prec@1 87.500 (83.205)	Prec@5 98.438 (99.339)
TRAINING - Epoch: [110][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5494 (0.4982)	Prec@1 82.812 (83.171)	Prec@5 99.219 (99.325)
EVALUATING - Epoch: [110][0/79]	Time 0.374 (0.374)	Data 0.350 (0.350)	Loss 0.7472 (0.7472)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:11

 Epoch: 111	Training Loss 0.5034 	Training Prec@1 82.986 	Training Prec@5 99.268 	Validation Loss 0.6841 	Validation Prec@1 78.230 	Validation Prec@5 98.430 

lr: 0.09738439473389743
TRAINING - Epoch: [111][0/391]	Time 0.974 (0.974)	Data 0.385 (0.385)	Loss 0.4031 (0.4031)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [111][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3733 (0.4794)	Prec@1 85.156 (83.818)	Prec@5 100.000 (99.118)
TRAINING - Epoch: [111][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4245 (0.4842)	Prec@1 85.938 (83.528)	Prec@5 100.000 (99.164)
TRAINING - Epoch: [111][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.4942 (0.4876)	Prec@1 78.125 (83.459)	Prec@5 100.000 (99.211)
EVALUATING - Epoch: [111][0/79]	Time 0.404 (0.404)	Data 0.385 (0.385)	Loss 0.8101 (0.8101)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:31

 Epoch: 112	Training Loss 0.4864 	Training Prec@1 83.504 	Training Prec@5 99.244 	Validation Loss 0.7980 	Validation Prec@1 76.170 	Validation Prec@5 98.190 

lr: 0.09733381816303395
TRAINING - Epoch: [112][0/391]	Time 0.922 (0.922)	Data 0.328 (0.328)	Loss 0.3694 (0.3694)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [112][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.5452 (0.4771)	Prec@1 78.906 (83.818)	Prec@5 100.000 (99.350)
TRAINING - Epoch: [112][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4382 (0.4814)	Prec@1 80.469 (83.543)	Prec@5 100.000 (99.312)
TRAINING - Epoch: [112][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5209 (0.4870)	Prec@1 80.469 (83.363)	Prec@5 100.000 (99.297)
EVALUATING - Epoch: [112][0/79]	Time 0.340 (0.340)	Data 0.319 (0.319)	Loss 0.7423 (0.7423)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:18:05

 Epoch: 113	Training Loss 0.4875 	Training Prec@1 83.340 	Training Prec@5 99.320 	Validation Loss 0.9442 	Validation Prec@1 71.880 	Validation Prec@5 97.470 

lr: 0.0972827706666282
TRAINING - Epoch: [113][0/391]	Time 0.924 (0.924)	Data 0.348 (0.348)	Loss 0.5211 (0.5211)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [113][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4165 (0.4726)	Prec@1 86.719 (83.926)	Prec@5 100.000 (99.343)
TRAINING - Epoch: [113][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4987 (0.4800)	Prec@1 85.938 (83.679)	Prec@5 98.438 (99.250)
TRAINING - Epoch: [113][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.4630 (0.4814)	Prec@1 81.250 (83.568)	Prec@5 100.000 (99.255)
EVALUATING - Epoch: [113][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.5411 (0.5411)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 114	Training Loss 0.4801 	Training Prec@1 83.588 	Training Prec@5 99.252 	Validation Loss 0.6368 	Validation Prec@1 79.010 	Validation Prec@5 99.020 

lr: 0.09723125275255325
TRAINING - Epoch: [114][0/391]	Time 0.927 (0.927)	Data 0.343 (0.343)	Loss 0.4825 (0.4825)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [114][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.5334 (0.4534)	Prec@1 82.812 (84.491)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [114][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5451 (0.4675)	Prec@1 80.469 (83.951)	Prec@5 100.000 (99.405)
TRAINING - Epoch: [114][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5688 (0.4704)	Prec@1 78.906 (83.801)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [114][0/79]	Time 0.345 (0.345)	Data 0.322 (0.322)	Loss 1.0081 (1.0081)	Prec@1 76.562 (76.562)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 115	Training Loss 0.4777 	Training Prec@1 83.618 	Training Prec@5 99.354 	Validation Loss 0.8970 	Validation Prec@1 74.610 	Validation Prec@5 96.720 

lr: 0.09717926493336226
TRAINING - Epoch: [115][0/391]	Time 1.006 (1.006)	Data 0.366 (0.366)	Loss 0.4809 (0.4809)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [115][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.4675 (0.4674)	Prec@1 82.812 (83.988)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [115][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3726 (0.4829)	Prec@1 85.938 (83.640)	Prec@5 99.219 (99.242)
TRAINING - Epoch: [115][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4611 (0.4861)	Prec@1 84.375 (83.586)	Prec@5 100.000 (99.227)
EVALUATING - Epoch: [115][0/79]	Time 0.364 (0.364)	Data 0.345 (0.345)	Loss 0.6618 (0.6618)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:21

 Epoch: 116	Training Loss 0.4860 	Training Prec@1 83.554 	Training Prec@5 99.250 	Validation Loss 0.6995 	Validation Prec@1 77.910 	Validation Prec@5 99.070 

lr: 0.09712680772628364
TRAINING - Epoch: [116][0/391]	Time 0.924 (0.924)	Data 0.350 (0.350)	Loss 0.3685 (0.3685)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [116][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4402 (0.4618)	Prec@1 85.938 (84.445)	Prec@5 100.000 (99.319)
TRAINING - Epoch: [116][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3947 (0.4905)	Prec@1 85.156 (83.291)	Prec@5 100.000 (99.331)
TRAINING - Epoch: [116][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.4598 (0.4885)	Prec@1 83.594 (83.363)	Prec@5 100.000 (99.307)
EVALUATING - Epoch: [116][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.7410 (0.7410)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:46

 Epoch: 117	Training Loss 0.4937 	Training Prec@1 83.270 	Training Prec@5 99.310 	Validation Loss 0.8815 	Validation Prec@1 73.880 	Validation Prec@5 97.690 

lr: 0.09707388165321562
TRAINING - Epoch: [117][0/391]	Time 0.979 (0.979)	Data 0.383 (0.383)	Loss 0.6100 (0.6100)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [117][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4182 (0.4707)	Prec@1 87.500 (83.926)	Prec@5 100.000 (99.350)
TRAINING - Epoch: [117][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5620 (0.4788)	Prec@1 81.250 (83.738)	Prec@5 99.219 (99.324)
TRAINING - Epoch: [117][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.4515 (0.4860)	Prec@1 85.938 (83.542)	Prec@5 99.219 (99.252)
EVALUATING - Epoch: [117][0/79]	Time 0.414 (0.414)	Data 0.394 (0.394)	Loss 0.7573 (0.7573)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:36

 Epoch: 118	Training Loss 0.4858 	Training Prec@1 83.506 	Training Prec@5 99.252 	Validation Loss 0.6274 	Validation Prec@1 79.730 	Validation Prec@5 98.870 

lr: 0.09702048724072126
TRAINING - Epoch: [118][0/391]	Time 0.967 (0.967)	Data 0.349 (0.349)	Loss 0.3070 (0.3070)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [118][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4935 (0.4620)	Prec@1 83.594 (84.228)	Prec@5 99.219 (99.350)
TRAINING - Epoch: [118][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.5202 (0.4716)	Prec@1 83.594 (84.021)	Prec@5 98.438 (99.258)
TRAINING - Epoch: [118][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5440 (0.4762)	Prec@1 76.562 (83.934)	Prec@5 100.000 (99.260)
EVALUATING - Epoch: [118][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.7585 (0.7585)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:31

 Epoch: 119	Training Loss 0.4804 	Training Prec@1 83.808 	Training Prec@5 99.276 	Validation Loss 0.8585 	Validation Prec@1 74.560 	Validation Prec@5 97.870 

lr: 0.09696662502002318
TRAINING - Epoch: [119][0/391]	Time 0.938 (0.938)	Data 0.375 (0.375)	Loss 0.5345 (0.5345)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [119][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5208 (0.4650)	Prec@1 83.594 (84.236)	Prec@5 99.219 (99.428)
TRAINING - Epoch: [119][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.7081 (0.4793)	Prec@1 79.688 (83.877)	Prec@5 97.656 (99.320)
TRAINING - Epoch: [119][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.5216 (0.4890)	Prec@1 85.156 (83.456)	Prec@5 100.000 (99.325)
EVALUATING - Epoch: [119][0/79]	Time 0.356 (0.356)	Data 0.336 (0.336)	Loss 0.5728 (0.5728)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:37

 Epoch: 120	Training Loss 0.4968 	Training Prec@1 83.152 	Training Prec@5 99.300 	Validation Loss 0.6583 	Validation Prec@1 78.660 	Validation Prec@5 98.670 

lr: 0.09691229552699815
TRAINING - Epoch: [120][0/391]	Time 0.896 (0.896)	Data 0.338 (0.338)	Loss 0.5483 (0.5483)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [120][100/391]	Time 0.062 (0.070)	Data 0.000 (0.003)	Loss 0.4805 (0.4599)	Prec@1 78.125 (84.197)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [120][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.5104 (0.4717)	Prec@1 83.594 (83.889)	Prec@5 99.219 (99.444)
TRAINING - Epoch: [120][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4457 (0.4754)	Prec@1 84.375 (83.734)	Prec@5 100.000 (99.400)
EVALUATING - Epoch: [120][0/79]	Time 0.370 (0.370)	Data 0.346 (0.346)	Loss 0.7270 (0.7270)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:40

 Epoch: 121	Training Loss 0.4813 	Training Prec@1 83.542 	Training Prec@5 99.372 	Validation Loss 0.8323 	Validation Prec@1 75.270 	Validation Prec@5 98.540 

lr: 0.09685749930217188
TRAINING - Epoch: [121][0/391]	Time 0.923 (0.923)	Data 0.351 (0.351)	Loss 0.6204 (0.6204)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [121][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.5133 (0.4725)	Prec@1 80.469 (84.035)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [121][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.5395 (0.4761)	Prec@1 85.938 (83.687)	Prec@5 100.000 (99.382)
TRAINING - Epoch: [121][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4559 (0.4775)	Prec@1 84.375 (83.666)	Prec@5 100.000 (99.367)
EVALUATING - Epoch: [121][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.8988 (0.8988)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:14

 Epoch: 122	Training Loss 0.4777 	Training Prec@1 83.718 	Training Prec@5 99.334 	Validation Loss 1.0321 	Validation Prec@1 70.910 	Validation Prec@5 97.030 

lr: 0.09680223689071363
TRAINING - Epoch: [122][0/391]	Time 0.914 (0.914)	Data 0.343 (0.343)	Loss 0.4492 (0.4492)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [122][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4352 (0.4414)	Prec@1 83.594 (84.800)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [122][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5177 (0.4572)	Prec@1 80.469 (84.332)	Prec@5 100.000 (99.452)
TRAINING - Epoch: [122][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4373 (0.4699)	Prec@1 84.375 (84.017)	Prec@5 100.000 (99.367)
EVALUATING - Epoch: [122][0/79]	Time 0.373 (0.373)	Data 0.354 (0.354)	Loss 0.5815 (0.5815)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:57

 Epoch: 123	Training Loss 0.4761 	Training Prec@1 83.936 	Training Prec@5 99.312 	Validation Loss 0.6701 	Validation Prec@1 78.990 	Validation Prec@5 98.860 

lr: 0.09674650884243076
TRAINING - Epoch: [123][0/391]	Time 0.934 (0.934)	Data 0.370 (0.370)	Loss 0.2851 (0.2851)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [123][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5514 (0.4950)	Prec@1 84.375 (83.493)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [123][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5804 (0.4842)	Prec@1 82.031 (83.605)	Prec@5 98.438 (99.312)
TRAINING - Epoch: [123][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5331 (0.4822)	Prec@1 85.938 (83.659)	Prec@5 99.219 (99.299)
EVALUATING - Epoch: [123][0/79]	Time 0.345 (0.345)	Data 0.325 (0.325)	Loss 0.7409 (0.7409)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:06

 Epoch: 124	Training Loss 0.4866 	Training Prec@1 83.444 	Training Prec@5 99.304 	Validation Loss 0.7913 	Validation Prec@1 76.370 	Validation Prec@5 98.690 

lr: 0.09669031571176322
TRAINING - Epoch: [124][0/391]	Time 0.907 (0.907)	Data 0.351 (0.351)	Loss 0.5321 (0.5321)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [124][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.4540 (0.4919)	Prec@1 83.594 (83.130)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [124][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3505 (0.4806)	Prec@1 89.844 (83.469)	Prec@5 99.219 (99.363)
TRAINING - Epoch: [124][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.5544 (0.4786)	Prec@1 83.594 (83.640)	Prec@5 98.438 (99.354)
EVALUATING - Epoch: [124][0/79]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.6314 (0.6314)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:18:41

 Epoch: 125	Training Loss 0.4801 	Training Prec@1 83.706 	Training Prec@5 99.336 	Validation Loss 0.8579 	Validation Prec@1 75.090 	Validation Prec@5 98.100 

lr: 0.09663365805777813
TRAINING - Epoch: [125][0/391]	Time 0.910 (0.910)	Data 0.337 (0.337)	Loss 0.5472 (0.5472)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [125][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6322 (0.4608)	Prec@1 78.906 (84.220)	Prec@5 99.219 (99.304)
TRAINING - Epoch: [125][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4219 (0.4673)	Prec@1 86.719 (84.173)	Prec@5 100.000 (99.289)
TRAINING - Epoch: [125][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6155 (0.4732)	Prec@1 79.688 (83.980)	Prec@5 99.219 (99.294)
EVALUATING - Epoch: [125][0/79]	Time 0.375 (0.375)	Data 0.353 (0.353)	Loss 0.6493 (0.6493)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:21

 Epoch: 126	Training Loss 0.4737 	Training Prec@1 83.948 	Training Prec@5 99.326 	Validation Loss 0.7921 	Validation Prec@1 76.560 	Validation Prec@5 97.860 

lr: 0.09657653644416415
TRAINING - Epoch: [126][0/391]	Time 0.902 (0.902)	Data 0.337 (0.337)	Loss 0.4246 (0.4246)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [126][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5293 (0.4682)	Prec@1 76.562 (83.849)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [126][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3964 (0.4738)	Prec@1 84.375 (83.722)	Prec@5 100.000 (99.413)
TRAINING - Epoch: [126][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5229 (0.4757)	Prec@1 82.031 (83.724)	Prec@5 97.656 (99.411)
EVALUATING - Epoch: [126][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 1.0100 (1.0100)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:17

 Epoch: 127	Training Loss 0.4776 	Training Prec@1 83.654 	Training Prec@5 99.386 	Validation Loss 0.8534 	Validation Prec@1 74.660 	Validation Prec@5 96.960 

lr: 0.0965189514392259
TRAINING - Epoch: [127][0/391]	Time 0.922 (0.922)	Data 0.348 (0.348)	Loss 0.4965 (0.4965)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [127][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5395 (0.4607)	Prec@1 82.031 (84.437)	Prec@5 98.438 (99.250)
TRAINING - Epoch: [127][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4783 (0.4575)	Prec@1 82.031 (84.356)	Prec@5 100.000 (99.331)
TRAINING - Epoch: [127][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3164 (0.4617)	Prec@1 92.969 (84.134)	Prec@5 99.219 (99.341)
EVALUATING - Epoch: [127][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.6527 (0.6527)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:52

 Epoch: 128	Training Loss 0.4621 	Training Prec@1 84.190 	Training Prec@5 99.326 	Validation Loss 0.7502 	Validation Prec@1 77.040 	Validation Prec@5 98.250 

lr: 0.09646090361587825
TRAINING - Epoch: [128][0/391]	Time 0.952 (0.952)	Data 0.395 (0.395)	Loss 0.2944 (0.2944)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [128][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3536 (0.4651)	Prec@1 85.938 (84.019)	Prec@5 100.000 (99.296)
TRAINING - Epoch: [128][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.6198 (0.4561)	Prec@1 78.125 (84.495)	Prec@5 99.219 (99.374)
TRAINING - Epoch: [128][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5233 (0.4686)	Prec@1 82.812 (84.027)	Prec@5 100.000 (99.325)
EVALUATING - Epoch: [128][0/79]	Time 0.390 (0.390)	Data 0.368 (0.368)	Loss 0.8765 (0.8765)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:34

 Epoch: 129	Training Loss 0.4712 	Training Prec@1 84.014 	Training Prec@5 99.302 	Validation Loss 0.9349 	Validation Prec@1 73.330 	Validation Prec@5 96.930 

lr: 0.09640239355164071
TRAINING - Epoch: [129][0/391]	Time 0.934 (0.934)	Data 0.373 (0.373)	Loss 0.4024 (0.4024)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [129][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5373 (0.4358)	Prec@1 82.031 (85.218)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [129][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5997 (0.4484)	Prec@1 82.812 (84.853)	Prec@5 98.438 (99.398)
TRAINING - Epoch: [129][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4795 (0.4662)	Prec@1 80.469 (84.282)	Prec@5 99.219 (99.338)
EVALUATING - Epoch: [129][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.6099 (0.6099)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 130	Training Loss 0.4690 	Training Prec@1 84.202 	Training Prec@5 99.304 	Validation Loss 0.7109 	Validation Prec@1 78.050 	Validation Prec@5 98.760 

lr: 0.0963434218286316
TRAINING - Epoch: [130][0/391]	Time 0.911 (0.911)	Data 0.347 (0.347)	Loss 0.4647 (0.4647)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [130][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3976 (0.4645)	Prec@1 86.719 (84.406)	Prec@5 100.000 (99.335)
TRAINING - Epoch: [130][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5152 (0.4720)	Prec@1 84.375 (84.208)	Prec@5 100.000 (99.281)
TRAINING - Epoch: [130][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5595 (0.4773)	Prec@1 76.562 (83.944)	Prec@5 99.219 (99.284)
EVALUATING - Epoch: [130][0/79]	Time 0.357 (0.357)	Data 0.334 (0.334)	Loss 0.6680 (0.6680)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:51

 Epoch: 131	Training Loss 0.4803 	Training Prec@1 83.700 	Training Prec@5 99.300 	Validation Loss 0.7532 	Validation Prec@1 76.140 	Validation Prec@5 98.380 

lr: 0.09628398903356236
TRAINING - Epoch: [131][0/391]	Time 0.903 (0.903)	Data 0.345 (0.345)	Loss 0.4991 (0.4991)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [131][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.5790 (0.4716)	Prec@1 78.125 (83.625)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [131][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4892 (0.4742)	Prec@1 82.812 (83.850)	Prec@5 100.000 (99.366)
TRAINING - Epoch: [131][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5266 (0.4772)	Prec@1 82.031 (83.799)	Prec@5 99.219 (99.315)
EVALUATING - Epoch: [131][0/79]	Time 0.371 (0.371)	Data 0.347 (0.347)	Loss 0.8087 (0.8087)	Prec@1 78.125 (78.125)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:43

 Epoch: 132	Training Loss 0.4770 	Training Prec@1 83.846 	Training Prec@5 99.314 	Validation Loss 0.8152 	Validation Prec@1 76.760 	Validation Prec@5 97.840 

lr: 0.09622409575773158
TRAINING - Epoch: [132][0/391]	Time 0.921 (0.921)	Data 0.363 (0.363)	Loss 0.4278 (0.4278)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [132][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5654 (0.4603)	Prec@1 79.688 (84.244)	Prec@5 97.656 (99.304)
TRAINING - Epoch: [132][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4739 (0.4703)	Prec@1 87.500 (84.087)	Prec@5 100.000 (99.296)
TRAINING - Epoch: [132][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3737 (0.4706)	Prec@1 89.062 (83.978)	Prec@5 99.219 (99.320)
EVALUATING - Epoch: [132][0/79]	Time 0.375 (0.375)	Data 0.353 (0.353)	Loss 0.5367 (0.5367)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:32

 Epoch: 133	Training Loss 0.4682 	Training Prec@1 84.066 	Training Prec@5 99.322 	Validation Loss 0.5770 	Validation Prec@1 81.120 	Validation Prec@5 98.930 

lr: 0.09616374259701922
TRAINING - Epoch: [133][0/391]	Time 1.010 (1.010)	Data 0.341 (0.341)	Loss 0.5697 (0.5697)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [133][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4194 (0.4473)	Prec@1 87.500 (84.886)	Prec@5 99.219 (99.350)
TRAINING - Epoch: [133][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4466 (0.4660)	Prec@1 85.156 (84.429)	Prec@5 98.438 (99.363)
TRAINING - Epoch: [133][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4784 (0.4732)	Prec@1 81.250 (84.152)	Prec@5 100.000 (99.338)
EVALUATING - Epoch: [133][0/79]	Time 0.340 (0.340)	Data 0.318 (0.318)	Loss 0.6648 (0.6648)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:01

 Epoch: 134	Training Loss 0.4771 	Training Prec@1 83.940 	Training Prec@5 99.336 	Validation Loss 0.7372 	Validation Prec@1 78.180 	Validation Prec@5 98.010 

lr: 0.09610293015188064
TRAINING - Epoch: [134][0/391]	Time 0.948 (0.948)	Data 0.372 (0.372)	Loss 0.5007 (0.5007)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [134][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4521 (0.4525)	Prec@1 85.938 (84.151)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [134][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.6366 (0.4652)	Prec@1 79.688 (83.897)	Prec@5 100.000 (99.335)
TRAINING - Epoch: [134][300/391]	Time 0.064 (0.066)	Data 0.005 (0.002)	Loss 0.4701 (0.4667)	Prec@1 82.031 (83.962)	Prec@5 100.000 (99.351)
EVALUATING - Epoch: [134][0/79]	Time 0.342 (0.342)	Data 0.321 (0.321)	Loss 0.7924 (0.7924)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:28

 Epoch: 135	Training Loss 0.4711 	Training Prec@1 83.950 	Training Prec@5 99.316 	Validation Loss 0.8182 	Validation Prec@1 75.510 	Validation Prec@5 98.410 

lr: 0.09604165902734065
TRAINING - Epoch: [135][0/391]	Time 1.041 (1.041)	Data 0.375 (0.375)	Loss 0.4260 (0.4260)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [135][100/391]	Time 0.062 (0.074)	Data 0.000 (0.004)	Loss 0.3534 (0.4485)	Prec@1 89.844 (84.506)	Prec@5 98.438 (99.304)
TRAINING - Epoch: [135][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.6963 (0.4616)	Prec@1 79.688 (84.041)	Prec@5 98.438 (99.324)
TRAINING - Epoch: [135][300/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3659 (0.4732)	Prec@1 88.281 (83.762)	Prec@5 100.000 (99.315)
EVALUATING - Epoch: [135][0/79]	Time 0.368 (0.368)	Data 0.349 (0.349)	Loss 0.6886 (0.6886)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:01

 Epoch: 136	Training Loss 0.4704 	Training Prec@1 83.910 	Training Prec@5 99.328 	Validation Loss 0.9239 	Validation Prec@1 72.020 	Validation Prec@5 98.620 

lr: 0.09597992983298743
TRAINING - Epoch: [136][0/391]	Time 0.965 (0.965)	Data 0.377 (0.377)	Loss 0.3571 (0.3571)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [136][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3340 (0.4817)	Prec@1 86.719 (83.540)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [136][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4106 (0.4701)	Prec@1 86.719 (83.827)	Prec@5 99.219 (99.320)
TRAINING - Epoch: [136][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5208 (0.4730)	Prec@1 82.031 (83.703)	Prec@5 99.219 (99.336)
EVALUATING - Epoch: [136][0/79]	Time 0.370 (0.370)	Data 0.348 (0.348)	Loss 0.5504 (0.5504)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:41

 Epoch: 137	Training Loss 0.4711 	Training Prec@1 83.834 	Training Prec@5 99.344 	Validation Loss 0.6325 	Validation Prec@1 79.440 	Validation Prec@5 98.780 

lr: 0.09591774318296659
TRAINING - Epoch: [137][0/391]	Time 1.014 (1.014)	Data 0.377 (0.377)	Loss 0.5355 (0.5355)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [137][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.3209 (0.4484)	Prec@1 87.500 (84.677)	Prec@5 100.000 (99.412)
TRAINING - Epoch: [137][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.6192 (0.4530)	Prec@1 78.906 (84.484)	Prec@5 96.875 (99.409)
TRAINING - Epoch: [137][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5011 (0.4571)	Prec@1 82.031 (84.367)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [137][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.8353 (0.8353)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:19

 Epoch: 138	Training Loss 0.4610 	Training Prec@1 84.324 	Training Prec@5 99.366 	Validation Loss 0.8720 	Validation Prec@1 75.320 	Validation Prec@5 98.130 

lr: 0.09585509969597487
TRAINING - Epoch: [138][0/391]	Time 0.898 (0.898)	Data 0.333 (0.333)	Loss 0.4567 (0.4567)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [138][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4118 (0.4573)	Prec@1 85.938 (84.445)	Prec@5 99.219 (99.420)
TRAINING - Epoch: [138][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4432 (0.4475)	Prec@1 85.156 (84.667)	Prec@5 100.000 (99.413)
TRAINING - Epoch: [138][300/391]	Time 0.067 (0.066)	Data 0.000 (0.001)	Loss 0.4113 (0.4520)	Prec@1 82.812 (84.479)	Prec@5 99.219 (99.385)
EVALUATING - Epoch: [138][0/79]	Time 0.380 (0.380)	Data 0.359 (0.359)	Loss 0.6690 (0.6690)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:57

 Epoch: 139	Training Loss 0.4583 	Training Prec@1 84.316 	Training Prec@5 99.374 	Validation Loss 0.8388 	Validation Prec@1 74.430 	Validation Prec@5 98.480 

lr: 0.0957919999952542
TRAINING - Epoch: [139][0/391]	Time 0.926 (0.926)	Data 0.355 (0.355)	Loss 0.4961 (0.4961)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [139][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.4803 (0.4570)	Prec@1 82.031 (84.468)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [139][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.5650 (0.4781)	Prec@1 82.812 (83.784)	Prec@5 100.000 (99.363)
TRAINING - Epoch: [139][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.5921 (0.4706)	Prec@1 82.812 (83.983)	Prec@5 100.000 (99.362)
EVALUATING - Epoch: [139][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.6382 (0.6382)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:27

 Epoch: 140	Training Loss 0.4674 	Training Prec@1 84.038 	Training Prec@5 99.366 	Validation Loss 0.6918 	Validation Prec@1 78.030 	Validation Prec@5 98.640 

lr: 0.09572844470858534
TRAINING - Epoch: [140][0/391]	Time 0.951 (0.951)	Data 0.364 (0.364)	Loss 0.4818 (0.4818)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [140][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.5057 (0.4591)	Prec@1 85.938 (84.313)	Prec@5 98.438 (99.443)
TRAINING - Epoch: [140][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.4820 (0.4622)	Prec@1 86.719 (84.449)	Prec@5 99.219 (99.370)
TRAINING - Epoch: [140][300/391]	Time 0.067 (0.067)	Data 0.000 (0.002)	Loss 0.3492 (0.4654)	Prec@1 91.406 (84.315)	Prec@5 100.000 (99.387)
EVALUATING - Epoch: [140][0/79]	Time 0.420 (0.420)	Data 0.399 (0.399)	Loss 0.7296 (0.7296)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:30:06

 Epoch: 141	Training Loss 0.4650 	Training Prec@1 84.388 	Training Prec@5 99.366 	Validation Loss 0.8467 	Validation Prec@1 74.950 	Validation Prec@5 98.360 

lr: 0.09566443446828168
TRAINING - Epoch: [141][0/391]	Time 0.977 (0.977)	Data 0.383 (0.383)	Loss 0.3713 (0.3713)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [141][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.5140 (0.4682)	Prec@1 80.469 (83.895)	Prec@5 100.000 (99.373)
TRAINING - Epoch: [141][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.4042 (0.4819)	Prec@1 83.594 (83.512)	Prec@5 99.219 (99.409)
TRAINING - Epoch: [141][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4373 (0.4792)	Prec@1 84.375 (83.568)	Prec@5 99.219 (99.377)
EVALUATING - Epoch: [141][0/79]	Time 0.376 (0.376)	Data 0.354 (0.354)	Loss 0.5512 (0.5512)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:37

 Epoch: 142	Training Loss 0.4820 	Training Prec@1 83.454 	Training Prec@5 99.366 	Validation Loss 0.6522 	Validation Prec@1 79.720 	Validation Prec@5 98.560 

lr: 0.095599969911183
TRAINING - Epoch: [142][0/391]	Time 1.020 (1.020)	Data 0.382 (0.382)	Loss 0.4909 (0.4909)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [142][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3222 (0.4572)	Prec@1 85.156 (84.661)	Prec@5 100.000 (99.389)
TRAINING - Epoch: [142][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.4488 (0.4734)	Prec@1 85.156 (84.216)	Prec@5 97.656 (99.401)
TRAINING - Epoch: [142][300/391]	Time 0.068 (0.067)	Data 0.000 (0.002)	Loss 0.5634 (0.4842)	Prec@1 78.125 (83.757)	Prec@5 100.000 (99.346)
EVALUATING - Epoch: [142][0/79]	Time 0.378 (0.378)	Data 0.359 (0.359)	Loss 0.8681 (0.8681)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:28:56

 Epoch: 143	Training Loss 0.4873 	Training Prec@1 83.616 	Training Prec@5 99.328 	Validation Loss 1.0114 	Validation Prec@1 71.860 	Validation Prec@5 98.000 

lr: 0.09553505167864906
TRAINING - Epoch: [143][0/391]	Time 0.981 (0.981)	Data 0.369 (0.369)	Loss 0.4235 (0.4235)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [143][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.4838 (0.4905)	Prec@1 84.375 (83.594)	Prec@5 100.000 (99.273)
TRAINING - Epoch: [143][200/391]	Time 0.062 (0.069)	Data 0.000 (0.002)	Loss 0.2535 (0.4848)	Prec@1 92.188 (83.932)	Prec@5 100.000 (99.312)
TRAINING - Epoch: [143][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3766 (0.4775)	Prec@1 88.281 (84.077)	Prec@5 100.000 (99.349)
EVALUATING - Epoch: [143][0/79]	Time 0.370 (0.370)	Data 0.350 (0.350)	Loss 0.7980 (0.7980)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:30:00

 Epoch: 144	Training Loss 0.4836 	Training Prec@1 83.834 	Training Prec@5 99.330 	Validation Loss 0.7080 	Validation Prec@1 78.270 	Validation Prec@5 98.380 

lr: 0.09546968041655324
TRAINING - Epoch: [144][0/391]	Time 0.938 (0.938)	Data 0.370 (0.370)	Loss 0.3802 (0.3802)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [144][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3940 (0.4415)	Prec@1 89.062 (84.878)	Prec@5 99.219 (99.497)
TRAINING - Epoch: [144][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.4282 (0.4619)	Prec@1 83.594 (84.297)	Prec@5 98.438 (99.405)
TRAINING - Epoch: [144][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.4807 (0.4658)	Prec@1 78.906 (84.186)	Prec@5 97.656 (99.367)
EVALUATING - Epoch: [144][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.6312 (0.6312)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:09

 Epoch: 145	Training Loss 0.4668 	Training Prec@1 84.158 	Training Prec@5 99.338 	Validation Loss 0.7377 	Validation Prec@1 77.310 	Validation Prec@5 98.360 

lr: 0.09540385677527613
TRAINING - Epoch: [145][0/391]	Time 0.989 (0.989)	Data 0.353 (0.353)	Loss 0.4924 (0.4924)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [145][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.4430 (0.4310)	Prec@1 84.375 (85.412)	Prec@5 98.438 (99.466)
TRAINING - Epoch: [145][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.3821 (0.4414)	Prec@1 88.281 (85.160)	Prec@5 99.219 (99.409)
TRAINING - Epoch: [145][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.4859 (0.4488)	Prec@1 82.812 (84.767)	Prec@5 100.000 (99.372)
EVALUATING - Epoch: [145][0/79]	Time 0.371 (0.371)	Data 0.350 (0.350)	Loss 0.8610 (0.8610)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:13

 Epoch: 146	Training Loss 0.4548 	Training Prec@1 84.542 	Training Prec@5 99.336 	Validation Loss 0.8507 	Validation Prec@1 74.110 	Validation Prec@5 98.040 

lr: 0.09533758140969908
TRAINING - Epoch: [146][0/391]	Time 0.935 (0.935)	Data 0.352 (0.352)	Loss 0.4268 (0.4268)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [146][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.5628 (0.4463)	Prec@1 80.469 (84.700)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [146][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.4024 (0.4538)	Prec@1 85.156 (84.659)	Prec@5 99.219 (99.436)
TRAINING - Epoch: [146][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.3995 (0.4624)	Prec@1 85.938 (84.396)	Prec@5 99.219 (99.421)
EVALUATING - Epoch: [146][0/79]	Time 0.338 (0.338)	Data 0.316 (0.316)	Loss 0.7166 (0.7166)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:28:41

 Epoch: 147	Training Loss 0.4600 	Training Prec@1 84.488 	Training Prec@5 99.402 	Validation Loss 0.7443 	Validation Prec@1 78.020 	Validation Prec@5 98.530 

lr: 0.09527085497919767
TRAINING - Epoch: [147][0/391]	Time 0.948 (0.948)	Data 0.371 (0.371)	Loss 0.4144 (0.4144)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [147][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3830 (0.4434)	Prec@1 86.719 (84.862)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [147][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5138 (0.4698)	Prec@1 84.375 (84.286)	Prec@5 97.656 (99.351)
TRAINING - Epoch: [147][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.4156 (0.4730)	Prec@1 85.156 (84.105)	Prec@5 99.219 (99.346)
EVALUATING - Epoch: [147][0/79]	Time 0.365 (0.365)	Data 0.342 (0.342)	Loss 0.5877 (0.5877)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:31

 Epoch: 148	Training Loss 0.4727 	Training Prec@1 84.048 	Training Prec@5 99.344 	Validation Loss 0.7710 	Validation Prec@1 77.040 	Validation Prec@5 98.200 

lr: 0.09520367814763508
TRAINING - Epoch: [148][0/391]	Time 1.027 (1.027)	Data 0.388 (0.388)	Loss 0.4416 (0.4416)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [148][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.4636 (0.4519)	Prec@1 87.500 (84.824)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [148][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.4185 (0.4605)	Prec@1 85.938 (84.356)	Prec@5 100.000 (99.359)
TRAINING - Epoch: [148][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5082 (0.4700)	Prec@1 81.250 (84.149)	Prec@5 100.000 (99.328)
EVALUATING - Epoch: [148][0/79]	Time 0.383 (0.383)	Data 0.356 (0.356)	Loss 0.5850 (0.5850)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:09

 Epoch: 149	Training Loss 0.4714 	Training Prec@1 84.036 	Training Prec@5 99.322 	Validation Loss 0.7002 	Validation Prec@1 78.200 	Validation Prec@5 98.290 

lr: 0.09513605158335557
TRAINING - Epoch: [149][0/391]	Time 0.940 (0.940)	Data 0.351 (0.351)	Loss 0.5986 (0.5986)	Prec@1 75.781 (75.781)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [149][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2939 (0.4559)	Prec@1 89.844 (84.383)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [149][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3924 (0.4513)	Prec@1 86.719 (84.457)	Prec@5 100.000 (99.440)
TRAINING - Epoch: [149][300/391]	Time 0.062 (0.067)	Data 0.000 (0.001)	Loss 0.3660 (0.4575)	Prec@1 87.500 (84.245)	Prec@5 100.000 (99.406)
EVALUATING - Epoch: [149][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.6531 (0.6531)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:33

 Epoch: 150	Training Loss 0.4653 	Training Prec@1 84.098 	Training Prec@5 99.404 	Validation Loss 0.8829 	Validation Prec@1 75.080 	Validation Prec@5 98.070 

lr: 0.09506797595917782
TRAINING - Epoch: [150][0/391]	Time 0.959 (0.959)	Data 0.376 (0.376)	Loss 0.5734 (0.5734)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [150][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3959 (0.4627)	Prec@1 83.594 (84.561)	Prec@5 100.000 (99.381)
TRAINING - Epoch: [150][200/391]	Time 0.067 (0.068)	Data 0.000 (0.002)	Loss 0.4498 (0.4628)	Prec@1 84.375 (84.208)	Prec@5 99.219 (99.374)
TRAINING - Epoch: [150][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4196 (0.4721)	Prec@1 85.938 (84.084)	Prec@5 98.438 (99.333)
EVALUATING - Epoch: [150][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 0.7633 (0.7633)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:00

 Epoch: 151	Training Loss 0.4753 	Training Prec@1 83.972 	Training Prec@5 99.348 	Validation Loss 0.7756 	Validation Prec@1 76.800 	Validation Prec@5 98.070 

lr: 0.09499945195238821
TRAINING - Epoch: [151][0/391]	Time 0.943 (0.943)	Data 0.356 (0.356)	Loss 0.4387 (0.4387)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [151][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.6878 (0.4756)	Prec@1 78.125 (84.305)	Prec@5 100.000 (99.281)
TRAINING - Epoch: [151][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4017 (0.4688)	Prec@1 84.375 (84.235)	Prec@5 99.219 (99.320)
TRAINING - Epoch: [151][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3596 (0.4691)	Prec@1 87.500 (84.219)	Prec@5 100.000 (99.299)
EVALUATING - Epoch: [151][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.8046 (0.8046)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:02

 Epoch: 152	Training Loss 0.4710 	Training Prec@1 84.132 	Training Prec@5 99.292 	Validation Loss 0.8348 	Validation Prec@1 74.500 	Validation Prec@5 98.680 

lr: 0.09493048024473406
TRAINING - Epoch: [152][0/391]	Time 0.987 (0.987)	Data 0.357 (0.357)	Loss 0.4183 (0.4183)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [152][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.5691 (0.4379)	Prec@1 78.906 (85.172)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [152][200/391]	Time 0.067 (0.069)	Data 0.000 (0.002)	Loss 0.3374 (0.4438)	Prec@1 87.500 (84.966)	Prec@5 100.000 (99.495)
TRAINING - Epoch: [152][300/391]	Time 0.065 (0.067)	Data 0.000 (0.001)	Loss 0.5834 (0.4600)	Prec@1 82.812 (84.489)	Prec@5 98.438 (99.439)
EVALUATING - Epoch: [152][0/79]	Time 0.388 (0.388)	Data 0.367 (0.367)	Loss 0.9593 (0.9593)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:30:53

 Epoch: 153	Training Loss 0.4648 	Training Prec@1 84.346 	Training Prec@5 99.382 	Validation Loss 1.0565 	Validation Prec@1 71.140 	Validation Prec@5 97.590 

lr: 0.09486106152241695
TRAINING - Epoch: [153][0/391]	Time 1.027 (1.027)	Data 0.396 (0.396)	Loss 0.4533 (0.4533)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [153][100/391]	Time 0.063 (0.074)	Data 0.000 (0.004)	Loss 0.3628 (0.4608)	Prec@1 85.156 (84.367)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [153][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.5067 (0.4669)	Prec@1 82.031 (84.181)	Prec@5 99.219 (99.359)
TRAINING - Epoch: [153][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2802 (0.4636)	Prec@1 89.844 (84.357)	Prec@5 100.000 (99.336)
EVALUATING - Epoch: [153][0/79]	Time 0.369 (0.369)	Data 0.349 (0.349)	Loss 0.6215 (0.6215)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:54

 Epoch: 154	Training Loss 0.4626 	Training Prec@1 84.282 	Training Prec@5 99.348 	Validation Loss 0.6913 	Validation Prec@1 78.640 	Validation Prec@5 98.680 

lr: 0.09479119647608575
TRAINING - Epoch: [154][0/391]	Time 0.955 (0.955)	Data 0.362 (0.362)	Loss 0.3165 (0.3165)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [154][100/391]	Time 0.067 (0.073)	Data 0.000 (0.004)	Loss 0.4396 (0.4766)	Prec@1 86.719 (84.127)	Prec@5 99.219 (99.273)
TRAINING - Epoch: [154][200/391]	Time 0.062 (0.069)	Data 0.000 (0.002)	Loss 0.4730 (0.4696)	Prec@1 84.375 (84.208)	Prec@5 100.000 (99.351)
TRAINING - Epoch: [154][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3978 (0.4647)	Prec@1 85.156 (84.313)	Prec@5 100.000 (99.367)
EVALUATING - Epoch: [154][0/79]	Time 0.371 (0.371)	Data 0.347 (0.347)	Loss 0.6365 (0.6365)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:28:39

 Epoch: 155	Training Loss 0.4638 	Training Prec@1 84.372 	Training Prec@5 99.368 	Validation Loss 0.6970 	Validation Prec@1 78.850 	Validation Prec@5 98.600 

lr: 0.09472088580082985
TRAINING - Epoch: [155][0/391]	Time 0.954 (0.954)	Data 0.384 (0.384)	Loss 0.3006 (0.3006)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [155][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.4128 (0.4340)	Prec@1 87.500 (85.149)	Prec@5 99.219 (99.466)
TRAINING - Epoch: [155][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.6156 (0.4392)	Prec@1 85.938 (85.094)	Prec@5 97.656 (99.386)
TRAINING - Epoch: [155][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4553 (0.4478)	Prec@1 80.469 (84.728)	Prec@5 99.219 (99.382)
EVALUATING - Epoch: [155][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.4707 (0.4707)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:33

 Epoch: 156	Training Loss 0.4490 	Training Prec@1 84.632 	Training Prec@5 99.402 	Validation Loss 0.6263 	Validation Prec@1 79.530 	Validation Prec@5 98.910 

lr: 0.09465013019617224
TRAINING - Epoch: [156][0/391]	Time 0.951 (0.951)	Data 0.360 (0.360)	Loss 0.2543 (0.2543)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [156][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.5926 (0.4431)	Prec@1 79.688 (84.739)	Prec@5 98.438 (99.420)
TRAINING - Epoch: [156][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.5091 (0.4424)	Prec@1 81.250 (84.799)	Prec@5 100.000 (99.440)
TRAINING - Epoch: [156][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4269 (0.4513)	Prec@1 83.594 (84.564)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [156][0/79]	Time 0.382 (0.382)	Data 0.355 (0.355)	Loss 0.8069 (0.8069)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:35

 Epoch: 157	Training Loss 0.4530 	Training Prec@1 84.566 	Training Prec@5 99.390 	Validation Loss 0.8913 	Validation Prec@1 72.980 	Validation Prec@5 97.990 

lr: 0.09457893036606248
TRAINING - Epoch: [157][0/391]	Time 0.927 (0.927)	Data 0.349 (0.349)	Loss 0.4865 (0.4865)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [157][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4870 (0.4388)	Prec@1 82.812 (85.172)	Prec@5 98.438 (99.397)
TRAINING - Epoch: [157][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5552 (0.4559)	Prec@1 79.688 (84.297)	Prec@5 100.000 (99.394)
TRAINING - Epoch: [157][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5526 (0.4632)	Prec@1 80.469 (84.079)	Prec@5 100.000 (99.367)
EVALUATING - Epoch: [157][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 0.5544 (0.5544)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:06

 Epoch: 158	Training Loss 0.4680 	Training Prec@1 84.018 	Training Prec@5 99.346 	Validation Loss 0.6880 	Validation Prec@1 78.630 	Validation Prec@5 98.490 

lr: 0.09450728701886979
TRAINING - Epoch: [158][0/391]	Time 1.002 (1.002)	Data 0.383 (0.383)	Loss 0.3934 (0.3934)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [158][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.3571 (0.4624)	Prec@1 85.156 (84.305)	Prec@5 99.219 (99.343)
TRAINING - Epoch: [158][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4297 (0.4669)	Prec@1 85.156 (84.317)	Prec@5 98.438 (99.351)
TRAINING - Epoch: [158][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3784 (0.4746)	Prec@1 85.156 (84.051)	Prec@5 99.219 (99.330)
EVALUATING - Epoch: [158][0/79]	Time 0.358 (0.358)	Data 0.336 (0.336)	Loss 1.2680 (1.2680)	Prec@1 67.969 (67.969)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:38

 Epoch: 159	Training Loss 0.4717 	Training Prec@1 84.074 	Training Prec@5 99.354 	Validation Loss 1.0555 	Validation Prec@1 71.550 	Validation Prec@5 96.910 

lr: 0.09443520086737589
TRAINING - Epoch: [159][0/391]	Time 0.940 (0.940)	Data 0.349 (0.349)	Loss 0.4000 (0.4000)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [159][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4972 (0.4516)	Prec@1 86.719 (85.002)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [159][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3752 (0.4678)	Prec@1 85.938 (84.173)	Prec@5 99.219 (99.359)
TRAINING - Epoch: [159][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.6276 (0.4705)	Prec@1 78.906 (84.191)	Prec@5 98.438 (99.377)
EVALUATING - Epoch: [159][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 0.7307 (0.7307)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:58

 Epoch: 160	Training Loss 0.4759 	Training Prec@1 83.998 	Training Prec@5 99.356 	Validation Loss 0.7809 	Validation Prec@1 76.750 	Validation Prec@5 98.300 

lr: 0.09436267262876803
TRAINING - Epoch: [160][0/391]	Time 1.019 (1.019)	Data 0.385 (0.385)	Loss 0.3676 (0.3676)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [160][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.4397 (0.4466)	Prec@1 82.031 (84.684)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [160][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.3628 (0.4473)	Prec@1 85.938 (84.764)	Prec@5 99.219 (99.460)
TRAINING - Epoch: [160][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3911 (0.4506)	Prec@1 88.281 (84.637)	Prec@5 98.438 (99.416)
EVALUATING - Epoch: [160][0/79]	Time 0.358 (0.358)	Data 0.334 (0.334)	Loss 0.9306 (0.9306)	Prec@1 74.219 (74.219)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:28:28

 Epoch: 161	Training Loss 0.4546 	Training Prec@1 84.558 	Training Prec@5 99.390 	Validation Loss 1.0144 	Validation Prec@1 71.950 	Validation Prec@5 97.440 

lr: 0.09428970302463179
TRAINING - Epoch: [161][0/391]	Time 0.953 (0.953)	Data 0.351 (0.351)	Loss 0.5699 (0.5699)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [161][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.4163 (0.4391)	Prec@1 85.938 (85.017)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [161][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3804 (0.4437)	Prec@1 86.719 (84.966)	Prec@5 100.000 (99.413)
TRAINING - Epoch: [161][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.4786 (0.4448)	Prec@1 85.938 (84.863)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [161][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.6352 (0.6352)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:04

 Epoch: 162	Training Loss 0.4523 	Training Prec@1 84.590 	Training Prec@5 99.364 	Validation Loss 0.7052 	Validation Prec@1 77.970 	Validation Prec@5 98.470 

lr: 0.09421629278094386
TRAINING - Epoch: [162][0/391]	Time 0.924 (0.924)	Data 0.354 (0.354)	Loss 0.2882 (0.2882)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [162][100/391]	Time 0.060 (0.072)	Data 0.000 (0.004)	Loss 0.3409 (0.4374)	Prec@1 88.281 (84.901)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [162][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5126 (0.4514)	Prec@1 83.594 (84.604)	Prec@5 98.438 (99.413)
TRAINING - Epoch: [162][300/391]	Time 0.068 (0.066)	Data 0.000 (0.001)	Loss 0.4668 (0.4533)	Prec@1 88.281 (84.492)	Prec@5 99.219 (99.413)
EVALUATING - Epoch: [162][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.6123 (0.6123)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:00

 Epoch: 163	Training Loss 0.4573 	Training Prec@1 84.368 	Training Prec@5 99.382 	Validation Loss 0.7732 	Validation Prec@1 77.440 	Validation Prec@5 98.630 

lr: 0.09414244262806495
TRAINING - Epoch: [163][0/391]	Time 0.918 (0.918)	Data 0.353 (0.353)	Loss 0.6428 (0.6428)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [163][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.3821 (0.4562)	Prec@1 83.594 (84.537)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [163][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.5550 (0.4523)	Prec@1 79.688 (84.600)	Prec@5 98.438 (99.363)
TRAINING - Epoch: [163][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.3366 (0.4554)	Prec@1 86.719 (84.515)	Prec@5 99.219 (99.333)
EVALUATING - Epoch: [163][0/79]	Time 0.398 (0.398)	Data 0.373 (0.373)	Loss 0.7991 (0.7991)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:31

 Epoch: 164	Training Loss 0.4556 	Training Prec@1 84.524 	Training Prec@5 99.324 	Validation Loss 0.9183 	Validation Prec@1 73.890 	Validation Prec@5 98.090 

lr: 0.09406815330073239
TRAINING - Epoch: [164][0/391]	Time 0.945 (0.945)	Data 0.373 (0.373)	Loss 0.4923 (0.4923)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [164][100/391]	Time 0.070 (0.072)	Data 0.000 (0.004)	Loss 0.4762 (0.4554)	Prec@1 83.594 (84.599)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [164][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3548 (0.4540)	Prec@1 90.625 (84.667)	Prec@5 99.219 (99.382)
TRAINING - Epoch: [164][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.5254 (0.4561)	Prec@1 82.031 (84.476)	Prec@5 100.000 (99.413)
EVALUATING - Epoch: [164][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.9092 (0.9092)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:06

 Epoch: 165	Training Loss 0.4600 	Training Prec@1 84.304 	Training Prec@5 99.374 	Validation Loss 0.8432 	Validation Prec@1 74.870 	Validation Prec@5 98.720 

lr: 0.09399342553805283
TRAINING - Epoch: [165][0/391]	Time 0.962 (0.962)	Data 0.352 (0.352)	Loss 0.2132 (0.2132)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [165][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.6529 (0.4525)	Prec@1 78.125 (84.476)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [165][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.3845 (0.4467)	Prec@1 87.500 (84.686)	Prec@5 99.219 (99.351)
TRAINING - Epoch: [165][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.3692 (0.4484)	Prec@1 85.156 (84.712)	Prec@5 99.219 (99.346)
EVALUATING - Epoch: [165][0/79]	Time 0.378 (0.378)	Data 0.351 (0.351)	Loss 0.4775 (0.4775)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:29:47

 Epoch: 166	Training Loss 0.4556 	Training Prec@1 84.524 	Training Prec@5 99.326 	Validation Loss 0.6564 	Validation Prec@1 79.250 	Validation Prec@5 98.740 

lr: 0.093918260083495
TRAINING - Epoch: [166][0/391]	Time 0.989 (0.989)	Data 0.374 (0.374)	Loss 0.4506 (0.4506)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [166][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3372 (0.4478)	Prec@1 85.938 (84.700)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [166][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4068 (0.4447)	Prec@1 86.719 (84.873)	Prec@5 100.000 (99.405)
TRAINING - Epoch: [166][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4581 (0.4517)	Prec@1 85.156 (84.546)	Prec@5 99.219 (99.372)
EVALUATING - Epoch: [166][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.6992 (0.6992)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:50

 Epoch: 167	Training Loss 0.4589 	Training Prec@1 84.364 	Training Prec@5 99.332 	Validation Loss 0.7029 	Validation Prec@1 78.560 	Validation Prec@5 98.310 

lr: 0.09384265768488219
TRAINING - Epoch: [167][0/391]	Time 0.909 (0.909)	Data 0.354 (0.354)	Loss 0.4321 (0.4321)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [167][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5975 (0.4444)	Prec@1 82.031 (84.886)	Prec@5 98.438 (99.366)
TRAINING - Epoch: [167][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6163 (0.4449)	Prec@1 78.125 (84.954)	Prec@5 99.219 (99.413)
TRAINING - Epoch: [167][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3225 (0.4449)	Prec@1 88.281 (84.928)	Prec@5 100.000 (99.400)
EVALUATING - Epoch: [167][0/79]	Time 0.365 (0.365)	Data 0.346 (0.346)	Loss 0.6284 (0.6284)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:31

 Epoch: 168	Training Loss 0.4475 	Training Prec@1 84.762 	Training Prec@5 99.412 	Validation Loss 0.6527 	Validation Prec@1 79.120 	Validation Prec@5 98.870 

lr: 0.0937666190943849
TRAINING - Epoch: [168][0/391]	Time 0.901 (0.901)	Data 0.342 (0.342)	Loss 0.3887 (0.3887)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [168][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5046 (0.4489)	Prec@1 82.031 (84.746)	Prec@5 98.438 (99.304)
TRAINING - Epoch: [168][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3321 (0.4526)	Prec@1 85.156 (84.464)	Prec@5 100.000 (99.316)
TRAINING - Epoch: [168][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.6215 (0.4520)	Prec@1 78.906 (84.507)	Prec@5 100.000 (99.356)
EVALUATING - Epoch: [168][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.4829 (0.4829)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:14

 Epoch: 169	Training Loss 0.4512 	Training Prec@1 84.530 	Training Prec@5 99.354 	Validation Loss 0.6223 	Validation Prec@1 79.820 	Validation Prec@5 98.730 

lr: 0.09369014506851328
TRAINING - Epoch: [169][0/391]	Time 0.934 (0.934)	Data 0.375 (0.375)	Loss 0.3818 (0.3818)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [169][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4910 (0.4268)	Prec@1 83.594 (85.373)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [169][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3615 (0.4378)	Prec@1 89.062 (85.044)	Prec@5 100.000 (99.339)
TRAINING - Epoch: [169][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5408 (0.4385)	Prec@1 82.031 (84.910)	Prec@5 99.219 (99.351)
EVALUATING - Epoch: [169][0/79]	Time 0.370 (0.370)	Data 0.351 (0.351)	Loss 0.5962 (0.5962)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 170	Training Loss 0.4396 	Training Prec@1 84.834 	Training Prec@5 99.348 	Validation Loss 0.6455 	Validation Prec@1 79.120 	Validation Prec@5 98.740 

lr: 0.09361323636810964
TRAINING - Epoch: [170][0/391]	Time 0.926 (0.926)	Data 0.370 (0.370)	Loss 0.4621 (0.4621)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [170][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4342 (0.4455)	Prec@1 83.594 (84.506)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [170][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4438 (0.4372)	Prec@1 81.250 (85.001)	Prec@5 100.000 (99.366)
TRAINING - Epoch: [170][300/391]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.6478 (0.4408)	Prec@1 76.562 (84.829)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [170][0/79]	Time 0.357 (0.357)	Data 0.335 (0.335)	Loss 0.7141 (0.7141)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:42

 Epoch: 171	Training Loss 0.4410 	Training Prec@1 84.828 	Training Prec@5 99.414 	Validation Loss 0.7515 	Validation Prec@1 76.360 	Validation Prec@5 98.850 

lr: 0.0935358937583409
TRAINING - Epoch: [171][0/391]	Time 0.950 (0.950)	Data 0.376 (0.376)	Loss 0.5918 (0.5918)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [171][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3880 (0.4284)	Prec@1 84.375 (85.079)	Prec@5 100.000 (99.551)
TRAINING - Epoch: [171][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6021 (0.4337)	Prec@1 83.594 (85.059)	Prec@5 100.000 (99.448)
TRAINING - Epoch: [171][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4108 (0.4490)	Prec@1 84.375 (84.658)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [171][0/79]	Time 0.339 (0.339)	Data 0.317 (0.317)	Loss 0.8701 (0.8701)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 172	Training Loss 0.4533 	Training Prec@1 84.488 	Training Prec@5 99.400 	Validation Loss 0.7775 	Validation Prec@1 76.610 	Validation Prec@5 98.020 

lr: 0.09345811800869096
TRAINING - Epoch: [172][0/391]	Time 0.950 (0.950)	Data 0.355 (0.355)	Loss 0.3878 (0.3878)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [172][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4308 (0.4263)	Prec@1 84.375 (85.110)	Prec@5 99.219 (99.489)
TRAINING - Epoch: [172][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5840 (0.4297)	Prec@1 75.781 (85.226)	Prec@5 100.000 (99.483)
TRAINING - Epoch: [172][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4521 (0.4354)	Prec@1 84.375 (84.975)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [172][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.7725 (0.7725)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:08

 Epoch: 173	Training Loss 0.4422 	Training Prec@1 84.708 	Training Prec@5 99.418 	Validation Loss 0.6737 	Validation Prec@1 78.510 	Validation Prec@5 98.980 

lr: 0.093379909892953
TRAINING - Epoch: [173][0/391]	Time 0.925 (0.925)	Data 0.357 (0.357)	Loss 0.2971 (0.2971)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [173][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.3573 (0.4211)	Prec@1 87.500 (85.736)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [173][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5052 (0.4614)	Prec@1 83.594 (84.515)	Prec@5 99.219 (99.382)
TRAINING - Epoch: [173][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4381 (0.4656)	Prec@1 87.500 (84.209)	Prec@5 99.219 (99.372)
EVALUATING - Epoch: [173][0/79]	Time 0.351 (0.351)	Data 0.326 (0.326)	Loss 0.7342 (0.7342)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:08

 Epoch: 174	Training Loss 0.4667 	Training Prec@1 84.212 	Training Prec@5 99.380 	Validation Loss 0.7185 	Validation Prec@1 77.630 	Validation Prec@5 98.580 

lr: 0.09330127018922188
TRAINING - Epoch: [174][0/391]	Time 0.906 (0.906)	Data 0.343 (0.343)	Loss 0.2756 (0.2756)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [174][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4475 (0.4413)	Prec@1 86.719 (84.916)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [174][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4660 (0.4409)	Prec@1 82.812 (84.962)	Prec@5 100.000 (99.390)
TRAINING - Epoch: [174][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4584 (0.4502)	Prec@1 86.719 (84.671)	Prec@5 98.438 (99.390)
EVALUATING - Epoch: [174][0/79]	Time 0.394 (0.394)	Data 0.369 (0.369)	Loss 0.6278 (0.6278)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 175	Training Loss 0.4515 	Training Prec@1 84.656 	Training Prec@5 99.406 	Validation Loss 0.6886 	Validation Prec@1 79.410 	Validation Prec@5 98.710 

lr: 0.09322219967988632
TRAINING - Epoch: [175][0/391]	Time 0.918 (0.918)	Data 0.357 (0.357)	Loss 0.4425 (0.4425)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [175][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3339 (0.4632)	Prec@1 85.938 (84.336)	Prec@5 100.000 (99.505)
TRAINING - Epoch: [175][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4893 (0.4500)	Prec@1 84.375 (84.818)	Prec@5 99.219 (99.468)
TRAINING - Epoch: [175][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4859 (0.4522)	Prec@1 86.719 (84.583)	Prec@5 98.438 (99.429)
EVALUATING - Epoch: [175][0/79]	Time 0.336 (0.336)	Data 0.318 (0.318)	Loss 0.7352 (0.7352)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:09

 Epoch: 176	Training Loss 0.4502 	Training Prec@1 84.612 	Training Prec@5 99.420 	Validation Loss 0.7498 	Validation Prec@1 76.370 	Validation Prec@5 98.870 

lr: 0.0931426991516211
TRAINING - Epoch: [176][0/391]	Time 0.928 (0.928)	Data 0.361 (0.361)	Loss 0.3766 (0.3766)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [176][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4583 (0.4560)	Prec@1 83.594 (84.352)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [176][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.7421 (0.4522)	Prec@1 79.688 (84.468)	Prec@5 97.656 (99.363)
TRAINING - Epoch: [176][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4630 (0.4618)	Prec@1 85.156 (84.243)	Prec@5 100.000 (99.336)
EVALUATING - Epoch: [176][0/79]	Time 0.385 (0.385)	Data 0.366 (0.366)	Loss 0.7358 (0.7358)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:47

 Epoch: 177	Training Loss 0.4616 	Training Prec@1 84.266 	Training Prec@5 99.344 	Validation Loss 0.8583 	Validation Prec@1 74.830 	Validation Prec@5 98.240 

lr: 0.09306276939537932
TRAINING - Epoch: [177][0/391]	Time 0.922 (0.922)	Data 0.358 (0.358)	Loss 0.3582 (0.3582)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [177][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2869 (0.4344)	Prec@1 89.062 (84.994)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [177][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5598 (0.4440)	Prec@1 79.688 (84.818)	Prec@5 99.219 (99.370)
TRAINING - Epoch: [177][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.4530 (0.4503)	Prec@1 85.938 (84.666)	Prec@5 99.219 (99.364)
EVALUATING - Epoch: [177][0/79]	Time 0.378 (0.378)	Data 0.353 (0.353)	Loss 0.8454 (0.8454)	Prec@1 72.656 (72.656)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 178	Training Loss 0.4582 	Training Prec@1 84.556 	Training Prec@5 99.364 	Validation Loss 0.8282 	Validation Prec@1 74.890 	Validation Prec@5 97.780 

lr: 0.09298241120638447
TRAINING - Epoch: [178][0/391]	Time 0.935 (0.935)	Data 0.344 (0.344)	Loss 0.4769 (0.4769)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [178][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5703 (0.4579)	Prec@1 80.469 (84.592)	Prec@5 100.000 (99.304)
TRAINING - Epoch: [178][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.5973 (0.4536)	Prec@1 85.156 (84.608)	Prec@5 97.656 (99.355)
TRAINING - Epoch: [178][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4441 (0.4579)	Prec@1 82.812 (84.406)	Prec@5 100.000 (99.359)
EVALUATING - Epoch: [178][0/79]	Time 0.353 (0.353)	Data 0.332 (0.332)	Loss 0.5837 (0.5837)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:05

 Epoch: 179	Training Loss 0.4592 	Training Prec@1 84.476 	Training Prec@5 99.356 	Validation Loss 0.6623 	Validation Prec@1 79.110 	Validation Prec@5 98.510 

lr: 0.09290162538412251
TRAINING - Epoch: [179][0/391]	Time 0.943 (0.943)	Data 0.371 (0.371)	Loss 0.4903 (0.4903)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [179][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4716 (0.4660)	Prec@1 84.375 (84.336)	Prec@5 99.219 (99.373)
TRAINING - Epoch: [179][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4070 (0.4597)	Prec@1 89.062 (84.348)	Prec@5 100.000 (99.409)
TRAINING - Epoch: [179][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.7316 (0.4642)	Prec@1 78.906 (84.245)	Prec@5 99.219 (99.419)
EVALUATING - Epoch: [179][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.6063 (0.6063)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:37

 Epoch: 180	Training Loss 0.4689 	Training Prec@1 84.122 	Training Prec@5 99.400 	Validation Loss 0.7222 	Validation Prec@1 77.760 	Validation Prec@5 98.480 

lr: 0.09282041273233398
TRAINING - Epoch: [180][0/391]	Time 0.920 (0.920)	Data 0.344 (0.344)	Loss 0.2734 (0.2734)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [180][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4675 (0.4351)	Prec@1 82.812 (85.187)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [180][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4723 (0.4617)	Prec@1 81.250 (84.301)	Prec@5 100.000 (99.370)
TRAINING - Epoch: [180][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3762 (0.4648)	Prec@1 85.156 (84.258)	Prec@5 99.219 (99.380)
EVALUATING - Epoch: [180][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.7080 (0.7080)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 181	Training Loss 0.4607 	Training Prec@1 84.422 	Training Prec@5 99.376 	Validation Loss 0.8273 	Validation Prec@1 76.410 	Validation Prec@5 97.540 

lr: 0.09273877405900588
TRAINING - Epoch: [181][0/391]	Time 0.913 (0.913)	Data 0.346 (0.346)	Loss 0.3534 (0.3534)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [181][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3212 (0.4420)	Prec@1 89.844 (85.094)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [181][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5560 (0.4514)	Prec@1 80.469 (84.600)	Prec@5 99.219 (99.382)
TRAINING - Epoch: [181][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3621 (0.4534)	Prec@1 86.719 (84.609)	Prec@5 99.219 (99.354)
EVALUATING - Epoch: [181][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.6605 (0.6605)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 182	Training Loss 0.4493 	Training Prec@1 84.702 	Training Prec@5 99.348 	Validation Loss 0.5918 	Validation Prec@1 80.790 	Validation Prec@5 99.020 

lr: 0.09265671017636379
TRAINING - Epoch: [182][0/391]	Time 0.929 (0.929)	Data 0.378 (0.378)	Loss 0.2775 (0.2775)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [182][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3603 (0.4583)	Prec@1 85.938 (84.421)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [182][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3961 (0.4430)	Prec@1 89.062 (85.063)	Prec@5 99.219 (99.386)
TRAINING - Epoch: [182][300/391]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.5187 (0.4487)	Prec@1 79.688 (84.785)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [182][0/79]	Time 0.366 (0.366)	Data 0.343 (0.343)	Loss 0.6858 (0.6858)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:04

 Epoch: 183	Training Loss 0.4438 	Training Prec@1 85.016 	Training Prec@5 99.384 	Validation Loss 0.7560 	Validation Prec@1 77.470 	Validation Prec@5 98.210 

lr: 0.09257422190086369
TRAINING - Epoch: [183][0/391]	Time 0.955 (0.955)	Data 0.368 (0.368)	Loss 0.4605 (0.4605)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [183][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4190 (0.4371)	Prec@1 85.156 (85.002)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [183][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4443 (0.4524)	Prec@1 85.156 (84.663)	Prec@5 99.219 (99.308)
TRAINING - Epoch: [183][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3851 (0.4506)	Prec@1 85.938 (84.645)	Prec@5 100.000 (99.325)
EVALUATING - Epoch: [183][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.5371 (0.5371)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:08

 Epoch: 184	Training Loss 0.4538 	Training Prec@1 84.572 	Training Prec@5 99.320 	Validation Loss 0.5738 	Validation Prec@1 81.080 	Validation Prec@5 98.900 

lr: 0.09249131005318383
TRAINING - Epoch: [184][0/391]	Time 0.903 (0.903)	Data 0.335 (0.335)	Loss 0.6251 (0.6251)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [184][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2974 (0.4381)	Prec@1 88.281 (84.978)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [184][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4565 (0.4496)	Prec@1 85.938 (84.748)	Prec@5 99.219 (99.398)
TRAINING - Epoch: [184][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6543 (0.4532)	Prec@1 78.906 (84.539)	Prec@5 97.656 (99.385)
EVALUATING - Epoch: [184][0/79]	Time 0.374 (0.374)	Data 0.352 (0.352)	Loss 0.8104 (0.8104)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:39

 Epoch: 185	Training Loss 0.4537 	Training Prec@1 84.444 	Training Prec@5 99.382 	Validation Loss 0.8007 	Validation Prec@1 75.220 	Validation Prec@5 98.380 

lr: 0.09240797545821662
TRAINING - Epoch: [185][0/391]	Time 0.919 (0.919)	Data 0.333 (0.333)	Loss 0.3086 (0.3086)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [185][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3740 (0.4402)	Prec@1 89.062 (85.110)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [185][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3653 (0.4444)	Prec@1 85.938 (85.110)	Prec@5 100.000 (99.433)
TRAINING - Epoch: [185][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.5203 (0.4449)	Prec@1 84.375 (84.962)	Prec@5 99.219 (99.411)
EVALUATING - Epoch: [185][0/79]	Time 0.362 (0.362)	Data 0.341 (0.341)	Loss 0.6478 (0.6478)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:40

 Epoch: 186	Training Loss 0.4541 	Training Prec@1 84.606 	Training Prec@5 99.388 	Validation Loss 0.6857 	Validation Prec@1 78.400 	Validation Prec@5 98.440 

lr: 0.09232421894506036
TRAINING - Epoch: [186][0/391]	Time 0.927 (0.927)	Data 0.357 (0.357)	Loss 0.3305 (0.3305)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [186][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.5305 (0.4382)	Prec@1 80.469 (84.839)	Prec@5 99.219 (99.428)
TRAINING - Epoch: [186][200/391]	Time 0.067 (0.067)	Data 0.000 (0.002)	Loss 0.3535 (0.4481)	Prec@1 86.719 (84.705)	Prec@5 100.000 (99.390)
TRAINING - Epoch: [186][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.5728 (0.4484)	Prec@1 79.688 (84.684)	Prec@5 99.219 (99.406)
EVALUATING - Epoch: [186][0/79]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.5318 (0.5318)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:05

 Epoch: 187	Training Loss 0.4504 	Training Prec@1 84.672 	Training Prec@5 99.376 	Validation Loss 0.6272 	Validation Prec@1 79.530 	Validation Prec@5 99.030 

lr: 0.0922400413470111
TRAINING - Epoch: [187][0/391]	Time 1.046 (1.046)	Data 0.398 (0.398)	Loss 0.3652 (0.3652)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [187][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.2812 (0.4527)	Prec@1 86.719 (84.329)	Prec@5 100.000 (99.373)
TRAINING - Epoch: [187][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3116 (0.4453)	Prec@1 87.500 (84.709)	Prec@5 100.000 (99.401)
TRAINING - Epoch: [187][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5430 (0.4491)	Prec@1 86.719 (84.710)	Prec@5 99.219 (99.369)
EVALUATING - Epoch: [187][0/79]	Time 0.371 (0.371)	Data 0.350 (0.350)	Loss 0.5903 (0.5903)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:47

 Epoch: 188	Training Loss 0.4517 	Training Prec@1 84.654 	Training Prec@5 99.360 	Validation Loss 0.6889 	Validation Prec@1 79.110 	Validation Prec@5 98.620 

lr: 0.09215544350155419
TRAINING - Epoch: [188][0/391]	Time 0.919 (0.919)	Data 0.362 (0.362)	Loss 0.3640 (0.3640)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [188][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3229 (0.4244)	Prec@1 88.281 (85.481)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [188][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3995 (0.4370)	Prec@1 88.281 (85.389)	Prec@5 100.000 (99.491)
TRAINING - Epoch: [188][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3697 (0.4395)	Prec@1 85.938 (85.257)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [188][0/79]	Time 0.372 (0.372)	Data 0.349 (0.349)	Loss 0.5742 (0.5742)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:55

 Epoch: 189	Training Loss 0.4423 	Training Prec@1 85.032 	Training Prec@5 99.446 	Validation Loss 0.6509 	Validation Prec@1 79.810 	Validation Prec@5 98.450 

lr: 0.09207042625035607
TRAINING - Epoch: [189][0/391]	Time 0.916 (0.916)	Data 0.344 (0.344)	Loss 0.3170 (0.3170)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [189][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3921 (0.4129)	Prec@1 89.062 (86.061)	Prec@5 99.219 (99.528)
TRAINING - Epoch: [189][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3658 (0.4184)	Prec@1 85.938 (85.887)	Prec@5 100.000 (99.506)
TRAINING - Epoch: [189][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4862 (0.4231)	Prec@1 83.594 (85.590)	Prec@5 100.000 (99.486)
EVALUATING - Epoch: [189][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.6335 (0.6335)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:42

 Epoch: 190	Training Loss 0.4342 	Training Prec@1 85.262 	Training Prec@5 99.456 	Validation Loss 0.6534 	Validation Prec@1 79.940 	Validation Prec@5 98.690 

lr: 0.09198499043925586
TRAINING - Epoch: [190][0/391]	Time 0.934 (0.934)	Data 0.382 (0.382)	Loss 0.4692 (0.4692)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [190][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3499 (0.4377)	Prec@1 91.406 (85.280)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [190][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4904 (0.4375)	Prec@1 83.594 (85.191)	Prec@5 99.219 (99.413)
TRAINING - Epoch: [190][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5318 (0.4403)	Prec@1 81.250 (85.203)	Prec@5 97.656 (99.419)
EVALUATING - Epoch: [190][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 1.4121 (1.4121)	Prec@1 64.062 (64.062)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 191	Training Loss 0.4439 	Training Prec@1 84.974 	Training Prec@5 99.416 	Validation Loss 1.4921 	Validation Prec@1 62.860 	Validation Prec@5 96.560 

lr: 0.09189913691825695
TRAINING - Epoch: [191][0/391]	Time 0.909 (0.909)	Data 0.339 (0.339)	Loss 0.2628 (0.2628)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [191][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2814 (0.4224)	Prec@1 88.281 (85.930)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [191][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4777 (0.4316)	Prec@1 77.344 (85.389)	Prec@5 100.000 (99.363)
TRAINING - Epoch: [191][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.7288 (0.4407)	Prec@1 77.344 (85.081)	Prec@5 98.438 (99.349)
EVALUATING - Epoch: [191][0/79]	Time 0.376 (0.376)	Data 0.355 (0.355)	Loss 0.7647 (0.7647)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:03

 Epoch: 192	Training Loss 0.4475 	Training Prec@1 84.838 	Training Prec@5 99.332 	Validation Loss 0.8956 	Validation Prec@1 75.160 	Validation Prec@5 97.990 

lr: 0.09181286654151855
TRAINING - Epoch: [192][0/391]	Time 0.929 (0.929)	Data 0.360 (0.360)	Loss 0.4202 (0.4202)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [192][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3882 (0.4638)	Prec@1 85.156 (84.429)	Prec@5 100.000 (99.335)
TRAINING - Epoch: [192][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.5459 (0.4631)	Prec@1 80.469 (84.394)	Prec@5 100.000 (99.374)
TRAINING - Epoch: [192][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5170 (0.4652)	Prec@1 81.250 (84.305)	Prec@5 98.438 (99.372)
EVALUATING - Epoch: [192][0/79]	Time 0.335 (0.335)	Data 0.314 (0.314)	Loss 0.6882 (0.6882)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:02

 Epoch: 193	Training Loss 0.4610 	Training Prec@1 84.436 	Training Prec@5 99.384 	Validation Loss 0.6507 	Validation Prec@1 79.860 	Validation Prec@5 98.570 

lr: 0.09172618016734714
TRAINING - Epoch: [193][0/391]	Time 0.921 (0.921)	Data 0.366 (0.366)	Loss 0.5848 (0.5848)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [193][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4400 (0.4413)	Prec@1 82.031 (85.149)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [193][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3327 (0.4433)	Prec@1 86.719 (85.110)	Prec@5 100.000 (99.370)
TRAINING - Epoch: [193][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4959 (0.4515)	Prec@1 81.250 (84.821)	Prec@5 100.000 (99.367)
EVALUATING - Epoch: [193][0/79]	Time 0.366 (0.366)	Data 0.346 (0.346)	Loss 0.7181 (0.7181)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 194	Training Loss 0.4521 	Training Prec@1 84.818 	Training Prec@5 99.364 	Validation Loss 0.8126 	Validation Prec@1 75.790 	Validation Prec@5 98.640 

lr: 0.09163907865818802
TRAINING - Epoch: [194][0/391]	Time 0.945 (0.945)	Data 0.377 (0.377)	Loss 0.3879 (0.3879)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [194][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4716 (0.4485)	Prec@1 84.375 (84.777)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [194][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4575 (0.4480)	Prec@1 83.594 (84.756)	Prec@5 99.219 (99.413)
TRAINING - Epoch: [194][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5662 (0.4446)	Prec@1 82.812 (84.892)	Prec@5 99.219 (99.387)
EVALUATING - Epoch: [194][0/79]	Time 0.377 (0.377)	Data 0.353 (0.353)	Loss 0.7363 (0.7363)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:58

 Epoch: 195	Training Loss 0.4430 	Training Prec@1 84.960 	Training Prec@5 99.398 	Validation Loss 0.7722 	Validation Prec@1 76.490 	Validation Prec@5 98.000 

lr: 0.09155156288061661
TRAINING - Epoch: [195][0/391]	Time 0.913 (0.913)	Data 0.342 (0.342)	Loss 0.5355 (0.5355)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [195][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4680 (0.4631)	Prec@1 82.031 (84.004)	Prec@5 99.219 (99.397)
TRAINING - Epoch: [195][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5145 (0.4519)	Prec@1 82.812 (84.495)	Prec@5 100.000 (99.394)
TRAINING - Epoch: [195][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3779 (0.4509)	Prec@1 89.844 (84.476)	Prec@5 100.000 (99.380)
EVALUATING - Epoch: [195][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.9063 (0.9063)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 196	Training Loss 0.4484 	Training Prec@1 84.592 	Training Prec@5 99.370 	Validation Loss 0.8288 	Validation Prec@1 75.310 	Validation Prec@5 97.980 

lr: 0.09146363370532998
TRAINING - Epoch: [196][0/391]	Time 0.899 (0.899)	Data 0.338 (0.338)	Loss 0.3839 (0.3839)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [196][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4681 (0.4521)	Prec@1 83.594 (84.491)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [196][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.5039 (0.4479)	Prec@1 83.594 (84.678)	Prec@5 99.219 (99.448)
TRAINING - Epoch: [196][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4701 (0.4461)	Prec@1 84.375 (84.655)	Prec@5 100.000 (99.463)
EVALUATING - Epoch: [196][0/79]	Time 0.373 (0.373)	Data 0.352 (0.352)	Loss 0.7805 (0.7805)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 197	Training Loss 0.4504 	Training Prec@1 84.586 	Training Prec@5 99.436 	Validation Loss 0.7569 	Validation Prec@1 77.400 	Validation Prec@5 98.360 

lr: 0.09137529200713805
TRAINING - Epoch: [197][0/391]	Time 0.950 (0.950)	Data 0.381 (0.381)	Loss 0.4891 (0.4891)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [197][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3807 (0.4191)	Prec@1 84.375 (85.814)	Prec@5 99.219 (99.528)
TRAINING - Epoch: [197][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.3045 (0.4407)	Prec@1 87.500 (84.954)	Prec@5 100.000 (99.491)
TRAINING - Epoch: [197][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.5495 (0.4441)	Prec@1 80.469 (84.772)	Prec@5 98.438 (99.424)
EVALUATING - Epoch: [197][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.6703 (0.6703)	Prec@1 80.469 (80.469)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:05

 Epoch: 198	Training Loss 0.4431 	Training Prec@1 84.776 	Training Prec@5 99.434 	Validation Loss 0.7337 	Validation Prec@1 78.320 	Validation Prec@5 98.330 

lr: 0.09128653866495498
TRAINING - Epoch: [198][0/391]	Time 0.938 (0.938)	Data 0.351 (0.351)	Loss 0.5049 (0.5049)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [198][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3526 (0.4301)	Prec@1 89.062 (85.558)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [198][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4646 (0.4257)	Prec@1 82.031 (85.401)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [198][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2757 (0.4283)	Prec@1 90.625 (85.309)	Prec@5 100.000 (99.471)
EVALUATING - Epoch: [198][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.7883 (0.7883)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:21

 Epoch: 199	Training Loss 0.4338 	Training Prec@1 85.160 	Training Prec@5 99.444 	Validation Loss 0.7476 	Validation Prec@1 79.000 	Validation Prec@5 98.200 

lr: 0.09119737456179036
TRAINING - Epoch: [199][0/391]	Time 0.934 (0.934)	Data 0.364 (0.364)	Loss 0.5930 (0.5930)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [199][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4749 (0.4358)	Prec@1 85.938 (85.009)	Prec@5 98.438 (99.451)
TRAINING - Epoch: [199][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2908 (0.4336)	Prec@1 89.062 (85.296)	Prec@5 100.000 (99.475)
TRAINING - Epoch: [199][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4131 (0.4403)	Prec@1 84.375 (85.006)	Prec@5 100.000 (99.452)
EVALUATING - Epoch: [199][0/79]	Time 0.357 (0.357)	Data 0.332 (0.332)	Loss 0.6068 (0.6068)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:38

 Epoch: 200	Training Loss 0.4409 	Training Prec@1 84.940 	Training Prec@5 99.422 	Validation Loss 0.7057 	Validation Prec@1 78.340 	Validation Prec@5 98.620 

lr: 0.09110780058474047
TRAINING - Epoch: [200][0/391]	Time 0.900 (0.900)	Data 0.355 (0.355)	Loss 0.4652 (0.4652)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [200][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4723 (0.4412)	Prec@1 79.688 (85.249)	Prec@5 99.219 (99.350)
TRAINING - Epoch: [200][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3810 (0.4474)	Prec@1 87.500 (85.005)	Prec@5 99.219 (99.339)
TRAINING - Epoch: [200][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6245 (0.4475)	Prec@1 78.906 (84.842)	Prec@5 99.219 (99.369)
EVALUATING - Epoch: [200][0/79]	Time 0.343 (0.343)	Data 0.322 (0.322)	Loss 0.7718 (0.7718)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:19

 Epoch: 201	Training Loss 0.4440 	Training Prec@1 84.938 	Training Prec@5 99.380 	Validation Loss 0.8553 	Validation Prec@1 74.540 	Validation Prec@5 98.670 

lr: 0.0910178176249794
TRAINING - Epoch: [201][0/391]	Time 0.892 (0.892)	Data 0.344 (0.344)	Loss 0.2824 (0.2824)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [201][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3164 (0.4197)	Prec@1 89.844 (85.922)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [201][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5872 (0.4327)	Prec@1 81.250 (85.339)	Prec@5 99.219 (99.460)
TRAINING - Epoch: [201][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.7268 (0.4413)	Prec@1 75.000 (85.094)	Prec@5 100.000 (99.421)
EVALUATING - Epoch: [201][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.6492 (0.6492)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 202	Training Loss 0.4503 	Training Prec@1 84.828 	Training Prec@5 99.368 	Validation Loss 0.7118 	Validation Prec@1 78.210 	Validation Prec@5 98.470 

lr: 0.09092742657775027
TRAINING - Epoch: [202][0/391]	Time 0.933 (0.933)	Data 0.380 (0.380)	Loss 0.5442 (0.5442)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [202][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5015 (0.4581)	Prec@1 83.594 (84.483)	Prec@5 98.438 (99.366)
TRAINING - Epoch: [202][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4463 (0.4651)	Prec@1 84.375 (84.356)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [202][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3843 (0.4540)	Prec@1 84.375 (84.676)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [202][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 0.6972 (0.6972)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:03

 Epoch: 203	Training Loss 0.4490 	Training Prec@1 84.858 	Training Prec@5 99.406 	Validation Loss 0.8717 	Validation Prec@1 73.730 	Validation Prec@5 98.260 

lr: 0.09083662834235627
TRAINING - Epoch: [203][0/391]	Time 0.900 (0.900)	Data 0.344 (0.344)	Loss 0.4585 (0.4585)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [203][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4531 (0.4466)	Prec@1 87.500 (84.638)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [203][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3911 (0.4487)	Prec@1 89.062 (84.834)	Prec@5 98.438 (99.293)
TRAINING - Epoch: [203][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3431 (0.4445)	Prec@1 87.500 (84.858)	Prec@5 100.000 (99.343)
EVALUATING - Epoch: [203][0/79]	Time 0.332 (0.332)	Data 0.310 (0.310)	Loss 0.5632 (0.5632)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:41

 Epoch: 204	Training Loss 0.4531 	Training Prec@1 84.634 	Training Prec@5 99.342 	Validation Loss 0.7166 	Validation Prec@1 78.160 	Validation Prec@5 98.180 

lr: 0.09074542382215167
TRAINING - Epoch: [204][0/391]	Time 0.898 (0.898)	Data 0.327 (0.327)	Loss 0.2690 (0.2690)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [204][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.4959 (0.4599)	Prec@1 85.938 (84.011)	Prec@5 98.438 (99.312)
TRAINING - Epoch: [204][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3878 (0.4479)	Prec@1 85.156 (84.468)	Prec@5 100.000 (99.316)
TRAINING - Epoch: [204][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.4472 (0.4452)	Prec@1 82.812 (84.611)	Prec@5 100.000 (99.372)
EVALUATING - Epoch: [204][0/79]	Time 0.367 (0.367)	Data 0.345 (0.345)	Loss 0.6378 (0.6378)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:30

 Epoch: 205	Training Loss 0.4450 	Training Prec@1 84.654 	Training Prec@5 99.390 	Validation Loss 0.7303 	Validation Prec@1 77.410 	Validation Prec@5 98.750 

lr: 0.09065381392453294
TRAINING - Epoch: [205][0/391]	Time 0.898 (0.898)	Data 0.334 (0.334)	Loss 0.4035 (0.4035)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [205][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4454 (0.4307)	Prec@1 83.594 (85.210)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [205][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3938 (0.4347)	Prec@1 85.156 (85.238)	Prec@5 100.000 (99.386)
TRAINING - Epoch: [205][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.5558 (0.4411)	Prec@1 82.812 (85.058)	Prec@5 99.219 (99.385)
EVALUATING - Epoch: [205][0/79]	Time 0.356 (0.356)	Data 0.332 (0.332)	Loss 0.6765 (0.6765)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:35

 Epoch: 206	Training Loss 0.4421 	Training Prec@1 85.004 	Training Prec@5 99.368 	Validation Loss 0.7729 	Validation Prec@1 75.960 	Validation Prec@5 98.730 

lr: 0.09056179956092959
TRAINING - Epoch: [206][0/391]	Time 0.925 (0.925)	Data 0.374 (0.374)	Loss 0.4606 (0.4606)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [206][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3240 (0.4323)	Prec@1 90.625 (84.994)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [206][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4445 (0.4345)	Prec@1 86.719 (85.044)	Prec@5 99.219 (99.464)
TRAINING - Epoch: [206][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4622 (0.4402)	Prec@1 82.031 (84.967)	Prec@5 100.000 (99.450)
EVALUATING - Epoch: [206][0/79]	Time 0.345 (0.345)	Data 0.324 (0.324)	Loss 0.8605 (0.8605)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 207	Training Loss 0.4368 	Training Prec@1 85.108 	Training Prec@5 99.442 	Validation Loss 0.8410 	Validation Prec@1 75.980 	Validation Prec@5 98.230 

lr: 0.09046938164679527
TRAINING - Epoch: [207][0/391]	Time 0.904 (0.904)	Data 0.344 (0.344)	Loss 0.3476 (0.3476)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [207][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4946 (0.4312)	Prec@1 84.375 (85.257)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [207][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.7179 (0.4317)	Prec@1 81.250 (85.195)	Prec@5 97.656 (99.433)
TRAINING - Epoch: [207][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3287 (0.4324)	Prec@1 88.281 (85.213)	Prec@5 99.219 (99.460)
EVALUATING - Epoch: [207][0/79]	Time 0.342 (0.342)	Data 0.323 (0.323)	Loss 1.1509 (1.1509)	Prec@1 70.312 (70.312)	Prec@5 92.969 (92.969)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:31

 Epoch: 208	Training Loss 0.4414 	Training Prec@1 84.938 	Training Prec@5 99.410 	Validation Loss 1.1258 	Validation Prec@1 70.650 	Validation Prec@5 94.770 

lr: 0.09037656110159846
TRAINING - Epoch: [208][0/391]	Time 0.931 (0.931)	Data 0.375 (0.375)	Loss 0.3917 (0.3917)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [208][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4026 (0.4406)	Prec@1 85.156 (84.978)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [208][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5255 (0.4360)	Prec@1 81.250 (85.001)	Prec@5 98.438 (99.534)
TRAINING - Epoch: [208][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4159 (0.4425)	Prec@1 88.281 (84.770)	Prec@5 99.219 (99.481)
EVALUATING - Epoch: [208][0/79]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.5845 (0.5845)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:25

 Epoch: 209	Training Loss 0.4415 	Training Prec@1 84.820 	Training Prec@5 99.458 	Validation Loss 0.5637 	Validation Prec@1 81.330 	Validation Prec@5 99.140 

lr: 0.09028333884881354
TRAINING - Epoch: [209][0/391]	Time 0.909 (0.909)	Data 0.349 (0.349)	Loss 0.3949 (0.3949)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [209][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3896 (0.4483)	Prec@1 87.500 (84.599)	Prec@5 99.219 (99.296)
TRAINING - Epoch: [209][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4624 (0.4417)	Prec@1 83.594 (84.814)	Prec@5 100.000 (99.347)
TRAINING - Epoch: [209][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3332 (0.4357)	Prec@1 83.594 (84.933)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [209][0/79]	Time 0.370 (0.370)	Data 0.348 (0.348)	Loss 0.9092 (0.9092)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:15

 Epoch: 210	Training Loss 0.4405 	Training Prec@1 84.810 	Training Prec@5 99.424 	Validation Loss 0.9015 	Validation Prec@1 74.300 	Validation Prec@5 97.820 

lr: 0.09018971581591138
TRAINING - Epoch: [210][0/391]	Time 0.939 (0.939)	Data 0.372 (0.372)	Loss 0.3817 (0.3817)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [210][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3941 (0.4135)	Prec@1 86.719 (85.218)	Prec@5 100.000 (99.513)
TRAINING - Epoch: [210][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3281 (0.4256)	Prec@1 85.938 (85.055)	Prec@5 99.219 (99.440)
TRAINING - Epoch: [210][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5081 (0.4287)	Prec@1 82.812 (85.091)	Prec@5 100.000 (99.437)
EVALUATING - Epoch: [210][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.6502 (0.6502)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:15

 Epoch: 211	Training Loss 0.4308 	Training Prec@1 85.070 	Training Prec@5 99.436 	Validation Loss 0.7498 	Validation Prec@1 76.870 	Validation Prec@5 98.310 

lr: 0.09009569293435031
TRAINING - Epoch: [211][0/391]	Time 0.919 (0.919)	Data 0.354 (0.354)	Loss 0.3970 (0.3970)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [211][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3938 (0.4293)	Prec@1 85.938 (85.288)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [211][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4901 (0.4267)	Prec@1 87.500 (85.506)	Prec@5 98.438 (99.460)
TRAINING - Epoch: [211][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4268 (0.4282)	Prec@1 87.500 (85.374)	Prec@5 100.000 (99.468)
EVALUATING - Epoch: [211][0/79]	Time 0.375 (0.375)	Data 0.353 (0.353)	Loss 0.8275 (0.8275)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 212	Training Loss 0.4344 	Training Prec@1 85.178 	Training Prec@5 99.438 	Validation Loss 0.9058 	Validation Prec@1 74.240 	Validation Prec@5 98.060 

lr: 0.0900012711395667
TRAINING - Epoch: [212][0/391]	Time 0.928 (0.928)	Data 0.357 (0.357)	Loss 0.3724 (0.3724)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [212][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.5677 (0.4497)	Prec@1 82.031 (84.831)	Prec@5 98.438 (99.288)
TRAINING - Epoch: [212][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3737 (0.4497)	Prec@1 87.500 (84.744)	Prec@5 99.219 (99.285)
TRAINING - Epoch: [212][300/391]	Time 0.063 (0.066)	Data 0.001 (0.001)	Loss 0.5507 (0.4505)	Prec@1 81.250 (84.679)	Prec@5 99.219 (99.328)
EVALUATING - Epoch: [212][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.6607 (0.6607)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:00

 Epoch: 213	Training Loss 0.4533 	Training Prec@1 84.616 	Training Prec@5 99.354 	Validation Loss 0.7911 	Validation Prec@1 76.460 	Validation Prec@5 98.350 

lr: 0.08990645137096577
TRAINING - Epoch: [213][0/391]	Time 0.902 (0.902)	Data 0.335 (0.335)	Loss 0.3712 (0.3712)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [213][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4666 (0.4330)	Prec@1 83.594 (85.326)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [213][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4436 (0.4456)	Prec@1 87.500 (84.810)	Prec@5 100.000 (99.479)
TRAINING - Epoch: [213][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.4085 (0.4466)	Prec@1 86.719 (84.746)	Prec@5 99.219 (99.486)
EVALUATING - Epoch: [213][0/79]	Time 0.354 (0.354)	Data 0.333 (0.333)	Loss 0.7352 (0.7352)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 214	Training Loss 0.4410 	Training Prec@1 84.902 	Training Prec@5 99.494 	Validation Loss 0.6866 	Validation Prec@1 79.330 	Validation Prec@5 98.420 

lr: 0.08981123457191216
TRAINING - Epoch: [214][0/391]	Time 0.905 (0.905)	Data 0.349 (0.349)	Loss 0.4243 (0.4243)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [214][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2912 (0.4145)	Prec@1 89.844 (85.582)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [214][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5572 (0.4183)	Prec@1 82.812 (85.650)	Prec@5 99.219 (99.510)
TRAINING - Epoch: [214][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5947 (0.4236)	Prec@1 80.469 (85.437)	Prec@5 100.000 (99.491)
EVALUATING - Epoch: [214][0/79]	Time 0.356 (0.356)	Data 0.332 (0.332)	Loss 0.6376 (0.6376)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:15

 Epoch: 215	Training Loss 0.4226 	Training Prec@1 85.478 	Training Prec@5 99.470 	Validation Loss 0.8115 	Validation Prec@1 75.970 	Validation Prec@5 97.880 

lr: 0.08971562168972062
TRAINING - Epoch: [215][0/391]	Time 0.926 (0.926)	Data 0.343 (0.343)	Loss 0.4116 (0.4116)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [215][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5701 (0.4150)	Prec@1 81.250 (85.713)	Prec@5 98.438 (99.513)
TRAINING - Epoch: [215][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4691 (0.4213)	Prec@1 86.719 (85.483)	Prec@5 98.438 (99.526)
TRAINING - Epoch: [215][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4510 (0.4255)	Prec@1 83.594 (85.374)	Prec@5 100.000 (99.481)
EVALUATING - Epoch: [215][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.5004 (0.5004)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:19

 Epoch: 216	Training Loss 0.4301 	Training Prec@1 85.230 	Training Prec@5 99.460 	Validation Loss 0.5702 	Validation Prec@1 81.730 	Validation Prec@5 99.060 

lr: 0.08961961367564647
TRAINING - Epoch: [216][0/391]	Time 0.951 (0.951)	Data 0.393 (0.393)	Loss 0.4408 (0.4408)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [216][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4804 (0.4257)	Prec@1 82.812 (85.326)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [216][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3903 (0.4329)	Prec@1 85.938 (85.253)	Prec@5 97.656 (99.491)
TRAINING - Epoch: [216][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3948 (0.4360)	Prec@1 85.938 (85.193)	Prec@5 99.219 (99.478)
EVALUATING - Epoch: [216][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.5632 (0.5632)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 217	Training Loss 0.4336 	Training Prec@1 85.284 	Training Prec@5 99.448 	Validation Loss 0.6619 	Validation Prec@1 79.570 	Validation Prec@5 98.470 

lr: 0.08952321148487627
TRAINING - Epoch: [217][0/391]	Time 0.918 (0.918)	Data 0.343 (0.343)	Loss 0.4794 (0.4794)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [217][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4656 (0.4266)	Prec@1 84.375 (85.450)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [217][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5463 (0.4367)	Prec@1 80.469 (85.141)	Prec@5 100.000 (99.386)
TRAINING - Epoch: [217][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2892 (0.4372)	Prec@1 90.625 (85.213)	Prec@5 99.219 (99.390)
EVALUATING - Epoch: [217][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.6242 (0.6242)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:53

 Epoch: 218	Training Loss 0.4464 	Training Prec@1 84.942 	Training Prec@5 99.356 	Validation Loss 0.6745 	Validation Prec@1 78.010 	Validation Prec@5 98.730 

lr: 0.08942641607651824
TRAINING - Epoch: [218][0/391]	Time 0.936 (0.936)	Data 0.378 (0.378)	Loss 0.3288 (0.3288)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [218][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3678 (0.4356)	Prec@1 89.844 (85.133)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [218][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4640 (0.4314)	Prec@1 82.031 (85.358)	Prec@5 99.219 (99.499)
TRAINING - Epoch: [218][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3021 (0.4359)	Prec@1 87.500 (85.302)	Prec@5 100.000 (99.452)
EVALUATING - Epoch: [218][0/79]	Time 0.373 (0.373)	Data 0.349 (0.349)	Loss 0.6413 (0.6413)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:25

 Epoch: 219	Training Loss 0.4314 	Training Prec@1 85.332 	Training Prec@5 99.464 	Validation Loss 0.7430 	Validation Prec@1 77.830 	Validation Prec@5 98.670 

lr: 0.08932922841359275
TRAINING - Epoch: [219][0/391]	Time 0.906 (0.906)	Data 0.342 (0.342)	Loss 0.5412 (0.5412)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [219][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5750 (0.4203)	Prec@1 81.250 (85.288)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [219][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3312 (0.4192)	Prec@1 88.281 (85.491)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [219][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4520 (0.4200)	Prec@1 82.812 (85.439)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [219][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.6470 (0.6470)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:53

 Epoch: 220	Training Loss 0.4261 	Training Prec@1 85.244 	Training Prec@5 99.454 	Validation Loss 0.8266 	Validation Prec@1 76.670 	Validation Prec@5 98.050 

lr: 0.08923164946302269
TRAINING - Epoch: [220][0/391]	Time 0.934 (0.934)	Data 0.369 (0.369)	Loss 0.3595 (0.3595)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [220][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3515 (0.4031)	Prec@1 88.281 (86.355)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [220][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4622 (0.4059)	Prec@1 80.469 (86.112)	Prec@5 99.219 (99.576)
TRAINING - Epoch: [220][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4861 (0.4134)	Prec@1 84.375 (85.847)	Prec@5 99.219 (99.561)
EVALUATING - Epoch: [220][0/79]	Time 0.335 (0.335)	Data 0.316 (0.316)	Loss 0.6052 (0.6052)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 221	Training Loss 0.4190 	Training Prec@1 85.742 	Training Prec@5 99.542 	Validation Loss 0.6924 	Validation Prec@1 77.950 	Validation Prec@5 98.590 

lr: 0.08913368019562386
TRAINING - Epoch: [221][0/391]	Time 0.908 (0.908)	Data 0.344 (0.344)	Loss 0.5196 (0.5196)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [221][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3418 (0.4135)	Prec@1 86.719 (85.450)	Prec@5 100.000 (99.505)
TRAINING - Epoch: [221][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3102 (0.4223)	Prec@1 89.844 (85.444)	Prec@5 100.000 (99.456)
TRAINING - Epoch: [221][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4426 (0.4239)	Prec@1 78.906 (85.335)	Prec@5 100.000 (99.445)
EVALUATING - Epoch: [221][0/79]	Time 0.342 (0.342)	Data 0.321 (0.321)	Loss 0.6556 (0.6556)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:54

 Epoch: 222	Training Loss 0.4277 	Training Prec@1 85.166 	Training Prec@5 99.452 	Validation Loss 0.6950 	Validation Prec@1 78.260 	Validation Prec@5 98.620 

lr: 0.08903532158609542
TRAINING - Epoch: [222][0/391]	Time 0.961 (0.961)	Data 0.345 (0.345)	Loss 0.4252 (0.4252)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [222][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5983 (0.4109)	Prec@1 82.031 (85.636)	Prec@5 98.438 (99.567)
TRAINING - Epoch: [222][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4124 (0.4170)	Prec@1 83.594 (85.592)	Prec@5 98.438 (99.491)
TRAINING - Epoch: [222][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4162 (0.4260)	Prec@1 82.031 (85.341)	Prec@5 100.000 (99.468)
EVALUATING - Epoch: [222][0/79]	Time 0.388 (0.388)	Data 0.365 (0.365)	Loss 0.5952 (0.5952)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:10

 Epoch: 223	Training Loss 0.4347 	Training Prec@1 85.114 	Training Prec@5 99.446 	Validation Loss 0.5886 	Validation Prec@1 80.900 	Validation Prec@5 99.080 

lr: 0.08893657461301004
TRAINING - Epoch: [223][0/391]	Time 0.915 (0.915)	Data 0.345 (0.345)	Loss 0.3077 (0.3077)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [223][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3881 (0.4334)	Prec@1 89.844 (85.195)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [223][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.5010 (0.4339)	Prec@1 82.812 (85.102)	Prec@5 97.656 (99.425)
TRAINING - Epoch: [223][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3022 (0.4297)	Prec@1 88.281 (85.195)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [223][0/79]	Time 0.363 (0.363)	Data 0.343 (0.343)	Loss 0.4555 (0.4555)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:18:51

 Epoch: 224	Training Loss 0.4313 	Training Prec@1 85.174 	Training Prec@5 99.442 	Validation Loss 0.6480 	Validation Prec@1 79.910 	Validation Prec@5 98.860 

lr: 0.08883744025880423
TRAINING - Epoch: [224][0/391]	Time 0.903 (0.903)	Data 0.341 (0.341)	Loss 0.3962 (0.3962)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [224][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4861 (0.4401)	Prec@1 80.469 (85.226)	Prec@5 99.219 (99.404)
TRAINING - Epoch: [224][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.6377 (0.4341)	Prec@1 81.250 (85.308)	Prec@5 98.438 (99.425)
TRAINING - Epoch: [224][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6313 (0.4505)	Prec@1 81.250 (84.793)	Prec@5 99.219 (99.413)
EVALUATING - Epoch: [224][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.6951 (0.6951)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:25

 Epoch: 225	Training Loss 0.4531 	Training Prec@1 84.698 	Training Prec@5 99.424 	Validation Loss 0.7731 	Validation Prec@1 77.250 	Validation Prec@5 98.540 

lr: 0.08873791950976859
TRAINING - Epoch: [225][0/391]	Time 0.926 (0.926)	Data 0.368 (0.368)	Loss 0.4133 (0.4133)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [225][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3068 (0.4425)	Prec@1 90.625 (85.017)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [225][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4912 (0.4382)	Prec@1 82.031 (85.040)	Prec@5 99.219 (99.464)
TRAINING - Epoch: [225][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6476 (0.4382)	Prec@1 82.031 (85.076)	Prec@5 98.438 (99.471)
EVALUATING - Epoch: [225][0/79]	Time 0.373 (0.373)	Data 0.352 (0.352)	Loss 0.6071 (0.6071)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 226	Training Loss 0.4418 	Training Prec@1 84.970 	Training Prec@5 99.420 	Validation Loss 0.6544 	Validation Prec@1 79.300 	Validation Prec@5 98.710 

lr: 0.08863801335603796
TRAINING - Epoch: [226][0/391]	Time 0.903 (0.903)	Data 0.343 (0.343)	Loss 0.6647 (0.6647)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [226][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3518 (0.4194)	Prec@1 89.062 (85.280)	Prec@5 99.219 (99.397)
TRAINING - Epoch: [226][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4071 (0.4230)	Prec@1 86.719 (85.354)	Prec@5 98.438 (99.436)
TRAINING - Epoch: [226][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4959 (0.4282)	Prec@1 82.812 (85.174)	Prec@5 99.219 (99.419)
EVALUATING - Epoch: [226][0/79]	Time 0.355 (0.355)	Data 0.332 (0.332)	Loss 0.7618 (0.7618)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:39

 Epoch: 227	Training Loss 0.4253 	Training Prec@1 85.194 	Training Prec@5 99.458 	Validation Loss 0.8447 	Validation Prec@1 75.690 	Validation Prec@5 98.420 

lr: 0.0885377227915816
TRAINING - Epoch: [227][0/391]	Time 0.940 (0.940)	Data 0.355 (0.355)	Loss 0.3988 (0.3988)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [227][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4031 (0.4237)	Prec@1 85.938 (85.698)	Prec@5 98.438 (99.327)
TRAINING - Epoch: [227][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5243 (0.4267)	Prec@1 84.375 (85.541)	Prec@5 99.219 (99.359)
TRAINING - Epoch: [227][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3141 (0.4305)	Prec@1 89.844 (85.418)	Prec@5 100.000 (99.385)
EVALUATING - Epoch: [227][0/79]	Time 0.374 (0.374)	Data 0.352 (0.352)	Loss 0.4658 (0.4658)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:33

 Epoch: 228	Training Loss 0.4308 	Training Prec@1 85.258 	Training Prec@5 99.412 	Validation Loss 0.6723 	Validation Prec@1 79.450 	Validation Prec@5 98.660 

lr: 0.08843704881419327
TRAINING - Epoch: [228][0/391]	Time 0.918 (0.918)	Data 0.348 (0.348)	Loss 0.3434 (0.3434)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [228][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.3638 (0.4278)	Prec@1 85.156 (85.535)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [228][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3904 (0.4300)	Prec@1 86.719 (85.452)	Prec@5 99.219 (99.440)
TRAINING - Epoch: [228][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5829 (0.4455)	Prec@1 83.594 (84.938)	Prec@5 98.438 (99.411)
EVALUATING - Epoch: [228][0/79]	Time 0.360 (0.360)	Data 0.337 (0.337)	Loss 0.5916 (0.5916)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:07

 Epoch: 229	Training Loss 0.4509 	Training Prec@1 84.752 	Training Prec@5 99.386 	Validation Loss 0.6811 	Validation Prec@1 79.780 	Validation Prec@5 98.690 

lr: 0.08833599242548132
TRAINING - Epoch: [229][0/391]	Time 0.954 (0.954)	Data 0.344 (0.344)	Loss 0.4280 (0.4280)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [229][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3882 (0.4451)	Prec@1 85.938 (84.762)	Prec@5 100.000 (99.466)
TRAINING - Epoch: [229][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3007 (0.4398)	Prec@1 89.062 (85.012)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [229][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5095 (0.4345)	Prec@1 82.812 (85.250)	Prec@5 100.000 (99.468)
EVALUATING - Epoch: [229][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.8842 (0.8842)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:49

 Epoch: 230	Training Loss 0.4366 	Training Prec@1 85.150 	Training Prec@5 99.468 	Validation Loss 0.9334 	Validation Prec@1 72.470 	Validation Prec@5 98.350 

lr: 0.08823455463085869
TRAINING - Epoch: [230][0/391]	Time 0.934 (0.934)	Data 0.367 (0.367)	Loss 0.3504 (0.3504)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [230][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5396 (0.4180)	Prec@1 82.031 (85.620)	Prec@5 99.219 (99.459)
TRAINING - Epoch: [230][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3960 (0.4186)	Prec@1 85.938 (85.712)	Prec@5 100.000 (99.510)
TRAINING - Epoch: [230][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3934 (0.4236)	Prec@1 83.594 (85.559)	Prec@5 98.438 (99.463)
EVALUATING - Epoch: [230][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 1.0161 (1.0161)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:52

 Epoch: 231	Training Loss 0.4271 	Training Prec@1 85.418 	Training Prec@5 99.462 	Validation Loss 1.0278 	Validation Prec@1 71.790 	Validation Prec@5 98.770 

lr: 0.088132736439533
TRAINING - Epoch: [231][0/391]	Time 0.918 (0.918)	Data 0.348 (0.348)	Loss 0.4666 (0.4666)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [231][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4436 (0.4485)	Prec@1 82.031 (84.901)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [231][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4389 (0.4354)	Prec@1 84.375 (85.211)	Prec@5 99.219 (99.405)
TRAINING - Epoch: [231][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4379 (0.4353)	Prec@1 84.375 (85.276)	Prec@5 99.219 (99.362)
EVALUATING - Epoch: [231][0/79]	Time 0.357 (0.357)	Data 0.334 (0.334)	Loss 0.5804 (0.5804)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:44

 Epoch: 232	Training Loss 0.4371 	Training Prec@1 85.172 	Training Prec@5 99.378 	Validation Loss 0.7208 	Validation Prec@1 78.360 	Validation Prec@5 98.800 

lr: 0.0880305388644964
TRAINING - Epoch: [232][0/391]	Time 0.896 (0.896)	Data 0.345 (0.345)	Loss 0.4217 (0.4217)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [232][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.4484 (0.4147)	Prec@1 88.281 (85.938)	Prec@5 99.219 (99.497)
TRAINING - Epoch: [232][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4637 (0.4273)	Prec@1 85.156 (85.491)	Prec@5 100.000 (99.537)
TRAINING - Epoch: [232][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.5637 (0.4349)	Prec@1 81.250 (85.276)	Prec@5 99.219 (99.496)
EVALUATING - Epoch: [232][0/79]	Time 0.361 (0.361)	Data 0.341 (0.341)	Loss 0.5446 (0.5446)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:19:30

 Epoch: 233	Training Loss 0.4435 	Training Prec@1 85.014 	Training Prec@5 99.478 	Validation Loss 0.7397 	Validation Prec@1 78.000 	Validation Prec@5 98.360 

lr: 0.08792796292251555
TRAINING - Epoch: [233][0/391]	Time 0.903 (0.903)	Data 0.339 (0.339)	Loss 0.4604 (0.4604)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [233][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4430 (0.4425)	Prec@1 85.156 (84.916)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [233][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5338 (0.4401)	Prec@1 83.594 (84.954)	Prec@5 99.219 (99.436)
TRAINING - Epoch: [233][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.4983 (0.4447)	Prec@1 83.594 (84.855)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [233][0/79]	Time 0.360 (0.360)	Data 0.339 (0.339)	Loss 0.6140 (0.6140)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:50

 Epoch: 234	Training Loss 0.4472 	Training Prec@1 84.828 	Training Prec@5 99.422 	Validation Loss 0.7307 	Validation Prec@1 77.260 	Validation Prec@5 98.810 

lr: 0.08782500963412151
TRAINING - Epoch: [234][0/391]	Time 0.958 (0.958)	Data 0.343 (0.343)	Loss 0.3385 (0.3385)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [234][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4444 (0.4066)	Prec@1 84.375 (85.675)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [234][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.5430 (0.4284)	Prec@1 85.938 (85.300)	Prec@5 99.219 (99.436)
TRAINING - Epoch: [234][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.5257 (0.4334)	Prec@1 80.469 (85.169)	Prec@5 99.219 (99.411)
EVALUATING - Epoch: [234][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.7418 (0.7418)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:27

 Epoch: 235	Training Loss 0.4333 	Training Prec@1 85.232 	Training Prec@5 99.384 	Validation Loss 0.8566 	Validation Prec@1 75.280 	Validation Prec@5 98.080 

lr: 0.08772168002359956
TRAINING - Epoch: [235][0/391]	Time 0.974 (0.974)	Data 0.392 (0.392)	Loss 0.4934 (0.4934)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [235][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4473 (0.4092)	Prec@1 81.250 (86.170)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [235][200/391]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.4476 (0.4171)	Prec@1 82.812 (85.778)	Prec@5 99.219 (99.444)
TRAINING - Epoch: [235][300/391]	Time 0.066 (0.066)	Data 0.000 (0.002)	Loss 0.4542 (0.4198)	Prec@1 84.375 (85.735)	Prec@5 97.656 (99.429)
EVALUATING - Epoch: [235][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.6357 (0.6357)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:25

 Epoch: 236	Training Loss 0.4225 	Training Prec@1 85.616 	Training Prec@5 99.440 	Validation Loss 0.7534 	Validation Prec@1 78.470 	Validation Prec@5 98.500 

lr: 0.08761797511897902
TRAINING - Epoch: [236][0/391]	Time 0.900 (0.900)	Data 0.332 (0.332)	Loss 0.5266 (0.5266)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [236][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4715 (0.4345)	Prec@1 82.031 (85.288)	Prec@5 100.000 (99.513)
TRAINING - Epoch: [236][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3967 (0.4329)	Prec@1 88.281 (85.285)	Prec@5 100.000 (99.475)
TRAINING - Epoch: [236][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4658 (0.4296)	Prec@1 82.812 (85.320)	Prec@5 100.000 (99.494)
EVALUATING - Epoch: [236][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 1.0120 (1.0120)	Prec@1 74.219 (74.219)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 237	Training Loss 0.4319 	Training Prec@1 85.224 	Training Prec@5 99.486 	Validation Loss 1.0217 	Validation Prec@1 72.960 	Validation Prec@5 96.480 

lr: 0.08751389595202301
TRAINING - Epoch: [237][0/391]	Time 0.911 (0.911)	Data 0.345 (0.345)	Loss 0.6798 (0.6798)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [237][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4084 (0.4187)	Prec@1 87.500 (85.535)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [237][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4353 (0.4353)	Prec@1 85.938 (85.121)	Prec@5 97.656 (99.475)
TRAINING - Epoch: [237][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3174 (0.4342)	Prec@1 86.719 (85.104)	Prec@5 100.000 (99.483)
EVALUATING - Epoch: [237][0/79]	Time 0.370 (0.370)	Data 0.346 (0.346)	Loss 0.5769 (0.5769)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:45

 Epoch: 238	Training Loss 0.4360 	Training Prec@1 85.092 	Training Prec@5 99.488 	Validation Loss 0.6748 	Validation Prec@1 78.870 	Validation Prec@5 98.800 

lr: 0.08740944355821822
TRAINING - Epoch: [238][0/391]	Time 0.939 (0.939)	Data 0.381 (0.381)	Loss 0.4400 (0.4400)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [238][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.5100 (0.4164)	Prec@1 83.594 (85.760)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [238][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.3677 (0.4200)	Prec@1 85.938 (85.700)	Prec@5 100.000 (99.491)
TRAINING - Epoch: [238][300/391]	Time 0.066 (0.066)	Data 0.000 (0.002)	Loss 0.3429 (0.4216)	Prec@1 86.719 (85.597)	Prec@5 100.000 (99.502)
EVALUATING - Epoch: [238][0/79]	Time 0.375 (0.375)	Data 0.353 (0.353)	Loss 0.7043 (0.7043)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:37

 Epoch: 239	Training Loss 0.4254 	Training Prec@1 85.422 	Training Prec@5 99.478 	Validation Loss 0.7644 	Validation Prec@1 76.570 	Validation Prec@5 97.780 

lr: 0.08730461897676457
TRAINING - Epoch: [239][0/391]	Time 0.951 (0.951)	Data 0.379 (0.379)	Loss 0.4163 (0.4163)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [239][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4926 (0.4257)	Prec@1 85.938 (85.566)	Prec@5 98.438 (99.435)
TRAINING - Epoch: [239][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3102 (0.4243)	Prec@1 88.281 (85.533)	Prec@5 99.219 (99.456)
TRAINING - Epoch: [239][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.3582 (0.4307)	Prec@1 86.719 (85.322)	Prec@5 100.000 (99.442)
EVALUATING - Epoch: [239][0/79]	Time 0.368 (0.368)	Data 0.344 (0.344)	Loss 0.7941 (0.7941)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:40

 Epoch: 240	Training Loss 0.4287 	Training Prec@1 85.372 	Training Prec@5 99.460 	Validation Loss 0.8930 	Validation Prec@1 74.360 	Validation Prec@5 98.550 

lr: 0.0871994232505649
TRAINING - Epoch: [240][0/391]	Time 0.902 (0.902)	Data 0.349 (0.349)	Loss 0.6417 (0.6417)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [240][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.4673 (0.4296)	Prec@1 82.812 (84.947)	Prec@5 98.438 (99.420)
TRAINING - Epoch: [240][200/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.4505 (0.4236)	Prec@1 82.812 (85.156)	Prec@5 99.219 (99.487)
TRAINING - Epoch: [240][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.4639 (0.4262)	Prec@1 82.812 (85.226)	Prec@5 99.219 (99.452)
EVALUATING - Epoch: [240][0/79]	Time 0.370 (0.370)	Data 0.347 (0.347)	Loss 0.5745 (0.5745)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:47

 Epoch: 241	Training Loss 0.4252 	Training Prec@1 85.280 	Training Prec@5 99.484 	Validation Loss 0.7893 	Validation Prec@1 76.130 	Validation Prec@5 98.780 

lr: 0.08709385742621453
TRAINING - Epoch: [241][0/391]	Time 0.931 (0.931)	Data 0.357 (0.357)	Loss 0.5231 (0.5231)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [241][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2921 (0.3909)	Prec@1 88.281 (86.471)	Prec@5 99.219 (99.459)
TRAINING - Epoch: [241][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4712 (0.4070)	Prec@1 83.594 (86.027)	Prec@5 99.219 (99.468)
TRAINING - Epoch: [241][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3124 (0.4169)	Prec@1 88.281 (85.626)	Prec@5 100.000 (99.442)
EVALUATING - Epoch: [241][0/79]	Time 0.347 (0.347)	Data 0.326 (0.326)	Loss 0.7752 (0.7752)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 242	Training Loss 0.4192 	Training Prec@1 85.656 	Training Prec@5 99.440 	Validation Loss 0.7464 	Validation Prec@1 78.030 	Validation Prec@5 98.330 

lr: 0.08698792255399099
TRAINING - Epoch: [242][0/391]	Time 0.971 (0.971)	Data 0.389 (0.389)	Loss 0.3174 (0.3174)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [242][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3791 (0.3806)	Prec@1 85.156 (87.075)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [242][200/391]	Time 0.066 (0.068)	Data 0.000 (0.002)	Loss 0.5810 (0.3985)	Prec@1 84.375 (86.338)	Prec@5 97.656 (99.475)
TRAINING - Epoch: [242][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.3364 (0.4065)	Prec@1 88.281 (86.207)	Prec@5 100.000 (99.463)
EVALUATING - Epoch: [242][0/79]	Time 0.388 (0.388)	Data 0.361 (0.361)	Loss 0.7029 (0.7029)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:54

 Epoch: 243	Training Loss 0.4130 	Training Prec@1 85.982 	Training Prec@5 99.446 	Validation Loss 0.7199 	Validation Prec@1 77.700 	Validation Prec@5 98.610 

lr: 0.0868816196878434
TRAINING - Epoch: [243][0/391]	Time 0.935 (0.935)	Data 0.352 (0.352)	Loss 0.3876 (0.3876)	Prec@1 89.844 (89.844)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [243][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3585 (0.4055)	Prec@1 84.375 (86.270)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [243][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4908 (0.4147)	Prec@1 85.156 (85.910)	Prec@5 99.219 (99.456)
TRAINING - Epoch: [243][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5127 (0.4208)	Prec@1 79.688 (85.764)	Prec@5 99.219 (99.398)
EVALUATING - Epoch: [243][0/79]	Time 0.366 (0.366)	Data 0.343 (0.343)	Loss 0.4989 (0.4989)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:42

 Epoch: 244	Training Loss 0.4239 	Training Prec@1 85.562 	Training Prec@5 99.384 	Validation Loss 0.6547 	Validation Prec@1 79.810 	Validation Prec@5 98.820 

lr: 0.08677494988538205
TRAINING - Epoch: [244][0/391]	Time 0.943 (0.943)	Data 0.374 (0.374)	Loss 0.3729 (0.3729)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [244][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.6600 (0.4027)	Prec@1 76.562 (86.092)	Prec@5 98.438 (99.489)
TRAINING - Epoch: [244][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2383 (0.4216)	Prec@1 92.188 (85.444)	Prec@5 100.000 (99.417)
TRAINING - Epoch: [244][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5326 (0.4231)	Prec@1 83.594 (85.390)	Prec@5 97.656 (99.434)
EVALUATING - Epoch: [244][0/79]	Time 0.359 (0.359)	Data 0.336 (0.336)	Loss 0.6550 (0.6550)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:35

 Epoch: 245	Training Loss 0.4271 	Training Prec@1 85.256 	Training Prec@5 99.422 	Validation Loss 0.7090 	Validation Prec@1 77.470 	Validation Prec@5 98.520 

lr: 0.08666791420786799
TRAINING - Epoch: [245][0/391]	Time 0.938 (0.938)	Data 0.354 (0.354)	Loss 0.4264 (0.4264)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [245][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4730 (0.4058)	Prec@1 85.156 (85.999)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [245][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3713 (0.4136)	Prec@1 85.938 (85.665)	Prec@5 100.000 (99.444)
TRAINING - Epoch: [245][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3277 (0.4162)	Prec@1 89.844 (85.681)	Prec@5 98.438 (99.468)
EVALUATING - Epoch: [245][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.5592 (0.5592)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:37

 Epoch: 246	Training Loss 0.4199 	Training Prec@1 85.474 	Training Prec@5 99.460 	Validation Loss 0.8207 	Validation Prec@1 74.110 	Validation Prec@5 98.910 

lr: 0.08656051372020226
TRAINING - Epoch: [246][0/391]	Time 0.937 (0.937)	Data 0.358 (0.358)	Loss 0.3067 (0.3067)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [246][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3302 (0.4203)	Prec@1 91.406 (85.698)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [246][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.6193 (0.4188)	Prec@1 77.344 (85.599)	Prec@5 99.219 (99.510)
TRAINING - Epoch: [246][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4233 (0.4239)	Prec@1 87.500 (85.387)	Prec@5 100.000 (99.507)
EVALUATING - Epoch: [246][0/79]	Time 0.384 (0.384)	Data 0.362 (0.362)	Loss 0.6846 (0.6846)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:09

 Epoch: 247	Training Loss 0.4233 	Training Prec@1 85.386 	Training Prec@5 99.508 	Validation Loss 0.8064 	Validation Prec@1 76.490 	Validation Prec@5 98.730 

lr: 0.08645274949091548
TRAINING - Epoch: [247][0/391]	Time 0.963 (0.963)	Data 0.378 (0.378)	Loss 0.5354 (0.5354)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [247][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3695 (0.4225)	Prec@1 89.062 (85.566)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [247][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4227 (0.4147)	Prec@1 85.156 (85.766)	Prec@5 97.656 (99.518)
TRAINING - Epoch: [247][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3860 (0.4177)	Prec@1 85.938 (85.603)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [247][0/79]	Time 0.375 (0.375)	Data 0.354 (0.354)	Loss 0.8139 (0.8139)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:49

 Epoch: 248	Training Loss 0.4165 	Training Prec@1 85.610 	Training Prec@5 99.522 	Validation Loss 0.7365 	Validation Prec@1 78.170 	Validation Prec@5 98.640 

lr: 0.08634462259215712
TRAINING - Epoch: [248][0/391]	Time 0.951 (0.951)	Data 0.383 (0.383)	Loss 0.4270 (0.4270)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [248][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.4707 (0.4258)	Prec@1 84.375 (85.473)	Prec@5 97.656 (99.513)
TRAINING - Epoch: [248][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4778 (0.4193)	Prec@1 82.812 (85.868)	Prec@5 100.000 (99.452)
TRAINING - Epoch: [248][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.5304 (0.4254)	Prec@1 84.375 (85.585)	Prec@5 99.219 (99.434)
EVALUATING - Epoch: [248][0/79]	Time 0.368 (0.368)	Data 0.345 (0.345)	Loss 0.7311 (0.7311)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:18

 Epoch: 249	Training Loss 0.4258 	Training Prec@1 85.500 	Training Prec@5 99.448 	Validation Loss 0.7103 	Validation Prec@1 77.770 	Validation Prec@5 98.400 

lr: 0.08623613409968486
TRAINING - Epoch: [249][0/391]	Time 0.925 (0.925)	Data 0.348 (0.348)	Loss 0.4669 (0.4669)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [249][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2493 (0.4143)	Prec@1 91.406 (85.914)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [249][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5049 (0.4203)	Prec@1 82.812 (85.553)	Prec@5 98.438 (99.444)
TRAINING - Epoch: [249][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3799 (0.4210)	Prec@1 89.062 (85.668)	Prec@5 99.219 (99.447)
EVALUATING - Epoch: [249][0/79]	Time 0.357 (0.357)	Data 0.337 (0.337)	Loss 0.5974 (0.5974)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 250	Training Loss 0.4222 	Training Prec@1 85.646 	Training Prec@5 99.452 	Validation Loss 0.6890 	Validation Prec@1 78.510 	Validation Prec@5 98.770 

lr: 0.0861272850928539
TRAINING - Epoch: [250][0/391]	Time 0.932 (0.932)	Data 0.344 (0.344)	Loss 0.3298 (0.3298)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [250][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.2958 (0.4035)	Prec@1 88.281 (86.262)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [250][200/391]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.4808 (0.4043)	Prec@1 79.688 (86.318)	Prec@5 98.438 (99.506)
TRAINING - Epoch: [250][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5259 (0.4064)	Prec@1 79.688 (86.085)	Prec@5 99.219 (99.491)
EVALUATING - Epoch: [250][0/79]	Time 0.383 (0.383)	Data 0.365 (0.365)	Loss 0.7636 (0.7636)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:39

 Epoch: 251	Training Loss 0.4130 	Training Prec@1 85.812 	Training Prec@5 99.448 	Validation Loss 0.8753 	Validation Prec@1 74.550 	Validation Prec@5 98.220 

lr: 0.08601807665460615
TRAINING - Epoch: [251][0/391]	Time 0.938 (0.938)	Data 0.347 (0.347)	Loss 0.5200 (0.5200)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [251][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.4727 (0.4395)	Prec@1 86.719 (84.940)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [251][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4118 (0.4157)	Prec@1 87.500 (85.665)	Prec@5 100.000 (99.386)
TRAINING - Epoch: [251][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2710 (0.4167)	Prec@1 92.969 (85.605)	Prec@5 99.219 (99.439)
EVALUATING - Epoch: [251][0/79]	Time 0.352 (0.352)	Data 0.329 (0.329)	Loss 0.5905 (0.5905)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:38

 Epoch: 252	Training Loss 0.4136 	Training Prec@1 85.636 	Training Prec@5 99.476 	Validation Loss 0.6728 	Validation Prec@1 79.560 	Validation Prec@5 98.850 

lr: 0.08590850987145959
TRAINING - Epoch: [252][0/391]	Time 0.897 (0.897)	Data 0.340 (0.340)	Loss 0.5980 (0.5980)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [252][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4871 (0.4111)	Prec@1 83.594 (85.829)	Prec@5 98.438 (99.482)
TRAINING - Epoch: [252][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4462 (0.4071)	Prec@1 81.250 (86.007)	Prec@5 100.000 (99.448)
TRAINING - Epoch: [252][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3072 (0.4087)	Prec@1 83.594 (85.899)	Prec@5 100.000 (99.507)
EVALUATING - Epoch: [252][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.5228 (0.5228)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:22

 Epoch: 253	Training Loss 0.4156 	Training Prec@1 85.652 	Training Prec@5 99.486 	Validation Loss 0.7170 	Validation Prec@1 78.230 	Validation Prec@5 98.800 

lr: 0.08579858583349735
TRAINING - Epoch: [253][0/391]	Time 0.949 (0.949)	Data 0.367 (0.367)	Loss 0.4173 (0.4173)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [253][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.4423 (0.3888)	Prec@1 82.812 (86.657)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [253][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4633 (0.4077)	Prec@1 82.031 (85.938)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [253][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5515 (0.4094)	Prec@1 80.469 (85.857)	Prec@5 100.000 (99.502)
EVALUATING - Epoch: [253][0/79]	Time 0.357 (0.357)	Data 0.338 (0.338)	Loss 0.6135 (0.6135)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:53

 Epoch: 254	Training Loss 0.4138 	Training Prec@1 85.756 	Training Prec@5 99.486 	Validation Loss 0.7164 	Validation Prec@1 78.400 	Validation Prec@5 98.650 

lr: 0.08568830563435689
TRAINING - Epoch: [254][0/391]	Time 0.938 (0.938)	Data 0.382 (0.382)	Loss 0.4362 (0.4362)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [254][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3415 (0.3968)	Prec@1 88.281 (86.154)	Prec@5 98.438 (99.466)
TRAINING - Epoch: [254][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2844 (0.3936)	Prec@1 89.844 (86.245)	Prec@5 100.000 (99.483)
TRAINING - Epoch: [254][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.3279 (0.4034)	Prec@1 89.062 (85.971)	Prec@5 98.438 (99.476)
EVALUATING - Epoch: [254][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.7452 (0.7452)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:01

 Epoch: 255	Training Loss 0.4085 	Training Prec@1 85.854 	Training Prec@5 99.486 	Validation Loss 0.8771 	Validation Prec@1 75.020 	Validation Prec@5 98.770 

lr: 0.08557767037121917
TRAINING - Epoch: [255][0/391]	Time 0.967 (0.967)	Data 0.351 (0.351)	Loss 0.4001 (0.4001)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [255][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4567 (0.4101)	Prec@1 82.031 (85.597)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [255][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.4771 (0.4146)	Prec@1 84.375 (85.560)	Prec@5 100.000 (99.518)
TRAINING - Epoch: [255][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3846 (0.4204)	Prec@1 87.500 (85.525)	Prec@5 100.000 (99.486)
EVALUATING - Epoch: [255][0/79]	Time 0.391 (0.391)	Data 0.369 (0.369)	Loss 0.5998 (0.5998)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:25

 Epoch: 256	Training Loss 0.4256 	Training Prec@1 85.334 	Training Prec@5 99.446 	Validation Loss 0.7434 	Validation Prec@1 76.800 	Validation Prec@5 98.540 

lr: 0.08546668114479763
TRAINING - Epoch: [256][0/391]	Time 0.918 (0.918)	Data 0.341 (0.341)	Loss 0.3928 (0.3928)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [256][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4532 (0.4084)	Prec@1 82.812 (86.038)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [256][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3496 (0.4049)	Prec@1 88.281 (86.213)	Prec@5 99.219 (99.541)
TRAINING - Epoch: [256][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4812 (0.4071)	Prec@1 83.594 (86.117)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [256][0/79]	Time 0.358 (0.358)	Data 0.340 (0.340)	Loss 0.7856 (0.7856)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:56

 Epoch: 257	Training Loss 0.4158 	Training Prec@1 85.816 	Training Prec@5 99.462 	Validation Loss 0.7309 	Validation Prec@1 77.680 	Validation Prec@5 98.650 

lr: 0.08535533905932734
TRAINING - Epoch: [257][0/391]	Time 0.897 (0.897)	Data 0.340 (0.340)	Loss 0.4619 (0.4619)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [257][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4992 (0.4064)	Prec@1 76.562 (85.999)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [257][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4734 (0.4148)	Prec@1 84.375 (85.735)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [257][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4784 (0.4245)	Prec@1 83.594 (85.452)	Prec@5 98.438 (99.481)
EVALUATING - Epoch: [257][0/79]	Time 0.361 (0.361)	Data 0.340 (0.340)	Loss 0.9805 (0.9805)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 258	Training Loss 0.4272 	Training Prec@1 85.378 	Training Prec@5 99.466 	Validation Loss 0.8694 	Validation Prec@1 75.560 	Validation Prec@5 97.000 

lr: 0.08524364522255397
TRAINING - Epoch: [258][0/391]	Time 0.946 (0.946)	Data 0.381 (0.381)	Loss 0.4026 (0.4026)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [258][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3028 (0.4152)	Prec@1 90.625 (85.272)	Prec@5 99.219 (99.466)
TRAINING - Epoch: [258][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.3345 (0.4221)	Prec@1 87.500 (85.265)	Prec@5 99.219 (99.475)
TRAINING - Epoch: [258][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.5839 (0.4338)	Prec@1 81.250 (85.037)	Prec@5 98.438 (99.473)
EVALUATING - Epoch: [258][0/79]	Time 0.346 (0.346)	Data 0.326 (0.326)	Loss 0.5754 (0.5754)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 259	Training Loss 0.4339 	Training Prec@1 85.152 	Training Prec@5 99.458 	Validation Loss 0.6347 	Validation Prec@1 80.770 	Validation Prec@5 99.000 

lr: 0.08513160074572275
TRAINING - Epoch: [259][0/391]	Time 0.920 (0.920)	Data 0.339 (0.339)	Loss 0.3868 (0.3868)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [259][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4211 (0.4215)	Prec@1 85.938 (85.497)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [259][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4311 (0.4228)	Prec@1 83.594 (85.327)	Prec@5 99.219 (99.487)
TRAINING - Epoch: [259][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3228 (0.4243)	Prec@1 86.719 (85.351)	Prec@5 100.000 (99.476)
EVALUATING - Epoch: [259][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.4464 (0.4464)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 260	Training Loss 0.4246 	Training Prec@1 85.454 	Training Prec@5 99.460 	Validation Loss 0.6078 	Validation Prec@1 81.580 	Validation Prec@5 98.870 

lr: 0.0850192067435675
TRAINING - Epoch: [260][0/391]	Time 0.920 (0.920)	Data 0.350 (0.350)	Loss 0.3663 (0.3663)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [260][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4217 (0.4153)	Prec@1 86.719 (85.899)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [260][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4494 (0.4228)	Prec@1 82.031 (85.549)	Prec@5 100.000 (99.464)
TRAINING - Epoch: [260][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4669 (0.4243)	Prec@1 85.938 (85.483)	Prec@5 99.219 (99.424)
EVALUATING - Epoch: [260][0/79]	Time 0.372 (0.372)	Data 0.347 (0.347)	Loss 0.5275 (0.5275)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 261	Training Loss 0.4152 	Training Prec@1 85.784 	Training Prec@5 99.464 	Validation Loss 0.7187 	Validation Prec@1 78.520 	Validation Prec@5 98.430 

lr: 0.08490646433429941
TRAINING - Epoch: [261][0/391]	Time 0.900 (0.900)	Data 0.332 (0.332)	Loss 0.3262 (0.3262)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [261][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3804 (0.4140)	Prec@1 85.156 (85.504)	Prec@5 100.000 (99.544)
TRAINING - Epoch: [261][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4359 (0.4207)	Prec@1 85.938 (85.300)	Prec@5 100.000 (99.530)
TRAINING - Epoch: [261][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4061 (0.4231)	Prec@1 87.500 (85.343)	Prec@5 99.219 (99.499)
EVALUATING - Epoch: [261][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.5921 (0.5921)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 262	Training Loss 0.4230 	Training Prec@1 85.382 	Training Prec@5 99.504 	Validation Loss 0.7320 	Validation Prec@1 78.260 	Validation Prec@5 98.570 

lr: 0.08479337463959602
TRAINING - Epoch: [262][0/391]	Time 0.930 (0.930)	Data 0.357 (0.357)	Loss 0.3364 (0.3364)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [262][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3823 (0.3855)	Prec@1 87.500 (87.020)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [262][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.3661 (0.4094)	Prec@1 87.500 (86.268)	Prec@5 100.000 (99.471)
TRAINING - Epoch: [262][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4805 (0.4139)	Prec@1 82.031 (85.958)	Prec@5 98.438 (99.481)
EVALUATING - Epoch: [262][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.4880 (0.4880)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:19:30

 Epoch: 263	Training Loss 0.4136 	Training Prec@1 85.922 	Training Prec@5 99.486 	Validation Loss 0.7031 	Validation Prec@1 77.950 	Validation Prec@5 98.680 

lr: 0.08467993878459
TRAINING - Epoch: [263][0/391]	Time 0.919 (0.919)	Data 0.341 (0.341)	Loss 0.4445 (0.4445)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [263][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3326 (0.4178)	Prec@1 85.938 (85.141)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [263][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5320 (0.4229)	Prec@1 81.250 (85.195)	Prec@5 100.000 (99.561)
TRAINING - Epoch: [263][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4901 (0.4238)	Prec@1 82.812 (85.374)	Prec@5 100.000 (99.541)
EVALUATING - Epoch: [263][0/79]	Time 0.365 (0.365)	Data 0.342 (0.342)	Loss 0.6918 (0.6918)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:03

 Epoch: 264	Training Loss 0.4281 	Training Prec@1 85.218 	Training Prec@5 99.542 	Validation Loss 0.8294 	Validation Prec@1 76.070 	Validation Prec@5 97.850 

lr: 0.084566157897858
TRAINING - Epoch: [264][0/391]	Time 0.901 (0.901)	Data 0.345 (0.345)	Loss 0.4756 (0.4756)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [264][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3908 (0.4219)	Prec@1 88.281 (85.682)	Prec@5 100.000 (99.389)
TRAINING - Epoch: [264][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3303 (0.4175)	Prec@1 89.844 (85.665)	Prec@5 99.219 (99.452)
TRAINING - Epoch: [264][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4639 (0.4254)	Prec@1 85.156 (85.475)	Prec@5 100.000 (99.419)
EVALUATING - Epoch: [264][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 0.5071 (0.5071)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 265	Training Loss 0.4248 	Training Prec@1 85.450 	Training Prec@5 99.428 	Validation Loss 0.7439 	Validation Prec@1 77.890 	Validation Prec@5 97.770 

lr: 0.08445203311140939
TRAINING - Epoch: [265][0/391]	Time 0.923 (0.923)	Data 0.351 (0.351)	Loss 0.3613 (0.3613)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [265][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4568 (0.4287)	Prec@1 81.250 (85.257)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [265][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3134 (0.4182)	Prec@1 87.500 (85.545)	Prec@5 99.219 (99.448)
TRAINING - Epoch: [265][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3937 (0.4196)	Prec@1 86.719 (85.585)	Prec@5 100.000 (99.481)
EVALUATING - Epoch: [265][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.5800 (0.5800)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:37

 Epoch: 266	Training Loss 0.4251 	Training Prec@1 85.360 	Training Prec@5 99.434 	Validation Loss 0.6983 	Validation Prec@1 77.770 	Validation Prec@5 98.680 

lr: 0.08433756556067501
TRAINING - Epoch: [266][0/391]	Time 0.977 (0.977)	Data 0.352 (0.352)	Loss 0.2653 (0.2653)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [266][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3946 (0.3813)	Prec@1 85.156 (86.928)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [266][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3220 (0.3976)	Prec@1 86.719 (86.264)	Prec@5 99.219 (99.561)
TRAINING - Epoch: [266][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4191 (0.4081)	Prec@1 87.500 (86.000)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [266][0/79]	Time 0.346 (0.346)	Data 0.327 (0.327)	Loss 0.5314 (0.5314)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:37

 Epoch: 267	Training Loss 0.4124 	Training Prec@1 85.852 	Training Prec@5 99.512 	Validation Loss 0.6726 	Validation Prec@1 78.810 	Validation Prec@5 98.680 

lr: 0.08422275638449589
TRAINING - Epoch: [267][0/391]	Time 0.919 (0.919)	Data 0.357 (0.357)	Loss 0.4585 (0.4585)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [267][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3343 (0.4041)	Prec@1 88.281 (86.224)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [267][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4024 (0.4149)	Prec@1 86.719 (85.833)	Prec@5 100.000 (99.491)
TRAINING - Epoch: [267][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3970 (0.4144)	Prec@1 87.500 (85.896)	Prec@5 100.000 (99.463)
EVALUATING - Epoch: [267][0/79]	Time 0.351 (0.351)	Data 0.329 (0.329)	Loss 0.9027 (0.9027)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:45

 Epoch: 268	Training Loss 0.4117 	Training Prec@1 85.962 	Training Prec@5 99.466 	Validation Loss 0.8107 	Validation Prec@1 75.360 	Validation Prec@5 98.750 

lr: 0.08410760672511186
TRAINING - Epoch: [268][0/391]	Time 0.912 (0.912)	Data 0.335 (0.335)	Loss 0.3200 (0.3200)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [268][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.5586 (0.4339)	Prec@1 84.375 (85.032)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [268][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4077 (0.4257)	Prec@1 87.500 (85.370)	Prec@5 100.000 (99.464)
TRAINING - Epoch: [268][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3899 (0.4260)	Prec@1 89.062 (85.496)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [268][0/79]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 1.0079 (1.0079)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:49

 Epoch: 269	Training Loss 0.4239 	Training Prec@1 85.510 	Training Prec@5 99.440 	Validation Loss 0.9132 	Validation Prec@1 73.990 	Validation Prec@5 98.390 

lr: 0.08399211772815027
TRAINING - Epoch: [269][0/391]	Time 0.895 (0.895)	Data 0.343 (0.343)	Loss 0.3826 (0.3826)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [269][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4833 (0.3946)	Prec@1 84.375 (86.448)	Prec@5 98.438 (99.629)
TRAINING - Epoch: [269][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3882 (0.4054)	Prec@1 84.375 (85.871)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [269][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4743 (0.4072)	Prec@1 84.375 (85.880)	Prec@5 99.219 (99.541)
EVALUATING - Epoch: [269][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.5455 (0.5455)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:00

 Epoch: 270	Training Loss 0.4110 	Training Prec@1 85.874 	Training Prec@5 99.532 	Validation Loss 0.6017 	Validation Prec@1 80.940 	Validation Prec@5 99.160 

lr: 0.08387629054261449
TRAINING - Epoch: [270][0/391]	Time 0.919 (0.919)	Data 0.367 (0.367)	Loss 0.4642 (0.4642)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [270][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2731 (0.4084)	Prec@1 89.844 (86.170)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [270][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5004 (0.4150)	Prec@1 79.688 (86.004)	Prec@5 99.219 (99.413)
TRAINING - Epoch: [270][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5183 (0.4200)	Prec@1 83.594 (85.719)	Prec@5 99.219 (99.437)
EVALUATING - Epoch: [270][0/79]	Time 0.361 (0.361)	Data 0.339 (0.339)	Loss 0.7004 (0.7004)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:10

 Epoch: 271	Training Loss 0.4212 	Training Prec@1 85.690 	Training Prec@5 99.454 	Validation Loss 0.7474 	Validation Prec@1 78.770 	Validation Prec@5 98.430 

lr: 0.08376012632087264
TRAINING - Epoch: [271][0/391]	Time 0.905 (0.905)	Data 0.337 (0.337)	Loss 0.4953 (0.4953)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [271][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3807 (0.3999)	Prec@1 87.500 (86.123)	Prec@5 98.438 (99.489)
TRAINING - Epoch: [271][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2997 (0.4139)	Prec@1 88.281 (85.584)	Prec@5 100.000 (99.495)
TRAINING - Epoch: [271][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3867 (0.4152)	Prec@1 84.375 (85.475)	Prec@5 99.219 (99.515)
EVALUATING - Epoch: [271][0/79]	Time 0.341 (0.341)	Data 0.323 (0.323)	Loss 0.7448 (0.7448)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:26

 Epoch: 272	Training Loss 0.4203 	Training Prec@1 85.526 	Training Prec@5 99.456 	Validation Loss 0.6619 	Validation Prec@1 79.060 	Validation Prec@5 98.830 

lr: 0.0836436262186459
TRAINING - Epoch: [272][0/391]	Time 0.914 (0.914)	Data 0.349 (0.349)	Loss 0.3839 (0.3839)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [272][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3985 (0.3860)	Prec@1 86.719 (86.796)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [272][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4358 (0.3943)	Prec@1 83.594 (86.684)	Prec@5 99.219 (99.530)
TRAINING - Epoch: [272][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3654 (0.3969)	Prec@1 85.156 (86.436)	Prec@5 100.000 (99.520)
EVALUATING - Epoch: [272][0/79]	Time 0.388 (0.388)	Data 0.364 (0.364)	Loss 0.7573 (0.7573)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 273	Training Loss 0.3993 	Training Prec@1 86.392 	Training Prec@5 99.532 	Validation Loss 0.7722 	Validation Prec@1 76.360 	Validation Prec@5 98.570 

lr: 0.08352679139499726
TRAINING - Epoch: [273][0/391]	Time 0.917 (0.917)	Data 0.347 (0.347)	Loss 0.4338 (0.4338)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [273][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3702 (0.4051)	Prec@1 83.594 (86.170)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [273][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4456 (0.4108)	Prec@1 82.812 (86.042)	Prec@5 98.438 (99.483)
TRAINING - Epoch: [273][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3845 (0.4148)	Prec@1 87.500 (85.854)	Prec@5 99.219 (99.517)
EVALUATING - Epoch: [273][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.4411 (0.4411)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:32

 Epoch: 274	Training Loss 0.4144 	Training Prec@1 85.886 	Training Prec@5 99.516 	Validation Loss 0.5340 	Validation Prec@1 82.390 	Validation Prec@5 99.230 

lr: 0.08340962301231976
TRAINING - Epoch: [274][0/391]	Time 0.912 (0.912)	Data 0.360 (0.360)	Loss 0.2851 (0.2851)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [274][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.2578 (0.3805)	Prec@1 93.750 (86.974)	Prec@5 99.219 (99.621)
TRAINING - Epoch: [274][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4156 (0.4030)	Prec@1 89.062 (86.431)	Prec@5 98.438 (99.518)
TRAINING - Epoch: [274][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3956 (0.4109)	Prec@1 87.500 (85.995)	Prec@5 99.219 (99.504)
EVALUATING - Epoch: [274][0/79]	Time 0.343 (0.343)	Data 0.324 (0.324)	Loss 0.7947 (0.7947)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:30

 Epoch: 275	Training Loss 0.4121 	Training Prec@1 85.944 	Training Prec@5 99.490 	Validation Loss 0.7360 	Validation Prec@1 77.910 	Validation Prec@5 98.650 

lr: 0.08329212223632507
TRAINING - Epoch: [275][0/391]	Time 0.902 (0.902)	Data 0.334 (0.334)	Loss 0.4096 (0.4096)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [275][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.6262 (0.4048)	Prec@1 81.250 (85.868)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [275][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3791 (0.4060)	Prec@1 89.062 (85.953)	Prec@5 98.438 (99.518)
TRAINING - Epoch: [275][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3483 (0.4066)	Prec@1 88.281 (85.963)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [275][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.6554 (0.6554)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 276	Training Loss 0.4089 	Training Prec@1 86.008 	Training Prec@5 99.480 	Validation Loss 0.7791 	Validation Prec@1 76.160 	Validation Prec@5 98.720 

lr: 0.08317429023603186
TRAINING - Epoch: [276][0/391]	Time 0.901 (0.901)	Data 0.349 (0.349)	Loss 0.4759 (0.4759)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [276][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4608 (0.4097)	Prec@1 83.594 (85.914)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [276][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3157 (0.4088)	Prec@1 87.500 (86.074)	Prec@5 100.000 (99.487)
TRAINING - Epoch: [276][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.4103 (0.4148)	Prec@1 86.719 (85.766)	Prec@5 99.219 (99.471)
EVALUATING - Epoch: [276][0/79]	Time 0.379 (0.379)	Data 0.355 (0.355)	Loss 0.7064 (0.7064)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:29

 Epoch: 277	Training Loss 0.4140 	Training Prec@1 85.806 	Training Prec@5 99.462 	Validation Loss 0.7398 	Validation Prec@1 77.510 	Validation Prec@5 98.330 

lr: 0.08305612818375414
TRAINING - Epoch: [277][0/391]	Time 0.912 (0.912)	Data 0.343 (0.343)	Loss 0.3729 (0.3729)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [277][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4977 (0.4023)	Prec@1 83.594 (86.363)	Prec@5 98.438 (99.451)
TRAINING - Epoch: [277][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3218 (0.4095)	Prec@1 86.719 (86.074)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [277][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2860 (0.4110)	Prec@1 90.625 (86.075)	Prec@5 99.219 (99.455)
EVALUATING - Epoch: [277][0/79]	Time 0.342 (0.342)	Data 0.323 (0.323)	Loss 0.7767 (0.7767)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:07

 Epoch: 278	Training Loss 0.4178 	Training Prec@1 85.806 	Training Prec@5 99.460 	Validation Loss 0.7971 	Validation Prec@1 75.600 	Validation Prec@5 98.180 

lr: 0.08293763725508965
TRAINING - Epoch: [278][0/391]	Time 0.916 (0.916)	Data 0.362 (0.362)	Loss 0.4225 (0.4225)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [278][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5299 (0.4043)	Prec@1 82.031 (86.154)	Prec@5 98.438 (99.582)
TRAINING - Epoch: [278][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4383 (0.4130)	Prec@1 85.938 (85.980)	Prec@5 98.438 (99.549)
TRAINING - Epoch: [278][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5603 (0.4152)	Prec@1 83.594 (85.857)	Prec@5 99.219 (99.491)
EVALUATING - Epoch: [278][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.5276 (0.5276)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:11

 Epoch: 279	Training Loss 0.4151 	Training Prec@1 85.806 	Training Prec@5 99.468 	Validation Loss 0.5948 	Validation Prec@1 81.010 	Validation Prec@5 98.970 

lr: 0.08281881862890808
TRAINING - Epoch: [279][0/391]	Time 0.914 (0.914)	Data 0.343 (0.343)	Loss 0.3564 (0.3564)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [279][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4792 (0.3822)	Prec@1 85.938 (86.626)	Prec@5 100.000 (99.513)
TRAINING - Epoch: [279][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2774 (0.3894)	Prec@1 89.844 (86.454)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [279][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3665 (0.3937)	Prec@1 86.719 (86.262)	Prec@5 99.219 (99.520)
EVALUATING - Epoch: [279][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.8800 (0.8800)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:24

 Epoch: 280	Training Loss 0.3946 	Training Prec@1 86.176 	Training Prec@5 99.514 	Validation Loss 0.8708 	Validation Prec@1 74.640 	Validation Prec@5 98.510 

lr: 0.08269967348733942
TRAINING - Epoch: [280][0/391]	Time 0.915 (0.915)	Data 0.344 (0.344)	Loss 0.3657 (0.3657)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [280][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3772 (0.3942)	Prec@1 86.719 (86.649)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [280][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4408 (0.3999)	Prec@1 83.594 (86.237)	Prec@5 100.000 (99.549)
TRAINING - Epoch: [280][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.3638 (0.4102)	Prec@1 85.938 (85.919)	Prec@5 100.000 (99.517)
EVALUATING - Epoch: [280][0/79]	Time 0.333 (0.333)	Data 0.312 (0.312)	Loss 0.4937 (0.4937)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:14

 Epoch: 281	Training Loss 0.4150 	Training Prec@1 85.724 	Training Prec@5 99.526 	Validation Loss 0.7706 	Validation Prec@1 76.980 	Validation Prec@5 98.400 

lr: 0.08258020301576219
TRAINING - Epoch: [281][0/391]	Time 0.950 (0.950)	Data 0.385 (0.385)	Loss 0.4576 (0.4576)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [281][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.4823 (0.4130)	Prec@1 83.594 (85.953)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [281][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3734 (0.4115)	Prec@1 84.375 (85.860)	Prec@5 99.219 (99.460)
TRAINING - Epoch: [281][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4580 (0.4169)	Prec@1 85.938 (85.681)	Prec@5 98.438 (99.437)
EVALUATING - Epoch: [281][0/79]	Time 0.382 (0.382)	Data 0.360 (0.360)	Loss 0.9044 (0.9044)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:18:46

 Epoch: 282	Training Loss 0.4151 	Training Prec@1 85.738 	Training Prec@5 99.438 	Validation Loss 1.1172 	Validation Prec@1 70.770 	Validation Prec@5 97.580 

lr: 0.0824604084027916
TRAINING - Epoch: [282][0/391]	Time 0.899 (0.899)	Data 0.344 (0.344)	Loss 0.4248 (0.4248)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [282][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4918 (0.3999)	Prec@1 80.469 (86.162)	Prec@5 100.000 (99.551)
TRAINING - Epoch: [282][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5209 (0.4240)	Prec@1 81.250 (85.339)	Prec@5 98.438 (99.495)
TRAINING - Epoch: [282][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3452 (0.4215)	Prec@1 90.625 (85.413)	Prec@5 100.000 (99.478)
EVALUATING - Epoch: [282][0/79]	Time 0.349 (0.349)	Data 0.328 (0.328)	Loss 0.5418 (0.5418)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:51

 Epoch: 283	Training Loss 0.4189 	Training Prec@1 85.536 	Training Prec@5 99.490 	Validation Loss 0.7830 	Validation Prec@1 77.070 	Validation Prec@5 98.290 

lr: 0.08234029084026775
TRAINING - Epoch: [283][0/391]	Time 0.936 (0.936)	Data 0.384 (0.384)	Loss 0.4277 (0.4277)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [283][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.4477 (0.3825)	Prec@1 88.281 (86.479)	Prec@5 100.000 (99.636)
TRAINING - Epoch: [283][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3284 (0.4060)	Prec@1 88.281 (85.786)	Prec@5 100.000 (99.549)
TRAINING - Epoch: [283][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.4345 (0.4106)	Prec@1 84.375 (85.769)	Prec@5 99.219 (99.525)
EVALUATING - Epoch: [283][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.4127 (0.4127)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:25

 Epoch: 284	Training Loss 0.4113 	Training Prec@1 85.796 	Training Prec@5 99.500 	Validation Loss 0.6986 	Validation Prec@1 78.630 	Validation Prec@5 98.700 

lr: 0.0822198515232438
TRAINING - Epoch: [284][0/391]	Time 0.917 (0.917)	Data 0.350 (0.350)	Loss 0.5335 (0.5335)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [284][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4003 (0.4011)	Prec@1 83.594 (86.355)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [284][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4669 (0.4112)	Prec@1 83.594 (85.891)	Prec@5 99.219 (99.495)
TRAINING - Epoch: [284][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3806 (0.4146)	Prec@1 89.062 (85.745)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [284][0/79]	Time 0.345 (0.345)	Data 0.324 (0.324)	Loss 0.5625 (0.5625)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:29

 Epoch: 285	Training Loss 0.4242 	Training Prec@1 85.484 	Training Prec@5 99.478 	Validation Loss 0.6527 	Validation Prec@1 79.610 	Validation Prec@5 99.000 

lr: 0.08209909164997405
TRAINING - Epoch: [285][0/391]	Time 0.909 (0.909)	Data 0.341 (0.341)	Loss 0.4839 (0.4839)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [285][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3984 (0.4250)	Prec@1 87.500 (85.481)	Prec@5 99.219 (99.598)
TRAINING - Epoch: [285][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3927 (0.4205)	Prec@1 85.156 (85.553)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [285][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4645 (0.4218)	Prec@1 83.594 (85.517)	Prec@5 100.000 (99.561)
EVALUATING - Epoch: [285][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.7457 (0.7457)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 286	Training Loss 0.4209 	Training Prec@1 85.552 	Training Prec@5 99.540 	Validation Loss 0.8104 	Validation Prec@1 74.960 	Validation Prec@5 98.440 

lr: 0.08197801242190197
TRAINING - Epoch: [286][0/391]	Time 0.962 (0.962)	Data 0.370 (0.370)	Loss 0.5022 (0.5022)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [286][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2648 (0.3986)	Prec@1 89.844 (86.262)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [286][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3474 (0.4060)	Prec@1 88.281 (86.007)	Prec@5 99.219 (99.584)
TRAINING - Epoch: [286][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.4603 (0.4073)	Prec@1 86.719 (86.034)	Prec@5 100.000 (99.574)
EVALUATING - Epoch: [286][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.5621 (0.5621)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 287	Training Loss 0.4074 	Training Prec@1 86.012 	Training Prec@5 99.548 	Validation Loss 0.7628 	Validation Prec@1 77.710 	Validation Prec@5 98.690 

lr: 0.0818566150436484
TRAINING - Epoch: [287][0/391]	Time 0.946 (0.946)	Data 0.378 (0.378)	Loss 0.2450 (0.2450)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [287][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3223 (0.3745)	Prec@1 89.844 (87.106)	Prec@5 100.000 (99.513)
TRAINING - Epoch: [287][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3557 (0.3940)	Prec@1 87.500 (86.618)	Prec@5 100.000 (99.440)
TRAINING - Epoch: [287][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3398 (0.3999)	Prec@1 90.625 (86.319)	Prec@5 100.000 (99.473)
EVALUATING - Epoch: [287][0/79]	Time 0.350 (0.350)	Data 0.328 (0.328)	Loss 0.5580 (0.5580)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:37

 Epoch: 288	Training Loss 0.4031 	Training Prec@1 86.152 	Training Prec@5 99.466 	Validation Loss 0.8327 	Validation Prec@1 75.050 	Validation Prec@5 98.530 

lr: 0.08173490072299937
TRAINING - Epoch: [288][0/391]	Time 0.922 (0.922)	Data 0.358 (0.358)	Loss 0.4613 (0.4613)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [288][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5264 (0.4290)	Prec@1 78.125 (85.350)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [288][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4483 (0.4188)	Prec@1 84.375 (85.833)	Prec@5 99.219 (99.448)
TRAINING - Epoch: [288][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4711 (0.4140)	Prec@1 83.594 (85.950)	Prec@5 99.219 (99.471)
EVALUATING - Epoch: [288][0/79]	Time 0.369 (0.369)	Data 0.341 (0.341)	Loss 0.7360 (0.7360)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:44

 Epoch: 289	Training Loss 0.4165 	Training Prec@1 85.860 	Training Prec@5 99.468 	Validation Loss 0.8418 	Validation Prec@1 75.460 	Validation Prec@5 98.700 

lr: 0.08161287067089423
TRAINING - Epoch: [289][0/391]	Time 0.928 (0.928)	Data 0.352 (0.352)	Loss 0.4515 (0.4515)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [289][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3494 (0.4309)	Prec@1 85.938 (85.102)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [289][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4176 (0.4258)	Prec@1 86.719 (85.351)	Prec@5 99.219 (99.487)
TRAINING - Epoch: [289][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3486 (0.4267)	Prec@1 86.719 (85.203)	Prec@5 100.000 (99.442)
EVALUATING - Epoch: [289][0/79]	Time 0.343 (0.343)	Data 0.322 (0.322)	Loss 0.6975 (0.6975)	Prec@1 82.031 (82.031)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:45

 Epoch: 290	Training Loss 0.4190 	Training Prec@1 85.416 	Training Prec@5 99.472 	Validation Loss 0.6797 	Validation Prec@1 80.230 	Validation Prec@5 98.720 

lr: 0.08149052610141352
TRAINING - Epoch: [290][0/391]	Time 0.921 (0.921)	Data 0.348 (0.348)	Loss 0.4648 (0.4648)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [290][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5538 (0.4090)	Prec@1 81.250 (85.690)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [290][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2869 (0.4064)	Prec@1 88.281 (85.899)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [290][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4776 (0.4058)	Prec@1 85.156 (86.052)	Prec@5 99.219 (99.504)
EVALUATING - Epoch: [290][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.8228 (0.8228)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 291	Training Loss 0.4078 	Training Prec@1 85.974 	Training Prec@5 99.494 	Validation Loss 0.8118 	Validation Prec@1 76.710 	Validation Prec@5 97.960 

lr: 0.08136786823176698
TRAINING - Epoch: [291][0/391]	Time 0.926 (0.926)	Data 0.344 (0.344)	Loss 0.4396 (0.4396)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [291][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3759 (0.3869)	Prec@1 85.156 (86.208)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [291][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3236 (0.3979)	Prec@1 90.625 (86.136)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [291][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3154 (0.3980)	Prec@1 89.844 (86.184)	Prec@5 100.000 (99.515)
EVALUATING - Epoch: [291][0/79]	Time 0.366 (0.366)	Data 0.342 (0.342)	Loss 0.5339 (0.5339)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 292	Training Loss 0.4054 	Training Prec@1 85.960 	Training Prec@5 99.488 	Validation Loss 0.6927 	Validation Prec@1 79.150 	Validation Prec@5 97.800 

lr: 0.08124489828228132
TRAINING - Epoch: [292][0/391]	Time 0.972 (0.972)	Data 0.382 (0.382)	Loss 0.4265 (0.4265)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [292][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2831 (0.3951)	Prec@1 91.406 (86.649)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [292][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2798 (0.3948)	Prec@1 89.844 (86.478)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [292][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3811 (0.3962)	Prec@1 86.719 (86.467)	Prec@5 98.438 (99.556)
EVALUATING - Epoch: [292][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.7106 (0.7106)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:33

 Epoch: 293	Training Loss 0.4065 	Training Prec@1 86.110 	Training Prec@5 99.532 	Validation Loss 0.6758 	Validation Prec@1 79.270 	Validation Prec@5 98.840 

lr: 0.08112161747638817
TRAINING - Epoch: [293][0/391]	Time 0.924 (0.924)	Data 0.344 (0.344)	Loss 0.3067 (0.3067)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [293][100/391]	Time 0.067 (0.071)	Data 0.000 (0.004)	Loss 0.3066 (0.3930)	Prec@1 88.281 (86.672)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [293][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3854 (0.3987)	Prec@1 87.500 (86.622)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [293][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3098 (0.4068)	Prec@1 89.062 (86.335)	Prec@5 100.000 (99.530)
EVALUATING - Epoch: [293][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.8343 (0.8343)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:25

 Epoch: 294	Training Loss 0.4127 	Training Prec@1 86.176 	Training Prec@5 99.518 	Validation Loss 0.8153 	Validation Prec@1 76.270 	Validation Prec@5 97.770 

lr: 0.0809980270406119
TRAINING - Epoch: [294][0/391]	Time 0.945 (0.945)	Data 0.384 (0.384)	Loss 0.4609 (0.4609)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [294][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5575 (0.4230)	Prec@1 82.031 (85.806)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [294][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4773 (0.4168)	Prec@1 89.062 (85.984)	Prec@5 100.000 (99.522)
TRAINING - Epoch: [294][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2861 (0.4177)	Prec@1 90.625 (85.891)	Prec@5 100.000 (99.515)
EVALUATING - Epoch: [294][0/79]	Time 0.366 (0.366)	Data 0.346 (0.346)	Loss 0.3732 (0.3732)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:23

 Epoch: 295	Training Loss 0.4155 	Training Prec@1 85.946 	Training Prec@5 99.500 	Validation Loss 0.5762 	Validation Prec@1 81.610 	Validation Prec@5 98.870 

lr: 0.08087412820455733
TRAINING - Epoch: [295][0/391]	Time 0.940 (0.940)	Data 0.377 (0.377)	Loss 0.3168 (0.3168)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [295][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3931 (0.3777)	Prec@1 85.156 (86.966)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [295][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4402 (0.3960)	Prec@1 85.938 (86.322)	Prec@5 99.219 (99.576)
TRAINING - Epoch: [295][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5342 (0.4064)	Prec@1 82.031 (86.005)	Prec@5 97.656 (99.530)
EVALUATING - Epoch: [295][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 0.7956 (0.7956)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:53

 Epoch: 296	Training Loss 0.4050 	Training Prec@1 86.076 	Training Prec@5 99.506 	Validation Loss 0.8112 	Validation Prec@1 75.720 	Validation Prec@5 97.690 

lr: 0.08074992220089763
TRAINING - Epoch: [296][0/391]	Time 0.910 (0.910)	Data 0.354 (0.354)	Loss 0.3667 (0.3667)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [296][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3348 (0.3859)	Prec@1 85.938 (86.665)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [296][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5877 (0.3960)	Prec@1 78.125 (86.540)	Prec@5 100.000 (99.491)
TRAINING - Epoch: [296][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3270 (0.3993)	Prec@1 85.156 (86.433)	Prec@5 99.219 (99.489)
EVALUATING - Epoch: [296][0/79]	Time 0.340 (0.340)	Data 0.319 (0.319)	Loss 0.5332 (0.5332)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:52

 Epoch: 297	Training Loss 0.4024 	Training Prec@1 86.342 	Training Prec@5 99.508 	Validation Loss 0.6931 	Validation Prec@1 78.690 	Validation Prec@5 98.840 

lr: 0.08062541026536199
TRAINING - Epoch: [297][0/391]	Time 0.899 (0.899)	Data 0.335 (0.335)	Loss 0.4802 (0.4802)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [297][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2913 (0.3865)	Prec@1 87.500 (86.572)	Prec@5 99.219 (99.575)
TRAINING - Epoch: [297][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2663 (0.3995)	Prec@1 89.062 (86.042)	Prec@5 99.219 (99.596)
TRAINING - Epoch: [297][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5469 (0.4008)	Prec@1 82.031 (86.034)	Prec@5 99.219 (99.587)
EVALUATING - Epoch: [297][0/79]	Time 0.378 (0.378)	Data 0.355 (0.355)	Loss 0.5952 (0.5952)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:33

 Epoch: 298	Training Loss 0.3981 	Training Prec@1 86.096 	Training Prec@5 99.604 	Validation Loss 0.6253 	Validation Prec@1 80.060 	Validation Prec@5 99.020 

lr: 0.08050059363672324
TRAINING - Epoch: [298][0/391]	Time 0.950 (0.950)	Data 0.381 (0.381)	Loss 0.4041 (0.4041)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [298][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4857 (0.3957)	Prec@1 79.688 (86.301)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [298][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4776 (0.4027)	Prec@1 82.812 (86.326)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [298][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3287 (0.3976)	Prec@1 87.500 (86.322)	Prec@5 100.000 (99.567)
EVALUATING - Epoch: [298][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.6466 (0.6466)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:06

 Epoch: 299	Training Loss 0.4036 	Training Prec@1 86.120 	Training Prec@5 99.556 	Validation Loss 0.6897 	Validation Prec@1 79.160 	Validation Prec@5 98.010 

lr: 0.08037547355678575
TRAINING - Epoch: [299][0/391]	Time 0.932 (0.932)	Data 0.362 (0.362)	Loss 0.3873 (0.3873)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [299][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2959 (0.3835)	Prec@1 89.844 (87.106)	Prec@5 99.219 (99.544)
TRAINING - Epoch: [299][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4384 (0.3907)	Prec@1 84.375 (86.793)	Prec@5 98.438 (99.479)
TRAINING - Epoch: [299][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5315 (0.3895)	Prec@1 85.938 (86.745)	Prec@5 99.219 (99.507)
EVALUATING - Epoch: [299][0/79]	Time 0.356 (0.356)	Data 0.337 (0.337)	Loss 0.6678 (0.6678)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:25

 Epoch: 300	Training Loss 0.3916 	Training Prec@1 86.592 	Training Prec@5 99.520 	Validation Loss 0.7773 	Validation Prec@1 77.490 	Validation Prec@5 98.640 

lr: 0.08025005127037278
TRAINING - Epoch: [300][0/391]	Time 0.941 (0.941)	Data 0.346 (0.346)	Loss 0.5360 (0.5360)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [300][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3659 (0.3963)	Prec@1 87.500 (86.069)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [300][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3231 (0.3867)	Prec@1 89.844 (86.594)	Prec@5 100.000 (99.572)
TRAINING - Epoch: [300][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4219 (0.3919)	Prec@1 83.594 (86.483)	Prec@5 100.000 (99.556)
EVALUATING - Epoch: [300][0/79]	Time 0.365 (0.365)	Data 0.345 (0.345)	Loss 0.6462 (0.6462)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 301	Training Loss 0.3958 	Training Prec@1 86.298 	Training Prec@5 99.534 	Validation Loss 0.7254 	Validation Prec@1 77.560 	Validation Prec@5 98.400 

lr: 0.08012432802531437
TRAINING - Epoch: [301][0/391]	Time 0.898 (0.898)	Data 0.348 (0.348)	Loss 0.4457 (0.4457)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [301][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5955 (0.3973)	Prec@1 79.688 (86.394)	Prec@5 99.219 (99.373)
TRAINING - Epoch: [301][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2211 (0.3984)	Prec@1 92.969 (86.384)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [301][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2822 (0.4036)	Prec@1 90.625 (86.223)	Prec@5 100.000 (99.426)
EVALUATING - Epoch: [301][0/79]	Time 0.357 (0.357)	Data 0.338 (0.338)	Loss 0.5657 (0.5657)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:46

 Epoch: 302	Training Loss 0.4031 	Training Prec@1 86.236 	Training Prec@5 99.452 	Validation Loss 0.6151 	Validation Prec@1 80.290 	Validation Prec@5 98.980 

lr: 0.07999830507243474
TRAINING - Epoch: [302][0/391]	Time 0.926 (0.926)	Data 0.345 (0.345)	Loss 0.3795 (0.3795)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [302][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3618 (0.3647)	Prec@1 84.375 (87.183)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [302][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3559 (0.3918)	Prec@1 86.719 (86.559)	Prec@5 99.219 (99.491)
TRAINING - Epoch: [302][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2613 (0.3993)	Prec@1 89.062 (86.298)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [302][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.6558 (0.6558)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 303	Training Loss 0.4018 	Training Prec@1 86.162 	Training Prec@5 99.498 	Validation Loss 0.6615 	Validation Prec@1 79.540 	Validation Prec@5 98.750 

lr: 0.07987198366553998
TRAINING - Epoch: [303][0/391]	Time 0.908 (0.908)	Data 0.342 (0.342)	Loss 0.3329 (0.3329)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [303][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5511 (0.4149)	Prec@1 81.250 (85.713)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [303][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.3712 (0.4055)	Prec@1 86.719 (85.961)	Prec@5 99.219 (99.545)
TRAINING - Epoch: [303][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3555 (0.4093)	Prec@1 86.719 (85.844)	Prec@5 100.000 (99.533)
EVALUATING - Epoch: [303][0/79]	Time 0.421 (0.421)	Data 0.397 (0.397)	Loss 0.6280 (0.6280)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:01

 Epoch: 304	Training Loss 0.4104 	Training Prec@1 85.904 	Training Prec@5 99.516 	Validation Loss 0.5975 	Validation Prec@1 80.870 	Validation Prec@5 98.620 

lr: 0.07974536506140542
TRAINING - Epoch: [304][0/391]	Time 0.917 (0.917)	Data 0.345 (0.345)	Loss 0.3307 (0.3307)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [304][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4600 (0.4017)	Prec@1 83.594 (86.409)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [304][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3631 (0.3972)	Prec@1 87.500 (86.350)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [304][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3642 (0.4006)	Prec@1 85.938 (86.205)	Prec@5 100.000 (99.530)
EVALUATING - Epoch: [304][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 0.5761 (0.5761)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:17

 Epoch: 305	Training Loss 0.3994 	Training Prec@1 86.254 	Training Prec@5 99.542 	Validation Loss 0.6613 	Validation Prec@1 79.660 	Validation Prec@5 98.690 

lr: 0.0796184505197633
TRAINING - Epoch: [305][0/391]	Time 0.929 (0.929)	Data 0.363 (0.363)	Loss 0.5005 (0.5005)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [305][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4012 (0.3921)	Prec@1 87.500 (86.665)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [305][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.6248 (0.4064)	Prec@1 81.250 (86.155)	Prec@5 100.000 (99.499)
TRAINING - Epoch: [305][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4040 (0.4087)	Prec@1 87.500 (86.028)	Prec@5 100.000 (99.504)
EVALUATING - Epoch: [305][0/79]	Time 0.351 (0.351)	Data 0.332 (0.332)	Loss 0.6221 (0.6221)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:59

 Epoch: 306	Training Loss 0.4068 	Training Prec@1 86.022 	Training Prec@5 99.492 	Validation Loss 0.7285 	Validation Prec@1 78.410 	Validation Prec@5 98.510 

lr: 0.07949124130329005
TRAINING - Epoch: [306][0/391]	Time 0.930 (0.930)	Data 0.366 (0.366)	Loss 0.4128 (0.4128)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [306][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3126 (0.4026)	Prec@1 87.500 (86.162)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [306][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4690 (0.4011)	Prec@1 85.938 (86.120)	Prec@5 99.219 (99.545)
TRAINING - Epoch: [306][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3486 (0.4007)	Prec@1 88.281 (86.181)	Prec@5 100.000 (99.546)
EVALUATING - Epoch: [306][0/79]	Time 0.384 (0.384)	Data 0.362 (0.362)	Loss 0.5446 (0.5446)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:17

 Epoch: 307	Training Loss 0.4052 	Training Prec@1 86.066 	Training Prec@5 99.518 	Validation Loss 0.6641 	Validation Prec@1 79.340 	Validation Prec@5 98.720 

lr: 0.07936373867759396
TRAINING - Epoch: [307][0/391]	Time 0.917 (0.917)	Data 0.341 (0.341)	Loss 0.4682 (0.4682)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [307][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.6066 (0.3718)	Prec@1 82.031 (87.191)	Prec@5 98.438 (99.567)
TRAINING - Epoch: [307][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4453 (0.3885)	Prec@1 82.031 (86.637)	Prec@5 99.219 (99.549)
TRAINING - Epoch: [307][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3322 (0.3978)	Prec@1 85.938 (86.340)	Prec@5 99.219 (99.533)
EVALUATING - Epoch: [307][0/79]	Time 0.338 (0.338)	Data 0.316 (0.316)	Loss 0.5611 (0.5611)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:23

 Epoch: 308	Training Loss 0.3984 	Training Prec@1 86.300 	Training Prec@5 99.494 	Validation Loss 0.7778 	Validation Prec@1 75.940 	Validation Prec@5 98.560 

lr: 0.07923594391120234
TRAINING - Epoch: [308][0/391]	Time 0.895 (0.895)	Data 0.337 (0.337)	Loss 0.2606 (0.2606)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [308][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4383 (0.3808)	Prec@1 84.375 (86.812)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [308][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4103 (0.3959)	Prec@1 88.281 (86.474)	Prec@5 99.219 (99.502)
TRAINING - Epoch: [308][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4261 (0.4063)	Prec@1 85.156 (86.163)	Prec@5 100.000 (99.481)
EVALUATING - Epoch: [308][0/79]	Time 0.376 (0.376)	Data 0.355 (0.355)	Loss 0.6906 (0.6906)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:01

 Epoch: 309	Training Loss 0.4044 	Training Prec@1 86.142 	Training Prec@5 99.512 	Validation Loss 0.6615 	Validation Prec@1 79.150 	Validation Prec@5 98.620 

lr: 0.07910785827554905
TRAINING - Epoch: [309][0/391]	Time 0.922 (0.922)	Data 0.347 (0.347)	Loss 0.4024 (0.4024)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [309][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3978 (0.3839)	Prec@1 84.375 (86.456)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [309][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4081 (0.3877)	Prec@1 83.594 (86.435)	Prec@5 99.219 (99.592)
TRAINING - Epoch: [309][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4197 (0.3968)	Prec@1 86.719 (86.288)	Prec@5 99.219 (99.559)
EVALUATING - Epoch: [309][0/79]	Time 0.349 (0.349)	Data 0.326 (0.326)	Loss 0.6682 (0.6682)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:57

 Epoch: 310	Training Loss 0.3992 	Training Prec@1 86.238 	Training Prec@5 99.544 	Validation Loss 0.7593 	Validation Prec@1 76.770 	Validation Prec@5 98.540 

lr: 0.07897948304496186
TRAINING - Epoch: [310][0/391]	Time 0.926 (0.926)	Data 0.367 (0.367)	Loss 0.3582 (0.3582)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [310][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3204 (0.3908)	Prec@1 88.281 (86.533)	Prec@5 99.219 (99.606)
TRAINING - Epoch: [310][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5210 (0.3900)	Prec@1 82.812 (86.431)	Prec@5 99.219 (99.576)
TRAINING - Epoch: [310][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5365 (0.3903)	Prec@1 80.469 (86.462)	Prec@5 98.438 (99.580)
EVALUATING - Epoch: [310][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.8048 (0.8048)	Prec@1 74.219 (74.219)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:22

 Epoch: 311	Training Loss 0.3927 	Training Prec@1 86.418 	Training Prec@5 99.566 	Validation Loss 0.8457 	Validation Prec@1 76.060 	Validation Prec@5 97.860 

lr: 0.07885081949664968
TRAINING - Epoch: [311][0/391]	Time 0.943 (0.943)	Data 0.371 (0.371)	Loss 0.3352 (0.3352)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [311][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4178 (0.3803)	Prec@1 82.812 (86.827)	Prec@5 98.438 (99.513)
TRAINING - Epoch: [311][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3726 (0.3850)	Prec@1 85.938 (86.618)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [311][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4735 (0.3891)	Prec@1 85.156 (86.594)	Prec@5 100.000 (99.502)
EVALUATING - Epoch: [311][0/79]	Time 0.345 (0.345)	Data 0.325 (0.325)	Loss 0.7496 (0.7496)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:48

 Epoch: 312	Training Loss 0.3911 	Training Prec@1 86.628 	Training Prec@5 99.510 	Validation Loss 0.7030 	Validation Prec@1 78.090 	Validation Prec@5 98.750 

lr: 0.07872186891068991
TRAINING - Epoch: [312][0/391]	Time 0.919 (0.919)	Data 0.368 (0.368)	Loss 0.3858 (0.3858)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [312][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2879 (0.4006)	Prec@1 88.281 (86.224)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [312][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3360 (0.3896)	Prec@1 89.062 (86.711)	Prec@5 98.438 (99.576)
TRAINING - Epoch: [312][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4966 (0.3928)	Prec@1 82.812 (86.529)	Prec@5 100.000 (99.541)
EVALUATING - Epoch: [312][0/79]	Time 0.357 (0.357)	Data 0.336 (0.336)	Loss 0.6373 (0.6373)	Prec@1 82.031 (82.031)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:10

 Epoch: 313	Training Loss 0.3906 	Training Prec@1 86.596 	Training Prec@5 99.516 	Validation Loss 0.8000 	Validation Prec@1 77.190 	Validation Prec@5 98.040 

lr: 0.07859263257001572
TRAINING - Epoch: [313][0/391]	Time 0.906 (0.906)	Data 0.347 (0.347)	Loss 0.4794 (0.4794)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [313][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3204 (0.3927)	Prec@1 88.281 (86.580)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [313][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3807 (0.3935)	Prec@1 84.375 (86.392)	Prec@5 100.000 (99.561)
TRAINING - Epoch: [313][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3869 (0.3956)	Prec@1 85.156 (86.316)	Prec@5 99.219 (99.535)
EVALUATING - Epoch: [313][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.5423 (0.5423)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:35

 Epoch: 314	Training Loss 0.4022 	Training Prec@1 86.182 	Training Prec@5 99.522 	Validation Loss 0.7438 	Validation Prec@1 77.050 	Validation Prec@5 98.890 

lr: 0.07846311176040326
TRAINING - Epoch: [314][0/391]	Time 0.932 (0.932)	Data 0.353 (0.353)	Loss 0.3662 (0.3662)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [314][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3283 (0.3602)	Prec@1 89.062 (87.113)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [314][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3732 (0.3768)	Prec@1 91.406 (86.715)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [314][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5456 (0.3815)	Prec@1 83.594 (86.612)	Prec@5 99.219 (99.639)
EVALUATING - Epoch: [314][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.9172 (0.9172)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:56

 Epoch: 315	Training Loss 0.3847 	Training Prec@1 86.604 	Training Prec@5 99.604 	Validation Loss 0.8911 	Validation Prec@1 74.260 	Validation Prec@5 99.250 

lr: 0.07833330777045881
TRAINING - Epoch: [315][0/391]	Time 0.910 (0.910)	Data 0.353 (0.353)	Loss 0.4726 (0.4726)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [315][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3872 (0.3724)	Prec@1 85.156 (86.935)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [315][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.5403 (0.3882)	Prec@1 83.594 (86.528)	Prec@5 97.656 (99.650)
TRAINING - Epoch: [315][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5703 (0.3873)	Prec@1 82.031 (86.488)	Prec@5 99.219 (99.629)
EVALUATING - Epoch: [315][0/79]	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.7526 (0.7526)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:41

 Epoch: 316	Training Loss 0.3879 	Training Prec@1 86.536 	Training Prec@5 99.624 	Validation Loss 0.7729 	Validation Prec@1 77.560 	Validation Prec@5 98.570 

lr: 0.07820322189160613
TRAINING - Epoch: [316][0/391]	Time 0.917 (0.917)	Data 0.353 (0.353)	Loss 0.4230 (0.4230)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [316][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.4849 (0.3814)	Prec@1 82.812 (86.858)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [316][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3714 (0.3820)	Prec@1 84.375 (86.773)	Prec@5 100.000 (99.596)
TRAINING - Epoch: [316][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3653 (0.3769)	Prec@1 85.938 (86.893)	Prec@5 100.000 (99.590)
EVALUATING - Epoch: [316][0/79]	Time 0.346 (0.346)	Data 0.322 (0.322)	Loss 0.5148 (0.5148)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:38

 Epoch: 317	Training Loss 0.3788 	Training Prec@1 86.832 	Training Prec@5 99.590 	Validation Loss 0.6393 	Validation Prec@1 79.890 	Validation Prec@5 98.860 

lr: 0.07807285541807338
TRAINING - Epoch: [317][0/391]	Time 0.908 (0.908)	Data 0.352 (0.352)	Loss 0.2751 (0.2751)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [317][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3842 (0.3731)	Prec@1 87.500 (87.129)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [317][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2480 (0.3941)	Prec@1 90.625 (86.353)	Prec@5 100.000 (99.510)
TRAINING - Epoch: [317][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3283 (0.3945)	Prec@1 89.844 (86.296)	Prec@5 99.219 (99.517)
EVALUATING - Epoch: [317][0/79]	Time 0.364 (0.364)	Data 0.343 (0.343)	Loss 0.5506 (0.5506)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:00

 Epoch: 318	Training Loss 0.3953 	Training Prec@1 86.296 	Training Prec@5 99.546 	Validation Loss 0.6167 	Validation Prec@1 80.300 	Validation Prec@5 99.060 

lr: 0.07794220964688044
TRAINING - Epoch: [318][0/391]	Time 0.909 (0.909)	Data 0.350 (0.350)	Loss 0.3029 (0.3029)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [318][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4507 (0.3679)	Prec@1 87.500 (87.067)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [318][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4308 (0.3796)	Prec@1 82.031 (86.699)	Prec@5 100.000 (99.615)
TRAINING - Epoch: [318][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4998 (0.3868)	Prec@1 83.594 (86.483)	Prec@5 99.219 (99.577)
EVALUATING - Epoch: [318][0/79]	Time 0.363 (0.363)	Data 0.343 (0.343)	Loss 0.6380 (0.6380)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:13

 Epoch: 319	Training Loss 0.3948 	Training Prec@1 86.274 	Training Prec@5 99.540 	Validation Loss 0.7171 	Validation Prec@1 78.070 	Validation Prec@5 98.790 

lr: 0.0778112858778259
TRAINING - Epoch: [319][0/391]	Time 0.909 (0.909)	Data 0.361 (0.361)	Loss 0.2587 (0.2587)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [319][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4496 (0.3944)	Prec@1 85.156 (86.216)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [319][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2951 (0.3889)	Prec@1 88.281 (86.439)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [319][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3098 (0.3913)	Prec@1 89.062 (86.345)	Prec@5 100.000 (99.543)
EVALUATING - Epoch: [319][0/79]	Time 0.357 (0.357)	Data 0.337 (0.337)	Loss 0.6183 (0.6183)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:00

 Epoch: 320	Training Loss 0.3890 	Training Prec@1 86.340 	Training Prec@5 99.560 	Validation Loss 0.6345 	Validation Prec@1 79.480 	Validation Prec@5 98.980 

lr: 0.07768008541347418
TRAINING - Epoch: [320][0/391]	Time 0.898 (0.898)	Data 0.335 (0.335)	Loss 0.2760 (0.2760)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [320][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4341 (0.3775)	Prec@1 87.500 (87.198)	Prec@5 100.000 (99.551)
TRAINING - Epoch: [320][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3553 (0.3861)	Prec@1 88.281 (86.820)	Prec@5 99.219 (99.549)
TRAINING - Epoch: [320][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3936 (0.3971)	Prec@1 86.719 (86.425)	Prec@5 99.219 (99.541)
EVALUATING - Epoch: [320][0/79]	Time 0.376 (0.376)	Data 0.353 (0.353)	Loss 0.7374 (0.7374)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:01

 Epoch: 321	Training Loss 0.4014 	Training Prec@1 86.304 	Training Prec@5 99.542 	Validation Loss 0.7565 	Validation Prec@1 76.640 	Validation Prec@5 98.560 

lr: 0.07754860955914257
TRAINING - Epoch: [321][0/391]	Time 0.907 (0.907)	Data 0.337 (0.337)	Loss 0.3205 (0.3205)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [321][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4448 (0.3890)	Prec@1 81.250 (86.433)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [321][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3716 (0.3854)	Prec@1 88.281 (86.606)	Prec@5 98.438 (99.502)
TRAINING - Epoch: [321][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4438 (0.3911)	Prec@1 85.938 (86.418)	Prec@5 99.219 (99.507)
EVALUATING - Epoch: [321][0/79]	Time 0.373 (0.373)	Data 0.352 (0.352)	Loss 0.6157 (0.6157)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:53

 Epoch: 322	Training Loss 0.3952 	Training Prec@1 86.402 	Training Prec@5 99.506 	Validation Loss 0.6853 	Validation Prec@1 79.710 	Validation Prec@5 98.710 

lr: 0.07741685962288813
TRAINING - Epoch: [322][0/391]	Time 0.911 (0.911)	Data 0.342 (0.342)	Loss 0.3030 (0.3030)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [322][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3073 (0.3960)	Prec@1 91.406 (86.649)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [322][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4676 (0.3999)	Prec@1 83.594 (86.458)	Prec@5 99.219 (99.569)
TRAINING - Epoch: [322][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.6970 (0.4056)	Prec@1 80.469 (86.257)	Prec@5 96.875 (99.533)
EVALUATING - Epoch: [322][0/79]	Time 0.354 (0.354)	Data 0.334 (0.334)	Loss 0.4903 (0.4903)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:48

 Epoch: 323	Training Loss 0.4055 	Training Prec@1 86.270 	Training Prec@5 99.532 	Validation Loss 0.7214 	Validation Prec@1 79.060 	Validation Prec@5 98.510 

lr: 0.07728483691549487
TRAINING - Epoch: [323][0/391]	Time 0.910 (0.910)	Data 0.350 (0.350)	Loss 0.5577 (0.5577)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [323][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4172 (0.3811)	Prec@1 85.938 (86.819)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [323][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3584 (0.3770)	Prec@1 88.281 (87.104)	Prec@5 100.000 (99.514)
TRAINING - Epoch: [323][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4594 (0.3883)	Prec@1 81.250 (86.763)	Prec@5 99.219 (99.548)
EVALUATING - Epoch: [323][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.5784 (0.5784)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 324	Training Loss 0.3905 	Training Prec@1 86.576 	Training Prec@5 99.536 	Validation Loss 0.6316 	Validation Prec@1 79.980 	Validation Prec@5 98.800 

lr: 0.07715254275046059
TRAINING - Epoch: [324][0/391]	Time 0.947 (0.947)	Data 0.344 (0.344)	Loss 0.3039 (0.3039)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [324][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.4085 (0.3820)	Prec@1 85.156 (86.796)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [324][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4436 (0.3805)	Prec@1 83.594 (86.812)	Prec@5 100.000 (99.588)
TRAINING - Epoch: [324][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3619 (0.3880)	Prec@1 86.719 (86.607)	Prec@5 100.000 (99.543)
EVALUATING - Epoch: [324][0/79]	Time 0.376 (0.376)	Data 0.356 (0.356)	Loss 0.5500 (0.5500)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 325	Training Loss 0.3911 	Training Prec@1 86.534 	Training Prec@5 99.546 	Validation Loss 0.6404 	Validation Prec@1 80.670 	Validation Prec@5 98.490 

lr: 0.07701997844398376
TRAINING - Epoch: [325][0/391]	Time 0.936 (0.936)	Data 0.359 (0.359)	Loss 0.4283 (0.4283)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [325][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3384 (0.3856)	Prec@1 86.719 (86.804)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [325][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2981 (0.3828)	Prec@1 89.844 (86.855)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [325][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3850 (0.3829)	Prec@1 91.406 (86.836)	Prec@5 99.219 (99.538)
EVALUATING - Epoch: [325][0/79]	Time 0.343 (0.343)	Data 0.323 (0.323)	Loss 0.7881 (0.7881)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:54

 Epoch: 326	Training Loss 0.3827 	Training Prec@1 86.832 	Training Prec@5 99.538 	Validation Loss 0.7082 	Validation Prec@1 78.160 	Validation Prec@5 98.850 

lr: 0.07688714531495057
TRAINING - Epoch: [326][0/391]	Time 0.941 (0.941)	Data 0.368 (0.368)	Loss 0.3278 (0.3278)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [326][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3447 (0.3817)	Prec@1 87.500 (87.013)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [326][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.2926 (0.3727)	Prec@1 90.625 (87.189)	Prec@5 100.000 (99.619)
TRAINING - Epoch: [326][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4199 (0.3799)	Prec@1 87.500 (86.887)	Prec@5 100.000 (99.618)
EVALUATING - Epoch: [326][0/79]	Time 0.385 (0.385)	Data 0.360 (0.360)	Loss 0.6686 (0.6686)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 327	Training Loss 0.3864 	Training Prec@1 86.678 	Training Prec@5 99.598 	Validation Loss 0.6647 	Validation Prec@1 79.000 	Validation Prec@5 98.680 

lr: 0.07675404468492172
TRAINING - Epoch: [327][0/391]	Time 0.938 (0.938)	Data 0.382 (0.382)	Loss 0.3773 (0.3773)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [327][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2767 (0.3788)	Prec@1 89.844 (86.734)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [327][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2623 (0.3894)	Prec@1 89.844 (86.641)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [327][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2893 (0.3903)	Prec@1 90.625 (86.669)	Prec@5 99.219 (99.572)
EVALUATING - Epoch: [327][0/79]	Time 0.359 (0.359)	Data 0.336 (0.336)	Loss 0.5395 (0.5395)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:13

 Epoch: 328	Training Loss 0.3874 	Training Prec@1 86.754 	Training Prec@5 99.566 	Validation Loss 0.7438 	Validation Prec@1 77.510 	Validation Prec@5 98.660 

lr: 0.07662067787811926
TRAINING - Epoch: [328][0/391]	Time 0.902 (0.902)	Data 0.342 (0.342)	Loss 0.4258 (0.4258)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [328][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3025 (0.3749)	Prec@1 89.844 (87.167)	Prec@5 99.219 (99.559)
TRAINING - Epoch: [328][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4612 (0.3835)	Prec@1 85.938 (86.933)	Prec@5 100.000 (99.526)
TRAINING - Epoch: [328][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5675 (0.3830)	Prec@1 79.688 (86.778)	Prec@5 100.000 (99.541)
EVALUATING - Epoch: [328][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 0.5919 (0.5919)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:35

 Epoch: 329	Training Loss 0.3888 	Training Prec@1 86.460 	Training Prec@5 99.562 	Validation Loss 0.7225 	Validation Prec@1 76.840 	Validation Prec@5 98.800 

lr: 0.07648704622141345
TRAINING - Epoch: [329][0/391]	Time 0.904 (0.904)	Data 0.340 (0.340)	Loss 0.3955 (0.3955)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [329][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4232 (0.3770)	Prec@1 87.500 (87.020)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [329][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4295 (0.3822)	Prec@1 85.938 (86.866)	Prec@5 99.219 (99.607)
TRAINING - Epoch: [329][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.3278 (0.3907)	Prec@1 89.844 (86.488)	Prec@5 100.000 (99.639)
EVALUATING - Epoch: [329][0/79]	Time 0.357 (0.357)	Data 0.334 (0.334)	Loss 0.5206 (0.5206)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:33

 Epoch: 330	Training Loss 0.3959 	Training Prec@1 86.342 	Training Prec@5 99.602 	Validation Loss 0.5552 	Validation Prec@1 82.270 	Validation Prec@5 98.850 

lr: 0.07635315104430955
TRAINING - Epoch: [330][0/391]	Time 0.930 (0.930)	Data 0.345 (0.345)	Loss 0.3729 (0.3729)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [330][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2575 (0.3852)	Prec@1 89.844 (86.657)	Prec@5 100.000 (99.636)
TRAINING - Epoch: [330][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4329 (0.3810)	Prec@1 85.156 (86.828)	Prec@5 99.219 (99.607)
TRAINING - Epoch: [330][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3744 (0.3884)	Prec@1 84.375 (86.612)	Prec@5 99.219 (99.577)
EVALUATING - Epoch: [330][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.5494 (0.5494)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 331	Training Loss 0.3897 	Training Prec@1 86.626 	Training Prec@5 99.574 	Validation Loss 0.6157 	Validation Prec@1 80.070 	Validation Prec@5 99.030 

lr: 0.07621899367893463
TRAINING - Epoch: [331][0/391]	Time 0.930 (0.930)	Data 0.338 (0.338)	Loss 0.3732 (0.3732)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [331][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2946 (0.3597)	Prec@1 90.625 (87.384)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [331][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2753 (0.3668)	Prec@1 90.625 (87.197)	Prec@5 100.000 (99.572)
TRAINING - Epoch: [331][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3531 (0.3729)	Prec@1 83.594 (86.991)	Prec@5 100.000 (99.587)
EVALUATING - Epoch: [331][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.5781 (0.5781)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:02

 Epoch: 332	Training Loss 0.3764 	Training Prec@1 86.928 	Training Prec@5 99.594 	Validation Loss 0.5950 	Validation Prec@1 80.880 	Validation Prec@5 98.720 

lr: 0.0760845754600242
TRAINING - Epoch: [332][0/391]	Time 0.911 (0.911)	Data 0.364 (0.364)	Loss 0.4902 (0.4902)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [332][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4375 (0.3705)	Prec@1 85.938 (86.997)	Prec@5 98.438 (99.598)
TRAINING - Epoch: [332][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4496 (0.3817)	Prec@1 82.812 (86.563)	Prec@5 99.219 (99.592)
TRAINING - Epoch: [332][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4849 (0.3822)	Prec@1 85.938 (86.589)	Prec@5 100.000 (99.613)
EVALUATING - Epoch: [332][0/79]	Time 0.339 (0.339)	Data 0.317 (0.317)	Loss 0.4493 (0.4493)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:45

 Epoch: 333	Training Loss 0.3800 	Training Prec@1 86.678 	Training Prec@5 99.616 	Validation Loss 0.7320 	Validation Prec@1 77.880 	Validation Prec@5 98.800 

lr: 0.07594989772490908
TRAINING - Epoch: [333][0/391]	Time 0.923 (0.923)	Data 0.349 (0.349)	Loss 0.4216 (0.4216)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [333][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4178 (0.3773)	Prec@1 85.156 (86.959)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [333][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3095 (0.3938)	Prec@1 88.281 (86.521)	Prec@5 100.000 (99.530)
TRAINING - Epoch: [333][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3274 (0.3928)	Prec@1 87.500 (86.680)	Prec@5 100.000 (99.525)
EVALUATING - Epoch: [333][0/79]	Time 0.343 (0.343)	Data 0.320 (0.320)	Loss 0.6089 (0.6089)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:21

 Epoch: 334	Training Loss 0.3973 	Training Prec@1 86.504 	Training Prec@5 99.514 	Validation Loss 0.6879 	Validation Prec@1 79.590 	Validation Prec@5 98.880 

lr: 0.075814961813502
TRAINING - Epoch: [334][0/391]	Time 0.938 (0.938)	Data 0.345 (0.345)	Loss 0.3236 (0.3236)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [334][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3771 (0.3963)	Prec@1 86.719 (86.680)	Prec@5 99.219 (99.451)
TRAINING - Epoch: [334][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3175 (0.3878)	Prec@1 85.938 (86.769)	Prec@5 100.000 (99.526)
TRAINING - Epoch: [334][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.6446 (0.3890)	Prec@1 82.031 (86.695)	Prec@5 99.219 (99.525)
EVALUATING - Epoch: [334][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.6032 (0.6032)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:59

 Epoch: 335	Training Loss 0.3931 	Training Prec@1 86.512 	Training Prec@5 99.528 	Validation Loss 0.6935 	Validation Prec@1 78.920 	Validation Prec@5 98.620 

lr: 0.07567976906828429
TRAINING - Epoch: [335][0/391]	Time 0.911 (0.911)	Data 0.335 (0.335)	Loss 0.3654 (0.3654)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [335][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3409 (0.3784)	Prec@1 87.500 (86.788)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [335][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2899 (0.3829)	Prec@1 88.281 (86.746)	Prec@5 100.000 (99.588)
TRAINING - Epoch: [335][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4012 (0.3903)	Prec@1 84.375 (86.589)	Prec@5 99.219 (99.546)
EVALUATING - Epoch: [335][0/79]	Time 0.349 (0.349)	Data 0.328 (0.328)	Loss 0.7589 (0.7589)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:37

 Epoch: 336	Training Loss 0.3905 	Training Prec@1 86.584 	Training Prec@5 99.550 	Validation Loss 0.8359 	Validation Prec@1 75.090 	Validation Prec@5 98.700 

lr: 0.07554432083429251
TRAINING - Epoch: [336][0/391]	Time 0.953 (0.953)	Data 0.358 (0.358)	Loss 0.3016 (0.3016)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [336][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.5693 (0.3728)	Prec@1 79.688 (86.750)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [336][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2543 (0.3783)	Prec@1 92.188 (86.793)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [336][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5877 (0.3900)	Prec@1 82.812 (86.586)	Prec@5 99.219 (99.522)
EVALUATING - Epoch: [336][0/79]	Time 0.356 (0.356)	Data 0.334 (0.334)	Loss 0.3370 (0.3370)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:24

 Epoch: 337	Training Loss 0.3939 	Training Prec@1 86.454 	Training Prec@5 99.528 	Validation Loss 0.5347 	Validation Prec@1 83.150 	Validation Prec@5 99.030 

lr: 0.07540861845910511
TRAINING - Epoch: [337][0/391]	Time 0.895 (0.895)	Data 0.342 (0.342)	Loss 0.4829 (0.4829)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [337][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.2800 (0.3602)	Prec@1 89.062 (87.601)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [337][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4036 (0.3676)	Prec@1 86.719 (87.341)	Prec@5 100.000 (99.572)
TRAINING - Epoch: [337][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.5137 (0.3798)	Prec@1 84.375 (86.924)	Prec@5 100.000 (99.554)
EVALUATING - Epoch: [337][0/79]	Time 0.338 (0.338)	Data 0.319 (0.319)	Loss 0.5390 (0.5390)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:18:56

 Epoch: 338	Training Loss 0.3807 	Training Prec@1 86.888 	Training Prec@5 99.534 	Validation Loss 0.6312 	Validation Prec@1 80.470 	Validation Prec@5 98.990 

lr: 0.07527266329282901
TRAINING - Epoch: [338][0/391]	Time 0.912 (0.912)	Data 0.346 (0.346)	Loss 0.4870 (0.4870)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [338][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3319 (0.3873)	Prec@1 89.062 (86.889)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [338][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.3915 (0.3896)	Prec@1 88.281 (86.839)	Prec@5 99.219 (99.569)
TRAINING - Epoch: [338][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4160 (0.3988)	Prec@1 87.500 (86.470)	Prec@5 99.219 (99.509)
EVALUATING - Epoch: [338][0/79]	Time 0.351 (0.351)	Data 0.329 (0.329)	Loss 0.7721 (0.7721)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:18

 Epoch: 339	Training Loss 0.3988 	Training Prec@1 86.466 	Training Prec@5 99.492 	Validation Loss 0.9935 	Validation Prec@1 73.870 	Validation Prec@5 97.990 

lr: 0.07513645668808615
TRAINING - Epoch: [339][0/391]	Time 0.899 (0.899)	Data 0.338 (0.338)	Loss 0.5134 (0.5134)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [339][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4771 (0.3796)	Prec@1 82.812 (86.928)	Prec@5 99.219 (99.613)
TRAINING - Epoch: [339][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3686 (0.3815)	Prec@1 84.375 (86.831)	Prec@5 100.000 (99.588)
TRAINING - Epoch: [339][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3605 (0.3918)	Prec@1 85.938 (86.493)	Prec@5 100.000 (99.569)
EVALUATING - Epoch: [339][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.7126 (0.7126)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:18

 Epoch: 340	Training Loss 0.3967 	Training Prec@1 86.306 	Training Prec@5 99.568 	Validation Loss 0.6837 	Validation Prec@1 79.400 	Validation Prec@5 98.220 

lr: 0.07499999999999997
TRAINING - Epoch: [340][0/391]	Time 0.923 (0.923)	Data 0.352 (0.352)	Loss 0.4137 (0.4137)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [340][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4905 (0.3950)	Prec@1 85.156 (86.587)	Prec@5 98.438 (99.528)
TRAINING - Epoch: [340][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3635 (0.3950)	Prec@1 87.500 (86.497)	Prec@5 100.000 (99.549)
TRAINING - Epoch: [340][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5136 (0.3926)	Prec@1 83.594 (86.428)	Prec@5 99.219 (99.564)
EVALUATING - Epoch: [340][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.7259 (0.7259)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:23

 Epoch: 341	Training Loss 0.3919 	Training Prec@1 86.502 	Training Prec@5 99.568 	Validation Loss 0.6936 	Validation Prec@1 78.180 	Validation Prec@5 98.710 

lr: 0.07486329458618211
TRAINING - Epoch: [341][0/391]	Time 0.906 (0.906)	Data 0.346 (0.346)	Loss 0.4931 (0.4931)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [341][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3451 (0.3700)	Prec@1 88.281 (87.314)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [341][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.3940 (0.3779)	Prec@1 85.156 (87.034)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [341][300/391]	Time 0.066 (0.065)	Data 0.000 (0.001)	Loss 0.3743 (0.3829)	Prec@1 89.844 (86.877)	Prec@5 100.000 (99.577)
EVALUATING - Epoch: [341][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.5647 (0.5647)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:08

 Epoch: 342	Training Loss 0.3813 	Training Prec@1 86.916 	Training Prec@5 99.566 	Validation Loss 0.6854 	Validation Prec@1 79.050 	Validation Prec@5 98.630 

lr: 0.0747263418067187
TRAINING - Epoch: [342][0/391]	Time 0.926 (0.926)	Data 0.346 (0.346)	Loss 0.4058 (0.4058)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [342][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4784 (0.3627)	Prec@1 83.594 (87.485)	Prec@5 98.438 (99.667)
TRAINING - Epoch: [342][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3231 (0.3600)	Prec@1 87.500 (87.570)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [342][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4085 (0.3725)	Prec@1 85.938 (87.157)	Prec@5 100.000 (99.613)
EVALUATING - Epoch: [342][0/79]	Time 0.350 (0.350)	Data 0.329 (0.329)	Loss 0.6363 (0.6363)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:05

 Epoch: 343	Training Loss 0.3720 	Training Prec@1 87.072 	Training Prec@5 99.620 	Validation Loss 0.8612 	Validation Prec@1 75.930 	Validation Prec@5 98.560 

lr: 0.07458914302415698
TRAINING - Epoch: [343][0/391]	Time 0.928 (0.928)	Data 0.355 (0.355)	Loss 0.2612 (0.2612)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [343][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3249 (0.3708)	Prec@1 89.844 (87.515)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [343][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3485 (0.3758)	Prec@1 85.156 (87.166)	Prec@5 99.219 (99.569)
TRAINING - Epoch: [343][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5191 (0.3796)	Prec@1 84.375 (86.968)	Prec@5 96.875 (99.593)
EVALUATING - Epoch: [343][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.5423 (0.5423)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 344	Training Loss 0.3803 	Training Prec@1 86.956 	Training Prec@5 99.600 	Validation Loss 0.6377 	Validation Prec@1 80.310 	Validation Prec@5 99.020 

lr: 0.07445169960349163
TRAINING - Epoch: [344][0/391]	Time 0.914 (0.914)	Data 0.344 (0.344)	Loss 0.3109 (0.3109)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [344][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2553 (0.3728)	Prec@1 92.969 (87.067)	Prec@5 99.219 (99.489)
TRAINING - Epoch: [344][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2273 (0.3770)	Prec@1 91.406 (86.800)	Prec@5 100.000 (99.483)
TRAINING - Epoch: [344][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4741 (0.3769)	Prec@1 81.250 (86.932)	Prec@5 100.000 (99.525)
EVALUATING - Epoch: [344][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.4724 (0.4724)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:15

 Epoch: 345	Training Loss 0.3768 	Training Prec@1 86.934 	Training Prec@5 99.544 	Validation Loss 0.6778 	Validation Prec@1 78.940 	Validation Prec@5 98.820 

lr: 0.07431401291215127
TRAINING - Epoch: [345][0/391]	Time 0.911 (0.911)	Data 0.343 (0.343)	Loss 0.3773 (0.3773)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [345][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3442 (0.3828)	Prec@1 90.625 (86.804)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [345][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4062 (0.3782)	Prec@1 82.812 (86.956)	Prec@5 100.000 (99.642)
TRAINING - Epoch: [345][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4558 (0.3779)	Prec@1 82.812 (86.991)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [345][0/79]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.5457 (0.5457)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:59

 Epoch: 346	Training Loss 0.3775 	Training Prec@1 86.920 	Training Prec@5 99.630 	Validation Loss 0.6273 	Validation Prec@1 81.320 	Validation Prec@5 98.600 

lr: 0.07417608431998483
TRAINING - Epoch: [346][0/391]	Time 0.925 (0.925)	Data 0.362 (0.362)	Loss 0.3075 (0.3075)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [346][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4039 (0.3716)	Prec@1 86.719 (87.044)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [346][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3943 (0.3711)	Prec@1 88.281 (87.135)	Prec@5 100.000 (99.654)
TRAINING - Epoch: [346][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2670 (0.3726)	Prec@1 91.406 (87.100)	Prec@5 100.000 (99.647)
EVALUATING - Epoch: [346][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.5162 (0.5162)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:23

 Epoch: 347	Training Loss 0.3770 	Training Prec@1 87.010 	Training Prec@5 99.618 	Validation Loss 0.5657 	Validation Prec@1 82.090 	Validation Prec@5 99.230 

lr: 0.0740379151992479
TRAINING - Epoch: [347][0/391]	Time 0.919 (0.919)	Data 0.352 (0.352)	Loss 0.3192 (0.3192)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [347][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4512 (0.3523)	Prec@1 88.281 (87.670)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [347][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2345 (0.3607)	Prec@1 92.969 (87.360)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [347][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4223 (0.3748)	Prec@1 79.688 (86.849)	Prec@5 100.000 (99.608)
EVALUATING - Epoch: [347][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.8825 (0.8825)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:35

 Epoch: 348	Training Loss 0.3747 	Training Prec@1 86.880 	Training Prec@5 99.612 	Validation Loss 0.7986 	Validation Prec@1 76.220 	Validation Prec@5 97.860 

lr: 0.07389950692458912
TRAINING - Epoch: [348][0/391]	Time 0.943 (0.943)	Data 0.383 (0.383)	Loss 0.4131 (0.4131)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [348][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3026 (0.3570)	Prec@1 88.281 (87.616)	Prec@5 99.219 (99.675)
TRAINING - Epoch: [348][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3055 (0.3692)	Prec@1 88.281 (87.142)	Prec@5 99.219 (99.642)
TRAINING - Epoch: [348][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3798 (0.3718)	Prec@1 87.500 (87.116)	Prec@5 99.219 (99.637)
EVALUATING - Epoch: [348][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.4267 (0.4267)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 349	Training Loss 0.3726 	Training Prec@1 87.132 	Training Prec@5 99.610 	Validation Loss 0.5738 	Validation Prec@1 81.220 	Validation Prec@5 99.040 

lr: 0.07376086087303645
TRAINING - Epoch: [349][0/391]	Time 0.892 (0.892)	Data 0.342 (0.342)	Loss 0.3195 (0.3195)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [349][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3951 (0.3641)	Prec@1 86.719 (87.492)	Prec@5 99.219 (99.636)
TRAINING - Epoch: [349][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3904 (0.3724)	Prec@1 89.062 (87.154)	Prec@5 100.000 (99.623)
TRAINING - Epoch: [349][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4878 (0.3740)	Prec@1 85.938 (87.077)	Prec@5 99.219 (99.618)
EVALUATING - Epoch: [349][0/79]	Time 0.358 (0.358)	Data 0.336 (0.336)	Loss 0.7317 (0.7317)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:10

 Epoch: 350	Training Loss 0.3780 	Training Prec@1 87.012 	Training Prec@5 99.598 	Validation Loss 0.7768 	Validation Prec@1 75.810 	Validation Prec@5 98.580 

lr: 0.0736219784239835
TRAINING - Epoch: [350][0/391]	Time 0.933 (0.933)	Data 0.362 (0.362)	Loss 0.3626 (0.3626)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [350][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.3922 (0.3769)	Prec@1 87.500 (86.951)	Prec@5 99.219 (99.559)
TRAINING - Epoch: [350][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3790 (0.3723)	Prec@1 87.500 (87.228)	Prec@5 100.000 (99.596)
TRAINING - Epoch: [350][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4221 (0.3736)	Prec@1 85.156 (87.077)	Prec@5 99.219 (99.621)
EVALUATING - Epoch: [350][0/79]	Time 0.344 (0.344)	Data 0.324 (0.324)	Loss 0.4101 (0.4101)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:28

 Epoch: 351	Training Loss 0.3731 	Training Prec@1 87.060 	Training Prec@5 99.630 	Validation Loss 0.5738 	Validation Prec@1 81.030 	Validation Prec@5 99.020 

lr: 0.07348286095917587
TRAINING - Epoch: [351][0/391]	Time 0.928 (0.928)	Data 0.374 (0.374)	Loss 0.3228 (0.3228)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [351][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3432 (0.3541)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [351][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3897 (0.3617)	Prec@1 86.719 (87.251)	Prec@5 100.000 (99.604)
TRAINING - Epoch: [351][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3571 (0.3663)	Prec@1 87.500 (87.103)	Prec@5 99.219 (99.593)
EVALUATING - Epoch: [351][0/79]	Time 0.379 (0.379)	Data 0.359 (0.359)	Loss 0.4550 (0.4550)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:57

 Epoch: 352	Training Loss 0.3674 	Training Prec@1 87.072 	Training Prec@5 99.600 	Validation Loss 0.5640 	Validation Prec@1 82.000 	Validation Prec@5 99.070 

lr: 0.07334350986269726
TRAINING - Epoch: [352][0/391]	Time 0.918 (0.918)	Data 0.362 (0.362)	Loss 0.4504 (0.4504)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [352][100/391]	Time 0.068 (0.071)	Data 0.000 (0.004)	Loss 0.3843 (0.3889)	Prec@1 85.938 (86.479)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [352][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4585 (0.3739)	Prec@1 85.156 (86.874)	Prec@5 100.000 (99.600)
TRAINING - Epoch: [352][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3619 (0.3774)	Prec@1 85.938 (86.978)	Prec@5 100.000 (99.572)
EVALUATING - Epoch: [352][0/79]	Time 0.366 (0.366)	Data 0.346 (0.346)	Loss 0.4771 (0.4771)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:37

 Epoch: 353	Training Loss 0.3762 	Training Prec@1 86.996 	Training Prec@5 99.574 	Validation Loss 0.5886 	Validation Prec@1 81.210 	Validation Prec@5 99.030 

lr: 0.0732039265209558
TRAINING - Epoch: [353][0/391]	Time 0.916 (0.916)	Data 0.348 (0.348)	Loss 0.4954 (0.4954)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [353][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4612 (0.3627)	Prec@1 87.500 (87.438)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [353][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3706 (0.3742)	Prec@1 85.938 (87.088)	Prec@5 100.000 (99.592)
TRAINING - Epoch: [353][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4335 (0.3768)	Prec@1 87.500 (87.030)	Prec@5 98.438 (99.572)
EVALUATING - Epoch: [353][0/79]	Time 0.356 (0.356)	Data 0.335 (0.335)	Loss 0.4227 (0.4227)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:21

 Epoch: 354	Training Loss 0.3711 	Training Prec@1 87.182 	Training Prec@5 99.580 	Validation Loss 0.6220 	Validation Prec@1 80.240 	Validation Prec@5 98.970 

lr: 0.07306411232267025
TRAINING - Epoch: [354][0/391]	Time 0.911 (0.911)	Data 0.333 (0.333)	Loss 0.3973 (0.3973)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [354][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2940 (0.3624)	Prec@1 89.062 (87.423)	Prec@5 99.219 (99.737)
TRAINING - Epoch: [354][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3314 (0.3692)	Prec@1 87.500 (87.348)	Prec@5 100.000 (99.604)
TRAINING - Epoch: [354][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2130 (0.3683)	Prec@1 94.531 (87.318)	Prec@5 99.219 (99.580)
EVALUATING - Epoch: [354][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.7866 (0.7866)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:44

 Epoch: 355	Training Loss 0.3685 	Training Prec@1 87.330 	Training Prec@5 99.592 	Validation Loss 0.7566 	Validation Prec@1 78.030 	Validation Prec@5 98.300 

lr: 0.07292406865885614
TRAINING - Epoch: [355][0/391]	Time 0.945 (0.945)	Data 0.367 (0.367)	Loss 0.4316 (0.4316)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [355][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3737 (0.3682)	Prec@1 89.844 (87.183)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [355][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4758 (0.3651)	Prec@1 81.250 (87.465)	Prec@5 100.000 (99.619)
TRAINING - Epoch: [355][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3841 (0.3680)	Prec@1 86.719 (87.360)	Prec@5 98.438 (99.605)
EVALUATING - Epoch: [355][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.6095 (0.6095)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:26

 Epoch: 356	Training Loss 0.3699 	Training Prec@1 87.350 	Training Prec@5 99.616 	Validation Loss 0.6291 	Validation Prec@1 79.850 	Validation Prec@5 99.090 

lr: 0.07278379692281203
TRAINING - Epoch: [356][0/391]	Time 0.906 (0.906)	Data 0.344 (0.344)	Loss 0.4479 (0.4479)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [356][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4694 (0.3557)	Prec@1 83.594 (87.384)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [356][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2902 (0.3633)	Prec@1 88.281 (87.212)	Prec@5 100.000 (99.600)
TRAINING - Epoch: [356][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3378 (0.3707)	Prec@1 89.844 (87.017)	Prec@5 100.000 (99.595)
EVALUATING - Epoch: [356][0/79]	Time 0.356 (0.356)	Data 0.334 (0.334)	Loss 0.4615 (0.4615)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:23

 Epoch: 357	Training Loss 0.3699 	Training Prec@1 87.072 	Training Prec@5 99.598 	Validation Loss 0.6690 	Validation Prec@1 79.410 	Validation Prec@5 98.930 

lr: 0.07264329851010548
TRAINING - Epoch: [357][0/391]	Time 0.927 (0.927)	Data 0.327 (0.327)	Loss 0.2904 (0.2904)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [357][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.3128 (0.3476)	Prec@1 86.719 (87.817)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [357][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2755 (0.3538)	Prec@1 92.188 (87.706)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [357][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2574 (0.3611)	Prec@1 92.188 (87.565)	Prec@5 98.438 (99.564)
EVALUATING - Epoch: [357][0/79]	Time 0.367 (0.367)	Data 0.345 (0.345)	Loss 0.4843 (0.4843)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:03

 Epoch: 358	Training Loss 0.3710 	Training Prec@1 87.250 	Training Prec@5 99.572 	Validation Loss 0.6038 	Validation Prec@1 81.410 	Validation Prec@5 98.690 

lr: 0.07250257481855935
TRAINING - Epoch: [358][0/391]	Time 0.910 (0.910)	Data 0.338 (0.338)	Loss 0.2982 (0.2982)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [358][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3553 (0.3584)	Prec@1 88.281 (87.585)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [358][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3428 (0.3687)	Prec@1 86.719 (87.158)	Prec@5 100.000 (99.642)
TRAINING - Epoch: [358][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.5800 (0.3713)	Prec@1 81.250 (87.103)	Prec@5 97.656 (99.621)
EVALUATING - Epoch: [358][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.6180 (0.6180)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:31

 Epoch: 359	Training Loss 0.3725 	Training Prec@1 87.120 	Training Prec@5 99.616 	Validation Loss 0.6684 	Validation Prec@1 78.980 	Validation Prec@5 98.720 

lr: 0.07236162724823773
TRAINING - Epoch: [359][0/391]	Time 0.900 (0.900)	Data 0.341 (0.341)	Loss 0.3184 (0.3184)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [359][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1993 (0.3572)	Prec@1 92.969 (87.894)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [359][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3135 (0.3552)	Prec@1 85.156 (87.757)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [359][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4088 (0.3626)	Prec@1 85.938 (87.471)	Prec@5 100.000 (99.657)
EVALUATING - Epoch: [359][0/79]	Time 0.335 (0.335)	Data 0.316 (0.316)	Loss 0.6832 (0.6832)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:42

 Epoch: 360	Training Loss 0.3643 	Training Prec@1 87.412 	Training Prec@5 99.634 	Validation Loss 0.7149 	Validation Prec@1 77.770 	Validation Prec@5 98.560 

lr: 0.07222045720143214
TRAINING - Epoch: [360][0/391]	Time 0.922 (0.922)	Data 0.363 (0.363)	Loss 0.2977 (0.2977)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [360][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.3051 (0.3600)	Prec@1 89.062 (87.299)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [360][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3484 (0.3618)	Prec@1 88.281 (87.352)	Prec@5 100.000 (99.666)
TRAINING - Epoch: [360][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2681 (0.3633)	Prec@1 90.625 (87.303)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [360][0/79]	Time 0.363 (0.363)	Data 0.344 (0.344)	Loss 0.8383 (0.8383)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:22

 Epoch: 361	Training Loss 0.3685 	Training Prec@1 87.144 	Training Prec@5 99.628 	Validation Loss 0.7348 	Validation Prec@1 78.470 	Validation Prec@5 97.820 

lr: 0.0720790660826475
TRAINING - Epoch: [361][0/391]	Time 0.935 (0.935)	Data 0.359 (0.359)	Loss 0.4465 (0.4465)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [361][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3315 (0.3522)	Prec@1 88.281 (87.778)	Prec@5 99.219 (99.714)
TRAINING - Epoch: [361][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3369 (0.3609)	Prec@1 89.062 (87.345)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [361][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3831 (0.3665)	Prec@1 85.938 (87.087)	Prec@5 99.219 (99.717)
EVALUATING - Epoch: [361][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 1.1263 (1.1263)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 362	Training Loss 0.3672 	Training Prec@1 87.116 	Training Prec@5 99.706 	Validation Loss 1.1633 	Validation Prec@1 70.780 	Validation Prec@5 97.290 

lr: 0.0719374552985882
TRAINING - Epoch: [362][0/391]	Time 0.908 (0.908)	Data 0.336 (0.336)	Loss 0.4613 (0.4613)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [362][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3747 (0.3446)	Prec@1 85.938 (87.933)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [362][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4917 (0.3636)	Prec@1 82.812 (87.302)	Prec@5 100.000 (99.697)
TRAINING - Epoch: [362][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.4772 (0.3690)	Prec@1 85.156 (87.082)	Prec@5 98.438 (99.676)
EVALUATING - Epoch: [362][0/79]	Time 0.376 (0.376)	Data 0.354 (0.354)	Loss 0.5674 (0.5674)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:52

 Epoch: 363	Training Loss 0.3674 	Training Prec@1 87.144 	Training Prec@5 99.650 	Validation Loss 0.6288 	Validation Prec@1 80.400 	Validation Prec@5 98.910 

lr: 0.07179562625814406
TRAINING - Epoch: [363][0/391]	Time 0.939 (0.939)	Data 0.348 (0.348)	Loss 0.3372 (0.3372)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [363][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3717 (0.3604)	Prec@1 85.156 (87.461)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [363][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.2969 (0.3594)	Prec@1 89.062 (87.484)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [363][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4016 (0.3667)	Prec@1 86.719 (87.308)	Prec@5 100.000 (99.590)
EVALUATING - Epoch: [363][0/79]	Time 0.371 (0.371)	Data 0.352 (0.352)	Loss 0.7527 (0.7527)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 364	Training Loss 0.3666 	Training Prec@1 87.334 	Training Prec@5 99.592 	Validation Loss 0.7122 	Validation Prec@1 77.790 	Validation Prec@5 98.550 

lr: 0.07165358037237637
TRAINING - Epoch: [364][0/391]	Time 0.926 (0.926)	Data 0.371 (0.371)	Loss 0.3422 (0.3422)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [364][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2227 (0.3547)	Prec@1 91.406 (87.709)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [364][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2949 (0.3544)	Prec@1 90.625 (87.667)	Prec@5 100.000 (99.619)
TRAINING - Epoch: [364][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4306 (0.3613)	Prec@1 85.156 (87.427)	Prec@5 99.219 (99.624)
EVALUATING - Epoch: [364][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.4497 (0.4497)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:14

 Epoch: 365	Training Loss 0.3588 	Training Prec@1 87.530 	Training Prec@5 99.620 	Validation Loss 0.5822 	Validation Prec@1 81.970 	Validation Prec@5 99.200 

lr: 0.07151131905450382
TRAINING - Epoch: [365][0/391]	Time 0.915 (0.915)	Data 0.343 (0.343)	Loss 0.2705 (0.2705)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [365][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3727 (0.3582)	Prec@1 87.500 (87.430)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [365][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2897 (0.3606)	Prec@1 89.844 (87.461)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [365][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4961 (0.3670)	Prec@1 84.375 (87.324)	Prec@5 99.219 (99.595)
EVALUATING - Epoch: [365][0/79]	Time 0.364 (0.364)	Data 0.343 (0.343)	Loss 0.6355 (0.6355)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:18

 Epoch: 366	Training Loss 0.3688 	Training Prec@1 87.196 	Training Prec@5 99.604 	Validation Loss 0.6897 	Validation Prec@1 78.730 	Validation Prec@5 98.790 

lr: 0.07136884371988837
TRAINING - Epoch: [366][0/391]	Time 0.921 (0.921)	Data 0.363 (0.363)	Loss 0.2453 (0.2453)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [366][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3889 (0.3538)	Prec@1 84.375 (87.500)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [366][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4166 (0.3598)	Prec@1 85.156 (87.286)	Prec@5 99.219 (99.681)
TRAINING - Epoch: [366][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3595 (0.3706)	Prec@1 87.500 (87.043)	Prec@5 100.000 (99.626)
EVALUATING - Epoch: [366][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.3925 (0.3925)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:14

 Epoch: 367	Training Loss 0.3748 	Training Prec@1 86.938 	Training Prec@5 99.602 	Validation Loss 0.5502 	Validation Prec@1 82.360 	Validation Prec@5 99.170 

lr: 0.07122615578602136
TRAINING - Epoch: [367][0/391]	Time 0.912 (0.912)	Data 0.346 (0.346)	Loss 0.2551 (0.2551)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [367][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2990 (0.3569)	Prec@1 87.500 (87.546)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [367][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4010 (0.3525)	Prec@1 85.938 (87.667)	Prec@5 99.219 (99.674)
TRAINING - Epoch: [367][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4363 (0.3613)	Prec@1 84.375 (87.474)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [367][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.4152 (0.4152)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:36

 Epoch: 368	Training Loss 0.3668 	Training Prec@1 87.340 	Training Prec@5 99.642 	Validation Loss 0.6162 	Validation Prec@1 81.300 	Validation Prec@5 98.700 

lr: 0.07108325667250916
TRAINING - Epoch: [368][0/391]	Time 0.905 (0.905)	Data 0.343 (0.343)	Loss 0.3647 (0.3647)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [368][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4067 (0.3627)	Prec@1 86.719 (87.283)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [368][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2994 (0.3726)	Prec@1 88.281 (87.045)	Prec@5 99.219 (99.654)
TRAINING - Epoch: [368][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3952 (0.3674)	Prec@1 87.500 (87.225)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [368][0/79]	Time 0.364 (0.364)	Data 0.342 (0.342)	Loss 0.9755 (0.9755)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:18

 Epoch: 369	Training Loss 0.3685 	Training Prec@1 87.200 	Training Prec@5 99.632 	Validation Loss 0.7960 	Validation Prec@1 76.550 	Validation Prec@5 98.450 

lr: 0.07094014780105926
TRAINING - Epoch: [369][0/391]	Time 0.904 (0.904)	Data 0.349 (0.349)	Loss 0.4135 (0.4135)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [369][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2653 (0.3678)	Prec@1 85.938 (87.268)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [369][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4525 (0.3712)	Prec@1 83.594 (87.306)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [369][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2581 (0.3701)	Prec@1 90.625 (87.324)	Prec@5 100.000 (99.603)
EVALUATING - Epoch: [369][0/79]	Time 0.341 (0.341)	Data 0.318 (0.318)	Loss 0.5317 (0.5317)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:08

 Epoch: 370	Training Loss 0.3705 	Training Prec@1 87.318 	Training Prec@5 99.608 	Validation Loss 0.6089 	Validation Prec@1 81.360 	Validation Prec@5 99.130 

lr: 0.07079683059546601
TRAINING - Epoch: [370][0/391]	Time 0.906 (0.906)	Data 0.342 (0.342)	Loss 0.4286 (0.4286)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [370][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3182 (0.3583)	Prec@1 87.500 (87.523)	Prec@5 99.219 (99.606)
TRAINING - Epoch: [370][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3298 (0.3611)	Prec@1 85.938 (87.484)	Prec@5 100.000 (99.619)
TRAINING - Epoch: [370][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.4084 (0.3608)	Prec@1 87.500 (87.381)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [370][0/79]	Time 0.346 (0.346)	Data 0.322 (0.322)	Loss 0.9046 (0.9046)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:02

 Epoch: 371	Training Loss 0.3622 	Training Prec@1 87.324 	Training Prec@5 99.630 	Validation Loss 0.8734 	Validation Prec@1 75.110 	Validation Prec@5 97.760 

lr: 0.07065330648159648
TRAINING - Epoch: [371][0/391]	Time 0.912 (0.912)	Data 0.345 (0.345)	Loss 0.3185 (0.3185)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [371][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3990 (0.3505)	Prec@1 88.281 (87.701)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [371][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5540 (0.3644)	Prec@1 82.031 (87.352)	Prec@5 99.219 (99.619)
TRAINING - Epoch: [371][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3595 (0.3677)	Prec@1 87.500 (87.321)	Prec@5 100.000 (99.618)
EVALUATING - Epoch: [371][0/79]	Time 0.358 (0.358)	Data 0.335 (0.335)	Loss 0.4045 (0.4045)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:52

 Epoch: 372	Training Loss 0.3677 	Training Prec@1 87.390 	Training Prec@5 99.622 	Validation Loss 0.6685 	Validation Prec@1 79.720 	Validation Prec@5 98.930 

lr: 0.07050957688737632
TRAINING - Epoch: [372][0/391]	Time 0.931 (0.931)	Data 0.370 (0.370)	Loss 0.4070 (0.4070)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [372][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2974 (0.3438)	Prec@1 88.281 (88.119)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [372][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5150 (0.3576)	Prec@1 82.031 (87.558)	Prec@5 99.219 (99.635)
TRAINING - Epoch: [372][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4205 (0.3610)	Prec@1 87.500 (87.433)	Prec@5 99.219 (99.626)
EVALUATING - Epoch: [372][0/79]	Time 0.380 (0.380)	Data 0.355 (0.355)	Loss 0.5299 (0.5299)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:52

 Epoch: 373	Training Loss 0.3627 	Training Prec@1 87.438 	Training Prec@5 99.620 	Validation Loss 0.6888 	Validation Prec@1 79.700 	Validation Prec@5 98.690 

lr: 0.07036564324277539
TRAINING - Epoch: [373][0/391]	Time 0.919 (0.919)	Data 0.356 (0.356)	Loss 0.3121 (0.3121)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [373][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2516 (0.3606)	Prec@1 92.188 (87.531)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [373][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2001 (0.3611)	Prec@1 93.750 (87.457)	Prec@5 100.000 (99.689)
TRAINING - Epoch: [373][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3171 (0.3641)	Prec@1 87.500 (87.344)	Prec@5 99.219 (99.663)
EVALUATING - Epoch: [373][0/79]	Time 0.364 (0.364)	Data 0.342 (0.342)	Loss 0.7001 (0.7001)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:04

 Epoch: 374	Training Loss 0.3656 	Training Prec@1 87.264 	Training Prec@5 99.648 	Validation Loss 0.8012 	Validation Prec@1 77.270 	Validation Prec@5 98.430 

lr: 0.07022150697979379
TRAINING - Epoch: [374][0/391]	Time 0.927 (0.927)	Data 0.341 (0.341)	Loss 0.4203 (0.4203)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [374][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3603 (0.3580)	Prec@1 86.719 (87.786)	Prec@5 98.438 (99.636)
TRAINING - Epoch: [374][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2825 (0.3551)	Prec@1 90.625 (87.764)	Prec@5 100.000 (99.639)
TRAINING - Epoch: [374][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1705 (0.3580)	Prec@1 93.750 (87.664)	Prec@5 100.000 (99.631)
EVALUATING - Epoch: [374][0/79]	Time 0.342 (0.342)	Data 0.324 (0.324)	Loss 0.6936 (0.6936)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:52

 Epoch: 375	Training Loss 0.3637 	Training Prec@1 87.494 	Training Prec@5 99.622 	Validation Loss 0.6643 	Validation Prec@1 79.490 	Validation Prec@5 98.810 

lr: 0.07007716953244741
TRAINING - Epoch: [375][0/391]	Time 0.929 (0.929)	Data 0.371 (0.371)	Loss 0.3110 (0.3110)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [375][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.4173 (0.3516)	Prec@1 83.594 (88.026)	Prec@5 99.219 (99.544)
TRAINING - Epoch: [375][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3421 (0.3584)	Prec@1 87.500 (87.702)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [375][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3730 (0.3590)	Prec@1 87.500 (87.612)	Prec@5 100.000 (99.600)
EVALUATING - Epoch: [375][0/79]	Time 0.349 (0.349)	Data 0.326 (0.326)	Loss 0.4534 (0.4534)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:17:57

 Epoch: 376	Training Loss 0.3614 	Training Prec@1 87.558 	Training Prec@5 99.594 	Validation Loss 0.6057 	Validation Prec@1 80.910 	Validation Prec@5 98.990 

lr: 0.06993263233675374
TRAINING - Epoch: [376][0/391]	Time 0.917 (0.917)	Data 0.348 (0.348)	Loss 0.3701 (0.3701)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [376][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3220 (0.3541)	Prec@1 86.719 (87.802)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [376][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3865 (0.3501)	Prec@1 85.156 (87.788)	Prec@5 100.000 (99.639)
TRAINING - Epoch: [376][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4097 (0.3553)	Prec@1 88.281 (87.614)	Prec@5 100.000 (99.618)
EVALUATING - Epoch: [376][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.5156 (0.5156)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:32

 Epoch: 377	Training Loss 0.3614 	Training Prec@1 87.480 	Training Prec@5 99.628 	Validation Loss 0.6550 	Validation Prec@1 79.650 	Validation Prec@5 98.870 

lr: 0.06978789683071755
TRAINING - Epoch: [377][0/391]	Time 0.903 (0.903)	Data 0.336 (0.336)	Loss 0.2972 (0.2972)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [377][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.3023 (0.3505)	Prec@1 89.844 (87.438)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [377][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2617 (0.3595)	Prec@1 89.844 (87.271)	Prec@5 100.000 (99.576)
TRAINING - Epoch: [377][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3638 (0.3603)	Prec@1 89.062 (87.383)	Prec@5 99.219 (99.569)
EVALUATING - Epoch: [377][0/79]	Time 0.355 (0.355)	Data 0.334 (0.334)	Loss 0.4854 (0.4854)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:05

 Epoch: 378	Training Loss 0.3619 	Training Prec@1 87.416 	Training Prec@5 99.574 	Validation Loss 0.5837 	Validation Prec@1 81.120 	Validation Prec@5 99.020 

lr: 0.06964296445431666
TRAINING - Epoch: [378][0/391]	Time 0.917 (0.917)	Data 0.361 (0.361)	Loss 0.3463 (0.3463)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [378][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.4280 (0.3630)	Prec@1 84.375 (87.593)	Prec@5 99.219 (99.629)
TRAINING - Epoch: [378][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4454 (0.3658)	Prec@1 84.375 (87.426)	Prec@5 100.000 (99.592)
TRAINING - Epoch: [378][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3578 (0.3657)	Prec@1 87.500 (87.422)	Prec@5 100.000 (99.616)
EVALUATING - Epoch: [378][0/79]	Time 0.355 (0.355)	Data 0.329 (0.329)	Loss 0.6453 (0.6453)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 379	Training Loss 0.3652 	Training Prec@1 87.414 	Training Prec@5 99.622 	Validation Loss 0.6341 	Validation Prec@1 80.210 	Validation Prec@5 98.950 

lr: 0.06949783664948747
TRAINING - Epoch: [379][0/391]	Time 0.910 (0.910)	Data 0.360 (0.360)	Loss 0.4154 (0.4154)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [379][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2890 (0.3643)	Prec@1 89.062 (87.523)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [379][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3791 (0.3573)	Prec@1 86.719 (87.772)	Prec@5 100.000 (99.693)
TRAINING - Epoch: [379][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3047 (0.3709)	Prec@1 88.281 (87.290)	Prec@5 100.000 (99.642)
EVALUATING - Epoch: [379][0/79]	Time 0.386 (0.386)	Data 0.367 (0.367)	Loss 0.9106 (0.9106)	Prec@1 70.312 (70.312)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:32

 Epoch: 380	Training Loss 0.3706 	Training Prec@1 87.268 	Training Prec@5 99.624 	Validation Loss 0.8783 	Validation Prec@1 75.260 	Validation Prec@5 97.960 

lr: 0.06935251486011082
TRAINING - Epoch: [380][0/391]	Time 0.914 (0.914)	Data 0.344 (0.344)	Loss 0.3882 (0.3882)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [380][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4580 (0.3664)	Prec@1 89.844 (87.655)	Prec@5 98.438 (99.575)
TRAINING - Epoch: [380][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2873 (0.3777)	Prec@1 89.062 (87.100)	Prec@5 100.000 (99.572)
TRAINING - Epoch: [380][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3236 (0.3735)	Prec@1 88.281 (87.196)	Prec@5 100.000 (99.621)
EVALUATING - Epoch: [380][0/79]	Time 0.349 (0.349)	Data 0.326 (0.326)	Loss 0.5186 (0.5186)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:47

 Epoch: 381	Training Loss 0.3724 	Training Prec@1 87.218 	Training Prec@5 99.602 	Validation Loss 0.6459 	Validation Prec@1 80.880 	Validation Prec@5 98.560 

lr: 0.0692070005319974
TRAINING - Epoch: [381][0/391]	Time 0.930 (0.930)	Data 0.362 (0.362)	Loss 0.3579 (0.3579)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [381][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3048 (0.3737)	Prec@1 88.281 (87.183)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [381][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4153 (0.3757)	Prec@1 85.156 (86.933)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [381][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3433 (0.3726)	Prec@1 89.844 (87.012)	Prec@5 100.000 (99.580)
EVALUATING - Epoch: [381][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 0.6460 (0.6460)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 382	Training Loss 0.3695 	Training Prec@1 87.186 	Training Prec@5 99.590 	Validation Loss 0.6120 	Validation Prec@1 81.170 	Validation Prec@5 98.840 

lr: 0.06906129511287352
TRAINING - Epoch: [382][0/391]	Time 0.914 (0.914)	Data 0.344 (0.344)	Loss 0.2897 (0.2897)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [382][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2817 (0.3336)	Prec@1 91.406 (88.374)	Prec@5 99.219 (99.691)
TRAINING - Epoch: [382][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3974 (0.3469)	Prec@1 85.156 (87.877)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [382][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4735 (0.3500)	Prec@1 82.812 (87.840)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [382][0/79]	Time 0.361 (0.361)	Data 0.341 (0.341)	Loss 0.8511 (0.8511)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:57

 Epoch: 383	Training Loss 0.3540 	Training Prec@1 87.660 	Training Prec@5 99.650 	Validation Loss 0.8226 	Validation Prec@1 75.930 	Validation Prec@5 98.890 

lr: 0.06891540005236671
TRAINING - Epoch: [383][0/391]	Time 0.910 (0.910)	Data 0.352 (0.352)	Loss 0.3683 (0.3683)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [383][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4758 (0.3692)	Prec@1 80.469 (86.920)	Prec@5 99.219 (99.714)
TRAINING - Epoch: [383][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2622 (0.3658)	Prec@1 88.281 (87.267)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [383][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2885 (0.3679)	Prec@1 90.625 (87.233)	Prec@5 100.000 (99.647)
EVALUATING - Epoch: [383][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.5788 (0.5788)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:27

 Epoch: 384	Training Loss 0.3638 	Training Prec@1 87.348 	Training Prec@5 99.668 	Validation Loss 0.7018 	Validation Prec@1 78.790 	Validation Prec@5 98.950 

lr: 0.06876931680199114
TRAINING - Epoch: [384][0/391]	Time 0.923 (0.923)	Data 0.345 (0.345)	Loss 0.4067 (0.4067)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [384][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4693 (0.3311)	Prec@1 84.375 (88.428)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [384][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3288 (0.3466)	Prec@1 87.500 (87.970)	Prec@5 99.219 (99.631)
TRAINING - Epoch: [384][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4122 (0.3496)	Prec@1 85.938 (87.939)	Prec@5 99.219 (99.644)
EVALUATING - Epoch: [384][0/79]	Time 0.359 (0.359)	Data 0.338 (0.338)	Loss 0.6464 (0.6464)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:28

 Epoch: 385	Training Loss 0.3532 	Training Prec@1 87.792 	Training Prec@5 99.642 	Validation Loss 0.5792 	Validation Prec@1 81.640 	Validation Prec@5 98.990 

lr: 0.06862304681513338
TRAINING - Epoch: [385][0/391]	Time 0.924 (0.924)	Data 0.348 (0.348)	Loss 0.3533 (0.3533)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [385][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3412 (0.3679)	Prec@1 88.281 (87.167)	Prec@5 99.219 (99.629)
TRAINING - Epoch: [385][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3438 (0.3669)	Prec@1 85.938 (87.189)	Prec@5 100.000 (99.569)
TRAINING - Epoch: [385][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3580 (0.3674)	Prec@1 87.500 (87.217)	Prec@5 99.219 (99.567)
EVALUATING - Epoch: [385][0/79]	Time 0.336 (0.336)	Data 0.317 (0.317)	Loss 0.7126 (0.7126)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:29

 Epoch: 386	Training Loss 0.3687 	Training Prec@1 87.180 	Training Prec@5 99.582 	Validation Loss 0.7757 	Validation Prec@1 76.930 	Validation Prec@5 98.270 

lr: 0.0684765915470378
TRAINING - Epoch: [386][0/391]	Time 0.904 (0.904)	Data 0.339 (0.339)	Loss 0.4714 (0.4714)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [386][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4923 (0.3516)	Prec@1 84.375 (87.817)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [386][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3997 (0.3531)	Prec@1 82.031 (87.865)	Prec@5 100.000 (99.666)
TRAINING - Epoch: [386][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5246 (0.3616)	Prec@1 82.031 (87.448)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [386][0/79]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.5382 (0.5382)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 387	Training Loss 0.3603 	Training Prec@1 87.492 	Training Prec@5 99.626 	Validation Loss 0.5871 	Validation Prec@1 81.720 	Validation Prec@5 99.130 

lr: 0.06832995245479213
TRAINING - Epoch: [387][0/391]	Time 0.948 (0.948)	Data 0.380 (0.380)	Loss 0.2895 (0.2895)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [387][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2866 (0.3481)	Prec@1 92.188 (87.879)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [387][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.3402 (0.3508)	Prec@1 87.500 (87.749)	Prec@5 100.000 (99.623)
TRAINING - Epoch: [387][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4012 (0.3600)	Prec@1 86.719 (87.388)	Prec@5 100.000 (99.613)
EVALUATING - Epoch: [387][0/79]	Time 0.395 (0.395)	Data 0.374 (0.374)	Loss 0.5478 (0.5478)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:26

 Epoch: 388	Training Loss 0.3626 	Training Prec@1 87.302 	Training Prec@5 99.620 	Validation Loss 0.5959 	Validation Prec@1 82.020 	Validation Prec@5 99.050 

lr: 0.06818313099731302
TRAINING - Epoch: [388][0/391]	Time 0.916 (0.916)	Data 0.345 (0.345)	Loss 0.3108 (0.3108)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [388][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4103 (0.3502)	Prec@1 85.156 (87.500)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [388][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2707 (0.3520)	Prec@1 89.062 (87.586)	Prec@5 100.000 (99.600)
TRAINING - Epoch: [388][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3440 (0.3580)	Prec@1 85.156 (87.461)	Prec@5 99.219 (99.600)
EVALUATING - Epoch: [388][0/79]	Time 0.362 (0.362)	Data 0.338 (0.338)	Loss 0.4367 (0.4367)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:26

 Epoch: 389	Training Loss 0.3593 	Training Prec@1 87.352 	Training Prec@5 99.614 	Validation Loss 0.5240 	Validation Prec@1 83.260 	Validation Prec@5 99.070 

lr: 0.06803612863533143
TRAINING - Epoch: [389][0/391]	Time 0.903 (0.903)	Data 0.343 (0.343)	Loss 0.2935 (0.2935)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [389][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3557 (0.3527)	Prec@1 81.250 (87.778)	Prec@5 99.219 (99.698)
TRAINING - Epoch: [389][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5504 (0.3573)	Prec@1 82.812 (87.446)	Prec@5 98.438 (99.705)
TRAINING - Epoch: [389][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3071 (0.3613)	Prec@1 88.281 (87.474)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [389][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.5495 (0.5495)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:32

 Epoch: 390	Training Loss 0.3637 	Training Prec@1 87.406 	Training Prec@5 99.674 	Validation Loss 0.6602 	Validation Prec@1 79.920 	Validation Prec@5 98.830 

lr: 0.06788894683137817
TRAINING - Epoch: [390][0/391]	Time 0.920 (0.920)	Data 0.356 (0.356)	Loss 0.3828 (0.3828)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [390][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3627 (0.3372)	Prec@1 88.281 (88.552)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [390][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3893 (0.3447)	Prec@1 86.719 (88.005)	Prec@5 98.438 (99.666)
TRAINING - Epoch: [390][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2866 (0.3527)	Prec@1 89.062 (87.731)	Prec@5 100.000 (99.655)
EVALUATING - Epoch: [390][0/79]	Time 0.352 (0.352)	Data 0.328 (0.328)	Loss 0.8171 (0.8171)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:45

 Epoch: 391	Training Loss 0.3560 	Training Prec@1 87.674 	Training Prec@5 99.646 	Validation Loss 0.9475 	Validation Prec@1 74.840 	Validation Prec@5 97.360 

lr: 0.0677415870497693
TRAINING - Epoch: [391][0/391]	Time 0.932 (0.932)	Data 0.363 (0.363)	Loss 0.3994 (0.3994)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [391][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3525 (0.3480)	Prec@1 85.938 (87.647)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [391][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4089 (0.3520)	Prec@1 85.156 (87.523)	Prec@5 99.219 (99.666)
TRAINING - Epoch: [391][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3069 (0.3576)	Prec@1 88.281 (87.316)	Prec@5 100.000 (99.655)
EVALUATING - Epoch: [391][0/79]	Time 0.367 (0.367)	Data 0.343 (0.343)	Loss 0.5368 (0.5368)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 392	Training Loss 0.3594 	Training Prec@1 87.324 	Training Prec@5 99.616 	Validation Loss 0.5754 	Validation Prec@1 81.720 	Validation Prec@5 99.070 

lr: 0.06759405075659161
TRAINING - Epoch: [392][0/391]	Time 0.907 (0.907)	Data 0.356 (0.356)	Loss 0.2635 (0.2635)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [392][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4218 (0.3366)	Prec@1 88.281 (88.041)	Prec@5 97.656 (99.729)
TRAINING - Epoch: [392][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2836 (0.3453)	Prec@1 92.969 (87.753)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [392][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3534 (0.3525)	Prec@1 89.062 (87.477)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [392][0/79]	Time 0.374 (0.374)	Data 0.351 (0.351)	Loss 0.4783 (0.4783)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:11

 Epoch: 393	Training Loss 0.3541 	Training Prec@1 87.538 	Training Prec@5 99.642 	Validation Loss 0.6102 	Validation Prec@1 80.830 	Validation Prec@5 98.970 

lr: 0.06744633941968801
TRAINING - Epoch: [393][0/391]	Time 0.920 (0.920)	Data 0.349 (0.349)	Loss 0.3045 (0.3045)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [393][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.3959 (0.3539)	Prec@1 83.594 (87.515)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [393][200/391]	Time 0.067 (0.067)	Data 0.000 (0.002)	Loss 0.3433 (0.3566)	Prec@1 85.938 (87.593)	Prec@5 100.000 (99.701)
TRAINING - Epoch: [393][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3133 (0.3627)	Prec@1 88.281 (87.510)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [393][0/79]	Time 0.360 (0.360)	Data 0.339 (0.339)	Loss 0.7448 (0.7448)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:48

 Epoch: 394	Training Loss 0.3629 	Training Prec@1 87.534 	Training Prec@5 99.646 	Validation Loss 0.7523 	Validation Prec@1 77.510 	Validation Prec@5 98.510 

lr: 0.0672984545086429
TRAINING - Epoch: [394][0/391]	Time 0.914 (0.914)	Data 0.355 (0.355)	Loss 0.2987 (0.2987)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [394][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3455 (0.3514)	Prec@1 90.625 (87.894)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [394][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3176 (0.3526)	Prec@1 89.062 (87.931)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [394][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3891 (0.3568)	Prec@1 86.719 (87.666)	Prec@5 99.219 (99.657)
EVALUATING - Epoch: [394][0/79]	Time 0.387 (0.387)	Data 0.364 (0.364)	Loss 0.7105 (0.7105)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:57

 Epoch: 395	Training Loss 0.3577 	Training Prec@1 87.664 	Training Prec@5 99.644 	Validation Loss 1.0313 	Validation Prec@1 73.030 	Validation Prec@5 97.520 

lr: 0.06715039749476759
TRAINING - Epoch: [395][0/391]	Time 0.915 (0.915)	Data 0.351 (0.351)	Loss 0.4436 (0.4436)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [395][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3855 (0.3534)	Prec@1 86.719 (87.902)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [395][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3881 (0.3545)	Prec@1 88.281 (87.846)	Prec@5 98.438 (99.662)
TRAINING - Epoch: [395][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.2650 (0.3512)	Prec@1 91.406 (87.866)	Prec@5 100.000 (99.626)
EVALUATING - Epoch: [395][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.8696 (0.8696)	Prec@1 71.875 (71.875)	Prec@5 95.312 (95.312)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:48

 Epoch: 396	Training Loss 0.3558 	Training Prec@1 87.666 	Training Prec@5 99.618 	Validation Loss 1.0303 	Validation Prec@1 71.150 	Validation Prec@5 97.840 

lr: 0.06700216985108566
TRAINING - Epoch: [396][0/391]	Time 0.898 (0.898)	Data 0.332 (0.332)	Loss 0.2692 (0.2692)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [396][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.3301 (0.3741)	Prec@1 85.938 (86.897)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [396][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.3525 (0.3613)	Prec@1 89.062 (87.325)	Prec@5 99.219 (99.689)
TRAINING - Epoch: [396][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3711 (0.3643)	Prec@1 85.938 (87.266)	Prec@5 99.219 (99.650)
EVALUATING - Epoch: [396][0/79]	Time 0.395 (0.395)	Data 0.375 (0.375)	Loss 0.5925 (0.5925)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:40

 Epoch: 397	Training Loss 0.3634 	Training Prec@1 87.338 	Training Prec@5 99.636 	Validation Loss 0.6478 	Validation Prec@1 80.140 	Validation Prec@5 98.970 

lr: 0.06685377305231824
TRAINING - Epoch: [397][0/391]	Time 0.902 (0.902)	Data 0.339 (0.339)	Loss 0.3780 (0.3780)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [397][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5875 (0.3647)	Prec@1 78.906 (87.268)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [397][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.4576 (0.3696)	Prec@1 82.812 (87.197)	Prec@5 99.219 (99.631)
TRAINING - Epoch: [397][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3308 (0.3738)	Prec@1 90.625 (87.046)	Prec@5 98.438 (99.626)
EVALUATING - Epoch: [397][0/79]	Time 0.370 (0.370)	Data 0.348 (0.348)	Loss 0.5328 (0.5328)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:58

 Epoch: 398	Training Loss 0.3771 	Training Prec@1 86.992 	Training Prec@5 99.614 	Validation Loss 0.5512 	Validation Prec@1 81.730 	Validation Prec@5 98.890 

lr: 0.06670520857486947
TRAINING - Epoch: [398][0/391]	Time 0.926 (0.926)	Data 0.374 (0.374)	Loss 0.3036 (0.3036)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [398][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5141 (0.3405)	Prec@1 81.250 (88.382)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [398][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3939 (0.3503)	Prec@1 85.938 (88.079)	Prec@5 100.000 (99.642)
TRAINING - Epoch: [398][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4158 (0.3477)	Prec@1 86.719 (88.110)	Prec@5 100.000 (99.639)
EVALUATING - Epoch: [398][0/79]	Time 0.361 (0.361)	Data 0.339 (0.339)	Loss 0.5351 (0.5351)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:27

 Epoch: 399	Training Loss 0.3482 	Training Prec@1 88.058 	Training Prec@5 99.652 	Validation Loss 0.6494 	Validation Prec@1 80.000 	Validation Prec@5 98.530 

lr: 0.06655647789681164
TRAINING - Epoch: [399][0/391]	Time 0.933 (0.933)	Data 0.355 (0.355)	Loss 0.2897 (0.2897)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [399][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4080 (0.3426)	Prec@1 85.156 (88.127)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [399][200/391]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.2955 (0.3401)	Prec@1 90.625 (88.102)	Prec@5 100.000 (99.670)
TRAINING - Epoch: [399][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3382 (0.3419)	Prec@1 85.938 (88.050)	Prec@5 100.000 (99.670)
EVALUATING - Epoch: [399][0/79]	Time 0.347 (0.347)	Data 0.326 (0.326)	Loss 0.6511 (0.6511)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:55

 Epoch: 400	Training Loss 0.3460 	Training Prec@1 87.870 	Training Prec@5 99.650 	Validation Loss 0.6550 	Validation Prec@1 78.960 	Validation Prec@5 98.950 

lr: 0.06640758249787064
TRAINING - Epoch: [400][0/391]	Time 0.917 (0.917)	Data 0.344 (0.344)	Loss 0.3382 (0.3382)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [400][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3746 (0.3449)	Prec@1 87.500 (87.956)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [400][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4240 (0.3517)	Prec@1 87.500 (87.916)	Prec@5 98.438 (99.666)
TRAINING - Epoch: [400][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2913 (0.3521)	Prec@1 90.625 (87.752)	Prec@5 99.219 (99.676)
EVALUATING - Epoch: [400][0/79]	Time 0.337 (0.337)	Data 0.317 (0.317)	Loss 0.5749 (0.5749)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:53

 Epoch: 401	Training Loss 0.3547 	Training Prec@1 87.712 	Training Prec@5 99.666 	Validation Loss 0.5651 	Validation Prec@1 82.330 	Validation Prec@5 98.930 

lr: 0.06625852385941117
TRAINING - Epoch: [401][0/391]	Time 0.907 (0.907)	Data 0.356 (0.356)	Loss 0.3092 (0.3092)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [401][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4909 (0.3475)	Prec@1 87.500 (87.949)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [401][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3215 (0.3450)	Prec@1 89.062 (87.928)	Prec@5 100.000 (99.654)
TRAINING - Epoch: [401][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4416 (0.3497)	Prec@1 86.719 (87.822)	Prec@5 100.000 (99.657)
EVALUATING - Epoch: [401][0/79]	Time 0.359 (0.359)	Data 0.340 (0.340)	Loss 0.5551 (0.5551)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:22

 Epoch: 402	Training Loss 0.3481 	Training Prec@1 87.882 	Training Prec@5 99.664 	Validation Loss 0.6811 	Validation Prec@1 79.250 	Validation Prec@5 98.910 

lr: 0.06610930346442195
TRAINING - Epoch: [402][0/391]	Time 0.908 (0.908)	Data 0.353 (0.353)	Loss 0.3603 (0.3603)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [402][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3594 (0.3429)	Prec@1 85.156 (88.119)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [402][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3565 (0.3524)	Prec@1 87.500 (87.865)	Prec@5 98.438 (99.619)
TRAINING - Epoch: [402][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3087 (0.3560)	Prec@1 89.062 (87.741)	Prec@5 100.000 (99.616)
EVALUATING - Epoch: [402][0/79]	Time 0.371 (0.371)	Data 0.350 (0.350)	Loss 0.5624 (0.5624)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:29

 Epoch: 403	Training Loss 0.3541 	Training Prec@1 87.818 	Training Prec@5 99.620 	Validation Loss 0.5857 	Validation Prec@1 81.130 	Validation Prec@5 99.170 

lr: 0.06595992279750108
TRAINING - Epoch: [403][0/391]	Time 0.925 (0.925)	Data 0.355 (0.355)	Loss 0.2935 (0.2935)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [403][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.3425 (0.3285)	Prec@1 88.281 (88.506)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [403][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2776 (0.3317)	Prec@1 89.844 (88.487)	Prec@5 98.438 (99.662)
TRAINING - Epoch: [403][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.3246 (0.3382)	Prec@1 92.188 (88.273)	Prec@5 100.000 (99.657)
EVALUATING - Epoch: [403][0/79]	Time 0.366 (0.366)	Data 0.347 (0.347)	Loss 0.6335 (0.6335)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:16

 Epoch: 404	Training Loss 0.3422 	Training Prec@1 88.048 	Training Prec@5 99.640 	Validation Loss 0.7706 	Validation Prec@1 77.220 	Validation Prec@5 98.820 

lr: 0.06581038334484117
TRAINING - Epoch: [404][0/391]	Time 0.932 (0.932)	Data 0.341 (0.341)	Loss 0.4145 (0.4145)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [404][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2958 (0.3514)	Prec@1 87.500 (87.856)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [404][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3015 (0.3413)	Prec@1 88.281 (88.184)	Prec@5 100.000 (99.670)
TRAINING - Epoch: [404][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4197 (0.3542)	Prec@1 83.594 (87.775)	Prec@5 100.000 (99.644)
EVALUATING - Epoch: [404][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.7256 (0.7256)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:35

 Epoch: 405	Training Loss 0.3586 	Training Prec@1 87.716 	Training Prec@5 99.640 	Validation Loss 0.7191 	Validation Prec@1 79.070 	Validation Prec@5 97.920 

lr: 0.06566068659421465
TRAINING - Epoch: [405][0/391]	Time 0.952 (0.952)	Data 0.350 (0.350)	Loss 0.2646 (0.2646)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [405][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2066 (0.3443)	Prec@1 92.969 (88.150)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [405][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3485 (0.3473)	Prec@1 84.375 (87.994)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [405][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3660 (0.3484)	Prec@1 87.500 (87.957)	Prec@5 99.219 (99.670)
EVALUATING - Epoch: [405][0/79]	Time 0.347 (0.347)	Data 0.326 (0.326)	Loss 0.6075 (0.6075)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:48

 Epoch: 406	Training Loss 0.3528 	Training Prec@1 87.818 	Training Prec@5 99.672 	Validation Loss 0.6868 	Validation Prec@1 79.310 	Validation Prec@5 98.450 

lr: 0.06551083403495882
TRAINING - Epoch: [406][0/391]	Time 0.922 (0.922)	Data 0.356 (0.356)	Loss 0.1822 (0.1822)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [406][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3989 (0.3409)	Prec@1 87.500 (88.103)	Prec@5 99.219 (99.706)
TRAINING - Epoch: [406][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3214 (0.3416)	Prec@1 88.281 (88.176)	Prec@5 100.000 (99.681)
TRAINING - Epoch: [406][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3265 (0.3405)	Prec@1 86.719 (88.123)	Prec@5 100.000 (99.707)
EVALUATING - Epoch: [406][0/79]	Time 0.339 (0.339)	Data 0.319 (0.319)	Loss 0.6597 (0.6597)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:04

 Epoch: 407	Training Loss 0.3432 	Training Prec@1 88.044 	Training Prec@5 99.704 	Validation Loss 0.6670 	Validation Prec@1 79.360 	Validation Prec@5 98.750 

lr: 0.06536082715796122
TRAINING - Epoch: [407][0/391]	Time 0.919 (0.919)	Data 0.361 (0.361)	Loss 0.3849 (0.3849)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [407][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1829 (0.3158)	Prec@1 94.531 (88.699)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [407][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4233 (0.3369)	Prec@1 82.031 (88.056)	Prec@5 100.000 (99.697)
TRAINING - Epoch: [407][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3541 (0.3486)	Prec@1 89.062 (87.801)	Prec@5 99.219 (99.639)
EVALUATING - Epoch: [407][0/79]	Time 0.369 (0.369)	Data 0.346 (0.346)	Loss 0.5460 (0.5460)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:22

 Epoch: 408	Training Loss 0.3525 	Training Prec@1 87.746 	Training Prec@5 99.630 	Validation Loss 0.5451 	Validation Prec@1 82.640 	Validation Prec@5 98.990 

lr: 0.06521066745564463
TRAINING - Epoch: [408][0/391]	Time 0.916 (0.916)	Data 0.347 (0.347)	Loss 0.4135 (0.4135)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [408][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.2541 (0.3321)	Prec@1 89.844 (88.281)	Prec@5 100.000 (99.714)
TRAINING - Epoch: [408][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.3365 (0.3428)	Prec@1 90.625 (88.067)	Prec@5 98.438 (99.650)
TRAINING - Epoch: [408][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4052 (0.3464)	Prec@1 83.594 (87.957)	Prec@5 99.219 (99.642)
EVALUATING - Epoch: [408][0/79]	Time 0.335 (0.335)	Data 0.316 (0.316)	Loss 0.4648 (0.4648)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:18:08

 Epoch: 409	Training Loss 0.3496 	Training Prec@1 87.850 	Training Prec@5 99.634 	Validation Loss 0.6272 	Validation Prec@1 80.740 	Validation Prec@5 98.960 

lr: 0.06506035642195238
TRAINING - Epoch: [409][0/391]	Time 0.908 (0.908)	Data 0.353 (0.353)	Loss 0.2401 (0.2401)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [409][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2904 (0.3416)	Prec@1 90.625 (88.243)	Prec@5 99.219 (99.691)
TRAINING - Epoch: [409][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3057 (0.3343)	Prec@1 89.844 (88.460)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [409][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3595 (0.3373)	Prec@1 85.156 (88.294)	Prec@5 99.219 (99.699)
EVALUATING - Epoch: [409][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.4837 (0.4837)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:48

 Epoch: 410	Training Loss 0.3443 	Training Prec@1 88.022 	Training Prec@5 99.680 	Validation Loss 0.6363 	Validation Prec@1 79.770 	Validation Prec@5 98.880 

lr: 0.06490989555233326
TRAINING - Epoch: [410][0/391]	Time 0.978 (0.978)	Data 0.348 (0.348)	Loss 0.4651 (0.4651)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [410][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4022 (0.3495)	Prec@1 85.156 (87.871)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [410][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3951 (0.3519)	Prec@1 85.938 (87.858)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [410][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3330 (0.3518)	Prec@1 86.719 (87.850)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [410][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.6273 (0.6273)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:36

 Epoch: 411	Training Loss 0.3540 	Training Prec@1 87.844 	Training Prec@5 99.690 	Validation Loss 0.7710 	Validation Prec@1 76.470 	Validation Prec@5 98.930 

lr: 0.06475928634372692
TRAINING - Epoch: [411][0/391]	Time 0.900 (0.900)	Data 0.344 (0.344)	Loss 0.3900 (0.3900)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [411][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.5133 (0.3739)	Prec@1 82.031 (87.106)	Prec@5 99.219 (99.606)
TRAINING - Epoch: [411][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2480 (0.3639)	Prec@1 89.844 (87.477)	Prec@5 100.000 (99.635)
TRAINING - Epoch: [411][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3683 (0.3547)	Prec@1 85.156 (87.773)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [411][0/79]	Time 0.364 (0.364)	Data 0.344 (0.344)	Loss 0.4602 (0.4602)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:30

 Epoch: 412	Training Loss 0.3576 	Training Prec@1 87.704 	Training Prec@5 99.644 	Validation Loss 0.5417 	Validation Prec@1 83.060 	Validation Prec@5 99.220 

lr: 0.06460853029454876
TRAINING - Epoch: [412][0/391]	Time 0.933 (0.933)	Data 0.355 (0.355)	Loss 0.2667 (0.2667)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [412][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3596 (0.3383)	Prec@1 88.281 (88.034)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [412][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3424 (0.3518)	Prec@1 84.375 (87.807)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [412][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3127 (0.3495)	Prec@1 91.406 (88.001)	Prec@5 97.656 (99.670)
EVALUATING - Epoch: [412][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.4496 (0.4496)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:08

 Epoch: 413	Training Loss 0.3517 	Training Prec@1 87.940 	Training Prec@5 99.638 	Validation Loss 0.5516 	Validation Prec@1 82.350 	Validation Prec@5 98.880 

lr: 0.06445762890467514
TRAINING - Epoch: [413][0/391]	Time 0.911 (0.911)	Data 0.348 (0.348)	Loss 0.3018 (0.3018)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [413][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2902 (0.3419)	Prec@1 89.844 (88.011)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [413][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2186 (0.3352)	Prec@1 92.969 (88.219)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [413][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.4228 (0.3418)	Prec@1 85.938 (88.097)	Prec@5 99.219 (99.631)
EVALUATING - Epoch: [413][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.5948 (0.5948)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:01

 Epoch: 414	Training Loss 0.3452 	Training Prec@1 87.946 	Training Prec@5 99.610 	Validation Loss 0.6514 	Validation Prec@1 80.270 	Validation Prec@5 98.740 

lr: 0.06430658367542841
TRAINING - Epoch: [414][0/391]	Time 0.918 (0.918)	Data 0.341 (0.341)	Loss 0.3262 (0.3262)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [414][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2288 (0.3206)	Prec@1 92.188 (89.078)	Prec@5 99.219 (99.729)
TRAINING - Epoch: [414][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3394 (0.3342)	Prec@1 89.062 (88.581)	Prec@5 100.000 (99.701)
TRAINING - Epoch: [414][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2763 (0.3415)	Prec@1 87.500 (88.237)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [414][0/79]	Time 0.347 (0.347)	Data 0.326 (0.326)	Loss 0.6388 (0.6388)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:04

 Epoch: 415	Training Loss 0.3435 	Training Prec@1 88.070 	Training Prec@5 99.668 	Validation Loss 0.5990 	Validation Prec@1 81.880 	Validation Prec@5 98.830 

lr: 0.06415539610956196
TRAINING - Epoch: [415][0/391]	Time 0.917 (0.917)	Data 0.356 (0.356)	Loss 0.3723 (0.3723)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [415][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.5199 (0.3591)	Prec@1 83.594 (87.593)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [415][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3083 (0.3592)	Prec@1 90.625 (87.679)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [415][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2057 (0.3567)	Prec@1 92.188 (87.684)	Prec@5 100.000 (99.676)
EVALUATING - Epoch: [415][0/79]	Time 0.371 (0.371)	Data 0.348 (0.348)	Loss 0.6019 (0.6019)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:04

 Epoch: 416	Training Loss 0.3560 	Training Prec@1 87.682 	Training Prec@5 99.686 	Validation Loss 0.6308 	Validation Prec@1 80.410 	Validation Prec@5 98.370 

lr: 0.06400406771124534
TRAINING - Epoch: [416][0/391]	Time 0.915 (0.915)	Data 0.350 (0.350)	Loss 0.2917 (0.2917)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [416][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3519 (0.3388)	Prec@1 85.938 (88.157)	Prec@5 99.219 (99.698)
TRAINING - Epoch: [416][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3555 (0.3334)	Prec@1 88.281 (88.421)	Prec@5 100.000 (99.701)
TRAINING - Epoch: [416][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.3837 (0.3373)	Prec@1 82.031 (88.175)	Prec@5 100.000 (99.709)
EVALUATING - Epoch: [416][0/79]	Time 0.370 (0.370)	Data 0.348 (0.348)	Loss 0.8634 (0.8634)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:58

 Epoch: 417	Training Loss 0.3400 	Training Prec@1 88.080 	Training Prec@5 99.700 	Validation Loss 0.8017 	Validation Prec@1 77.190 	Validation Prec@5 98.030 

lr: 0.06385259998604915
TRAINING - Epoch: [417][0/391]	Time 0.903 (0.903)	Data 0.347 (0.347)	Loss 0.4109 (0.4109)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [417][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4274 (0.3409)	Prec@1 85.156 (88.181)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [417][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3373 (0.3444)	Prec@1 86.719 (88.017)	Prec@5 100.000 (99.635)
TRAINING - Epoch: [417][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3038 (0.3451)	Prec@1 89.844 (87.980)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [417][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.5364 (0.5364)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:51

 Epoch: 418	Training Loss 0.3443 	Training Prec@1 88.068 	Training Prec@5 99.642 	Validation Loss 0.5913 	Validation Prec@1 81.060 	Validation Prec@5 99.120 

lr: 0.06370099444093029
TRAINING - Epoch: [418][0/391]	Time 0.934 (0.934)	Data 0.345 (0.345)	Loss 0.2739 (0.2739)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [418][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2601 (0.3396)	Prec@1 91.406 (88.312)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [418][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2589 (0.3321)	Prec@1 89.844 (88.351)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [418][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3437 (0.3417)	Prec@1 88.281 (88.045)	Prec@5 100.000 (99.694)
EVALUATING - Epoch: [418][0/79]	Time 0.347 (0.347)	Data 0.329 (0.329)	Loss 0.6455 (0.6455)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 419	Training Loss 0.3418 	Training Prec@1 88.084 	Training Prec@5 99.692 	Validation Loss 0.7631 	Validation Prec@1 79.520 	Validation Prec@5 97.690 

lr: 0.06354925258421673
TRAINING - Epoch: [419][0/391]	Time 0.918 (0.918)	Data 0.343 (0.343)	Loss 0.3110 (0.3110)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [419][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3663 (0.3249)	Prec@1 89.062 (88.622)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [419][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3457 (0.3241)	Prec@1 85.938 (88.604)	Prec@5 99.219 (99.712)
TRAINING - Epoch: [419][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2338 (0.3321)	Prec@1 92.969 (88.424)	Prec@5 100.000 (99.668)
EVALUATING - Epoch: [419][0/79]	Time 0.358 (0.358)	Data 0.336 (0.336)	Loss 0.4718 (0.4718)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 420	Training Loss 0.3393 	Training Prec@1 88.170 	Training Prec@5 99.652 	Validation Loss 0.5118 	Validation Prec@1 83.390 	Validation Prec@5 99.260 

lr: 0.06339737592559265
TRAINING - Epoch: [420][0/391]	Time 0.929 (0.929)	Data 0.378 (0.378)	Loss 0.2319 (0.2319)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [420][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3590 (0.3160)	Prec@1 86.719 (89.032)	Prec@5 99.219 (99.729)
TRAINING - Epoch: [420][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2992 (0.3310)	Prec@1 89.062 (88.363)	Prec@5 99.219 (99.751)
TRAINING - Epoch: [420][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3863 (0.3352)	Prec@1 86.719 (88.266)	Prec@5 100.000 (99.714)
EVALUATING - Epoch: [420][0/79]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.5420 (0.5420)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:47

 Epoch: 421	Training Loss 0.3375 	Training Prec@1 88.222 	Training Prec@5 99.710 	Validation Loss 0.6016 	Validation Prec@1 81.270 	Validation Prec@5 98.870 

lr: 0.06324536597608338
TRAINING - Epoch: [421][0/391]	Time 0.896 (0.896)	Data 0.346 (0.346)	Loss 0.3159 (0.3159)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [421][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3301 (0.3190)	Prec@1 89.062 (88.645)	Prec@5 99.219 (99.776)
TRAINING - Epoch: [421][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3132 (0.3266)	Prec@1 89.062 (88.413)	Prec@5 100.000 (99.747)
TRAINING - Epoch: [421][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2695 (0.3306)	Prec@1 88.281 (88.357)	Prec@5 100.000 (99.740)
EVALUATING - Epoch: [421][0/79]	Time 0.381 (0.381)	Data 0.358 (0.358)	Loss 0.4753 (0.4753)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:06

 Epoch: 422	Training Loss 0.3338 	Training Prec@1 88.296 	Training Prec@5 99.724 	Validation Loss 0.6827 	Validation Prec@1 80.160 	Validation Prec@5 98.550 

lr: 0.06309322424804033
TRAINING - Epoch: [422][0/391]	Time 0.914 (0.914)	Data 0.344 (0.344)	Loss 0.3337 (0.3337)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [422][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3136 (0.3225)	Prec@1 88.281 (88.823)	Prec@5 99.219 (99.799)
TRAINING - Epoch: [422][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4223 (0.3295)	Prec@1 87.500 (88.581)	Prec@5 99.219 (99.743)
TRAINING - Epoch: [422][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3577 (0.3348)	Prec@1 88.281 (88.338)	Prec@5 100.000 (99.753)
EVALUATING - Epoch: [422][0/79]	Time 0.389 (0.389)	Data 0.366 (0.366)	Loss 0.9153 (0.9153)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:00

 Epoch: 423	Training Loss 0.3348 	Training Prec@1 88.362 	Training Prec@5 99.742 	Validation Loss 0.7458 	Validation Prec@1 77.900 	Validation Prec@5 98.330 

lr: 0.06294095225512601
TRAINING - Epoch: [423][0/391]	Time 0.919 (0.919)	Data 0.340 (0.340)	Loss 0.2835 (0.2835)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [423][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3029 (0.3227)	Prec@1 87.500 (88.869)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [423][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2328 (0.3284)	Prec@1 92.188 (88.565)	Prec@5 100.000 (99.712)
TRAINING - Epoch: [423][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2157 (0.3380)	Prec@1 92.969 (88.341)	Prec@5 99.219 (99.676)
EVALUATING - Epoch: [423][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.5740 (0.5740)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:35

 Epoch: 424	Training Loss 0.3395 	Training Prec@1 88.206 	Training Prec@5 99.662 	Validation Loss 0.7285 	Validation Prec@1 78.780 	Validation Prec@5 98.440 

lr: 0.06278855151229897
TRAINING - Epoch: [424][0/391]	Time 0.909 (0.909)	Data 0.341 (0.341)	Loss 0.2497 (0.2497)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [424][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3065 (0.3440)	Prec@1 88.281 (88.142)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [424][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3378 (0.3384)	Prec@1 88.281 (88.270)	Prec@5 100.000 (99.728)
TRAINING - Epoch: [424][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3538 (0.3441)	Prec@1 90.625 (88.141)	Prec@5 100.000 (99.722)
EVALUATING - Epoch: [424][0/79]	Time 0.357 (0.357)	Data 0.336 (0.336)	Loss 0.6559 (0.6559)	Prec@1 80.469 (80.469)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:21

 Epoch: 425	Training Loss 0.3444 	Training Prec@1 88.120 	Training Prec@5 99.726 	Validation Loss 0.6882 	Validation Prec@1 79.700 	Validation Prec@5 98.430 

lr: 0.06263602353579864
TRAINING - Epoch: [425][0/391]	Time 0.936 (0.936)	Data 0.369 (0.369)	Loss 0.3879 (0.3879)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [425][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2527 (0.3430)	Prec@1 92.188 (88.219)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [425][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2327 (0.3446)	Prec@1 90.625 (88.075)	Prec@5 100.000 (99.627)
TRAINING - Epoch: [425][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3340 (0.3446)	Prec@1 88.281 (88.029)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [425][0/79]	Time 0.380 (0.380)	Data 0.358 (0.358)	Loss 0.5847 (0.5847)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 426	Training Loss 0.3473 	Training Prec@1 87.912 	Training Prec@5 99.668 	Validation Loss 0.7211 	Validation Prec@1 79.060 	Validation Prec@5 98.690 

lr: 0.062483369843130306
TRAINING - Epoch: [426][0/391]	Time 0.963 (0.963)	Data 0.343 (0.343)	Loss 0.4597 (0.4597)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [426][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1231 (0.3270)	Prec@1 96.094 (88.560)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [426][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3173 (0.3319)	Prec@1 88.281 (88.382)	Prec@5 99.219 (99.708)
TRAINING - Epoch: [426][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3511 (0.3374)	Prec@1 86.719 (88.115)	Prec@5 100.000 (99.702)
EVALUATING - Epoch: [426][0/79]	Time 0.358 (0.358)	Data 0.334 (0.334)	Loss 0.4633 (0.4633)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:24

 Epoch: 427	Training Loss 0.3361 	Training Prec@1 88.194 	Training Prec@5 99.690 	Validation Loss 0.6940 	Validation Prec@1 79.320 	Validation Prec@5 98.460 

lr: 0.062330591953050074
TRAINING - Epoch: [427][0/391]	Time 0.907 (0.907)	Data 0.343 (0.343)	Loss 0.3774 (0.3774)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [427][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2849 (0.3130)	Prec@1 91.406 (88.660)	Prec@5 98.438 (99.760)
TRAINING - Epoch: [427][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2076 (0.3249)	Prec@1 94.531 (88.394)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [427][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3468 (0.3260)	Prec@1 88.281 (88.569)	Prec@5 100.000 (99.699)
EVALUATING - Epoch: [427][0/79]	Time 0.338 (0.338)	Data 0.317 (0.317)	Loss 0.6967 (0.6967)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:29

 Epoch: 428	Training Loss 0.3306 	Training Prec@1 88.398 	Training Prec@5 99.682 	Validation Loss 0.8464 	Validation Prec@1 76.380 	Validation Prec@5 97.290 

lr: 0.06217769138554957
TRAINING - Epoch: [428][0/391]	Time 0.914 (0.914)	Data 0.339 (0.339)	Loss 0.4080 (0.4080)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [428][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2834 (0.3148)	Prec@1 92.188 (89.233)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [428][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4549 (0.3231)	Prec@1 85.938 (88.853)	Prec@5 99.219 (99.701)
TRAINING - Epoch: [428][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5431 (0.3309)	Prec@1 83.594 (88.611)	Prec@5 99.219 (99.694)
EVALUATING - Epoch: [428][0/79]	Time 0.346 (0.346)	Data 0.326 (0.326)	Loss 0.7175 (0.7175)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:32

 Epoch: 429	Training Loss 0.3341 	Training Prec@1 88.442 	Training Prec@5 99.692 	Validation Loss 0.6848 	Validation Prec@1 79.270 	Validation Prec@5 98.560 

lr: 0.06202466966184109
TRAINING - Epoch: [429][0/391]	Time 0.915 (0.915)	Data 0.358 (0.358)	Loss 0.2799 (0.2799)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [429][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3820 (0.3387)	Prec@1 87.500 (88.065)	Prec@5 98.438 (99.606)
TRAINING - Epoch: [429][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4925 (0.3469)	Prec@1 83.594 (87.826)	Prec@5 98.438 (99.666)
TRAINING - Epoch: [429][300/391]	Time 0.066 (0.066)	Data 0.000 (0.001)	Loss 0.3003 (0.3404)	Prec@1 87.500 (88.120)	Prec@5 100.000 (99.663)
EVALUATING - Epoch: [429][0/79]	Time 0.353 (0.353)	Data 0.332 (0.332)	Loss 0.6102 (0.6102)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:33

 Epoch: 430	Training Loss 0.3415 	Training Prec@1 88.166 	Training Prec@5 99.652 	Validation Loss 0.6564 	Validation Prec@1 79.480 	Validation Prec@5 98.600 

lr: 0.06187152830434217
TRAINING - Epoch: [430][0/391]	Time 0.929 (0.929)	Data 0.368 (0.368)	Loss 0.4386 (0.4386)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [430][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.3174 (0.3202)	Prec@1 88.281 (88.776)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [430][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2013 (0.3340)	Prec@1 95.312 (88.293)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [430][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3001 (0.3375)	Prec@1 87.500 (88.258)	Prec@5 100.000 (99.686)
EVALUATING - Epoch: [430][0/79]	Time 0.364 (0.364)	Data 0.344 (0.344)	Loss 0.4827 (0.4827)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:18:37

 Epoch: 431	Training Loss 0.3368 	Training Prec@1 88.264 	Training Prec@5 99.710 	Validation Loss 0.6336 	Validation Prec@1 81.150 	Validation Prec@5 98.860 

lr: 0.06171826883666071
TRAINING - Epoch: [431][0/391]	Time 0.936 (0.936)	Data 0.377 (0.377)	Loss 0.4102 (0.4102)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [431][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2498 (0.3272)	Prec@1 88.281 (88.668)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [431][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3424 (0.3324)	Prec@1 86.719 (88.410)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [431][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2727 (0.3368)	Prec@1 91.406 (88.359)	Prec@5 99.219 (99.709)
EVALUATING - Epoch: [431][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.3412 (0.3412)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 432	Training Loss 0.3418 	Training Prec@1 88.234 	Training Prec@5 99.710 	Validation Loss 0.5495 	Validation Prec@1 82.590 	Validation Prec@5 99.090 

lr: 0.061564892783579635
TRAINING - Epoch: [432][0/391]	Time 0.914 (0.914)	Data 0.348 (0.348)	Loss 0.2249 (0.2249)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [432][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3776 (0.3415)	Prec@1 88.281 (88.119)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [432][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.2632 (0.3392)	Prec@1 92.188 (88.200)	Prec@5 100.000 (99.658)
TRAINING - Epoch: [432][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3007 (0.3359)	Prec@1 89.062 (88.294)	Prec@5 99.219 (99.670)
EVALUATING - Epoch: [432][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.5345 (0.5345)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:47

 Epoch: 433	Training Loss 0.3369 	Training Prec@1 88.240 	Training Prec@5 99.672 	Validation Loss 0.8046 	Validation Prec@1 76.750 	Validation Prec@5 98.270 

lr: 0.06141140167104176
TRAINING - Epoch: [433][0/391]	Time 0.914 (0.914)	Data 0.359 (0.359)	Loss 0.3573 (0.3573)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [433][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3818 (0.3416)	Prec@1 85.938 (88.157)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [433][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5088 (0.3349)	Prec@1 81.250 (88.351)	Prec@5 100.000 (99.670)
TRAINING - Epoch: [433][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2289 (0.3327)	Prec@1 90.625 (88.442)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [433][0/79]	Time 0.350 (0.350)	Data 0.331 (0.331)	Loss 0.5280 (0.5280)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:48

 Epoch: 434	Training Loss 0.3355 	Training Prec@1 88.336 	Training Prec@5 99.682 	Validation Loss 0.5765 	Validation Prec@1 81.460 	Validation Prec@5 99.230 

lr: 0.06125779702613468
TRAINING - Epoch: [434][0/391]	Time 0.943 (0.943)	Data 0.387 (0.387)	Loss 0.2720 (0.2720)	Prec@1 92.188 (92.188)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [434][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3563 (0.3248)	Prec@1 89.062 (88.645)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [434][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3197 (0.3296)	Prec@1 87.500 (88.429)	Prec@5 99.219 (99.689)
TRAINING - Epoch: [434][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3244 (0.3361)	Prec@1 89.844 (88.245)	Prec@5 100.000 (99.676)
EVALUATING - Epoch: [434][0/79]	Time 0.355 (0.355)	Data 0.332 (0.332)	Loss 0.6249 (0.6249)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:33

 Epoch: 435	Training Loss 0.3355 	Training Prec@1 88.266 	Training Prec@5 99.678 	Validation Loss 0.6237 	Validation Prec@1 80.930 	Validation Prec@5 98.840 

lr: 0.06110408037707548
TRAINING - Epoch: [435][0/391]	Time 0.915 (0.915)	Data 0.364 (0.364)	Loss 0.3031 (0.3031)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [435][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3003 (0.3407)	Prec@1 88.281 (88.173)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [435][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2647 (0.3366)	Prec@1 92.188 (88.437)	Prec@5 100.000 (99.666)
TRAINING - Epoch: [435][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3307 (0.3339)	Prec@1 85.156 (88.460)	Prec@5 100.000 (99.676)
EVALUATING - Epoch: [435][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 0.5624 (0.5624)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:43

 Epoch: 436	Training Loss 0.3360 	Training Prec@1 88.408 	Training Prec@5 99.688 	Validation Loss 0.6335 	Validation Prec@1 80.010 	Validation Prec@5 98.890 

lr: 0.06095025325319563
TRAINING - Epoch: [436][0/391]	Time 0.937 (0.937)	Data 0.362 (0.362)	Loss 0.3949 (0.3949)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [436][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4710 (0.3350)	Prec@1 81.250 (88.343)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [436][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3472 (0.3329)	Prec@1 85.156 (88.425)	Prec@5 99.219 (99.705)
TRAINING - Epoch: [436][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3184 (0.3319)	Prec@1 92.188 (88.395)	Prec@5 100.000 (99.694)
EVALUATING - Epoch: [436][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.5379 (0.5379)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:43

 Epoch: 437	Training Loss 0.3353 	Training Prec@1 88.282 	Training Prec@5 99.696 	Validation Loss 0.6398 	Validation Prec@1 81.020 	Validation Prec@5 98.850 

lr: 0.06079631718492566
TRAINING - Epoch: [437][0/391]	Time 0.895 (0.895)	Data 0.337 (0.337)	Loss 0.3205 (0.3205)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [437][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2330 (0.3149)	Prec@1 90.625 (89.233)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [437][200/391]	Time 0.059 (0.067)	Data 0.000 (0.002)	Loss 0.4023 (0.3211)	Prec@1 85.938 (88.864)	Prec@5 100.000 (99.724)
TRAINING - Epoch: [437][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3008 (0.3254)	Prec@1 89.844 (88.855)	Prec@5 100.000 (99.694)
EVALUATING - Epoch: [437][0/79]	Time 0.347 (0.347)	Data 0.328 (0.328)	Loss 0.6797 (0.6797)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:57

 Epoch: 438	Training Loss 0.3274 	Training Prec@1 88.734 	Training Prec@5 99.686 	Validation Loss 0.7035 	Validation Prec@1 79.620 	Validation Prec@5 98.690 

lr: 0.060642273703780045
TRAINING - Epoch: [438][0/391]	Time 0.905 (0.905)	Data 0.341 (0.341)	Loss 0.3299 (0.3299)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [438][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3438 (0.3213)	Prec@1 89.062 (88.931)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [438][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3332 (0.3341)	Prec@1 89.844 (88.573)	Prec@5 98.438 (99.654)
TRAINING - Epoch: [438][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2604 (0.3418)	Prec@1 91.406 (88.255)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [438][0/79]	Time 0.355 (0.355)	Data 0.336 (0.336)	Loss 0.6309 (0.6309)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:36

 Epoch: 439	Training Loss 0.3386 	Training Prec@1 88.278 	Training Prec@5 99.668 	Validation Loss 0.6303 	Validation Prec@1 80.170 	Validation Prec@5 98.590 

lr: 0.06048812434234185
TRAINING - Epoch: [439][0/391]	Time 0.942 (0.942)	Data 0.382 (0.382)	Loss 0.1641 (0.1641)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [439][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.2892 (0.3214)	Prec@1 90.625 (88.931)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [439][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2093 (0.3189)	Prec@1 92.969 (89.109)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [439][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.3035 (0.3227)	Prec@1 89.062 (88.852)	Prec@5 100.000 (99.725)
EVALUATING - Epoch: [439][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.6514 (0.6514)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:22

 Epoch: 440	Training Loss 0.3297 	Training Prec@1 88.644 	Training Prec@5 99.696 	Validation Loss 0.6602 	Validation Prec@1 79.560 	Validation Prec@5 98.560 

lr: 0.060333870634247624
TRAINING - Epoch: [440][0/391]	Time 0.912 (0.912)	Data 0.327 (0.327)	Loss 0.3279 (0.3279)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [440][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.2457 (0.3288)	Prec@1 88.281 (88.560)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [440][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2350 (0.3323)	Prec@1 93.750 (88.386)	Prec@5 100.000 (99.615)
TRAINING - Epoch: [440][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.3736 (0.3363)	Prec@1 87.500 (88.136)	Prec@5 99.219 (99.655)
EVALUATING - Epoch: [440][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.5493 (0.5493)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:12

 Epoch: 441	Training Loss 0.3368 	Training Prec@1 88.226 	Training Prec@5 99.660 	Validation Loss 0.7905 	Validation Prec@1 77.360 	Validation Prec@5 98.750 

lr: 0.060179514114172
TRAINING - Epoch: [441][0/391]	Time 0.902 (0.902)	Data 0.331 (0.331)	Loss 0.2415 (0.2415)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [441][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2751 (0.3167)	Prec@1 90.625 (88.722)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [441][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2637 (0.3212)	Prec@1 90.625 (88.616)	Prec@5 99.219 (99.755)
TRAINING - Epoch: [441][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3499 (0.3183)	Prec@1 86.719 (88.831)	Prec@5 100.000 (99.746)
EVALUATING - Epoch: [441][0/79]	Time 0.354 (0.354)	Data 0.335 (0.335)	Loss 0.5188 (0.5188)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:15

 Epoch: 442	Training Loss 0.3223 	Training Prec@1 88.718 	Training Prec@5 99.720 	Validation Loss 0.6583 	Validation Prec@1 79.960 	Validation Prec@5 98.500 

lr: 0.060025056317812533
TRAINING - Epoch: [442][0/391]	Time 0.908 (0.908)	Data 0.338 (0.338)	Loss 0.3092 (0.3092)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [442][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4768 (0.3256)	Prec@1 84.375 (88.738)	Prec@5 99.219 (99.706)
TRAINING - Epoch: [442][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3358 (0.3348)	Prec@1 86.719 (88.413)	Prec@5 100.000 (99.689)
TRAINING - Epoch: [442][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4304 (0.3369)	Prec@1 85.156 (88.419)	Prec@5 100.000 (99.689)
EVALUATING - Epoch: [442][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.5027 (0.5027)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:34

 Epoch: 443	Training Loss 0.3367 	Training Prec@1 88.428 	Training Prec@5 99.684 	Validation Loss 0.6610 	Validation Prec@1 80.240 	Validation Prec@5 98.880 

lr: 0.05987049878187433
TRAINING - Epoch: [443][0/391]	Time 0.909 (0.909)	Data 0.338 (0.338)	Loss 0.2827 (0.2827)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [443][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3416 (0.3292)	Prec@1 85.938 (88.436)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [443][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4384 (0.3309)	Prec@1 85.156 (88.499)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [443][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2857 (0.3311)	Prec@1 89.062 (88.445)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [443][0/79]	Time 0.358 (0.358)	Data 0.339 (0.339)	Loss 0.4523 (0.4523)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:43

 Epoch: 444	Training Loss 0.3317 	Training Prec@1 88.492 	Training Prec@5 99.656 	Validation Loss 0.6455 	Validation Prec@1 80.070 	Validation Prec@5 98.960 

lr: 0.059715843044054855
TRAINING - Epoch: [444][0/391]	Time 0.922 (0.922)	Data 0.352 (0.352)	Loss 0.3751 (0.3751)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [444][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2911 (0.3239)	Prec@1 89.844 (88.753)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [444][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2883 (0.3231)	Prec@1 88.281 (88.697)	Prec@5 99.219 (99.759)
TRAINING - Epoch: [444][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2374 (0.3261)	Prec@1 92.188 (88.606)	Prec@5 100.000 (99.725)
EVALUATING - Epoch: [444][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.6526 (0.6526)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:05

 Epoch: 445	Training Loss 0.3287 	Training Prec@1 88.546 	Training Prec@5 99.698 	Validation Loss 0.5882 	Validation Prec@1 81.830 	Validation Prec@5 98.970 

lr: 0.059561090643028586
TRAINING - Epoch: [445][0/391]	Time 0.905 (0.905)	Data 0.339 (0.339)	Loss 0.3500 (0.3500)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [445][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2256 (0.3248)	Prec@1 91.406 (88.892)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [445][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2357 (0.3316)	Prec@1 94.531 (88.538)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [445][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.4099 (0.3288)	Prec@1 81.250 (88.626)	Prec@5 100.000 (99.743)
EVALUATING - Epoch: [445][0/79]	Time 0.372 (0.372)	Data 0.349 (0.349)	Loss 0.4988 (0.4988)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:23

 Epoch: 446	Training Loss 0.3318 	Training Prec@1 88.488 	Training Prec@5 99.738 	Validation Loss 0.5878 	Validation Prec@1 81.550 	Validation Prec@5 98.810 

lr: 0.05940624311843165
TRAINING - Epoch: [446][0/391]	Time 0.931 (0.931)	Data 0.373 (0.373)	Loss 0.3526 (0.3526)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [446][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3685 (0.3116)	Prec@1 91.406 (88.707)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [446][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2978 (0.3232)	Prec@1 87.500 (88.425)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [446][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.3233 (0.3234)	Prec@1 89.844 (88.463)	Prec@5 100.000 (99.735)
EVALUATING - Epoch: [446][0/79]	Time 0.344 (0.344)	Data 0.322 (0.322)	Loss 0.4771 (0.4771)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:20:41

 Epoch: 447	Training Loss 0.3261 	Training Prec@1 88.514 	Training Prec@5 99.716 	Validation Loss 0.6524 	Validation Prec@1 81.060 	Validation Prec@5 99.110 

lr: 0.05925130201084667
TRAINING - Epoch: [447][0/391]	Time 0.919 (0.919)	Data 0.341 (0.341)	Loss 0.2816 (0.2816)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [447][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.5375 (0.3199)	Prec@1 82.031 (88.645)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [447][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2173 (0.3226)	Prec@1 91.406 (88.701)	Prec@5 100.000 (99.740)
TRAINING - Epoch: [447][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2852 (0.3181)	Prec@1 92.188 (88.865)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [447][0/79]	Time 0.384 (0.384)	Data 0.359 (0.359)	Loss 0.3588 (0.3588)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 448	Training Loss 0.3207 	Training Prec@1 88.814 	Training Prec@5 99.720 	Validation Loss 0.5096 	Validation Prec@1 83.500 	Validation Prec@5 99.190 

lr: 0.05909626886178718
TRAINING - Epoch: [448][0/391]	Time 0.925 (0.925)	Data 0.342 (0.342)	Loss 0.3214 (0.3214)	Prec@1 89.062 (89.062)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [448][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2443 (0.3170)	Prec@1 94.531 (89.016)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [448][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3617 (0.3146)	Prec@1 86.719 (88.938)	Prec@5 100.000 (99.743)
TRAINING - Epoch: [448][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2288 (0.3162)	Prec@1 91.406 (88.899)	Prec@5 100.000 (99.727)
EVALUATING - Epoch: [448][0/79]	Time 0.357 (0.357)	Data 0.333 (0.333)	Loss 0.7963 (0.7963)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:46

 Epoch: 449	Training Loss 0.3188 	Training Prec@1 88.860 	Training Prec@5 99.706 	Validation Loss 0.7923 	Validation Prec@1 77.080 	Validation Prec@5 97.780 

lr: 0.05894114521368256
TRAINING - Epoch: [449][0/391]	Time 0.900 (0.900)	Data 0.351 (0.351)	Loss 0.3142 (0.3142)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [449][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3155 (0.3044)	Prec@1 88.281 (89.364)	Prec@5 99.219 (99.698)
TRAINING - Epoch: [449][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3451 (0.3184)	Prec@1 89.062 (88.891)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [449][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3920 (0.3236)	Prec@1 90.625 (88.826)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [449][0/79]	Time 0.364 (0.364)	Data 0.346 (0.346)	Loss 0.5648 (0.5648)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:19:33

 Epoch: 450	Training Loss 0.3245 	Training Prec@1 88.864 	Training Prec@5 99.708 	Validation Loss 0.5157 	Validation Prec@1 83.680 	Validation Prec@5 99.100 

lr: 0.05878593260986253
TRAINING - Epoch: [450][0/391]	Time 0.907 (0.907)	Data 0.342 (0.342)	Loss 0.2992 (0.2992)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [450][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3159 (0.3165)	Prec@1 92.188 (89.202)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [450][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3069 (0.3152)	Prec@1 89.844 (89.156)	Prec@5 99.219 (99.728)
TRAINING - Epoch: [450][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3712 (0.3224)	Prec@1 86.719 (88.806)	Prec@5 100.000 (99.740)
EVALUATING - Epoch: [450][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.4655 (0.4655)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:24

 Epoch: 451	Training Loss 0.3265 	Training Prec@1 88.730 	Training Prec@5 99.736 	Validation Loss 0.5932 	Validation Prec@1 81.930 	Validation Prec@5 98.780 

lr: 0.058630632594541814
TRAINING - Epoch: [451][0/391]	Time 0.916 (0.916)	Data 0.338 (0.338)	Loss 0.1950 (0.1950)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [451][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3753 (0.3056)	Prec@1 85.156 (89.472)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [451][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2869 (0.3143)	Prec@1 88.281 (89.202)	Prec@5 100.000 (99.685)
TRAINING - Epoch: [451][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1798 (0.3153)	Prec@1 93.750 (88.982)	Prec@5 100.000 (99.730)
EVALUATING - Epoch: [451][0/79]	Time 0.335 (0.335)	Data 0.316 (0.316)	Loss 0.6019 (0.6019)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:33

 Epoch: 452	Training Loss 0.3197 	Training Prec@1 88.848 	Training Prec@5 99.738 	Validation Loss 0.6001 	Validation Prec@1 81.050 	Validation Prec@5 98.940 

lr: 0.058475246712804796
TRAINING - Epoch: [452][0/391]	Time 0.902 (0.902)	Data 0.336 (0.336)	Loss 0.2713 (0.2713)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [452][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2019 (0.3090)	Prec@1 92.188 (89.356)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [452][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2349 (0.3067)	Prec@1 92.969 (89.257)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [452][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2739 (0.3142)	Prec@1 88.281 (89.011)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [452][0/79]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 0.3782 (0.3782)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 453	Training Loss 0.3170 	Training Prec@1 88.930 	Training Prec@5 99.724 	Validation Loss 0.5896 	Validation Prec@1 81.850 	Validation Prec@5 98.970 

lr: 0.058319776510590206
TRAINING - Epoch: [453][0/391]	Time 0.917 (0.917)	Data 0.348 (0.348)	Loss 0.3425 (0.3425)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [453][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2540 (0.3108)	Prec@1 89.844 (88.900)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [453][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3328 (0.3202)	Prec@1 90.625 (88.728)	Prec@5 99.219 (99.736)
TRAINING - Epoch: [453][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.4166 (0.3240)	Prec@1 86.719 (88.689)	Prec@5 99.219 (99.691)
EVALUATING - Epoch: [453][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 0.4963 (0.4963)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:59

 Epoch: 454	Training Loss 0.3274 	Training Prec@1 88.558 	Training Prec@5 99.708 	Validation Loss 0.6042 	Validation Prec@1 81.280 	Validation Prec@5 98.630 

lr: 0.05816422353467559
TRAINING - Epoch: [454][0/391]	Time 0.904 (0.904)	Data 0.350 (0.350)	Loss 0.2324 (0.2324)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [454][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2875 (0.3163)	Prec@1 85.938 (89.047)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [454][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4858 (0.3221)	Prec@1 81.250 (88.876)	Prec@5 99.219 (99.705)
TRAINING - Epoch: [454][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3368 (0.3236)	Prec@1 85.156 (88.756)	Prec@5 100.000 (99.694)
EVALUATING - Epoch: [454][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.5385 (0.5385)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 455	Training Loss 0.3248 	Training Prec@1 88.712 	Training Prec@5 99.702 	Validation Loss 0.6547 	Validation Prec@1 79.620 	Validation Prec@5 99.040 

lr: 0.058008589332662105
TRAINING - Epoch: [455][0/391]	Time 0.935 (0.935)	Data 0.364 (0.364)	Loss 0.2347 (0.2347)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [455][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3914 (0.3017)	Prec@1 86.719 (89.325)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [455][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3446 (0.3179)	Prec@1 86.719 (88.806)	Prec@5 100.000 (99.751)
TRAINING - Epoch: [455][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4771 (0.3279)	Prec@1 82.031 (88.551)	Prec@5 99.219 (99.727)
EVALUATING - Epoch: [455][0/79]	Time 0.346 (0.346)	Data 0.324 (0.324)	Loss 0.6552 (0.6552)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:59

 Epoch: 456	Training Loss 0.3270 	Training Prec@1 88.594 	Training Prec@5 99.728 	Validation Loss 0.7998 	Validation Prec@1 77.000 	Validation Prec@5 98.380 

lr: 0.057852875452958925
TRAINING - Epoch: [456][0/391]	Time 0.907 (0.907)	Data 0.342 (0.342)	Loss 0.2159 (0.2159)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [456][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2629 (0.3171)	Prec@1 91.406 (88.784)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [456][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4454 (0.3117)	Prec@1 82.031 (88.930)	Prec@5 100.000 (99.763)
TRAINING - Epoch: [456][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2799 (0.3162)	Prec@1 90.625 (88.863)	Prec@5 100.000 (99.727)
EVALUATING - Epoch: [456][0/79]	Time 0.363 (0.363)	Data 0.340 (0.340)	Loss 0.4961 (0.4961)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:03

 Epoch: 457	Training Loss 0.3214 	Training Prec@1 88.796 	Training Prec@5 99.718 	Validation Loss 0.5562 	Validation Prec@1 82.150 	Validation Prec@5 99.120 

lr: 0.057697083444768024
TRAINING - Epoch: [457][0/391]	Time 0.913 (0.913)	Data 0.351 (0.351)	Loss 0.3347 (0.3347)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [457][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3163 (0.3117)	Prec@1 89.844 (88.908)	Prec@5 99.219 (99.675)
TRAINING - Epoch: [457][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2614 (0.3189)	Prec@1 93.750 (88.787)	Prec@5 100.000 (99.705)
TRAINING - Epoch: [457][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3655 (0.3168)	Prec@1 88.281 (88.876)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [457][0/79]	Time 0.366 (0.366)	Data 0.341 (0.341)	Loss 0.5867 (0.5867)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 458	Training Loss 0.3197 	Training Prec@1 88.748 	Training Prec@5 99.744 	Validation Loss 0.7256 	Validation Prec@1 78.210 	Validation Prec@5 98.810 

lr: 0.05754121485806867
TRAINING - Epoch: [458][0/391]	Time 0.931 (0.931)	Data 0.343 (0.343)	Loss 0.3632 (0.3632)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [458][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4289 (0.3303)	Prec@1 85.938 (88.707)	Prec@5 99.219 (99.714)
TRAINING - Epoch: [458][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2977 (0.3253)	Prec@1 89.844 (88.822)	Prec@5 99.219 (99.724)
TRAINING - Epoch: [458][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3342 (0.3278)	Prec@1 89.062 (88.702)	Prec@5 99.219 (99.691)
EVALUATING - Epoch: [458][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.6520 (0.6520)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:15

 Epoch: 459	Training Loss 0.3285 	Training Prec@1 88.558 	Training Prec@5 99.696 	Validation Loss 0.6683 	Validation Prec@1 80.420 	Validation Prec@5 98.510 

lr: 0.05738527124360196
TRAINING - Epoch: [459][0/391]	Time 0.918 (0.918)	Data 0.349 (0.349)	Loss 0.3802 (0.3802)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [459][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3599 (0.3050)	Prec@1 90.625 (89.240)	Prec@5 98.438 (99.791)
TRAINING - Epoch: [459][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.4480 (0.3147)	Prec@1 85.938 (88.923)	Prec@5 99.219 (99.747)
TRAINING - Epoch: [459][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2956 (0.3196)	Prec@1 87.500 (88.673)	Prec@5 100.000 (99.730)
EVALUATING - Epoch: [459][0/79]	Time 0.336 (0.336)	Data 0.312 (0.312)	Loss 0.5426 (0.5426)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:18

 Epoch: 460	Training Loss 0.3185 	Training Prec@1 88.808 	Training Prec@5 99.740 	Validation Loss 0.5877 	Validation Prec@1 81.210 	Validation Prec@5 99.150 

lr: 0.05722925415285552
TRAINING - Epoch: [460][0/391]	Time 0.903 (0.903)	Data 0.348 (0.348)	Loss 0.3361 (0.3361)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [460][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4817 (0.3040)	Prec@1 82.031 (89.588)	Prec@5 99.219 (99.745)
TRAINING - Epoch: [460][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1710 (0.3108)	Prec@1 92.188 (89.288)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [460][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.3654 (0.3159)	Prec@1 88.281 (89.037)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [460][0/79]	Time 0.373 (0.373)	Data 0.352 (0.352)	Loss 0.3913 (0.3913)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 461	Training Loss 0.3214 	Training Prec@1 88.770 	Training Prec@5 99.728 	Validation Loss 0.5022 	Validation Prec@1 84.260 	Validation Prec@5 99.290 

lr: 0.057073165138047895
TRAINING - Epoch: [461][0/391]	Time 0.922 (0.922)	Data 0.350 (0.350)	Loss 0.3882 (0.3882)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [461][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2264 (0.2988)	Prec@1 92.188 (89.596)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [461][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2476 (0.3003)	Prec@1 92.188 (89.467)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [461][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.5101 (0.3089)	Prec@1 85.156 (89.122)	Prec@5 99.219 (99.748)
EVALUATING - Epoch: [461][0/79]	Time 0.391 (0.391)	Data 0.369 (0.369)	Loss 0.4903 (0.4903)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:30

 Epoch: 462	Training Loss 0.3136 	Training Prec@1 88.954 	Training Prec@5 99.738 	Validation Loss 0.6759 	Validation Prec@1 78.740 	Validation Prec@5 98.370 

lr: 0.05691700575211332
TRAINING - Epoch: [462][0/391]	Time 0.958 (0.958)	Data 0.380 (0.380)	Loss 0.3410 (0.3410)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [462][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2518 (0.3088)	Prec@1 92.188 (89.403)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [462][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.4116 (0.3111)	Prec@1 86.719 (89.179)	Prec@5 99.219 (99.771)
TRAINING - Epoch: [462][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3520 (0.3142)	Prec@1 87.500 (89.042)	Prec@5 100.000 (99.727)
EVALUATING - Epoch: [462][0/79]	Time 0.360 (0.360)	Data 0.336 (0.336)	Loss 0.5534 (0.5534)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:29

 Epoch: 463	Training Loss 0.3195 	Training Prec@1 88.818 	Training Prec@5 99.714 	Validation Loss 0.6429 	Validation Prec@1 80.560 	Validation Prec@5 98.990 

lr: 0.05676077754868607
TRAINING - Epoch: [463][0/391]	Time 0.950 (0.950)	Data 0.362 (0.362)	Loss 0.3247 (0.3247)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [463][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4184 (0.3170)	Prec@1 85.156 (88.977)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [463][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4291 (0.3222)	Prec@1 85.938 (88.907)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [463][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4831 (0.3250)	Prec@1 82.812 (88.795)	Prec@5 100.000 (99.686)
EVALUATING - Epoch: [463][0/79]	Time 0.340 (0.340)	Data 0.319 (0.319)	Loss 0.7414 (0.7414)	Prec@1 75.781 (75.781)	Prec@5 95.312 (95.312)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:30

 Epoch: 464	Training Loss 0.3199 	Training Prec@1 88.982 	Training Prec@5 99.714 	Validation Loss 0.8033 	Validation Prec@1 76.950 	Validation Prec@5 98.390 

lr: 0.05660448208208511
TRAINING - Epoch: [464][0/391]	Time 0.923 (0.923)	Data 0.356 (0.356)	Loss 0.1909 (0.1909)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [464][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3127 (0.3234)	Prec@1 89.062 (88.560)	Prec@5 99.219 (99.652)
TRAINING - Epoch: [464][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2454 (0.3104)	Prec@1 89.844 (89.062)	Prec@5 100.000 (99.705)
TRAINING - Epoch: [464][300/391]	Time 0.066 (0.066)	Data 0.000 (0.001)	Loss 0.3191 (0.3161)	Prec@1 89.844 (88.847)	Prec@5 100.000 (99.707)
EVALUATING - Epoch: [464][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.3749 (0.3749)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 465	Training Loss 0.3175 	Training Prec@1 88.846 	Training Prec@5 99.726 	Validation Loss 0.4688 	Validation Prec@1 84.950 	Validation Prec@5 99.410 

lr: 0.05644812090729861
TRAINING - Epoch: [465][0/391]	Time 0.914 (0.914)	Data 0.350 (0.350)	Loss 0.3554 (0.3554)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [465][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3023 (0.3119)	Prec@1 85.938 (89.295)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [465][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2546 (0.3133)	Prec@1 89.844 (89.261)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [465][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2165 (0.3144)	Prec@1 94.531 (89.200)	Prec@5 100.000 (99.696)
EVALUATING - Epoch: [465][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.4622 (0.4622)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 466	Training Loss 0.3149 	Training Prec@1 89.148 	Training Prec@5 99.698 	Validation Loss 0.5412 	Validation Prec@1 83.150 	Validation Prec@5 99.180 

lr: 0.05629169557996847
TRAINING - Epoch: [466][0/391]	Time 0.913 (0.913)	Data 0.344 (0.344)	Loss 0.3401 (0.3401)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [466][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3895 (0.3164)	Prec@1 90.625 (89.217)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [466][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3540 (0.3093)	Prec@1 86.719 (89.323)	Prec@5 100.000 (99.767)
TRAINING - Epoch: [466][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3085 (0.3093)	Prec@1 89.062 (89.234)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [466][0/79]	Time 0.373 (0.373)	Data 0.343 (0.343)	Loss 0.8050 (0.8050)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 467	Training Loss 0.3139 	Training Prec@1 89.066 	Training Prec@5 99.768 	Validation Loss 0.8998 	Validation Prec@1 75.330 	Validation Prec@5 98.210 

lr: 0.056135207656374864
TRAINING - Epoch: [467][0/391]	Time 0.945 (0.945)	Data 0.383 (0.383)	Loss 0.3207 (0.3207)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [467][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2865 (0.3058)	Prec@1 87.500 (89.287)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [467][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2454 (0.3035)	Prec@1 92.969 (89.350)	Prec@5 99.219 (99.755)
TRAINING - Epoch: [467][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.2756 (0.3039)	Prec@1 90.625 (89.377)	Prec@5 100.000 (99.764)
EVALUATING - Epoch: [467][0/79]	Time 0.392 (0.392)	Data 0.370 (0.370)	Loss 0.4255 (0.4255)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 468	Training Loss 0.3099 	Training Prec@1 89.096 	Training Prec@5 99.756 	Validation Loss 0.5524 	Validation Prec@1 82.430 	Validation Prec@5 99.110 

lr: 0.055978658693420724
TRAINING - Epoch: [468][0/391]	Time 0.931 (0.931)	Data 0.361 (0.361)	Loss 0.3119 (0.3119)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [468][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3310 (0.3058)	Prec@1 89.062 (89.248)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [468][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3238 (0.3035)	Prec@1 90.625 (89.467)	Prec@5 100.000 (99.782)
TRAINING - Epoch: [468][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4317 (0.3084)	Prec@1 85.156 (89.268)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [468][0/79]	Time 0.338 (0.338)	Data 0.317 (0.317)	Loss 0.7994 (0.7994)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 469	Training Loss 0.3101 	Training Prec@1 89.180 	Training Prec@5 99.762 	Validation Loss 0.7947 	Validation Prec@1 77.320 	Validation Prec@5 97.940 

lr: 0.055822050248616265
TRAINING - Epoch: [469][0/391]	Time 0.928 (0.928)	Data 0.362 (0.362)	Loss 0.2728 (0.2728)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [469][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3323 (0.3078)	Prec@1 88.281 (89.209)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [469][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4310 (0.3060)	Prec@1 87.500 (89.335)	Prec@5 100.000 (99.736)
TRAINING - Epoch: [469][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1897 (0.3089)	Prec@1 94.531 (89.314)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [469][0/79]	Time 0.374 (0.374)	Data 0.351 (0.351)	Loss 0.5739 (0.5739)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 470	Training Loss 0.3100 	Training Prec@1 89.272 	Training Prec@5 99.724 	Validation Loss 0.5460 	Validation Prec@1 82.980 	Validation Prec@5 99.240 

lr: 0.05566538388006347
TRAINING - Epoch: [470][0/391]	Time 0.920 (0.920)	Data 0.345 (0.345)	Loss 0.2963 (0.2963)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [470][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.4148 (0.3191)	Prec@1 87.500 (89.078)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [470][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3096 (0.3087)	Prec@1 91.406 (89.362)	Prec@5 99.219 (99.666)
TRAINING - Epoch: [470][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3680 (0.3128)	Prec@1 86.719 (89.177)	Prec@5 100.000 (99.689)
EVALUATING - Epoch: [470][0/79]	Time 0.387 (0.387)	Data 0.366 (0.366)	Loss 0.4273 (0.4273)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 471	Training Loss 0.3127 	Training Prec@1 89.182 	Training Prec@5 99.696 	Validation Loss 0.5108 	Validation Prec@1 84.100 	Validation Prec@5 99.110 

lr: 0.05550866114644066
TRAINING - Epoch: [471][0/391]	Time 0.917 (0.917)	Data 0.351 (0.351)	Loss 0.1810 (0.1810)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [471][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3039 (0.3022)	Prec@1 90.625 (89.310)	Prec@5 99.219 (99.691)
TRAINING - Epoch: [471][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3714 (0.3061)	Prec@1 85.156 (89.214)	Prec@5 100.000 (99.736)
TRAINING - Epoch: [471][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4087 (0.3093)	Prec@1 84.375 (89.197)	Prec@5 99.219 (99.699)
EVALUATING - Epoch: [471][0/79]	Time 0.362 (0.362)	Data 0.341 (0.341)	Loss 0.4877 (0.4877)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 472	Training Loss 0.3115 	Training Prec@1 89.182 	Training Prec@5 99.700 	Validation Loss 0.5864 	Validation Prec@1 82.240 	Validation Prec@5 99.240 

lr: 0.05535188360698685
TRAINING - Epoch: [472][0/391]	Time 0.943 (0.943)	Data 0.347 (0.347)	Loss 0.3474 (0.3474)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [472][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1216 (0.2996)	Prec@1 96.094 (89.472)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [472][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4379 (0.3044)	Prec@1 85.938 (89.412)	Prec@5 99.219 (99.755)
TRAINING - Epoch: [472][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3300 (0.3123)	Prec@1 89.062 (89.086)	Prec@5 100.000 (99.743)
EVALUATING - Epoch: [472][0/79]	Time 0.381 (0.381)	Data 0.360 (0.360)	Loss 0.5143 (0.5143)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:18

 Epoch: 473	Training Loss 0.3117 	Training Prec@1 89.104 	Training Prec@5 99.760 	Validation Loss 0.6636 	Validation Prec@1 79.570 	Validation Prec@5 99.060 

lr: 0.05519505282148642
TRAINING - Epoch: [473][0/391]	Time 0.922 (0.922)	Data 0.349 (0.349)	Loss 0.2415 (0.2415)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [473][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2767 (0.3002)	Prec@1 88.281 (89.279)	Prec@5 100.000 (99.714)
TRAINING - Epoch: [473][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3482 (0.3156)	Prec@1 86.719 (88.787)	Prec@5 100.000 (99.736)
TRAINING - Epoch: [473][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.4148 (0.3153)	Prec@1 86.719 (88.850)	Prec@5 100.000 (99.746)
EVALUATING - Epoch: [473][0/79]	Time 0.355 (0.355)	Data 0.333 (0.333)	Loss 0.5344 (0.5344)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:01

 Epoch: 474	Training Loss 0.3200 	Training Prec@1 88.722 	Training Prec@5 99.730 	Validation Loss 0.6222 	Validation Prec@1 81.090 	Validation Prec@5 98.760 

lr: 0.0550381703502534
TRAINING - Epoch: [474][0/391]	Time 0.909 (0.909)	Data 0.356 (0.356)	Loss 0.2343 (0.2343)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [474][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3373 (0.3099)	Prec@1 89.062 (89.403)	Prec@5 98.438 (99.683)
TRAINING - Epoch: [474][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3670 (0.3130)	Prec@1 87.500 (89.129)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [474][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3112 (0.3199)	Prec@1 89.844 (88.842)	Prec@5 100.000 (99.704)
EVALUATING - Epoch: [474][0/79]	Time 0.377 (0.377)	Data 0.356 (0.356)	Loss 0.5985 (0.5985)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:28

 Epoch: 475	Training Loss 0.3187 	Training Prec@1 88.906 	Training Prec@5 99.706 	Validation Loss 0.6548 	Validation Prec@1 80.230 	Validation Prec@5 98.810 

lr: 0.054881237754116116
TRAINING - Epoch: [475][0/391]	Time 0.903 (0.903)	Data 0.344 (0.344)	Loss 0.4008 (0.4008)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [475][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2595 (0.2971)	Prec@1 90.625 (89.929)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [475][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3307 (0.3094)	Prec@1 88.281 (89.463)	Prec@5 100.000 (99.740)
TRAINING - Epoch: [475][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4504 (0.3217)	Prec@1 86.719 (89.037)	Prec@5 100.000 (99.702)
EVALUATING - Epoch: [475][0/79]	Time 0.366 (0.366)	Data 0.347 (0.347)	Loss 0.6070 (0.6070)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 476	Training Loss 0.3266 	Training Prec@1 88.762 	Training Prec@5 99.714 	Validation Loss 0.7660 	Validation Prec@1 77.880 	Validation Prec@5 98.570 

lr: 0.054724256594401555
TRAINING - Epoch: [476][0/391]	Time 0.939 (0.939)	Data 0.368 (0.368)	Loss 0.3086 (0.3086)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [476][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3063 (0.3271)	Prec@1 91.406 (88.521)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [476][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2959 (0.3193)	Prec@1 86.719 (88.996)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [476][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1866 (0.3199)	Prec@1 92.969 (88.912)	Prec@5 100.000 (99.702)
EVALUATING - Epoch: [476][0/79]	Time 0.343 (0.343)	Data 0.323 (0.323)	Loss 0.4722 (0.4722)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:35

 Epoch: 477	Training Loss 0.3181 	Training Prec@1 88.932 	Training Prec@5 99.734 	Validation Loss 0.5923 	Validation Prec@1 81.670 	Validation Prec@5 99.110 

lr: 0.05456722843291987
TRAINING - Epoch: [477][0/391]	Time 0.938 (0.938)	Data 0.376 (0.376)	Loss 0.2770 (0.2770)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [477][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1867 (0.2901)	Prec@1 92.188 (89.821)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [477][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4964 (0.2939)	Prec@1 84.375 (89.681)	Prec@5 99.219 (99.798)
TRAINING - Epoch: [477][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2203 (0.3011)	Prec@1 92.188 (89.351)	Prec@5 100.000 (99.785)
EVALUATING - Epoch: [477][0/79]	Time 0.359 (0.359)	Data 0.336 (0.336)	Loss 0.5722 (0.5722)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:43

 Epoch: 478	Training Loss 0.3032 	Training Prec@1 89.344 	Training Prec@5 99.760 	Validation Loss 0.6024 	Validation Prec@1 81.820 	Validation Prec@5 99.110 

lr: 0.05441015483194882
TRAINING - Epoch: [478][0/391]	Time 0.935 (0.935)	Data 0.357 (0.357)	Loss 0.2995 (0.2995)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [478][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2912 (0.2972)	Prec@1 88.281 (89.697)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [478][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2090 (0.3001)	Prec@1 92.188 (89.548)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [478][300/391]	Time 0.066 (0.066)	Data 0.000 (0.001)	Loss 0.3714 (0.2991)	Prec@1 88.281 (89.522)	Prec@5 99.219 (99.759)
EVALUATING - Epoch: [478][0/79]	Time 0.353 (0.353)	Data 0.327 (0.327)	Loss 0.7779 (0.7779)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:38

 Epoch: 479	Training Loss 0.3053 	Training Prec@1 89.344 	Training Prec@5 99.764 	Validation Loss 0.8057 	Validation Prec@1 77.690 	Validation Prec@5 97.980 

lr: 0.05425303735421826
TRAINING - Epoch: [479][0/391]	Time 0.976 (0.976)	Data 0.382 (0.382)	Loss 0.3361 (0.3361)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [479][100/391]	Time 0.066 (0.073)	Data 0.000 (0.004)	Loss 0.2598 (0.2953)	Prec@1 92.188 (89.975)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [479][200/391]	Time 0.066 (0.069)	Data 0.000 (0.002)	Loss 0.2249 (0.2941)	Prec@1 91.406 (89.797)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [479][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2848 (0.2967)	Prec@1 90.625 (89.644)	Prec@5 100.000 (99.759)
EVALUATING - Epoch: [479][0/79]	Time 0.340 (0.340)	Data 0.318 (0.318)	Loss 0.5871 (0.5871)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:27:21

 Epoch: 480	Training Loss 0.3013 	Training Prec@1 89.538 	Training Prec@5 99.766 	Validation Loss 0.6704 	Validation Prec@1 79.820 	Validation Prec@5 98.870 

lr: 0.054095877562894606
TRAINING - Epoch: [480][0/391]	Time 0.958 (0.958)	Data 0.380 (0.380)	Loss 0.2331 (0.2331)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [480][100/391]	Time 0.066 (0.072)	Data 0.000 (0.004)	Loss 0.2433 (0.3076)	Prec@1 92.969 (89.225)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [480][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.2426 (0.2924)	Prec@1 91.406 (89.750)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [480][300/391]	Time 0.067 (0.067)	Data 0.000 (0.002)	Loss 0.4531 (0.2997)	Prec@1 84.375 (89.584)	Prec@5 100.000 (99.777)
EVALUATING - Epoch: [480][0/79]	Time 0.379 (0.379)	Data 0.358 (0.358)	Loss 0.6156 (0.6156)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:52

 Epoch: 481	Training Loss 0.3063 	Training Prec@1 89.406 	Training Prec@5 99.766 	Validation Loss 0.6563 	Validation Prec@1 80.980 	Validation Prec@5 98.820 

lr: 0.0539386770215652
TRAINING - Epoch: [481][0/391]	Time 0.977 (0.977)	Data 0.370 (0.370)	Loss 0.1940 (0.1940)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [481][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.2487 (0.2911)	Prec@1 92.969 (89.519)	Prec@5 99.219 (99.791)
TRAINING - Epoch: [481][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.3376 (0.2979)	Prec@1 89.844 (89.482)	Prec@5 100.000 (99.724)
TRAINING - Epoch: [481][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2492 (0.3079)	Prec@1 92.188 (89.109)	Prec@5 100.000 (99.735)
EVALUATING - Epoch: [481][0/79]	Time 0.360 (0.360)	Data 0.337 (0.337)	Loss 0.5455 (0.5455)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:10

 Epoch: 482	Training Loss 0.3078 	Training Prec@1 89.130 	Training Prec@5 99.718 	Validation Loss 0.5775 	Validation Prec@1 81.770 	Validation Prec@5 99.020 

lr: 0.05378143729422283
TRAINING - Epoch: [482][0/391]	Time 0.997 (0.997)	Data 0.391 (0.391)	Loss 0.2919 (0.2919)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [482][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.2591 (0.2917)	Prec@1 91.406 (89.875)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [482][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.3135 (0.2945)	Prec@1 88.281 (89.708)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [482][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2846 (0.2957)	Prec@1 89.062 (89.683)	Prec@5 100.000 (99.746)
EVALUATING - Epoch: [482][0/79]	Time 0.368 (0.368)	Data 0.348 (0.348)	Loss 0.5741 (0.5741)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:58

 Epoch: 483	Training Loss 0.2971 	Training Prec@1 89.616 	Training Prec@5 99.756 	Validation Loss 0.6956 	Validation Prec@1 79.530 	Validation Prec@5 98.720 

lr: 0.05362415994525012
TRAINING - Epoch: [483][0/391]	Time 0.929 (0.929)	Data 0.350 (0.350)	Loss 0.3410 (0.3410)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [483][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1943 (0.2907)	Prec@1 92.188 (89.666)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [483][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2440 (0.3059)	Prec@1 93.750 (89.370)	Prec@5 100.000 (99.817)
TRAINING - Epoch: [483][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1609 (0.3017)	Prec@1 93.750 (89.499)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [483][0/79]	Time 0.355 (0.355)	Data 0.333 (0.333)	Loss 0.6286 (0.6286)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:23

 Epoch: 484	Training Loss 0.3040 	Training Prec@1 89.392 	Training Prec@5 99.804 	Validation Loss 0.6452 	Validation Prec@1 80.250 	Validation Prec@5 98.330 

lr: 0.053466846539404075
TRAINING - Epoch: [484][0/391]	Time 0.945 (0.945)	Data 0.353 (0.353)	Loss 0.2078 (0.2078)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [484][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.3551 (0.2801)	Prec@1 88.281 (89.929)	Prec@5 98.438 (99.752)
TRAINING - Epoch: [484][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2357 (0.2907)	Prec@1 91.406 (89.747)	Prec@5 100.000 (99.763)
TRAINING - Epoch: [484][300/391]	Time 0.065 (0.067)	Data 0.000 (0.001)	Loss 0.2793 (0.2946)	Prec@1 89.844 (89.636)	Prec@5 100.000 (99.751)
EVALUATING - Epoch: [484][0/79]	Time 0.353 (0.353)	Data 0.331 (0.331)	Loss 0.2489 (0.2489)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:35

 Epoch: 485	Training Loss 0.2988 	Training Prec@1 89.478 	Training Prec@5 99.744 	Validation Loss 0.4819 	Validation Prec@1 84.260 	Validation Prec@5 99.310 

lr: 0.05330949864180032
TRAINING - Epoch: [485][0/391]	Time 0.956 (0.956)	Data 0.364 (0.364)	Loss 0.1776 (0.1776)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [485][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.4283 (0.2836)	Prec@1 86.719 (90.014)	Prec@5 99.219 (99.799)
TRAINING - Epoch: [485][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2514 (0.2921)	Prec@1 92.969 (89.677)	Prec@5 99.219 (99.794)
TRAINING - Epoch: [485][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.3860 (0.2969)	Prec@1 83.594 (89.597)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [485][0/79]	Time 0.387 (0.387)	Data 0.364 (0.364)	Loss 0.6288 (0.6288)	Prec@1 75.781 (75.781)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:03

 Epoch: 486	Training Loss 0.2972 	Training Prec@1 89.612 	Training Prec@5 99.796 	Validation Loss 0.5807 	Validation Prec@1 81.650 	Validation Prec@5 98.990 

lr: 0.05315211781789773
TRAINING - Epoch: [486][0/391]	Time 0.963 (0.963)	Data 0.351 (0.351)	Loss 0.1760 (0.1760)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [486][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3224 (0.2931)	Prec@1 89.844 (89.674)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [486][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2340 (0.2945)	Prec@1 89.844 (89.463)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [486][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.3375 (0.2961)	Prec@1 86.719 (89.418)	Prec@5 98.438 (99.790)
EVALUATING - Epoch: [486][0/79]	Time 0.355 (0.355)	Data 0.331 (0.331)	Loss 0.6320 (0.6320)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:34

 Epoch: 487	Training Loss 0.3007 	Training Prec@1 89.254 	Training Prec@5 99.754 	Validation Loss 0.6589 	Validation Prec@1 81.220 	Validation Prec@5 98.940 

lr: 0.0529947056334827
TRAINING - Epoch: [487][0/391]	Time 0.927 (0.927)	Data 0.347 (0.347)	Loss 0.3107 (0.3107)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [487][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2712 (0.2845)	Prec@1 92.969 (89.991)	Prec@5 99.219 (99.845)
TRAINING - Epoch: [487][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2713 (0.2942)	Prec@1 89.062 (89.583)	Prec@5 100.000 (99.790)
TRAINING - Epoch: [487][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1949 (0.2955)	Prec@1 94.531 (89.613)	Prec@5 100.000 (99.785)
EVALUATING - Epoch: [487][0/79]	Time 0.384 (0.384)	Data 0.361 (0.361)	Loss 0.3641 (0.3641)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:23

 Epoch: 488	Training Loss 0.3009 	Training Prec@1 89.440 	Training Prec@5 99.768 	Validation Loss 0.5343 	Validation Prec@1 83.410 	Validation Prec@5 98.990 

lr: 0.052837263654653695
TRAINING - Epoch: [488][0/391]	Time 0.968 (0.968)	Data 0.379 (0.379)	Loss 0.2581 (0.2581)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [488][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3095 (0.2810)	Prec@1 88.281 (90.184)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [488][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3762 (0.2895)	Prec@1 87.500 (89.937)	Prec@5 100.000 (99.747)
TRAINING - Epoch: [488][300/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.3231 (0.2932)	Prec@1 88.281 (89.836)	Prec@5 100.000 (99.740)
EVALUATING - Epoch: [488][0/79]	Time 0.362 (0.362)	Data 0.343 (0.343)	Loss 0.5451 (0.5451)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:34

 Epoch: 489	Training Loss 0.2978 	Training Prec@1 89.668 	Training Prec@5 99.742 	Validation Loss 0.5981 	Validation Prec@1 82.100 	Validation Prec@5 99.260 

lr: 0.052679793447805524
TRAINING - Epoch: [489][0/391]	Time 0.942 (0.942)	Data 0.361 (0.361)	Loss 0.2426 (0.2426)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [489][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1900 (0.2846)	Prec@1 92.969 (89.929)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [489][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2509 (0.2936)	Prec@1 92.188 (89.828)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [489][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2551 (0.2953)	Prec@1 89.844 (89.696)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [489][0/79]	Time 0.388 (0.388)	Data 0.368 (0.368)	Loss 0.3684 (0.3684)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:53

 Epoch: 490	Training Loss 0.2941 	Training Prec@1 89.694 	Training Prec@5 99.792 	Validation Loss 0.5692 	Validation Prec@1 82.920 	Validation Prec@5 99.060 

lr: 0.052522296579613915
TRAINING - Epoch: [490][0/391]	Time 0.940 (0.940)	Data 0.356 (0.356)	Loss 0.2593 (0.2593)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [490][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3003 (0.2860)	Prec@1 87.500 (89.998)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [490][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5097 (0.2818)	Prec@1 84.375 (90.131)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [490][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.3222 (0.2889)	Prec@1 89.062 (89.883)	Prec@5 100.000 (99.787)
EVALUATING - Epoch: [490][0/79]	Time 0.390 (0.390)	Data 0.365 (0.365)	Loss 0.5329 (0.5329)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:23

 Epoch: 491	Training Loss 0.2919 	Training Prec@1 89.786 	Training Prec@5 99.784 	Validation Loss 0.6883 	Validation Prec@1 79.750 	Validation Prec@5 98.820 

lr: 0.05236477461701983
TRAINING - Epoch: [491][0/391]	Time 0.929 (0.929)	Data 0.346 (0.346)	Loss 0.2277 (0.2277)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [491][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3156 (0.2841)	Prec@1 85.938 (90.169)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [491][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2952 (0.2855)	Prec@1 89.844 (89.999)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [491][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3381 (0.2893)	Prec@1 91.406 (89.823)	Prec@5 99.219 (99.787)
EVALUATING - Epoch: [491][0/79]	Time 0.392 (0.392)	Data 0.368 (0.368)	Loss 0.4400 (0.4400)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:40

 Epoch: 492	Training Loss 0.2950 	Training Prec@1 89.622 	Training Prec@5 99.788 	Validation Loss 0.5981 	Validation Prec@1 81.330 	Validation Prec@5 99.170 

lr: 0.05220722912721384
TRAINING - Epoch: [492][0/391]	Time 0.969 (0.969)	Data 0.353 (0.353)	Loss 0.2445 (0.2445)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [492][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.2444 (0.2844)	Prec@1 92.188 (89.844)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [492][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2562 (0.2922)	Prec@1 87.500 (89.591)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [492][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.3528 (0.2975)	Prec@1 86.719 (89.537)	Prec@5 100.000 (99.756)
EVALUATING - Epoch: [492][0/79]	Time 0.365 (0.365)	Data 0.341 (0.341)	Loss 0.4565 (0.4565)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:14

 Epoch: 493	Training Loss 0.3036 	Training Prec@1 89.312 	Training Prec@5 99.756 	Validation Loss 0.6880 	Validation Prec@1 80.230 	Validation Prec@5 98.750 

lr: 0.05204966167762067
TRAINING - Epoch: [493][0/391]	Time 0.982 (0.982)	Data 0.353 (0.353)	Loss 0.2633 (0.2633)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [493][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1380 (0.3049)	Prec@1 95.312 (89.310)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [493][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3745 (0.3005)	Prec@1 87.500 (89.432)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [493][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.3194 (0.3016)	Prec@1 90.625 (89.486)	Prec@5 100.000 (99.777)
EVALUATING - Epoch: [493][0/79]	Time 0.356 (0.356)	Data 0.336 (0.336)	Loss 0.4186 (0.4186)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:28

 Epoch: 494	Training Loss 0.2995 	Training Prec@1 89.570 	Training Prec@5 99.778 	Validation Loss 0.5214 	Validation Prec@1 83.760 	Validation Prec@5 98.960 

lr: 0.0518920738358835
TRAINING - Epoch: [494][0/391]	Time 0.970 (0.970)	Data 0.379 (0.379)	Loss 0.2132 (0.2132)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [494][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3125 (0.2896)	Prec@1 89.844 (89.805)	Prec@5 99.219 (99.760)
TRAINING - Epoch: [494][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3600 (0.2974)	Prec@1 90.625 (89.560)	Prec@5 99.219 (99.778)
TRAINING - Epoch: [494][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1928 (0.3010)	Prec@1 91.406 (89.410)	Prec@5 100.000 (99.759)
EVALUATING - Epoch: [494][0/79]	Time 0.377 (0.377)	Data 0.352 (0.352)	Loss 0.4467 (0.4467)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:56

 Epoch: 495	Training Loss 0.3004 	Training Prec@1 89.464 	Training Prec@5 99.774 	Validation Loss 0.6001 	Validation Prec@1 82.020 	Validation Prec@5 98.680 

lr: 0.05173446716984834
TRAINING - Epoch: [495][0/391]	Time 0.958 (0.958)	Data 0.372 (0.372)	Loss 0.4382 (0.4382)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [495][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2264 (0.2931)	Prec@1 92.188 (89.735)	Prec@5 99.219 (99.706)
TRAINING - Epoch: [495][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3013 (0.2961)	Prec@1 88.281 (89.739)	Prec@5 99.219 (99.712)
TRAINING - Epoch: [495][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.4009 (0.3000)	Prec@1 85.938 (89.569)	Prec@5 98.438 (99.717)
EVALUATING - Epoch: [495][0/79]	Time 0.388 (0.388)	Data 0.367 (0.367)	Loss 0.3622 (0.3622)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:13

 Epoch: 496	Training Loss 0.2999 	Training Prec@1 89.578 	Training Prec@5 99.726 	Validation Loss 0.5505 	Validation Prec@1 83.250 	Validation Prec@5 99.140 

lr: 0.05157684324754854
TRAINING - Epoch: [496][0/391]	Time 0.960 (0.960)	Data 0.368 (0.368)	Loss 0.2335 (0.2335)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [496][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2183 (0.2974)	Prec@1 92.969 (89.418)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [496][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2834 (0.3000)	Prec@1 91.406 (89.377)	Prec@5 99.219 (99.740)
TRAINING - Epoch: [496][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2844 (0.2949)	Prec@1 91.406 (89.670)	Prec@5 100.000 (99.779)
EVALUATING - Epoch: [496][0/79]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.5233 (0.5233)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:29

 Epoch: 497	Training Loss 0.2990 	Training Prec@1 89.518 	Training Prec@5 99.766 	Validation Loss 0.5440 	Validation Prec@1 83.410 	Validation Prec@5 99.220 

lr: 0.051419203637189145
TRAINING - Epoch: [497][0/391]	Time 0.922 (0.922)	Data 0.351 (0.351)	Loss 0.2899 (0.2899)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [497][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2674 (0.2820)	Prec@1 91.406 (89.968)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [497][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2926 (0.2938)	Prec@1 89.062 (89.626)	Prec@5 99.219 (99.806)
TRAINING - Epoch: [497][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.2833 (0.2944)	Prec@1 91.406 (89.636)	Prec@5 100.000 (99.800)
EVALUATING - Epoch: [497][0/79]	Time 0.379 (0.379)	Data 0.356 (0.356)	Loss 0.5358 (0.5358)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:12

 Epoch: 498	Training Loss 0.2976 	Training Prec@1 89.490 	Training Prec@5 99.794 	Validation Loss 0.6092 	Validation Prec@1 80.970 	Validation Prec@5 98.870 

lr: 0.0512615499071312
TRAINING - Epoch: [498][0/391]	Time 0.977 (0.977)	Data 0.381 (0.381)	Loss 0.2864 (0.2864)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [498][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3715 (0.2922)	Prec@1 84.375 (89.751)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [498][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2474 (0.3013)	Prec@1 92.188 (89.579)	Prec@5 99.219 (99.743)
TRAINING - Epoch: [498][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1968 (0.3012)	Prec@1 92.969 (89.623)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [498][0/79]	Time 0.359 (0.359)	Data 0.339 (0.339)	Loss 0.5126 (0.5126)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:32

 Epoch: 499	Training Loss 0.3040 	Training Prec@1 89.550 	Training Prec@5 99.742 	Validation Loss 0.5374 	Validation Prec@1 83.260 	Validation Prec@5 99.120 

lr: 0.05110388362587631
TRAINING - Epoch: [499][0/391]	Time 0.973 (0.973)	Data 0.377 (0.377)	Loss 0.2294 (0.2294)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [499][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3055 (0.2927)	Prec@1 87.500 (89.867)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [499][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2923 (0.2970)	Prec@1 89.062 (89.657)	Prec@5 99.219 (99.790)
TRAINING - Epoch: [499][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2712 (0.3001)	Prec@1 89.844 (89.537)	Prec@5 99.219 (99.787)
EVALUATING - Epoch: [499][0/79]	Time 0.388 (0.388)	Data 0.366 (0.366)	Loss 0.6137 (0.6137)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:40

 Epoch: 500	Training Loss 0.3023 	Training Prec@1 89.498 	Training Prec@5 99.776 	Validation Loss 0.6712 	Validation Prec@1 79.970 	Validation Prec@5 98.950 

lr: 0.05094620636205093
TRAINING - Epoch: [500][0/391]	Time 0.960 (0.960)	Data 0.373 (0.373)	Loss 0.2868 (0.2868)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [500][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2621 (0.2886)	Prec@1 89.844 (89.805)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [500][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1898 (0.2889)	Prec@1 94.531 (89.875)	Prec@5 100.000 (99.778)
TRAINING - Epoch: [500][300/391]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.2844 (0.2961)	Prec@1 88.281 (89.691)	Prec@5 100.000 (99.769)
EVALUATING - Epoch: [500][0/79]	Time 0.371 (0.371)	Data 0.347 (0.347)	Loss 0.4529 (0.4529)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:33

 Epoch: 501	Training Loss 0.2999 	Training Prec@1 89.568 	Training Prec@5 99.758 	Validation Loss 0.5619 	Validation Prec@1 82.400 	Validation Prec@5 99.130 

lr: 0.05078851968439075
TRAINING - Epoch: [501][0/391]	Time 0.972 (0.972)	Data 0.348 (0.348)	Loss 0.3334 (0.3334)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [501][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.3122 (0.3044)	Prec@1 92.188 (89.519)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [501][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1333 (0.3074)	Prec@1 95.312 (89.416)	Prec@5 100.000 (99.778)
TRAINING - Epoch: [501][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.2463 (0.3072)	Prec@1 92.969 (89.330)	Prec@5 100.000 (99.766)
EVALUATING - Epoch: [501][0/79]	Time 0.356 (0.356)	Data 0.334 (0.334)	Loss 0.6777 (0.6777)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:58

 Epoch: 502	Training Loss 0.3047 	Training Prec@1 89.476 	Training Prec@5 99.754 	Validation Loss 0.6008 	Validation Prec@1 81.890 	Validation Prec@5 98.820 

lr: 0.05063082516172517
TRAINING - Epoch: [502][0/391]	Time 0.985 (0.985)	Data 0.371 (0.371)	Loss 0.4164 (0.4164)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [502][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.3801 (0.2915)	Prec@1 89.844 (89.488)	Prec@5 98.438 (99.783)
TRAINING - Epoch: [502][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2530 (0.2931)	Prec@1 89.844 (89.603)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [502][300/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.3121 (0.2938)	Prec@1 92.969 (89.735)	Prec@5 99.219 (99.759)
EVALUATING - Epoch: [502][0/79]	Time 0.364 (0.364)	Data 0.339 (0.339)	Loss 0.5703 (0.5703)	Prec@1 84.375 (84.375)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:56

 Epoch: 503	Training Loss 0.2975 	Training Prec@1 89.618 	Training Prec@5 99.760 	Validation Loss 0.6278 	Validation Prec@1 81.070 	Validation Prec@5 98.860 

lr: 0.050473124362961565
TRAINING - Epoch: [503][0/391]	Time 0.938 (0.938)	Data 0.345 (0.345)	Loss 0.3021 (0.3021)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [503][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2308 (0.2736)	Prec@1 89.844 (90.084)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [503][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2527 (0.2828)	Prec@1 90.625 (89.848)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [503][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.3254 (0.2853)	Prec@1 89.062 (89.849)	Prec@5 100.000 (99.792)
EVALUATING - Epoch: [503][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.3995 (0.3995)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:53

 Epoch: 504	Training Loss 0.2872 	Training Prec@1 89.772 	Training Prec@5 99.802 	Validation Loss 0.6241 	Validation Prec@1 81.620 	Validation Prec@5 99.050 

lr: 0.05031541885706985
TRAINING - Epoch: [504][0/391]	Time 0.947 (0.947)	Data 0.356 (0.356)	Loss 0.2765 (0.2765)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [504][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.4412 (0.3004)	Prec@1 86.719 (89.697)	Prec@5 97.656 (99.752)
TRAINING - Epoch: [504][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.2908 (0.3028)	Prec@1 92.188 (89.599)	Prec@5 100.000 (99.743)
TRAINING - Epoch: [504][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.4559 (0.3072)	Prec@1 86.719 (89.439)	Prec@5 100.000 (99.735)
EVALUATING - Epoch: [504][0/79]	Time 0.370 (0.370)	Data 0.345 (0.345)	Loss 0.9357 (0.9357)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:04

 Epoch: 505	Training Loss 0.3054 	Training Prec@1 89.426 	Training Prec@5 99.752 	Validation Loss 0.8487 	Validation Prec@1 76.590 	Validation Prec@5 98.130 

lr: 0.050157710213066684
TRAINING - Epoch: [505][0/391]	Time 0.940 (0.940)	Data 0.360 (0.360)	Loss 0.3373 (0.3373)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [505][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2667 (0.2798)	Prec@1 90.625 (90.107)	Prec@5 99.219 (99.783)
TRAINING - Epoch: [505][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3602 (0.2810)	Prec@1 85.156 (90.213)	Prec@5 99.219 (99.794)
TRAINING - Epoch: [505][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2390 (0.2862)	Prec@1 92.188 (89.974)	Prec@5 100.000 (99.785)
EVALUATING - Epoch: [505][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.3852 (0.3852)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:25

 Epoch: 506	Training Loss 0.2875 	Training Prec@1 89.972 	Training Prec@5 99.790 	Validation Loss 0.6352 	Validation Prec@1 80.850 	Validation Prec@5 98.950 

lr: 0.04999999999999999
TRAINING - Epoch: [506][0/391]	Time 0.967 (0.967)	Data 0.380 (0.380)	Loss 0.3003 (0.3003)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [506][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.2597 (0.2802)	Prec@1 89.062 (90.053)	Prec@5 100.000 (99.745)
TRAINING - Epoch: [506][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2008 (0.2774)	Prec@1 92.188 (90.143)	Prec@5 100.000 (99.782)
TRAINING - Epoch: [506][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2938 (0.2833)	Prec@1 87.500 (89.903)	Prec@5 100.000 (99.761)
EVALUATING - Epoch: [506][0/79]	Time 0.386 (0.386)	Data 0.361 (0.361)	Loss 0.6094 (0.6094)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:04

 Epoch: 507	Training Loss 0.2883 	Training Prec@1 89.748 	Training Prec@5 99.780 	Validation Loss 0.7376 	Validation Prec@1 79.810 	Validation Prec@5 98.400 

lr: 0.0498422897869333
TRAINING - Epoch: [507][0/391]	Time 0.956 (0.956)	Data 0.348 (0.348)	Loss 0.2750 (0.2750)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [507][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2522 (0.2895)	Prec@1 90.625 (89.666)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [507][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3398 (0.3014)	Prec@1 86.719 (89.335)	Prec@5 99.219 (99.810)
TRAINING - Epoch: [507][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.4195 (0.2946)	Prec@1 85.156 (89.563)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [507][0/79]	Time 0.391 (0.391)	Data 0.368 (0.368)	Loss 0.5740 (0.5740)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:47

 Epoch: 508	Training Loss 0.2917 	Training Prec@1 89.686 	Training Prec@5 99.798 	Validation Loss 0.6215 	Validation Prec@1 81.180 	Validation Prec@5 98.770 

lr: 0.04968458114293013
TRAINING - Epoch: [508][0/391]	Time 0.967 (0.967)	Data 0.343 (0.343)	Loss 0.2244 (0.2244)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [508][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.2929 (0.2876)	Prec@1 90.625 (90.014)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [508][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2971 (0.2862)	Prec@1 89.062 (89.937)	Prec@5 99.219 (99.829)
TRAINING - Epoch: [508][300/391]	Time 0.062 (0.067)	Data 0.000 (0.001)	Loss 0.2809 (0.2916)	Prec@1 90.625 (89.820)	Prec@5 100.000 (99.829)
EVALUATING - Epoch: [508][0/79]	Time 0.376 (0.376)	Data 0.354 (0.354)	Loss 0.7975 (0.7975)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:48

 Epoch: 509	Training Loss 0.2928 	Training Prec@1 89.790 	Training Prec@5 99.816 	Validation Loss 0.6612 	Validation Prec@1 80.500 	Validation Prec@5 98.500 

lr: 0.049526875637038406
TRAINING - Epoch: [509][0/391]	Time 0.974 (0.974)	Data 0.364 (0.364)	Loss 0.2839 (0.2839)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [509][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.2366 (0.2905)	Prec@1 91.406 (89.550)	Prec@5 100.000 (99.745)
TRAINING - Epoch: [509][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.3366 (0.2947)	Prec@1 86.719 (89.712)	Prec@5 100.000 (99.751)
TRAINING - Epoch: [509][300/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.1826 (0.3012)	Prec@1 93.750 (89.602)	Prec@5 100.000 (99.759)
EVALUATING - Epoch: [509][0/79]	Time 0.388 (0.388)	Data 0.363 (0.363)	Loss 0.7173 (0.7173)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:47

 Epoch: 510	Training Loss 0.3029 	Training Prec@1 89.556 	Training Prec@5 99.748 	Validation Loss 0.7882 	Validation Prec@1 78.420 	Validation Prec@5 98.200 

lr: 0.049369174838274806
TRAINING - Epoch: [510][0/391]	Time 0.932 (0.932)	Data 0.349 (0.349)	Loss 0.2837 (0.2837)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [510][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.1986 (0.2867)	Prec@1 93.750 (89.836)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [510][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2026 (0.2946)	Prec@1 92.969 (89.646)	Prec@5 100.000 (99.790)
TRAINING - Epoch: [510][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.2018 (0.2999)	Prec@1 91.406 (89.543)	Prec@5 100.000 (99.769)
EVALUATING - Epoch: [510][0/79]	Time 0.339 (0.339)	Data 0.319 (0.319)	Loss 0.6463 (0.6463)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:58

 Epoch: 511	Training Loss 0.3018 	Training Prec@1 89.432 	Training Prec@5 99.770 	Validation Loss 0.7413 	Validation Prec@1 78.350 	Validation Prec@5 98.820 

lr: 0.049211480315609214
TRAINING - Epoch: [511][0/391]	Time 0.945 (0.945)	Data 0.356 (0.356)	Loss 0.3328 (0.3328)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [511][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2212 (0.2792)	Prec@1 95.312 (90.091)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [511][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2957 (0.2855)	Prec@1 90.625 (90.131)	Prec@5 100.000 (99.786)
TRAINING - Epoch: [511][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2340 (0.2887)	Prec@1 91.406 (89.937)	Prec@5 98.438 (99.774)
EVALUATING - Epoch: [511][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.5657 (0.5657)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:04

 Epoch: 512	Training Loss 0.2918 	Training Prec@1 89.770 	Training Prec@5 99.790 	Validation Loss 0.5609 	Validation Prec@1 82.660 	Validation Prec@5 99.080 

lr: 0.04905379363794904
TRAINING - Epoch: [512][0/391]	Time 0.990 (0.990)	Data 0.397 (0.397)	Loss 0.3277 (0.3277)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [512][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.3148 (0.2967)	Prec@1 89.844 (89.821)	Prec@5 99.219 (99.776)
TRAINING - Epoch: [512][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3016 (0.2993)	Prec@1 89.844 (89.669)	Prec@5 100.000 (99.763)
TRAINING - Epoch: [512][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2522 (0.2963)	Prec@1 92.188 (89.735)	Prec@5 100.000 (99.766)
EVALUATING - Epoch: [512][0/79]	Time 0.354 (0.354)	Data 0.334 (0.334)	Loss 0.4495 (0.4495)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:01

 Epoch: 513	Training Loss 0.2981 	Training Prec@1 89.630 	Training Prec@5 99.774 	Validation Loss 0.5855 	Validation Prec@1 82.470 	Validation Prec@5 99.220 

lr: 0.04889611637412365
TRAINING - Epoch: [513][0/391]	Time 0.947 (0.947)	Data 0.356 (0.356)	Loss 0.3124 (0.3124)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [513][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2736 (0.2656)	Prec@1 91.406 (90.617)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [513][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2061 (0.2753)	Prec@1 92.969 (90.361)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [513][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.4087 (0.2824)	Prec@1 82.031 (90.085)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [513][0/79]	Time 0.356 (0.356)	Data 0.332 (0.332)	Loss 0.4972 (0.4972)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:01

 Epoch: 514	Training Loss 0.2869 	Training Prec@1 89.932 	Training Prec@5 99.818 	Validation Loss 0.5622 	Validation Prec@1 82.800 	Validation Prec@5 98.970 

lr: 0.048738450092868764
TRAINING - Epoch: [514][0/391]	Time 0.971 (0.971)	Data 0.349 (0.349)	Loss 0.2791 (0.2791)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [514][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2234 (0.2810)	Prec@1 92.969 (90.107)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [514][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3404 (0.2864)	Prec@1 89.844 (89.964)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [514][300/391]	Time 0.065 (0.067)	Data 0.000 (0.001)	Loss 0.3119 (0.2935)	Prec@1 87.500 (89.691)	Prec@5 100.000 (99.779)
EVALUATING - Epoch: [514][0/79]	Time 0.383 (0.383)	Data 0.361 (0.361)	Loss 0.3980 (0.3980)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:45

 Epoch: 515	Training Loss 0.2918 	Training Prec@1 89.684 	Training Prec@5 99.784 	Validation Loss 0.6103 	Validation Prec@1 81.970 	Validation Prec@5 98.620 

lr: 0.048580796362810846
TRAINING - Epoch: [515][0/391]	Time 0.952 (0.952)	Data 0.350 (0.350)	Loss 0.3075 (0.3075)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [515][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3168 (0.2917)	Prec@1 90.625 (89.859)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [515][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2347 (0.2855)	Prec@1 93.750 (90.030)	Prec@5 100.000 (99.778)
TRAINING - Epoch: [515][300/391]	Time 0.065 (0.067)	Data 0.000 (0.001)	Loss 0.2706 (0.2829)	Prec@1 89.844 (90.023)	Prec@5 100.000 (99.805)
EVALUATING - Epoch: [515][0/79]	Time 0.366 (0.366)	Data 0.347 (0.347)	Loss 0.3786 (0.3786)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:26

 Epoch: 516	Training Loss 0.2879 	Training Prec@1 89.982 	Training Prec@5 99.800 	Validation Loss 0.5283 	Validation Prec@1 82.770 	Validation Prec@5 99.300 

lr: 0.04842315675245142
TRAINING - Epoch: [516][0/391]	Time 0.952 (0.952)	Data 0.347 (0.347)	Loss 0.1636 (0.1636)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [516][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.1761 (0.2701)	Prec@1 95.312 (90.695)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [516][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3104 (0.2755)	Prec@1 85.938 (90.415)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [516][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.2338 (0.2766)	Prec@1 91.406 (90.384)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [516][0/79]	Time 0.367 (0.367)	Data 0.345 (0.345)	Loss 1.0424 (1.0424)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:44

 Epoch: 517	Training Loss 0.2784 	Training Prec@1 90.274 	Training Prec@5 99.788 	Validation Loss 0.9400 	Validation Prec@1 75.910 	Validation Prec@5 97.470 

lr: 0.04826553283015165
TRAINING - Epoch: [517][0/391]	Time 0.943 (0.943)	Data 0.354 (0.354)	Loss 0.2396 (0.2396)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [517][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2822 (0.2735)	Prec@1 91.406 (90.145)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [517][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1987 (0.2814)	Prec@1 93.750 (89.894)	Prec@5 99.219 (99.817)
TRAINING - Epoch: [517][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2926 (0.2894)	Prec@1 89.844 (89.724)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [517][0/79]	Time 0.366 (0.366)	Data 0.342 (0.342)	Loss 0.5746 (0.5746)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:02

 Epoch: 518	Training Loss 0.2919 	Training Prec@1 89.662 	Training Prec@5 99.808 	Validation Loss 0.7071 	Validation Prec@1 79.680 	Validation Prec@5 98.900 

lr: 0.04810792616411649
TRAINING - Epoch: [518][0/391]	Time 1.009 (1.009)	Data 0.350 (0.350)	Loss 0.3973 (0.3973)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [518][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2496 (0.2844)	Prec@1 90.625 (89.960)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [518][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2727 (0.2850)	Prec@1 91.406 (89.937)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [518][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3467 (0.2863)	Prec@1 85.938 (89.903)	Prec@5 100.000 (99.790)
EVALUATING - Epoch: [518][0/79]	Time 0.397 (0.397)	Data 0.374 (0.374)	Loss 0.3605 (0.3605)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:33

 Epoch: 519	Training Loss 0.2859 	Training Prec@1 89.904 	Training Prec@5 99.804 	Validation Loss 0.5436 	Validation Prec@1 83.330 	Validation Prec@5 99.130 

lr: 0.047950338322379306
TRAINING - Epoch: [519][0/391]	Time 0.932 (0.932)	Data 0.348 (0.348)	Loss 0.3344 (0.3344)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [519][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2938 (0.2668)	Prec@1 89.844 (90.594)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [519][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3631 (0.2813)	Prec@1 89.062 (90.178)	Prec@5 99.219 (99.802)
TRAINING - Epoch: [519][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2121 (0.2831)	Prec@1 91.406 (90.054)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [519][0/79]	Time 0.356 (0.356)	Data 0.335 (0.335)	Loss 0.5685 (0.5685)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:42

 Epoch: 520	Training Loss 0.2881 	Training Prec@1 89.934 	Training Prec@5 99.792 	Validation Loss 0.5845 	Validation Prec@1 81.920 	Validation Prec@5 99.230 

lr: 0.04779277087278615
TRAINING - Epoch: [520][0/391]	Time 0.934 (0.934)	Data 0.367 (0.367)	Loss 0.2170 (0.2170)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [520][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3661 (0.2818)	Prec@1 85.938 (89.766)	Prec@5 99.219 (99.783)
TRAINING - Epoch: [520][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1476 (0.2802)	Prec@1 96.094 (90.034)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [520][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2140 (0.2785)	Prec@1 91.406 (90.264)	Prec@5 100.000 (99.792)
EVALUATING - Epoch: [520][0/79]	Time 0.339 (0.339)	Data 0.317 (0.317)	Loss 0.6984 (0.6984)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:58

 Epoch: 521	Training Loss 0.2823 	Training Prec@1 90.094 	Training Prec@5 99.778 	Validation Loss 0.7652 	Validation Prec@1 78.020 	Validation Prec@5 98.680 

lr: 0.047635225382980165
TRAINING - Epoch: [521][0/391]	Time 0.952 (0.952)	Data 0.364 (0.364)	Loss 0.2627 (0.2627)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [521][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2366 (0.2723)	Prec@1 91.406 (90.447)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [521][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2726 (0.2736)	Prec@1 91.406 (90.345)	Prec@5 100.000 (99.763)
TRAINING - Epoch: [521][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2039 (0.2778)	Prec@1 92.969 (90.236)	Prec@5 100.000 (99.777)
EVALUATING - Epoch: [521][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.5225 (0.5225)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:19

 Epoch: 522	Training Loss 0.2805 	Training Prec@1 90.186 	Training Prec@5 99.760 	Validation Loss 0.5416 	Validation Prec@1 83.370 	Validation Prec@5 99.130 

lr: 0.04747770342038608
TRAINING - Epoch: [522][0/391]	Time 0.913 (0.913)	Data 0.352 (0.352)	Loss 0.3783 (0.3783)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [522][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2719 (0.2712)	Prec@1 91.406 (90.416)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [522][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2413 (0.2767)	Prec@1 91.406 (90.143)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [522][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2283 (0.2761)	Prec@1 92.188 (90.246)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [522][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.6239 (0.6239)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:49

 Epoch: 523	Training Loss 0.2781 	Training Prec@1 90.158 	Training Prec@5 99.836 	Validation Loss 0.6017 	Validation Prec@1 81.930 	Validation Prec@5 99.260 

lr: 0.04732020655219447
TRAINING - Epoch: [523][0/391]	Time 0.922 (0.922)	Data 0.358 (0.358)	Loss 0.2011 (0.2011)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [523][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2865 (0.2726)	Prec@1 92.969 (90.571)	Prec@5 99.219 (99.791)
TRAINING - Epoch: [523][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4131 (0.2719)	Prec@1 85.938 (90.613)	Prec@5 99.219 (99.794)
TRAINING - Epoch: [523][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3704 (0.2740)	Prec@1 85.156 (90.516)	Prec@5 99.219 (99.774)
EVALUATING - Epoch: [523][0/79]	Time 0.367 (0.367)	Data 0.344 (0.344)	Loss 0.4052 (0.4052)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:39

 Epoch: 524	Training Loss 0.2779 	Training Prec@1 90.392 	Training Prec@5 99.778 	Validation Loss 0.5477 	Validation Prec@1 83.480 	Validation Prec@5 99.110 

lr: 0.04716273634534631
TRAINING - Epoch: [524][0/391]	Time 0.912 (0.912)	Data 0.354 (0.354)	Loss 0.2783 (0.2783)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [524][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4225 (0.2803)	Prec@1 88.281 (90.207)	Prec@5 98.438 (99.799)
TRAINING - Epoch: [524][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3934 (0.2784)	Prec@1 85.156 (90.264)	Prec@5 100.000 (99.813)
TRAINING - Epoch: [524][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1534 (0.2788)	Prec@1 94.531 (90.288)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [524][0/79]	Time 0.349 (0.349)	Data 0.325 (0.325)	Loss 0.4956 (0.4956)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:36

 Epoch: 525	Training Loss 0.2847 	Training Prec@1 90.046 	Training Prec@5 99.770 	Validation Loss 0.5687 	Validation Prec@1 82.320 	Validation Prec@5 99.130 

lr: 0.0470052943665173
TRAINING - Epoch: [525][0/391]	Time 0.924 (0.924)	Data 0.342 (0.342)	Loss 0.3018 (0.3018)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [525][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2276 (0.2627)	Prec@1 92.188 (90.756)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [525][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3098 (0.2727)	Prec@1 89.844 (90.271)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [525][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1929 (0.2759)	Prec@1 92.188 (90.251)	Prec@5 100.000 (99.829)
EVALUATING - Epoch: [525][0/79]	Time 0.355 (0.355)	Data 0.334 (0.334)	Loss 0.4492 (0.4492)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:23

 Epoch: 526	Training Loss 0.2779 	Training Prec@1 90.158 	Training Prec@5 99.832 	Validation Loss 0.5857 	Validation Prec@1 82.530 	Validation Prec@5 99.020 

lr: 0.04684788218210228
TRAINING - Epoch: [526][0/391]	Time 0.920 (0.920)	Data 0.346 (0.346)	Loss 0.2897 (0.2897)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [526][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2265 (0.2661)	Prec@1 91.406 (90.594)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [526][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2711 (0.2720)	Prec@1 89.844 (90.481)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [526][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2831 (0.2729)	Prec@1 90.625 (90.472)	Prec@5 100.000 (99.842)
EVALUATING - Epoch: [526][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.7492 (0.7492)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:50

 Epoch: 527	Training Loss 0.2790 	Training Prec@1 90.266 	Training Prec@5 99.840 	Validation Loss 0.7793 	Validation Prec@1 78.970 	Validation Prec@5 97.820 

lr: 0.046690501358199674
TRAINING - Epoch: [527][0/391]	Time 0.908 (0.908)	Data 0.339 (0.339)	Loss 0.2658 (0.2658)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [527][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2143 (0.2763)	Prec@1 94.531 (90.014)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [527][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.2490 (0.2847)	Prec@1 91.406 (89.844)	Prec@5 100.000 (99.810)
TRAINING - Epoch: [527][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2397 (0.2900)	Prec@1 92.188 (89.761)	Prec@5 100.000 (99.805)
EVALUATING - Epoch: [527][0/79]	Time 0.365 (0.365)	Data 0.343 (0.343)	Loss 0.5095 (0.5095)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:58

 Epoch: 528	Training Loss 0.2914 	Training Prec@1 89.702 	Training Prec@5 99.804 	Validation Loss 0.6494 	Validation Prec@1 80.700 	Validation Prec@5 99.020 

lr: 0.04653315346059594
TRAINING - Epoch: [528][0/391]	Time 0.912 (0.912)	Data 0.333 (0.333)	Loss 0.3732 (0.3732)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [528][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.4173 (0.2791)	Prec@1 90.625 (90.161)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [528][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3101 (0.2892)	Prec@1 85.156 (89.797)	Prec@5 100.000 (99.778)
TRAINING - Epoch: [528][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1974 (0.2944)	Prec@1 92.969 (89.688)	Prec@5 100.000 (99.800)
EVALUATING - Epoch: [528][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.4009 (0.4009)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 529	Training Loss 0.2937 	Training Prec@1 89.714 	Training Prec@5 99.804 	Validation Loss 0.5735 	Validation Prec@1 82.980 	Validation Prec@5 99.060 

lr: 0.04637584005474987
TRAINING - Epoch: [529][0/391]	Time 0.910 (0.910)	Data 0.345 (0.345)	Loss 0.2755 (0.2755)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [529][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3113 (0.2619)	Prec@1 88.281 (90.880)	Prec@5 99.219 (99.783)
TRAINING - Epoch: [529][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3064 (0.2743)	Prec@1 88.281 (90.411)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [529][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1889 (0.2767)	Prec@1 92.969 (90.259)	Prec@5 100.000 (99.761)
EVALUATING - Epoch: [529][0/79]	Time 0.347 (0.347)	Data 0.326 (0.326)	Loss 0.6146 (0.6146)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:59

 Epoch: 530	Training Loss 0.2812 	Training Prec@1 90.068 	Training Prec@5 99.758 	Validation Loss 0.6021 	Validation Prec@1 81.930 	Validation Prec@5 99.090 

lr: 0.04621856270577719
TRAINING - Epoch: [530][0/391]	Time 0.928 (0.928)	Data 0.360 (0.360)	Loss 0.2981 (0.2981)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [530][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3408 (0.2713)	Prec@1 92.188 (90.455)	Prec@5 98.438 (99.814)
TRAINING - Epoch: [530][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2822 (0.2777)	Prec@1 90.625 (90.271)	Prec@5 100.000 (99.829)
TRAINING - Epoch: [530][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.5148 (0.2817)	Prec@1 85.938 (90.108)	Prec@5 100.000 (99.805)
EVALUATING - Epoch: [530][0/79]	Time 0.340 (0.340)	Data 0.321 (0.321)	Loss 0.5965 (0.5965)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 531	Training Loss 0.2831 	Training Prec@1 89.958 	Training Prec@5 99.792 	Validation Loss 0.6686 	Validation Prec@1 80.450 	Validation Prec@5 98.930 

lr: 0.04606132297843481
TRAINING - Epoch: [531][0/391]	Time 0.947 (0.947)	Data 0.374 (0.374)	Loss 0.1947 (0.1947)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [531][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2823 (0.2780)	Prec@1 89.844 (90.184)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [531][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2367 (0.2801)	Prec@1 93.750 (90.225)	Prec@5 99.219 (99.802)
TRAINING - Epoch: [531][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2989 (0.2806)	Prec@1 87.500 (90.153)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [531][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.6539 (0.6539)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:35

 Epoch: 532	Training Loss 0.2804 	Training Prec@1 90.190 	Training Prec@5 99.800 	Validation Loss 0.6193 	Validation Prec@1 80.990 	Validation Prec@5 99.010 

lr: 0.045904122437105385
TRAINING - Epoch: [532][0/391]	Time 0.954 (0.954)	Data 0.346 (0.346)	Loss 0.2605 (0.2605)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [532][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1673 (0.2626)	Prec@1 94.531 (90.903)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [532][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2392 (0.2669)	Prec@1 92.188 (90.613)	Prec@5 100.000 (99.821)
TRAINING - Epoch: [532][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3283 (0.2781)	Prec@1 85.938 (90.186)	Prec@5 99.219 (99.792)
EVALUATING - Epoch: [532][0/79]	Time 0.360 (0.360)	Data 0.339 (0.339)	Loss 0.5586 (0.5586)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:05

 Epoch: 533	Training Loss 0.2826 	Training Prec@1 89.998 	Training Prec@5 99.800 	Validation Loss 0.5747 	Validation Prec@1 82.920 	Validation Prec@5 99.010 

lr: 0.045746962645781736
TRAINING - Epoch: [533][0/391]	Time 0.929 (0.929)	Data 0.351 (0.351)	Loss 0.2452 (0.2452)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [533][100/391]	Time 0.066 (0.071)	Data 0.000 (0.004)	Loss 0.2035 (0.2549)	Prec@1 91.406 (91.089)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [533][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.3375 (0.2673)	Prec@1 88.281 (90.609)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [533][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2761 (0.2743)	Prec@1 87.500 (90.430)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [533][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.4275 (0.4275)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:38

 Epoch: 534	Training Loss 0.2760 	Training Prec@1 90.392 	Training Prec@5 99.804 	Validation Loss 0.5250 	Validation Prec@1 83.650 	Validation Prec@5 99.190 

lr: 0.04558984516805119
TRAINING - Epoch: [534][0/391]	Time 0.977 (0.977)	Data 0.359 (0.359)	Loss 0.2362 (0.2362)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [534][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2456 (0.2604)	Prec@1 88.281 (90.702)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [534][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2433 (0.2642)	Prec@1 91.406 (90.567)	Prec@5 99.219 (99.833)
TRAINING - Epoch: [534][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4431 (0.2690)	Prec@1 88.281 (90.420)	Prec@5 99.219 (99.829)
EVALUATING - Epoch: [534][0/79]	Time 0.353 (0.353)	Data 0.332 (0.332)	Loss 0.6814 (0.6814)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:56

 Epoch: 535	Training Loss 0.2708 	Training Prec@1 90.418 	Training Prec@5 99.812 	Validation Loss 0.5845 	Validation Prec@1 82.540 	Validation Prec@5 98.950 

lr: 0.04543277156708015
TRAINING - Epoch: [535][0/391]	Time 0.945 (0.945)	Data 0.350 (0.350)	Loss 0.3943 (0.3943)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [535][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3938 (0.2756)	Prec@1 86.719 (90.463)	Prec@5 98.438 (99.807)
TRAINING - Epoch: [535][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1801 (0.2718)	Prec@1 94.531 (90.528)	Prec@5 100.000 (99.829)
TRAINING - Epoch: [535][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.2796 (0.2783)	Prec@1 87.500 (90.218)	Prec@5 100.000 (99.824)
EVALUATING - Epoch: [535][0/79]	Time 0.355 (0.355)	Data 0.332 (0.332)	Loss 0.5446 (0.5446)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:12

 Epoch: 536	Training Loss 0.2768 	Training Prec@1 90.222 	Training Prec@5 99.824 	Validation Loss 0.6094 	Validation Prec@1 81.650 	Validation Prec@5 99.020 

lr: 0.04527574340559845
TRAINING - Epoch: [536][0/391]	Time 0.975 (0.975)	Data 0.344 (0.344)	Loss 0.1775 (0.1775)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [536][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2096 (0.2737)	Prec@1 92.969 (90.323)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [536][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3504 (0.2732)	Prec@1 86.719 (90.368)	Prec@5 100.000 (99.821)
TRAINING - Epoch: [536][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.3406 (0.2716)	Prec@1 88.281 (90.493)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [536][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.6642 (0.6642)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 537	Training Loss 0.2731 	Training Prec@1 90.478 	Training Prec@5 99.820 	Validation Loss 0.6542 	Validation Prec@1 80.450 	Validation Prec@5 99.240 

lr: 0.04511876224588388
TRAINING - Epoch: [537][0/391]	Time 0.976 (0.976)	Data 0.381 (0.381)	Loss 0.3062 (0.3062)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [537][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1595 (0.2567)	Prec@1 94.531 (91.159)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [537][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.3025 (0.2609)	Prec@1 86.719 (90.870)	Prec@5 100.000 (99.813)
TRAINING - Epoch: [537][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3153 (0.2663)	Prec@1 89.844 (90.646)	Prec@5 99.219 (99.824)
EVALUATING - Epoch: [537][0/79]	Time 0.374 (0.374)	Data 0.351 (0.351)	Loss 0.5386 (0.5386)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:12

 Epoch: 538	Training Loss 0.2686 	Training Prec@1 90.572 	Training Prec@5 99.802 	Validation Loss 0.8003 	Validation Prec@1 78.230 	Validation Prec@5 98.420 

lr: 0.0449618296497466
TRAINING - Epoch: [538][0/391]	Time 0.928 (0.928)	Data 0.353 (0.353)	Loss 0.5205 (0.5205)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [538][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1992 (0.2685)	Prec@1 92.969 (90.671)	Prec@5 100.000 (99.745)
TRAINING - Epoch: [538][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3315 (0.2806)	Prec@1 88.281 (90.201)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [538][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1941 (0.2883)	Prec@1 93.750 (90.018)	Prec@5 100.000 (99.795)
EVALUATING - Epoch: [538][0/79]	Time 0.373 (0.373)	Data 0.347 (0.347)	Loss 0.4356 (0.4356)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 539	Training Loss 0.2882 	Training Prec@1 89.988 	Training Prec@5 99.782 	Validation Loss 0.6015 	Validation Prec@1 82.070 	Validation Prec@5 99.040 

lr: 0.04480494717851359
TRAINING - Epoch: [539][0/391]	Time 0.943 (0.943)	Data 0.367 (0.367)	Loss 0.3133 (0.3133)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [539][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3119 (0.2488)	Prec@1 87.500 (91.329)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [539][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3222 (0.2623)	Prec@1 86.719 (90.878)	Prec@5 99.219 (99.810)
TRAINING - Epoch: [539][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.4217 (0.2697)	Prec@1 89.062 (90.713)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [539][0/79]	Time 0.364 (0.364)	Data 0.340 (0.340)	Loss 0.5845 (0.5845)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:39

 Epoch: 540	Training Loss 0.2714 	Training Prec@1 90.618 	Training Prec@5 99.818 	Validation Loss 0.7154 	Validation Prec@1 80.500 	Validation Prec@5 98.290 

lr: 0.04464811639301314
TRAINING - Epoch: [540][0/391]	Time 0.899 (0.899)	Data 0.335 (0.335)	Loss 0.2380 (0.2380)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [540][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.4527 (0.2724)	Prec@1 86.719 (90.602)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [540][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2753 (0.2669)	Prec@1 89.844 (90.722)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [540][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.1895 (0.2653)	Prec@1 93.750 (90.664)	Prec@5 99.219 (99.836)
EVALUATING - Epoch: [540][0/79]	Time 0.368 (0.368)	Data 0.346 (0.346)	Loss 0.5524 (0.5524)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:52

 Epoch: 541	Training Loss 0.2703 	Training Prec@1 90.572 	Training Prec@5 99.826 	Validation Loss 0.5478 	Validation Prec@1 83.190 	Validation Prec@5 99.380 

lr: 0.044491338853559353
TRAINING - Epoch: [541][0/391]	Time 0.943 (0.943)	Data 0.369 (0.369)	Loss 0.3789 (0.3789)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [541][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2922 (0.2784)	Prec@1 87.500 (90.107)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [541][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3231 (0.2807)	Prec@1 88.281 (90.054)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [541][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1966 (0.2749)	Prec@1 92.188 (90.316)	Prec@5 100.000 (99.842)
EVALUATING - Epoch: [541][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.5001 (0.5001)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 542	Training Loss 0.2772 	Training Prec@1 90.258 	Training Prec@5 99.840 	Validation Loss 0.5546 	Validation Prec@1 83.300 	Validation Prec@5 99.140 

lr: 0.04433461611993652
TRAINING - Epoch: [542][0/391]	Time 0.900 (0.900)	Data 0.344 (0.344)	Loss 0.1640 (0.1640)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [542][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1907 (0.2593)	Prec@1 92.188 (90.880)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [542][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2036 (0.2653)	Prec@1 91.406 (90.543)	Prec@5 99.219 (99.880)
TRAINING - Epoch: [542][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3097 (0.2689)	Prec@1 91.406 (90.441)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [542][0/79]	Time 0.377 (0.377)	Data 0.358 (0.358)	Loss 0.5943 (0.5943)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:41

 Epoch: 543	Training Loss 0.2674 	Training Prec@1 90.438 	Training Prec@5 99.878 	Validation Loss 0.6757 	Validation Prec@1 80.760 	Validation Prec@5 98.880 

lr: 0.044177949751383734
TRAINING - Epoch: [543][0/391]	Time 0.925 (0.925)	Data 0.340 (0.340)	Loss 0.2822 (0.2822)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [543][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1931 (0.2504)	Prec@1 92.188 (91.151)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [543][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2731 (0.2565)	Prec@1 92.188 (91.138)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [543][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.2432 (0.2638)	Prec@1 89.062 (90.804)	Prec@5 100.000 (99.811)
EVALUATING - Epoch: [543][0/79]	Time 0.354 (0.354)	Data 0.331 (0.331)	Loss 0.6168 (0.6168)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:06

 Epoch: 544	Training Loss 0.2680 	Training Prec@1 90.628 	Training Prec@5 99.788 	Validation Loss 0.5879 	Validation Prec@1 82.220 	Validation Prec@5 99.180 

lr: 0.044021341306579274
TRAINING - Epoch: [544][0/391]	Time 0.909 (0.909)	Data 0.335 (0.335)	Loss 0.2139 (0.2139)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [544][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2721 (0.2663)	Prec@1 90.625 (90.726)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [544][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4408 (0.2760)	Prec@1 85.938 (90.400)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [544][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1507 (0.2746)	Prec@1 95.312 (90.355)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [544][0/79]	Time 0.351 (0.351)	Data 0.332 (0.332)	Loss 0.4244 (0.4244)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:53

 Epoch: 545	Training Loss 0.2742 	Training Prec@1 90.292 	Training Prec@5 99.822 	Validation Loss 0.7569 	Validation Prec@1 79.050 	Validation Prec@5 98.920 

lr: 0.04386479234362513
TRAINING - Epoch: [545][0/391]	Time 0.916 (0.916)	Data 0.341 (0.341)	Loss 0.3172 (0.3172)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [545][100/391]	Time 0.060 (0.071)	Data 0.000 (0.004)	Loss 0.2773 (0.2612)	Prec@1 89.062 (90.772)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [545][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2336 (0.2629)	Prec@1 92.969 (90.672)	Prec@5 100.000 (99.813)
TRAINING - Epoch: [545][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2360 (0.2666)	Prec@1 92.188 (90.529)	Prec@5 99.219 (99.795)
EVALUATING - Epoch: [545][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.4205 (0.4205)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 546	Training Loss 0.2701 	Training Prec@1 90.402 	Training Prec@5 99.786 	Validation Loss 0.5243 	Validation Prec@1 83.920 	Validation Prec@5 99.210 

lr: 0.043708304420031534
TRAINING - Epoch: [546][0/391]	Time 0.913 (0.913)	Data 0.351 (0.351)	Loss 0.2504 (0.2504)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [546][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2495 (0.2542)	Prec@1 94.531 (91.159)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [546][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2700 (0.2560)	Prec@1 86.719 (90.901)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [546][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2058 (0.2664)	Prec@1 92.188 (90.667)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [546][0/79]	Time 0.366 (0.366)	Data 0.343 (0.343)	Loss 0.4686 (0.4686)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:23

 Epoch: 547	Training Loss 0.2680 	Training Prec@1 90.568 	Training Prec@5 99.820 	Validation Loss 0.5912 	Validation Prec@1 82.480 	Validation Prec@5 99.080 

lr: 0.0435518790927014
TRAINING - Epoch: [547][0/391]	Time 0.913 (0.913)	Data 0.344 (0.344)	Loss 0.1341 (0.1341)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [547][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2433 (0.2579)	Prec@1 92.188 (91.043)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [547][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2472 (0.2629)	Prec@1 92.969 (90.901)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [547][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3911 (0.2716)	Prec@1 85.156 (90.615)	Prec@5 100.000 (99.811)
EVALUATING - Epoch: [547][0/79]	Time 0.342 (0.342)	Data 0.319 (0.319)	Loss 0.6215 (0.6215)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:21

 Epoch: 548	Training Loss 0.2772 	Training Prec@1 90.402 	Training Prec@5 99.814 	Validation Loss 0.7892 	Validation Prec@1 77.920 	Validation Prec@5 98.850 

lr: 0.043395517917914905
TRAINING - Epoch: [548][0/391]	Time 0.921 (0.921)	Data 0.347 (0.347)	Loss 0.2713 (0.2713)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [548][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1953 (0.2814)	Prec@1 92.188 (90.323)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [548][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2835 (0.2776)	Prec@1 90.625 (90.407)	Prec@5 100.000 (99.810)
TRAINING - Epoch: [548][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2890 (0.2754)	Prec@1 92.969 (90.334)	Prec@5 99.219 (99.813)
EVALUATING - Epoch: [548][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.4831 (0.4831)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 549	Training Loss 0.2776 	Training Prec@1 90.242 	Training Prec@5 99.816 	Validation Loss 0.6311 	Validation Prec@1 81.210 	Validation Prec@5 98.930 

lr: 0.04323922245131393
TRAINING - Epoch: [549][0/391]	Time 0.931 (0.931)	Data 0.346 (0.346)	Loss 0.3651 (0.3651)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [549][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2451 (0.2677)	Prec@1 89.844 (90.834)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [549][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1868 (0.2658)	Prec@1 91.406 (90.777)	Prec@5 100.000 (99.813)
TRAINING - Epoch: [549][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2755 (0.2640)	Prec@1 90.625 (90.765)	Prec@5 100.000 (99.821)
EVALUATING - Epoch: [549][0/79]	Time 0.353 (0.353)	Data 0.333 (0.333)	Loss 0.4521 (0.4521)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 550	Training Loss 0.2683 	Training Prec@1 90.616 	Training Prec@5 99.818 	Validation Loss 0.5603 	Validation Prec@1 83.160 	Validation Prec@5 99.280 

lr: 0.043082994247886676
TRAINING - Epoch: [550][0/391]	Time 0.911 (0.911)	Data 0.342 (0.342)	Loss 0.2175 (0.2175)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [550][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3082 (0.2720)	Prec@1 89.062 (90.447)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [550][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2699 (0.2747)	Prec@1 88.281 (90.353)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [550][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3404 (0.2746)	Prec@1 91.406 (90.456)	Prec@5 100.000 (99.839)
EVALUATING - Epoch: [550][0/79]	Time 0.343 (0.343)	Data 0.320 (0.320)	Loss 0.4653 (0.4653)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 551	Training Loss 0.2743 	Training Prec@1 90.478 	Training Prec@5 99.826 	Validation Loss 0.5443 	Validation Prec@1 83.690 	Validation Prec@5 99.040 

lr: 0.0429268348619521
TRAINING - Epoch: [551][0/391]	Time 0.908 (0.908)	Data 0.342 (0.342)	Loss 0.3101 (0.3101)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [551][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2402 (0.2519)	Prec@1 92.969 (91.027)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [551][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2995 (0.2616)	Prec@1 90.625 (90.769)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [551][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2419 (0.2702)	Prec@1 91.406 (90.461)	Prec@5 99.219 (99.849)
EVALUATING - Epoch: [551][0/79]	Time 0.347 (0.347)	Data 0.324 (0.324)	Loss 0.6986 (0.6986)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:31

 Epoch: 552	Training Loss 0.2713 	Training Prec@1 90.440 	Training Prec@5 99.844 	Validation Loss 0.6802 	Validation Prec@1 80.710 	Validation Prec@5 98.420 

lr: 0.04277074584714448
TRAINING - Epoch: [552][0/391]	Time 0.915 (0.915)	Data 0.351 (0.351)	Loss 0.3050 (0.3050)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [552][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2668 (0.2579)	Prec@1 89.844 (90.811)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [552][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1703 (0.2616)	Prec@1 92.188 (90.629)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [552][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1579 (0.2687)	Prec@1 95.312 (90.412)	Prec@5 100.000 (99.821)
EVALUATING - Epoch: [552][0/79]	Time 0.360 (0.360)	Data 0.339 (0.339)	Loss 0.4669 (0.4669)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 553	Training Loss 0.2683 	Training Prec@1 90.502 	Training Prec@5 99.832 	Validation Loss 0.5978 	Validation Prec@1 82.350 	Validation Prec@5 99.070 

lr: 0.04261472875639802
TRAINING - Epoch: [553][0/391]	Time 0.932 (0.932)	Data 0.375 (0.375)	Loss 0.2607 (0.2607)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [553][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2287 (0.2520)	Prec@1 93.750 (91.081)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [553][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3214 (0.2677)	Prec@1 89.062 (90.637)	Prec@5 100.000 (99.829)
TRAINING - Epoch: [553][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2060 (0.2660)	Prec@1 91.406 (90.542)	Prec@5 100.000 (99.829)
EVALUATING - Epoch: [553][0/79]	Time 0.338 (0.338)	Data 0.317 (0.317)	Loss 0.4692 (0.4692)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 554	Training Loss 0.2663 	Training Prec@1 90.608 	Training Prec@5 99.824 	Validation Loss 0.5845 	Validation Prec@1 82.600 	Validation Prec@5 99.140 

lr: 0.04245878514193132
TRAINING - Epoch: [554][0/391]	Time 0.905 (0.905)	Data 0.331 (0.331)	Loss 0.2731 (0.2731)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [554][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.2835 (0.2688)	Prec@1 89.062 (90.486)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [554][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.2519 (0.2692)	Prec@1 88.281 (90.403)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [554][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2522 (0.2691)	Prec@1 91.406 (90.485)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [554][0/79]	Time 0.381 (0.381)	Data 0.359 (0.359)	Loss 0.4434 (0.4434)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 555	Training Loss 0.2682 	Training Prec@1 90.480 	Training Prec@5 99.848 	Validation Loss 0.6453 	Validation Prec@1 81.630 	Validation Prec@5 98.640 

lr: 0.04230291655523196
TRAINING - Epoch: [555][0/391]	Time 0.931 (0.931)	Data 0.343 (0.343)	Loss 0.2417 (0.2417)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [555][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2717 (0.2541)	Prec@1 89.844 (90.950)	Prec@5 99.219 (99.838)
TRAINING - Epoch: [555][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2625 (0.2535)	Prec@1 90.625 (90.955)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [555][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2556 (0.2515)	Prec@1 89.062 (91.035)	Prec@5 100.000 (99.847)
EVALUATING - Epoch: [555][0/79]	Time 0.367 (0.367)	Data 0.345 (0.345)	Loss 0.6757 (0.6757)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:22

 Epoch: 556	Training Loss 0.2549 	Training Prec@1 90.962 	Training Prec@5 99.842 	Validation Loss 0.6678 	Validation Prec@1 80.970 	Validation Prec@5 98.990 

lr: 0.042147124547041066
TRAINING - Epoch: [556][0/391]	Time 0.913 (0.913)	Data 0.335 (0.335)	Loss 0.2330 (0.2330)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [556][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2830 (0.2546)	Prec@1 89.062 (91.004)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [556][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2478 (0.2632)	Prec@1 91.406 (90.625)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [556][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2924 (0.2602)	Prec@1 89.062 (90.765)	Prec@5 100.000 (99.842)
EVALUATING - Epoch: [556][0/79]	Time 0.354 (0.354)	Data 0.332 (0.332)	Loss 0.5891 (0.5891)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:33

 Epoch: 557	Training Loss 0.2583 	Training Prec@1 90.828 	Training Prec@5 99.852 	Validation Loss 0.5696 	Validation Prec@1 82.900 	Validation Prec@5 99.100 

lr: 0.0419914106673379
TRAINING - Epoch: [557][0/391]	Time 0.908 (0.908)	Data 0.352 (0.352)	Loss 0.1144 (0.1144)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [557][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3836 (0.2517)	Prec@1 87.500 (91.213)	Prec@5 99.219 (99.791)
TRAINING - Epoch: [557][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3337 (0.2505)	Prec@1 88.281 (91.227)	Prec@5 99.219 (99.790)
TRAINING - Epoch: [557][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3562 (0.2574)	Prec@1 89.844 (91.027)	Prec@5 100.000 (99.800)
EVALUATING - Epoch: [557][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.4194 (0.4194)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:14

 Epoch: 558	Training Loss 0.2636 	Training Prec@1 90.822 	Training Prec@5 99.794 	Validation Loss 0.5437 	Validation Prec@1 83.930 	Validation Prec@5 99.150 

lr: 0.04183577646532439
TRAINING - Epoch: [558][0/391]	Time 0.942 (0.942)	Data 0.367 (0.367)	Loss 0.3253 (0.3253)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [558][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2037 (0.2531)	Prec@1 93.750 (91.097)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [558][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2687 (0.2577)	Prec@1 90.625 (91.006)	Prec@5 99.219 (99.856)
TRAINING - Epoch: [558][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2085 (0.2629)	Prec@1 93.750 (90.853)	Prec@5 99.219 (99.839)
EVALUATING - Epoch: [558][0/79]	Time 0.364 (0.364)	Data 0.345 (0.345)	Loss 0.6982 (0.6982)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:22

 Epoch: 559	Training Loss 0.2714 	Training Prec@1 90.524 	Training Prec@5 99.822 	Validation Loss 0.8218 	Validation Prec@1 78.340 	Validation Prec@5 98.560 

lr: 0.04168022348940979
TRAINING - Epoch: [559][0/391]	Time 0.935 (0.935)	Data 0.342 (0.342)	Loss 0.2447 (0.2447)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [559][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2007 (0.2570)	Prec@1 92.188 (90.996)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [559][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.2706 (0.2650)	Prec@1 91.406 (90.831)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [559][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.3223 (0.2680)	Prec@1 91.406 (90.635)	Prec@5 100.000 (99.839)
EVALUATING - Epoch: [559][0/79]	Time 0.372 (0.372)	Data 0.348 (0.348)	Loss 0.5504 (0.5504)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:18

 Epoch: 560	Training Loss 0.2698 	Training Prec@1 90.576 	Training Prec@5 99.832 	Validation Loss 0.7436 	Validation Prec@1 79.680 	Validation Prec@5 98.810 

lr: 0.041524753287195175
TRAINING - Epoch: [560][0/391]	Time 0.911 (0.911)	Data 0.353 (0.353)	Loss 0.3234 (0.3234)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [560][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3089 (0.2832)	Prec@1 86.719 (89.975)	Prec@5 99.219 (99.799)
TRAINING - Epoch: [560][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1419 (0.2822)	Prec@1 93.750 (89.937)	Prec@5 100.000 (99.829)
TRAINING - Epoch: [560][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1548 (0.2766)	Prec@1 95.312 (90.153)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [560][0/79]	Time 0.348 (0.348)	Data 0.324 (0.324)	Loss 0.4477 (0.4477)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:29

 Epoch: 561	Training Loss 0.2713 	Training Prec@1 90.396 	Training Prec@5 99.842 	Validation Loss 0.5238 	Validation Prec@1 84.570 	Validation Prec@5 99.170 

lr: 0.04136936740545819
TRAINING - Epoch: [561][0/391]	Time 0.909 (0.909)	Data 0.348 (0.348)	Loss 0.2688 (0.2688)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [561][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3431 (0.2496)	Prec@1 86.719 (91.321)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [561][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1357 (0.2549)	Prec@1 94.531 (91.076)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [561][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2838 (0.2638)	Prec@1 91.406 (90.877)	Prec@5 99.219 (99.826)
EVALUATING - Epoch: [561][0/79]	Time 0.360 (0.360)	Data 0.337 (0.337)	Loss 0.5785 (0.5785)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 562	Training Loss 0.2658 	Training Prec@1 90.734 	Training Prec@5 99.830 	Validation Loss 0.5902 	Validation Prec@1 82.870 	Validation Prec@5 99.030 

lr: 0.041214067390137464
TRAINING - Epoch: [562][0/391]	Time 0.923 (0.923)	Data 0.335 (0.335)	Loss 0.3411 (0.3411)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [562][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2544 (0.2545)	Prec@1 89.844 (90.965)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [562][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2213 (0.2582)	Prec@1 91.406 (90.788)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [562][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1512 (0.2665)	Prec@1 95.312 (90.641)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [562][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.4862 (0.4862)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:56

 Epoch: 563	Training Loss 0.2661 	Training Prec@1 90.622 	Training Prec@5 99.804 	Validation Loss 0.5449 	Validation Prec@1 83.560 	Validation Prec@5 98.950 

lr: 0.04105885478631741
TRAINING - Epoch: [563][0/391]	Time 0.901 (0.901)	Data 0.341 (0.341)	Loss 0.2769 (0.2769)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [563][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1884 (0.2489)	Prec@1 92.969 (91.375)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [563][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2273 (0.2483)	Prec@1 92.188 (91.262)	Prec@5 100.000 (99.883)
TRAINING - Epoch: [563][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2079 (0.2505)	Prec@1 90.625 (91.108)	Prec@5 100.000 (99.875)
EVALUATING - Epoch: [563][0/79]	Time 0.361 (0.361)	Data 0.340 (0.340)	Loss 0.5678 (0.5678)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 564	Training Loss 0.2566 	Training Prec@1 90.986 	Training Prec@5 99.864 	Validation Loss 0.6058 	Validation Prec@1 82.640 	Validation Prec@5 99.090 

lr: 0.040903731138212815
TRAINING - Epoch: [564][0/391]	Time 0.910 (0.910)	Data 0.343 (0.343)	Loss 0.1296 (0.1296)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [564][100/391]	Time 0.063 (0.070)	Data 0.000 (0.004)	Loss 0.4406 (0.2576)	Prec@1 84.375 (90.903)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [564][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.1876 (0.2577)	Prec@1 91.406 (90.913)	Prec@5 100.000 (99.848)
TRAINING - Epoch: [564][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2680 (0.2589)	Prec@1 90.625 (90.908)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [564][0/79]	Time 0.339 (0.339)	Data 0.317 (0.317)	Loss 0.7015 (0.7015)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:19:11

 Epoch: 565	Training Loss 0.2603 	Training Prec@1 90.800 	Training Prec@5 99.844 	Validation Loss 0.7771 	Validation Prec@1 80.100 	Validation Prec@5 98.470 

lr: 0.04074869798915332
TRAINING - Epoch: [565][0/391]	Time 0.905 (0.905)	Data 0.342 (0.342)	Loss 0.3400 (0.3400)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [565][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.2458 (0.2658)	Prec@1 91.406 (90.772)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [565][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2475 (0.2710)	Prec@1 89.844 (90.691)	Prec@5 99.219 (99.782)
TRAINING - Epoch: [565][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1570 (0.2709)	Prec@1 92.969 (90.620)	Prec@5 100.000 (99.795)
EVALUATING - Epoch: [565][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.5050 (0.5050)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:19:13

 Epoch: 566	Training Loss 0.2687 	Training Prec@1 90.672 	Training Prec@5 99.814 	Validation Loss 0.6817 	Validation Prec@1 80.780 	Validation Prec@5 99.050 

lr: 0.04059375688156833
TRAINING - Epoch: [566][0/391]	Time 0.931 (0.931)	Data 0.364 (0.364)	Loss 0.3292 (0.3292)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [566][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2464 (0.2662)	Prec@1 92.969 (90.996)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [566][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2831 (0.2639)	Prec@1 90.625 (90.874)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [566][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1999 (0.2653)	Prec@1 90.625 (90.755)	Prec@5 100.000 (99.829)
EVALUATING - Epoch: [566][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.4018 (0.4018)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:55

 Epoch: 567	Training Loss 0.2695 	Training Prec@1 90.554 	Training Prec@5 99.818 	Validation Loss 0.5333 	Validation Prec@1 83.960 	Validation Prec@5 99.280 

lr: 0.0404389093569714
TRAINING - Epoch: [567][0/391]	Time 0.910 (0.910)	Data 0.341 (0.341)	Loss 0.1942 (0.1942)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [567][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2460 (0.2402)	Prec@1 92.969 (91.445)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [567][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2124 (0.2556)	Prec@1 90.625 (91.123)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [567][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3239 (0.2574)	Prec@1 90.625 (91.020)	Prec@5 99.219 (99.834)
EVALUATING - Epoch: [567][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.4912 (0.4912)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:30

 Epoch: 568	Training Loss 0.2591 	Training Prec@1 90.916 	Training Prec@5 99.832 	Validation Loss 0.5134 	Validation Prec@1 84.080 	Validation Prec@5 99.330 

lr: 0.040284156955945116
TRAINING - Epoch: [568][0/391]	Time 0.922 (0.922)	Data 0.351 (0.351)	Loss 0.2037 (0.2037)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [568][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2103 (0.2449)	Prec@1 92.188 (91.259)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [568][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2596 (0.2464)	Prec@1 90.625 (91.286)	Prec@5 100.000 (99.868)
TRAINING - Epoch: [568][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2540 (0.2505)	Prec@1 93.750 (91.193)	Prec@5 99.219 (99.862)
EVALUATING - Epoch: [568][0/79]	Time 0.376 (0.376)	Data 0.356 (0.356)	Loss 0.5024 (0.5024)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 569	Training Loss 0.2524 	Training Prec@1 91.084 	Training Prec@5 99.858 	Validation Loss 0.5314 	Validation Prec@1 83.830 	Validation Prec@5 99.460 

lr: 0.04012950121812565
TRAINING - Epoch: [569][0/391]	Time 0.916 (0.916)	Data 0.344 (0.344)	Loss 0.3082 (0.3082)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [569][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2933 (0.2569)	Prec@1 90.625 (90.888)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [569][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3740 (0.2591)	Prec@1 83.594 (90.804)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [569][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.4556 (0.2674)	Prec@1 85.156 (90.648)	Prec@5 99.219 (99.842)
EVALUATING - Epoch: [569][0/79]	Time 0.361 (0.361)	Data 0.339 (0.339)	Loss 0.5182 (0.5182)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:48

 Epoch: 570	Training Loss 0.2636 	Training Prec@1 90.754 	Training Prec@5 99.842 	Validation Loss 0.5328 	Validation Prec@1 83.260 	Validation Prec@5 99.100 

lr: 0.03997494368218745
TRAINING - Epoch: [570][0/391]	Time 0.922 (0.922)	Data 0.339 (0.339)	Loss 0.2040 (0.2040)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [570][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1404 (0.2450)	Prec@1 96.094 (91.267)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [570][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1402 (0.2446)	Prec@1 93.750 (91.305)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [570][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1630 (0.2521)	Prec@1 93.750 (91.017)	Prec@5 100.000 (99.881)
EVALUATING - Epoch: [570][0/79]	Time 0.405 (0.405)	Data 0.381 (0.381)	Loss 0.5220 (0.5220)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 571	Training Loss 0.2544 	Training Prec@1 90.994 	Training Prec@5 99.872 	Validation Loss 0.5898 	Validation Prec@1 82.370 	Validation Prec@5 98.970 

lr: 0.03982048588582796
TRAINING - Epoch: [571][0/391]	Time 0.908 (0.908)	Data 0.349 (0.349)	Loss 0.2320 (0.2320)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [571][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.3755 (0.2551)	Prec@1 85.938 (90.958)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [571][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1697 (0.2516)	Prec@1 94.531 (91.169)	Prec@5 100.000 (99.872)
TRAINING - Epoch: [571][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1741 (0.2543)	Prec@1 92.969 (91.032)	Prec@5 100.000 (99.881)
EVALUATING - Epoch: [571][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.4791 (0.4791)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:01

 Epoch: 572	Training Loss 0.2545 	Training Prec@1 91.008 	Training Prec@5 99.882 	Validation Loss 0.6277 	Validation Prec@1 81.560 	Validation Prec@5 98.890 

lr: 0.03966612936575235
TRAINING - Epoch: [572][0/391]	Time 0.925 (0.925)	Data 0.348 (0.348)	Loss 0.2246 (0.2246)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [572][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2167 (0.2501)	Prec@1 92.188 (91.136)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [572][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2370 (0.2587)	Prec@1 91.406 (90.850)	Prec@5 100.000 (99.864)
TRAINING - Epoch: [572][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.1948 (0.2595)	Prec@1 93.750 (90.840)	Prec@5 100.000 (99.868)
EVALUATING - Epoch: [572][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 0.5005 (0.5005)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 573	Training Loss 0.2580 	Training Prec@1 90.928 	Training Prec@5 99.852 	Validation Loss 0.5712 	Validation Prec@1 82.660 	Validation Prec@5 99.160 

lr: 0.03951187565765811
TRAINING - Epoch: [573][0/391]	Time 0.912 (0.912)	Data 0.336 (0.336)	Loss 0.2219 (0.2219)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [573][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2433 (0.2472)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.838)
TRAINING - Epoch: [573][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.1795 (0.2493)	Prec@1 92.188 (91.371)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [573][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2166 (0.2565)	Prec@1 92.188 (91.084)	Prec@5 100.000 (99.836)
EVALUATING - Epoch: [573][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.3789 (0.3789)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 574	Training Loss 0.2554 	Training Prec@1 91.064 	Training Prec@5 99.840 	Validation Loss 0.6945 	Validation Prec@1 81.210 	Validation Prec@5 98.470 

lr: 0.03935772629621993
TRAINING - Epoch: [574][0/391]	Time 0.928 (0.928)	Data 0.348 (0.348)	Loss 0.2813 (0.2813)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [574][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3908 (0.2624)	Prec@1 84.375 (90.540)	Prec@5 99.219 (99.822)
TRAINING - Epoch: [574][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2777 (0.2629)	Prec@1 92.969 (90.644)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [574][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2230 (0.2650)	Prec@1 92.188 (90.560)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [574][0/79]	Time 0.381 (0.381)	Data 0.357 (0.357)	Loss 0.4235 (0.4235)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:49

 Epoch: 575	Training Loss 0.2653 	Training Prec@1 90.592 	Training Prec@5 99.854 	Validation Loss 0.6312 	Validation Prec@1 82.370 	Validation Prec@5 99.010 

lr: 0.0392036828150743
TRAINING - Epoch: [575][0/391]	Time 0.936 (0.936)	Data 0.346 (0.346)	Loss 0.1872 (0.1872)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [575][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1244 (0.2631)	Prec@1 94.531 (90.555)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [575][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1879 (0.2520)	Prec@1 93.750 (91.006)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [575][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2393 (0.2539)	Prec@1 93.750 (90.923)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [575][0/79]	Time 0.346 (0.346)	Data 0.326 (0.326)	Loss 0.4126 (0.4126)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 576	Training Loss 0.2516 	Training Prec@1 91.016 	Training Prec@5 99.856 	Validation Loss 0.5259 	Validation Prec@1 84.330 	Validation Prec@5 99.320 

lr: 0.03904974674680433
TRAINING - Epoch: [576][0/391]	Time 0.942 (0.942)	Data 0.360 (0.360)	Loss 0.2370 (0.2370)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [576][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3205 (0.2464)	Prec@1 90.625 (91.244)	Prec@5 99.219 (99.884)
TRAINING - Epoch: [576][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2096 (0.2436)	Prec@1 93.750 (91.294)	Prec@5 100.000 (99.864)
TRAINING - Epoch: [576][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2673 (0.2457)	Prec@1 92.188 (91.263)	Prec@5 100.000 (99.860)
EVALUATING - Epoch: [576][0/79]	Time 0.353 (0.353)	Data 0.330 (0.330)	Loss 0.4356 (0.4356)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 577	Training Loss 0.2507 	Training Prec@1 91.130 	Training Prec@5 99.862 	Validation Loss 0.5308 	Validation Prec@1 84.360 	Validation Prec@5 99.200 

lr: 0.03889591962292449
TRAINING - Epoch: [577][0/391]	Time 0.933 (0.933)	Data 0.373 (0.373)	Loss 0.1773 (0.1773)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [577][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.3974 (0.2309)	Prec@1 87.500 (91.948)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [577][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3099 (0.2362)	Prec@1 91.406 (91.721)	Prec@5 98.438 (99.860)
TRAINING - Epoch: [577][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3879 (0.2448)	Prec@1 87.500 (91.513)	Prec@5 100.000 (99.875)
EVALUATING - Epoch: [577][0/79]	Time 0.370 (0.370)	Data 0.349 (0.349)	Loss 0.3033 (0.3033)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:19:49

 Epoch: 578	Training Loss 0.2478 	Training Prec@1 91.344 	Training Prec@5 99.870 	Validation Loss 0.4928 	Validation Prec@1 84.640 	Validation Prec@5 99.040 

lr: 0.03874220297386528
TRAINING - Epoch: [578][0/391]	Time 0.904 (0.904)	Data 0.332 (0.332)	Loss 0.1928 (0.1928)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [578][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.3382 (0.2352)	Prec@1 90.625 (91.754)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [578][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1505 (0.2380)	Prec@1 94.531 (91.655)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [578][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.2328 (0.2416)	Prec@1 92.188 (91.632)	Prec@5 100.000 (99.896)
EVALUATING - Epoch: [578][0/79]	Time 0.338 (0.338)	Data 0.317 (0.317)	Loss 0.4438 (0.4438)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:50

 Epoch: 579	Training Loss 0.2423 	Training Prec@1 91.576 	Training Prec@5 99.900 	Validation Loss 0.5398 	Validation Prec@1 83.310 	Validation Prec@5 99.310 

lr: 0.03858859832895821
TRAINING - Epoch: [579][0/391]	Time 0.910 (0.910)	Data 0.345 (0.345)	Loss 0.1975 (0.1975)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [579][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2701 (0.2334)	Prec@1 91.406 (91.228)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [579][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2046 (0.2489)	Prec@1 91.406 (90.951)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [579][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2782 (0.2512)	Prec@1 89.062 (90.931)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [579][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.4910 (0.4910)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:38

 Epoch: 580	Training Loss 0.2509 	Training Prec@1 90.994 	Training Prec@5 99.854 	Validation Loss 0.4928 	Validation Prec@1 84.630 	Validation Prec@5 99.340 

lr: 0.038435107216420336
TRAINING - Epoch: [580][0/391]	Time 0.935 (0.935)	Data 0.355 (0.355)	Loss 0.2433 (0.2433)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [580][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2251 (0.2271)	Prec@1 91.406 (91.855)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [580][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1965 (0.2420)	Prec@1 92.969 (91.542)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [580][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1905 (0.2472)	Prec@1 92.188 (91.305)	Prec@5 100.000 (99.839)
EVALUATING - Epoch: [580][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 0.4072 (0.4072)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:22

 Epoch: 581	Training Loss 0.2490 	Training Prec@1 91.218 	Training Prec@5 99.846 	Validation Loss 0.5474 	Validation Prec@1 83.910 	Validation Prec@5 99.020 

lr: 0.03828173116333925
TRAINING - Epoch: [581][0/391]	Time 0.929 (0.929)	Data 0.349 (0.349)	Loss 0.1885 (0.1885)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [581][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1647 (0.2361)	Prec@1 93.750 (91.762)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [581][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2566 (0.2482)	Prec@1 89.844 (91.290)	Prec@5 99.219 (99.883)
TRAINING - Epoch: [581][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3123 (0.2549)	Prec@1 90.625 (91.069)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [581][0/79]	Time 0.358 (0.358)	Data 0.335 (0.335)	Loss 0.4475 (0.4475)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:08

 Epoch: 582	Training Loss 0.2550 	Training Prec@1 91.056 	Training Prec@5 99.840 	Validation Loss 0.5822 	Validation Prec@1 82.910 	Validation Prec@5 98.850 

lr: 0.03812847169565779
TRAINING - Epoch: [582][0/391]	Time 0.912 (0.912)	Data 0.347 (0.347)	Loss 0.2429 (0.2429)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [582][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2604 (0.2442)	Prec@1 90.625 (91.259)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [582][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.2666 (0.2426)	Prec@1 91.406 (91.282)	Prec@5 99.219 (99.903)
TRAINING - Epoch: [582][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2052 (0.2450)	Prec@1 91.406 (91.310)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [582][0/79]	Time 0.357 (0.357)	Data 0.335 (0.335)	Loss 0.4753 (0.4753)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:24

 Epoch: 583	Training Loss 0.2497 	Training Prec@1 91.182 	Training Prec@5 99.852 	Validation Loss 0.5526 	Validation Prec@1 83.220 	Validation Prec@5 99.140 

lr: 0.03797533033815889
TRAINING - Epoch: [583][0/391]	Time 0.925 (0.925)	Data 0.334 (0.334)	Loss 0.1720 (0.1720)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [583][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2295 (0.2403)	Prec@1 92.969 (91.569)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [583][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1607 (0.2330)	Prec@1 94.531 (91.830)	Prec@5 100.000 (99.817)
TRAINING - Epoch: [583][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2338 (0.2408)	Prec@1 92.188 (91.502)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [583][0/79]	Time 0.338 (0.338)	Data 0.317 (0.317)	Loss 0.4855 (0.4855)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 584	Training Loss 0.2473 	Training Prec@1 91.350 	Training Prec@5 99.824 	Validation Loss 0.5158 	Validation Prec@1 84.400 	Validation Prec@5 99.210 

lr: 0.03782230861445038
TRAINING - Epoch: [584][0/391]	Time 0.915 (0.915)	Data 0.362 (0.362)	Loss 0.2609 (0.2609)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [584][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2203 (0.2445)	Prec@1 89.844 (91.453)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [584][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3231 (0.2420)	Prec@1 89.844 (91.538)	Prec@5 99.219 (99.876)
TRAINING - Epoch: [584][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2750 (0.2485)	Prec@1 89.062 (91.289)	Prec@5 99.219 (99.862)
EVALUATING - Epoch: [584][0/79]	Time 0.366 (0.366)	Data 0.342 (0.342)	Loss 0.5427 (0.5427)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:54

 Epoch: 585	Training Loss 0.2489 	Training Prec@1 91.284 	Training Prec@5 99.856 	Validation Loss 0.5963 	Validation Prec@1 82.670 	Validation Prec@5 99.310 

lr: 0.0376694080469499
TRAINING - Epoch: [585][0/391]	Time 0.919 (0.919)	Data 0.344 (0.344)	Loss 0.2526 (0.2526)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [585][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2867 (0.2419)	Prec@1 88.281 (91.306)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [585][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2386 (0.2403)	Prec@1 90.625 (91.352)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [585][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0967 (0.2428)	Prec@1 96.094 (91.375)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [585][0/79]	Time 0.362 (0.362)	Data 0.339 (0.339)	Loss 0.6508 (0.6508)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:22

 Epoch: 586	Training Loss 0.2429 	Training Prec@1 91.426 	Training Prec@5 99.846 	Validation Loss 0.7483 	Validation Prec@1 79.650 	Validation Prec@5 98.870 

lr: 0.03751663015686964
TRAINING - Epoch: [586][0/391]	Time 0.916 (0.916)	Data 0.347 (0.347)	Loss 0.1969 (0.1969)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [586][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2444 (0.2430)	Prec@1 92.969 (91.484)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [586][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3155 (0.2437)	Prec@1 89.844 (91.352)	Prec@5 99.219 (99.903)
TRAINING - Epoch: [586][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2184 (0.2437)	Prec@1 92.969 (91.328)	Prec@5 100.000 (99.862)
EVALUATING - Epoch: [586][0/79]	Time 0.351 (0.351)	Data 0.329 (0.329)	Loss 0.6107 (0.6107)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:21

 Epoch: 587	Training Loss 0.2512 	Training Prec@1 91.122 	Training Prec@5 99.858 	Validation Loss 0.7302 	Validation Prec@1 79.330 	Validation Prec@5 98.960 

lr: 0.03736397646420132
TRAINING - Epoch: [587][0/391]	Time 0.906 (0.906)	Data 0.351 (0.351)	Loss 0.3274 (0.3274)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [587][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2484 (0.2421)	Prec@1 90.625 (91.460)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [587][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1979 (0.2495)	Prec@1 92.969 (91.154)	Prec@5 100.000 (99.872)
TRAINING - Epoch: [587][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1834 (0.2463)	Prec@1 92.188 (91.354)	Prec@5 100.000 (99.868)
EVALUATING - Epoch: [587][0/79]	Time 0.345 (0.345)	Data 0.324 (0.324)	Loss 0.5512 (0.5512)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:03

 Epoch: 588	Training Loss 0.2478 	Training Prec@1 91.342 	Training Prec@5 99.858 	Validation Loss 0.5250 	Validation Prec@1 84.330 	Validation Prec@5 99.350 

lr: 0.03721144848770099
TRAINING - Epoch: [588][0/391]	Time 0.903 (0.903)	Data 0.346 (0.346)	Loss 0.2586 (0.2586)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [588][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.2553 (0.2515)	Prec@1 90.625 (91.460)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [588][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.3008 (0.2463)	Prec@1 89.844 (91.492)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [588][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2263 (0.2504)	Prec@1 93.750 (91.344)	Prec@5 100.000 (99.847)
EVALUATING - Epoch: [588][0/79]	Time 0.353 (0.353)	Data 0.328 (0.328)	Loss 0.5205 (0.5205)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:20:05

 Epoch: 589	Training Loss 0.2507 	Training Prec@1 91.316 	Training Prec@5 99.854 	Validation Loss 0.5163 	Validation Prec@1 84.960 	Validation Prec@5 99.050 

lr: 0.03705904774487394
TRAINING - Epoch: [589][0/391]	Time 0.923 (0.923)	Data 0.346 (0.346)	Loss 0.1818 (0.1818)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [589][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.2672 (0.2084)	Prec@1 89.844 (92.690)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [589][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1802 (0.2311)	Prec@1 93.750 (91.896)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [589][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1429 (0.2406)	Prec@1 96.875 (91.528)	Prec@5 100.000 (99.852)
EVALUATING - Epoch: [589][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.6679 (0.6679)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:36

 Epoch: 590	Training Loss 0.2481 	Training Prec@1 91.266 	Training Prec@5 99.846 	Validation Loss 0.7036 	Validation Prec@1 80.330 	Validation Prec@5 99.290 

lr: 0.03690677575195966
TRAINING - Epoch: [590][0/391]	Time 0.942 (0.942)	Data 0.355 (0.355)	Loss 0.1721 (0.1721)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [590][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1840 (0.2479)	Prec@1 93.750 (91.050)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [590][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4805 (0.2527)	Prec@1 82.031 (90.920)	Prec@5 100.000 (99.883)
TRAINING - Epoch: [590][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2108 (0.2499)	Prec@1 92.969 (91.139)	Prec@5 100.000 (99.873)
EVALUATING - Epoch: [590][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.5660 (0.5660)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 591	Training Loss 0.2490 	Training Prec@1 91.132 	Training Prec@5 99.856 	Validation Loss 0.6047 	Validation Prec@1 82.340 	Validation Prec@5 99.200 

lr: 0.0367546340239166
TRAINING - Epoch: [591][0/391]	Time 0.947 (0.947)	Data 0.386 (0.386)	Loss 0.2356 (0.2356)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [591][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1562 (0.2306)	Prec@1 96.094 (92.025)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [591][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1686 (0.2449)	Prec@1 92.188 (91.294)	Prec@5 100.000 (99.887)
TRAINING - Epoch: [591][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.2443 (0.2497)	Prec@1 90.625 (91.160)	Prec@5 99.219 (99.865)
EVALUATING - Epoch: [591][0/79]	Time 0.343 (0.343)	Data 0.321 (0.321)	Loss 0.3704 (0.3704)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:52

 Epoch: 592	Training Loss 0.2515 	Training Prec@1 91.090 	Training Prec@5 99.862 	Validation Loss 0.5254 	Validation Prec@1 84.230 	Validation Prec@5 99.300 

lr: 0.03660262407440733
TRAINING - Epoch: [592][0/391]	Time 0.922 (0.922)	Data 0.338 (0.338)	Loss 0.1104 (0.1104)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [592][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2706 (0.2205)	Prec@1 91.406 (92.342)	Prec@5 99.219 (99.861)
TRAINING - Epoch: [592][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2107 (0.2250)	Prec@1 94.531 (92.083)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [592][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.3338 (0.2291)	Prec@1 86.719 (91.938)	Prec@5 100.000 (99.868)
EVALUATING - Epoch: [592][0/79]	Time 0.331 (0.331)	Data 0.311 (0.311)	Loss 0.4920 (0.4920)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:58

 Epoch: 593	Training Loss 0.2349 	Training Prec@1 91.766 	Training Prec@5 99.862 	Validation Loss 0.5340 	Validation Prec@1 84.460 	Validation Prec@5 99.190 

lr: 0.03645074741578323
TRAINING - Epoch: [593][0/391]	Time 0.939 (0.939)	Data 0.369 (0.369)	Loss 0.3159 (0.3159)	Prec@1 90.625 (90.625)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [593][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2968 (0.2461)	Prec@1 89.062 (91.453)	Prec@5 99.219 (99.768)
TRAINING - Epoch: [593][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.1463 (0.2403)	Prec@1 95.312 (91.550)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [593][300/391]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.2175 (0.2380)	Prec@1 91.406 (91.552)	Prec@5 100.000 (99.860)
EVALUATING - Epoch: [593][0/79]	Time 0.374 (0.374)	Data 0.354 (0.354)	Loss 0.6387 (0.6387)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:59

 Epoch: 594	Training Loss 0.2391 	Training Prec@1 91.554 	Training Prec@5 99.860 	Validation Loss 0.5338 	Validation Prec@1 83.720 	Validation Prec@5 99.430 

lr: 0.036299005559069675
TRAINING - Epoch: [594][0/391]	Time 0.919 (0.919)	Data 0.352 (0.352)	Loss 0.1390 (0.1390)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [594][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3124 (0.2156)	Prec@1 89.844 (92.304)	Prec@5 99.219 (99.853)
TRAINING - Epoch: [594][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1639 (0.2244)	Prec@1 91.406 (92.059)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [594][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2781 (0.2288)	Prec@1 89.062 (91.845)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [594][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.5003 (0.5003)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:55

 Epoch: 595	Training Loss 0.2325 	Training Prec@1 91.752 	Training Prec@5 99.882 	Validation Loss 0.5907 	Validation Prec@1 82.720 	Validation Prec@5 98.850 

lr: 0.03614740001395081
TRAINING - Epoch: [595][0/391]	Time 0.953 (0.953)	Data 0.375 (0.375)	Loss 0.3545 (0.3545)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [595][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2193 (0.2378)	Prec@1 91.406 (91.638)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [595][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1968 (0.2383)	Prec@1 94.531 (91.694)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [595][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2510 (0.2367)	Prec@1 92.188 (91.746)	Prec@5 99.219 (99.847)
EVALUATING - Epoch: [595][0/79]	Time 0.373 (0.373)	Data 0.353 (0.353)	Loss 0.5480 (0.5480)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 596	Training Loss 0.2407 	Training Prec@1 91.664 	Training Prec@5 99.844 	Validation Loss 0.5789 	Validation Prec@1 82.760 	Validation Prec@5 99.070 

lr: 0.03599593228875463
TRAINING - Epoch: [596][0/391]	Time 0.909 (0.909)	Data 0.341 (0.341)	Loss 0.1180 (0.1180)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [596][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1734 (0.2450)	Prec@1 92.188 (91.205)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [596][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1457 (0.2408)	Prec@1 93.750 (91.395)	Prec@5 100.000 (99.895)
TRAINING - Epoch: [596][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1627 (0.2439)	Prec@1 94.531 (91.365)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [596][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.3258 (0.3258)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 597	Training Loss 0.2426 	Training Prec@1 91.410 	Training Prec@5 99.890 	Validation Loss 0.5013 	Validation Prec@1 85.420 	Validation Prec@5 99.310 

lr: 0.03584460389043799
TRAINING - Epoch: [597][0/391]	Time 0.927 (0.927)	Data 0.349 (0.349)	Loss 0.2135 (0.2135)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [597][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3112 (0.2237)	Prec@1 89.844 (91.878)	Prec@5 99.219 (99.853)
TRAINING - Epoch: [597][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2601 (0.2332)	Prec@1 91.406 (91.698)	Prec@5 100.000 (99.848)
TRAINING - Epoch: [597][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.2610 (0.2340)	Prec@1 92.969 (91.658)	Prec@5 100.000 (99.875)
EVALUATING - Epoch: [597][0/79]	Time 0.358 (0.358)	Data 0.335 (0.335)	Loss 0.3265 (0.3265)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:33

 Epoch: 598	Training Loss 0.2347 	Training Prec@1 91.654 	Training Prec@5 99.866 	Validation Loss 0.6702 	Validation Prec@1 82.190 	Validation Prec@5 98.960 

lr: 0.03569341632457155
TRAINING - Epoch: [598][0/391]	Time 0.944 (0.944)	Data 0.354 (0.354)	Loss 0.1815 (0.1815)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [598][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2718 (0.2299)	Prec@1 90.625 (92.133)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [598][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2489 (0.2236)	Prec@1 91.406 (92.188)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [598][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.2619 (0.2299)	Prec@1 90.625 (91.944)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [598][0/79]	Time 0.389 (0.389)	Data 0.367 (0.367)	Loss 0.4401 (0.4401)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:56

 Epoch: 599	Training Loss 0.2320 	Training Prec@1 91.816 	Training Prec@5 99.868 	Validation Loss 0.5202 	Validation Prec@1 84.420 	Validation Prec@5 99.330 

lr: 0.03554237109532482
TRAINING - Epoch: [599][0/391]	Time 0.952 (0.952)	Data 0.351 (0.351)	Loss 0.1953 (0.1953)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [599][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1265 (0.2129)	Prec@1 96.094 (92.249)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [599][200/391]	Time 0.072 (0.068)	Data 0.000 (0.002)	Loss 0.2629 (0.2176)	Prec@1 94.531 (92.094)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [599][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1243 (0.2276)	Prec@1 95.312 (91.907)	Prec@5 100.000 (99.899)
EVALUATING - Epoch: [599][0/79]	Time 0.354 (0.354)	Data 0.331 (0.331)	Loss 0.4937 (0.4937)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:04

 Epoch: 600	Training Loss 0.2284 	Training Prec@1 91.954 	Training Prec@5 99.886 	Validation Loss 0.4865 	Validation Prec@1 85.680 	Validation Prec@5 99.260 

lr: 0.03539146970545121
TRAINING - Epoch: [600][0/391]	Time 0.918 (0.918)	Data 0.344 (0.344)	Loss 0.2725 (0.2725)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [600][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.1746 (0.2291)	Prec@1 94.531 (91.700)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [600][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2287 (0.2327)	Prec@1 91.406 (91.608)	Prec@5 100.000 (99.891)
TRAINING - Epoch: [600][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2933 (0.2316)	Prec@1 85.938 (91.642)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [600][0/79]	Time 0.323 (0.323)	Data 0.303 (0.303)	Loss 0.3275 (0.3275)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:13

 Epoch: 601	Training Loss 0.2329 	Training Prec@1 91.588 	Training Prec@5 99.874 	Validation Loss 0.4637 	Validation Prec@1 85.820 	Validation Prec@5 99.480 

lr: 0.035240713656273064
TRAINING - Epoch: [601][0/391]	Time 0.987 (0.987)	Data 0.383 (0.383)	Loss 0.2317 (0.2317)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [601][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.2066 (0.2360)	Prec@1 92.969 (91.391)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [601][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1820 (0.2313)	Prec@1 96.094 (91.663)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [601][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2326 (0.2325)	Prec@1 92.969 (91.759)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [601][0/79]	Time 0.377 (0.377)	Data 0.355 (0.355)	Loss 0.4377 (0.4377)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:09

 Epoch: 602	Training Loss 0.2342 	Training Prec@1 91.710 	Training Prec@5 99.890 	Validation Loss 0.6096 	Validation Prec@1 83.080 	Validation Prec@5 99.220 

lr: 0.03509010444766671
TRAINING - Epoch: [602][0/391]	Time 0.961 (0.961)	Data 0.386 (0.386)	Loss 0.3187 (0.3187)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [602][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1807 (0.2139)	Prec@1 92.969 (92.497)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [602][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2215 (0.2246)	Prec@1 89.844 (92.086)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [602][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3730 (0.2265)	Prec@1 86.719 (92.066)	Prec@5 100.000 (99.904)
EVALUATING - Epoch: [602][0/79]	Time 0.327 (0.327)	Data 0.308 (0.308)	Loss 0.5089 (0.5089)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:10

 Epoch: 603	Training Loss 0.2319 	Training Prec@1 91.882 	Training Prec@5 99.898 	Validation Loss 0.6067 	Validation Prec@1 82.970 	Validation Prec@5 98.910 

lr: 0.034939643578047616
TRAINING - Epoch: [603][0/391]	Time 0.975 (0.975)	Data 0.337 (0.337)	Loss 0.1613 (0.1613)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [603][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.2014 (0.2213)	Prec@1 92.969 (92.064)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [603][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3168 (0.2292)	Prec@1 89.062 (91.970)	Prec@5 99.219 (99.922)
TRAINING - Epoch: [603][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1681 (0.2311)	Prec@1 96.875 (91.915)	Prec@5 99.219 (99.896)
EVALUATING - Epoch: [603][0/79]	Time 0.355 (0.355)	Data 0.334 (0.334)	Loss 0.5411 (0.5411)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:45

 Epoch: 604	Training Loss 0.2322 	Training Prec@1 91.888 	Training Prec@5 99.890 	Validation Loss 0.5895 	Validation Prec@1 82.700 	Validation Prec@5 99.150 

lr: 0.034789332544355324
TRAINING - Epoch: [604][0/391]	Time 1.005 (1.005)	Data 0.382 (0.382)	Loss 0.1835 (0.1835)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [604][100/391]	Time 0.061 (0.073)	Data 0.000 (0.004)	Loss 0.3012 (0.2260)	Prec@1 92.188 (92.048)	Prec@5 99.219 (99.907)
TRAINING - Epoch: [604][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2477 (0.2315)	Prec@1 92.188 (91.838)	Prec@5 99.219 (99.872)
TRAINING - Epoch: [604][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2421 (0.2313)	Prec@1 89.062 (91.806)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [604][0/79]	Time 0.368 (0.368)	Data 0.348 (0.348)	Loss 0.5759 (0.5759)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:41

 Epoch: 605	Training Loss 0.2324 	Training Prec@1 91.778 	Training Prec@5 99.880 	Validation Loss 0.6541 	Validation Prec@1 81.130 	Validation Prec@5 99.170 

lr: 0.034639172842038754
TRAINING - Epoch: [605][0/391]	Time 0.955 (0.955)	Data 0.362 (0.362)	Loss 0.2940 (0.2940)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [605][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.3385 (0.2253)	Prec@1 86.719 (91.863)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [605][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2201 (0.2251)	Prec@1 92.969 (91.962)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [605][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1688 (0.2315)	Prec@1 95.312 (91.785)	Prec@5 100.000 (99.868)
EVALUATING - Epoch: [605][0/79]	Time 0.346 (0.346)	Data 0.326 (0.326)	Loss 0.3294 (0.3294)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 606	Training Loss 0.2298 	Training Prec@1 91.868 	Training Prec@5 99.872 	Validation Loss 0.4918 	Validation Prec@1 85.390 	Validation Prec@5 99.240 

lr: 0.034489165965041146
TRAINING - Epoch: [606][0/391]	Time 0.953 (0.953)	Data 0.354 (0.354)	Loss 0.1399 (0.1399)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [606][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.3096 (0.2155)	Prec@1 86.719 (92.536)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [606][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.0975 (0.2199)	Prec@1 97.656 (92.296)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [606][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.2325 (0.2223)	Prec@1 92.969 (92.154)	Prec@5 100.000 (99.899)
EVALUATING - Epoch: [606][0/79]	Time 0.416 (0.416)	Data 0.397 (0.397)	Loss 0.4642 (0.4642)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:36

 Epoch: 607	Training Loss 0.2276 	Training Prec@1 91.966 	Training Prec@5 99.880 	Validation Loss 0.6272 	Validation Prec@1 82.010 	Validation Prec@5 99.190 

lr: 0.03433931340578532
TRAINING - Epoch: [607][0/391]	Time 0.951 (0.951)	Data 0.355 (0.355)	Loss 0.1281 (0.1281)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [607][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.2784 (0.2191)	Prec@1 89.844 (92.126)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [607][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2797 (0.2265)	Prec@1 87.500 (91.865)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [607][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1780 (0.2270)	Prec@1 94.531 (91.860)	Prec@5 100.000 (99.870)
EVALUATING - Epoch: [607][0/79]	Time 0.352 (0.352)	Data 0.332 (0.332)	Loss 0.5086 (0.5086)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:20

 Epoch: 608	Training Loss 0.2275 	Training Prec@1 91.834 	Training Prec@5 99.874 	Validation Loss 0.5082 	Validation Prec@1 85.090 	Validation Prec@5 99.380 

lr: 0.0341896166551588
TRAINING - Epoch: [608][0/391]	Time 0.933 (0.933)	Data 0.360 (0.360)	Loss 0.2151 (0.2151)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [608][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2342 (0.2243)	Prec@1 89.844 (91.971)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [608][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1620 (0.2225)	Prec@1 96.875 (92.141)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [608][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2319 (0.2283)	Prec@1 90.625 (91.933)	Prec@5 100.000 (99.909)
EVALUATING - Epoch: [608][0/79]	Time 0.387 (0.387)	Data 0.363 (0.363)	Loss 0.4047 (0.4047)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:30

 Epoch: 609	Training Loss 0.2310 	Training Prec@1 91.816 	Training Prec@5 99.888 	Validation Loss 0.5915 	Validation Prec@1 83.560 	Validation Prec@5 99.170 

lr: 0.034040077202498895
TRAINING - Epoch: [609][0/391]	Time 0.950 (0.950)	Data 0.351 (0.351)	Loss 0.3046 (0.3046)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [609][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1467 (0.2163)	Prec@1 92.969 (92.334)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [609][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.3136 (0.2169)	Prec@1 89.062 (92.296)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [609][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1650 (0.2185)	Prec@1 92.188 (92.162)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [609][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.4674 (0.4674)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:36

 Epoch: 610	Training Loss 0.2198 	Training Prec@1 92.160 	Training Prec@5 99.890 	Validation Loss 0.6282 	Validation Prec@1 82.310 	Validation Prec@5 99.080 

lr: 0.03389069653557804
TRAINING - Epoch: [610][0/391]	Time 0.944 (0.944)	Data 0.344 (0.344)	Loss 0.2542 (0.2542)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [610][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2461 (0.2284)	Prec@1 90.625 (91.909)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [610][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3409 (0.2351)	Prec@1 88.281 (91.737)	Prec@5 99.219 (99.856)
TRAINING - Epoch: [610][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2277 (0.2328)	Prec@1 90.625 (91.798)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [610][0/79]	Time 0.378 (0.378)	Data 0.359 (0.359)	Loss 0.4299 (0.4299)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:58

 Epoch: 611	Training Loss 0.2313 	Training Prec@1 91.868 	Training Prec@5 99.864 	Validation Loss 0.5559 	Validation Prec@1 83.950 	Validation Prec@5 99.220 

lr: 0.03374147614058881
TRAINING - Epoch: [611][0/391]	Time 0.975 (0.975)	Data 0.354 (0.354)	Loss 0.2087 (0.2087)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [611][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2490 (0.2220)	Prec@1 91.406 (92.257)	Prec@5 99.219 (99.899)
TRAINING - Epoch: [611][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2490 (0.2198)	Prec@1 90.625 (92.292)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [611][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1425 (0.2196)	Prec@1 93.750 (92.258)	Prec@5 100.000 (99.899)
EVALUATING - Epoch: [611][0/79]	Time 0.404 (0.404)	Data 0.379 (0.379)	Loss 0.4052 (0.4052)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:40

 Epoch: 612	Training Loss 0.2201 	Training Prec@1 92.318 	Training Prec@5 99.886 	Validation Loss 0.5389 	Validation Prec@1 84.480 	Validation Prec@5 99.200 

lr: 0.033592417502129324
TRAINING - Epoch: [612][0/391]	Time 1.001 (1.001)	Data 0.370 (0.370)	Loss 0.1812 (0.1812)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [612][100/391]	Time 0.068 (0.073)	Data 0.000 (0.004)	Loss 0.1604 (0.2184)	Prec@1 93.750 (92.334)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [612][200/391]	Time 0.062 (0.068)	Data 0.001 (0.002)	Loss 0.2197 (0.2173)	Prec@1 91.406 (92.320)	Prec@5 100.000 (99.895)
TRAINING - Epoch: [612][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1654 (0.2202)	Prec@1 94.531 (92.260)	Prec@5 100.000 (99.894)
EVALUATING - Epoch: [612][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.3924 (0.3924)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:59

 Epoch: 613	Training Loss 0.2216 	Training Prec@1 92.260 	Training Prec@5 99.896 	Validation Loss 0.4903 	Validation Prec@1 85.210 	Validation Prec@5 99.220 

lr: 0.03344352210318833
TRAINING - Epoch: [613][0/391]	Time 0.927 (0.927)	Data 0.359 (0.359)	Loss 0.1170 (0.1170)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [613][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.3013 (0.2193)	Prec@1 91.406 (92.350)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [613][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2603 (0.2279)	Prec@1 92.188 (91.993)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [613][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3242 (0.2235)	Prec@1 87.500 (92.094)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [613][0/79]	Time 0.367 (0.367)	Data 0.346 (0.346)	Loss 0.4472 (0.4472)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 614	Training Loss 0.2237 	Training Prec@1 92.112 	Training Prec@5 99.874 	Validation Loss 0.5495 	Validation Prec@1 83.710 	Validation Prec@5 99.110 

lr: 0.03329479142513051
TRAINING - Epoch: [614][0/391]	Time 0.966 (0.966)	Data 0.351 (0.351)	Loss 0.1996 (0.1996)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [614][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.2109 (0.2296)	Prec@1 92.969 (91.940)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [614][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1558 (0.2291)	Prec@1 94.531 (91.939)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [614][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3143 (0.2260)	Prec@1 89.844 (92.060)	Prec@5 99.219 (99.883)
EVALUATING - Epoch: [614][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.6723 (0.6723)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:59

 Epoch: 615	Training Loss 0.2289 	Training Prec@1 91.944 	Training Prec@5 99.882 	Validation Loss 0.6157 	Validation Prec@1 82.420 	Validation Prec@5 98.900 

lr: 0.03314622694768171
TRAINING - Epoch: [615][0/391]	Time 0.948 (0.948)	Data 0.365 (0.365)	Loss 0.2309 (0.2309)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [615][100/391]	Time 0.066 (0.072)	Data 0.000 (0.004)	Loss 0.1313 (0.2206)	Prec@1 93.750 (92.381)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [615][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1877 (0.2219)	Prec@1 92.188 (92.230)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [615][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.1912 (0.2214)	Prec@1 92.188 (92.216)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [615][0/79]	Time 0.353 (0.353)	Data 0.332 (0.332)	Loss 0.4520 (0.4520)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:47

 Epoch: 616	Training Loss 0.2253 	Training Prec@1 92.068 	Training Prec@5 99.888 	Validation Loss 0.5643 	Validation Prec@1 83.510 	Validation Prec@5 99.020 

lr: 0.03299783014891432
TRAINING - Epoch: [616][0/391]	Time 0.960 (0.960)	Data 0.348 (0.348)	Loss 0.2090 (0.2090)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [616][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2647 (0.2116)	Prec@1 90.625 (92.659)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [616][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2192 (0.2157)	Prec@1 91.406 (92.483)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [616][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2837 (0.2233)	Prec@1 89.844 (92.141)	Prec@5 100.000 (99.925)
EVALUATING - Epoch: [616][0/79]	Time 0.359 (0.359)	Data 0.338 (0.338)	Loss 0.4141 (0.4141)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 617	Training Loss 0.2237 	Training Prec@1 92.190 	Training Prec@5 99.918 	Validation Loss 0.5036 	Validation Prec@1 84.930 	Validation Prec@5 99.400 

lr: 0.03284960250523236
TRAINING - Epoch: [617][0/391]	Time 0.974 (0.974)	Data 0.370 (0.370)	Loss 0.3610 (0.3610)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [617][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2356 (0.2305)	Prec@1 91.406 (91.894)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [617][200/391]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.3577 (0.2302)	Prec@1 89.844 (92.036)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [617][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2164 (0.2251)	Prec@1 92.188 (92.167)	Prec@5 100.000 (99.852)
EVALUATING - Epoch: [617][0/79]	Time 0.374 (0.374)	Data 0.353 (0.353)	Loss 0.5221 (0.5221)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 618	Training Loss 0.2225 	Training Prec@1 92.158 	Training Prec@5 99.858 	Validation Loss 0.7114 	Validation Prec@1 81.330 	Validation Prec@5 98.870 

lr: 0.03270154549135706
TRAINING - Epoch: [618][0/391]	Time 0.936 (0.936)	Data 0.344 (0.344)	Loss 0.1658 (0.1658)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [618][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1547 (0.2051)	Prec@1 94.531 (92.814)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [618][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2657 (0.2119)	Prec@1 92.188 (92.436)	Prec@5 100.000 (99.934)
TRAINING - Epoch: [618][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1711 (0.2169)	Prec@1 93.750 (92.239)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [618][0/79]	Time 0.365 (0.365)	Data 0.342 (0.342)	Loss 0.4379 (0.4379)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:35

 Epoch: 619	Training Loss 0.2181 	Training Prec@1 92.228 	Training Prec@5 99.918 	Validation Loss 0.5050 	Validation Prec@1 85.150 	Validation Prec@5 99.080 

lr: 0.03255366058031195
TRAINING - Epoch: [619][0/391]	Time 0.990 (0.990)	Data 0.369 (0.369)	Loss 0.1473 (0.1473)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [619][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2760 (0.2042)	Prec@1 89.844 (92.922)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [619][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2111 (0.2100)	Prec@1 91.406 (92.615)	Prec@5 100.000 (99.895)
TRAINING - Epoch: [619][300/391]	Time 0.063 (0.067)	Data 0.000 (0.001)	Loss 0.2785 (0.2119)	Prec@1 89.844 (92.553)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [619][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.4177 (0.4177)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:59

 Epoch: 620	Training Loss 0.2156 	Training Prec@1 92.376 	Training Prec@5 99.906 	Validation Loss 0.5698 	Validation Prec@1 83.360 	Validation Prec@5 99.130 

lr: 0.03240594924340833
TRAINING - Epoch: [620][0/391]	Time 0.965 (0.965)	Data 0.355 (0.355)	Loss 0.2642 (0.2642)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [620][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1803 (0.2056)	Prec@1 92.969 (92.520)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [620][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1615 (0.2116)	Prec@1 92.188 (92.386)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [620][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2303 (0.2121)	Prec@1 91.406 (92.424)	Prec@5 100.000 (99.920)
EVALUATING - Epoch: [620][0/79]	Time 0.370 (0.370)	Data 0.348 (0.348)	Loss 0.5173 (0.5173)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:00

 Epoch: 621	Training Loss 0.2131 	Training Prec@1 92.452 	Training Prec@5 99.904 	Validation Loss 0.5658 	Validation Prec@1 83.680 	Validation Prec@5 99.150 

lr: 0.03225841295023066
TRAINING - Epoch: [621][0/391]	Time 0.931 (0.931)	Data 0.365 (0.365)	Loss 0.2170 (0.2170)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [621][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2155 (0.2151)	Prec@1 92.188 (92.226)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [621][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2834 (0.2143)	Prec@1 90.625 (92.316)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [621][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2938 (0.2141)	Prec@1 89.062 (92.317)	Prec@5 100.000 (99.909)
EVALUATING - Epoch: [621][0/79]	Time 0.339 (0.339)	Data 0.316 (0.316)	Loss 0.3300 (0.3300)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 622	Training Loss 0.2135 	Training Prec@1 92.388 	Training Prec@5 99.916 	Validation Loss 0.5213 	Validation Prec@1 85.090 	Validation Prec@5 99.090 

lr: 0.03211105316862179
TRAINING - Epoch: [622][0/391]	Time 0.911 (0.911)	Data 0.349 (0.349)	Loss 0.1708 (0.1708)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [622][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2269 (0.2126)	Prec@1 92.188 (92.373)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [622][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2426 (0.2188)	Prec@1 89.844 (92.211)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [622][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2174 (0.2129)	Prec@1 92.969 (92.455)	Prec@5 100.000 (99.914)
EVALUATING - Epoch: [622][0/79]	Time 0.366 (0.366)	Data 0.341 (0.341)	Loss 0.4871 (0.4871)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 623	Training Loss 0.2138 	Training Prec@1 92.384 	Training Prec@5 99.910 	Validation Loss 0.5776 	Validation Prec@1 83.750 	Validation Prec@5 98.940 

lr: 0.031963871364668536
TRAINING - Epoch: [623][0/391]	Time 0.911 (0.911)	Data 0.347 (0.347)	Loss 0.1859 (0.1859)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [623][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2481 (0.2143)	Prec@1 91.406 (92.536)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [623][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2191 (0.2199)	Prec@1 90.625 (92.273)	Prec@5 99.219 (99.899)
TRAINING - Epoch: [623][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2104 (0.2224)	Prec@1 91.406 (92.120)	Prec@5 100.000 (99.904)
EVALUATING - Epoch: [623][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.5540 (0.5540)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:57

 Epoch: 624	Training Loss 0.2180 	Training Prec@1 92.288 	Training Prec@5 99.900 	Validation Loss 0.6142 	Validation Prec@1 83.230 	Validation Prec@5 99.020 

lr: 0.03181686900268693
TRAINING - Epoch: [624][0/391]	Time 0.938 (0.938)	Data 0.361 (0.361)	Loss 0.1622 (0.1622)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [624][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1457 (0.2111)	Prec@1 95.312 (92.450)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [624][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1044 (0.2086)	Prec@1 96.875 (92.615)	Prec@5 99.219 (99.922)
TRAINING - Epoch: [624][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2142 (0.2069)	Prec@1 93.750 (92.616)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [624][0/79]	Time 0.354 (0.354)	Data 0.332 (0.332)	Loss 0.5064 (0.5064)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 625	Training Loss 0.2069 	Training Prec@1 92.688 	Training Prec@5 99.920 	Validation Loss 0.5944 	Validation Prec@1 83.030 	Validation Prec@5 99.190 

lr: 0.031670047545207816
TRAINING - Epoch: [625][0/391]	Time 0.932 (0.932)	Data 0.343 (0.343)	Loss 0.2381 (0.2381)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [625][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2093 (0.2130)	Prec@1 95.312 (92.466)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [625][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2585 (0.2113)	Prec@1 89.062 (92.603)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [625][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1528 (0.2114)	Prec@1 93.750 (92.598)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [625][0/79]	Time 0.350 (0.350)	Data 0.329 (0.329)	Loss 0.4217 (0.4217)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:02

 Epoch: 626	Training Loss 0.2140 	Training Prec@1 92.528 	Training Prec@5 99.918 	Validation Loss 0.5224 	Validation Prec@1 83.890 	Validation Prec@5 99.360 

lr: 0.03152340845296216
TRAINING - Epoch: [626][0/391]	Time 0.955 (0.955)	Data 0.346 (0.346)	Loss 0.2494 (0.2494)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [626][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1639 (0.1984)	Prec@1 95.312 (92.922)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [626][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1258 (0.2016)	Prec@1 94.531 (92.864)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [626][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2519 (0.2054)	Prec@1 92.188 (92.675)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [626][0/79]	Time 0.338 (0.338)	Data 0.319 (0.319)	Loss 0.3676 (0.3676)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 627	Training Loss 0.2049 	Training Prec@1 92.682 	Training Prec@5 99.918 	Validation Loss 0.5732 	Validation Prec@1 84.060 	Validation Prec@5 99.290 

lr: 0.03137695318486655
TRAINING - Epoch: [627][0/391]	Time 0.911 (0.911)	Data 0.349 (0.349)	Loss 0.1512 (0.1512)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [627][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2034 (0.1959)	Prec@1 91.406 (92.845)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [627][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3819 (0.2049)	Prec@1 87.500 (92.728)	Prec@5 99.219 (99.907)
TRAINING - Epoch: [627][300/391]	Time 0.068 (0.065)	Data 0.000 (0.001)	Loss 0.1576 (0.2060)	Prec@1 94.531 (92.686)	Prec@5 100.000 (99.912)
EVALUATING - Epoch: [627][0/79]	Time 0.346 (0.346)	Data 0.319 (0.319)	Loss 0.4319 (0.4319)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:20

 Epoch: 628	Training Loss 0.2048 	Training Prec@1 92.760 	Training Prec@5 99.924 	Validation Loss 0.5153 	Validation Prec@1 85.470 	Validation Prec@5 99.380 

lr: 0.03123068319800879
TRAINING - Epoch: [628][0/391]	Time 0.947 (0.947)	Data 0.371 (0.371)	Loss 0.1051 (0.1051)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [628][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1011 (0.2032)	Prec@1 97.656 (92.984)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [628][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1242 (0.2009)	Prec@1 96.875 (93.085)	Prec@5 100.000 (99.891)
TRAINING - Epoch: [628][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.3328 (0.1992)	Prec@1 86.719 (93.083)	Prec@5 100.000 (99.896)
EVALUATING - Epoch: [628][0/79]	Time 0.338 (0.338)	Data 0.319 (0.319)	Loss 0.4349 (0.4349)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 629	Training Loss 0.2033 	Training Prec@1 92.876 	Training Prec@5 99.888 	Validation Loss 0.5844 	Validation Prec@1 84.040 	Validation Prec@5 99.250 

lr: 0.031084599947633226
TRAINING - Epoch: [629][0/391]	Time 0.924 (0.924)	Data 0.348 (0.348)	Loss 0.2343 (0.2343)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [629][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2759 (0.1880)	Prec@1 92.969 (93.294)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [629][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1326 (0.1959)	Prec@1 95.312 (93.004)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [629][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.3523 (0.2045)	Prec@1 88.281 (92.699)	Prec@5 100.000 (99.894)
EVALUATING - Epoch: [629][0/79]	Time 0.377 (0.377)	Data 0.352 (0.352)	Loss 0.4021 (0.4021)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 630	Training Loss 0.2039 	Training Prec@1 92.732 	Training Prec@5 99.902 	Validation Loss 0.5387 	Validation Prec@1 84.780 	Validation Prec@5 99.250 

lr: 0.030938704887126408
TRAINING - Epoch: [630][0/391]	Time 1.004 (1.004)	Data 0.367 (0.367)	Loss 0.2014 (0.2014)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [630][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1221 (0.1965)	Prec@1 96.094 (92.992)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [630][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1187 (0.1898)	Prec@1 96.875 (93.268)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [630][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1785 (0.1964)	Prec@1 95.312 (92.974)	Prec@5 100.000 (99.925)
EVALUATING - Epoch: [630][0/79]	Time 0.365 (0.365)	Data 0.345 (0.345)	Loss 0.6506 (0.6506)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:17

 Epoch: 631	Training Loss 0.2001 	Training Prec@1 92.874 	Training Prec@5 99.926 	Validation Loss 0.6254 	Validation Prec@1 82.410 	Validation Prec@5 99.170 

lr: 0.03079299946800255
TRAINING - Epoch: [631][0/391]	Time 0.932 (0.932)	Data 0.366 (0.366)	Loss 0.2257 (0.2257)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [631][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1203 (0.1947)	Prec@1 96.094 (93.038)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [631][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2164 (0.1950)	Prec@1 91.406 (93.019)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [631][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2378 (0.1976)	Prec@1 89.844 (93.018)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [631][0/79]	Time 0.371 (0.371)	Data 0.350 (0.350)	Loss 0.5811 (0.5811)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:17

 Epoch: 632	Training Loss 0.1998 	Training Prec@1 92.892 	Training Prec@5 99.940 	Validation Loss 0.5745 	Validation Prec@1 83.620 	Validation Prec@5 99.340 

lr: 0.03064748513988914
TRAINING - Epoch: [632][0/391]	Time 0.929 (0.929)	Data 0.343 (0.343)	Loss 0.2540 (0.2540)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [632][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1355 (0.1901)	Prec@1 93.750 (93.472)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [632][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1789 (0.1972)	Prec@1 94.531 (93.105)	Prec@5 100.000 (99.891)
TRAINING - Epoch: [632][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1861 (0.1988)	Prec@1 92.188 (93.039)	Prec@5 99.219 (99.901)
EVALUATING - Epoch: [632][0/79]	Time 0.374 (0.374)	Data 0.352 (0.352)	Loss 0.4031 (0.4031)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 633	Training Loss 0.1978 	Training Prec@1 93.012 	Training Prec@5 99.904 	Validation Loss 0.5793 	Validation Prec@1 83.680 	Validation Prec@5 99.220 

lr: 0.03050216335051247
TRAINING - Epoch: [633][0/391]	Time 0.953 (0.953)	Data 0.368 (0.368)	Loss 0.1420 (0.1420)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [633][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2051 (0.1958)	Prec@1 91.406 (93.007)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [633][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.1625 (0.1924)	Prec@1 93.750 (93.085)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [633][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2181 (0.1953)	Prec@1 92.188 (93.008)	Prec@5 100.000 (99.925)
EVALUATING - Epoch: [633][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.5097 (0.5097)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 634	Training Loss 0.1970 	Training Prec@1 92.950 	Training Prec@5 99.926 	Validation Loss 0.5510 	Validation Prec@1 84.250 	Validation Prec@5 99.120 

lr: 0.030357035545683312
TRAINING - Epoch: [634][0/391]	Time 0.932 (0.932)	Data 0.363 (0.363)	Loss 0.2014 (0.2014)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [634][100/391]	Time 0.066 (0.071)	Data 0.000 (0.004)	Loss 0.1768 (0.1920)	Prec@1 93.750 (93.154)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [634][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1566 (0.1980)	Prec@1 94.531 (93.066)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [634][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.2343 (0.1994)	Prec@1 93.750 (92.974)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [634][0/79]	Time 0.356 (0.356)	Data 0.336 (0.336)	Loss 0.2853 (0.2853)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:42

 Epoch: 635	Training Loss 0.1988 	Training Prec@1 92.984 	Training Prec@5 99.938 	Validation Loss 0.4703 	Validation Prec@1 86.140 	Validation Prec@5 99.260 

lr: 0.030212103169282394
TRAINING - Epoch: [635][0/391]	Time 0.913 (0.913)	Data 0.342 (0.342)	Loss 0.1663 (0.1663)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [635][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2649 (0.1954)	Prec@1 91.406 (93.147)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [635][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2005 (0.1994)	Prec@1 94.531 (92.953)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [635][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2324 (0.2040)	Prec@1 87.500 (92.771)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [635][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.5442 (0.5442)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 636	Training Loss 0.2030 	Training Prec@1 92.804 	Training Prec@5 99.930 	Validation Loss 0.5314 	Validation Prec@1 84.480 	Validation Prec@5 99.430 

lr: 0.03006736766324622
TRAINING - Epoch: [636][0/391]	Time 0.933 (0.933)	Data 0.344 (0.344)	Loss 0.1995 (0.1995)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [636][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2344 (0.1854)	Prec@1 89.844 (93.417)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [636][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1997 (0.1889)	Prec@1 92.969 (93.377)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [636][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2025 (0.1928)	Prec@1 92.969 (93.239)	Prec@5 100.000 (99.938)
EVALUATING - Epoch: [636][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.4569 (0.4569)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 637	Training Loss 0.1942 	Training Prec@1 93.112 	Training Prec@5 99.930 	Validation Loss 0.5837 	Validation Prec@1 83.480 	Validation Prec@5 99.180 

lr: 0.029922830467552536
TRAINING - Epoch: [637][0/391]	Time 0.949 (0.949)	Data 0.351 (0.351)	Loss 0.2397 (0.2397)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [637][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2538 (0.1871)	Prec@1 90.625 (93.332)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [637][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1713 (0.1952)	Prec@1 93.750 (92.953)	Prec@5 100.000 (99.914)
TRAINING - Epoch: [637][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2338 (0.1955)	Prec@1 93.750 (92.935)	Prec@5 99.219 (99.914)
EVALUATING - Epoch: [637][0/79]	Time 0.371 (0.371)	Data 0.352 (0.352)	Loss 0.6391 (0.6391)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 638	Training Loss 0.1991 	Training Prec@1 92.878 	Training Prec@5 99.920 	Validation Loss 0.5665 	Validation Prec@1 83.130 	Validation Prec@5 99.110 

lr: 0.02977849302020614
TRAINING - Epoch: [638][0/391]	Time 0.955 (0.955)	Data 0.379 (0.379)	Loss 0.1960 (0.1960)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [638][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2321 (0.1871)	Prec@1 90.625 (93.286)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [638][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.3101 (0.1901)	Prec@1 86.719 (93.163)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [638][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1765 (0.1909)	Prec@1 95.312 (93.192)	Prec@5 100.000 (99.927)
EVALUATING - Epoch: [638][0/79]	Time 0.362 (0.362)	Data 0.343 (0.343)	Loss 0.5197 (0.5197)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 639	Training Loss 0.1953 	Training Prec@1 93.042 	Training Prec@5 99.922 	Validation Loss 0.5561 	Validation Prec@1 83.760 	Validation Prec@5 99.230 

lr: 0.029634356757224558
TRAINING - Epoch: [639][0/391]	Time 0.930 (0.930)	Data 0.346 (0.346)	Loss 0.2790 (0.2790)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [639][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1778 (0.1880)	Prec@1 95.312 (93.062)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [639][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1744 (0.1876)	Prec@1 94.531 (93.144)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [639][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1627 (0.1917)	Prec@1 91.406 (93.015)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [639][0/79]	Time 0.368 (0.368)	Data 0.345 (0.345)	Loss 0.5574 (0.5574)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 640	Training Loss 0.1948 	Training Prec@1 92.980 	Training Prec@5 99.938 	Validation Loss 0.6152 	Validation Prec@1 82.840 	Validation Prec@5 99.220 

lr: 0.02949042311262364
TRAINING - Epoch: [640][0/391]	Time 0.971 (0.971)	Data 0.342 (0.342)	Loss 0.1138 (0.1138)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [640][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.2433 (0.2060)	Prec@1 92.188 (92.528)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [640][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1111 (0.2029)	Prec@1 96.875 (92.712)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [640][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2117 (0.1991)	Prec@1 92.188 (92.919)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [640][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.3484 (0.3484)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 641	Training Loss 0.1961 	Training Prec@1 93.030 	Training Prec@5 99.918 	Validation Loss 0.5252 	Validation Prec@1 85.080 	Validation Prec@5 99.330 

lr: 0.029346693518403452
TRAINING - Epoch: [641][0/391]	Time 0.941 (0.941)	Data 0.369 (0.369)	Loss 0.0818 (0.0818)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [641][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1772 (0.1866)	Prec@1 94.531 (93.263)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [641][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2187 (0.1888)	Prec@1 90.625 (93.179)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [641][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.1683 (0.1918)	Prec@1 92.188 (93.150)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [641][0/79]	Time 0.374 (0.374)	Data 0.350 (0.350)	Loss 0.4105 (0.4105)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:22

 Epoch: 642	Training Loss 0.1916 	Training Prec@1 93.136 	Training Prec@5 99.944 	Validation Loss 0.5255 	Validation Prec@1 85.330 	Validation Prec@5 99.330 

lr: 0.02920316940453393
TRAINING - Epoch: [642][0/391]	Time 0.959 (0.959)	Data 0.378 (0.378)	Loss 0.2795 (0.2795)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [642][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2444 (0.1911)	Prec@1 89.844 (93.023)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [642][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2066 (0.1936)	Prec@1 92.969 (93.066)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [642][300/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.1638 (0.1947)	Prec@1 93.750 (93.023)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [642][0/79]	Time 0.331 (0.331)	Data 0.310 (0.310)	Loss 0.2445 (0.2445)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:33

 Epoch: 643	Training Loss 0.1976 	Training Prec@1 92.972 	Training Prec@5 99.916 	Validation Loss 0.5667 	Validation Prec@1 84.070 	Validation Prec@5 99.240 

lr: 0.02905985219894069
TRAINING - Epoch: [643][0/391]	Time 0.915 (0.915)	Data 0.340 (0.340)	Loss 0.1272 (0.1272)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [643][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.1123 (0.1807)	Prec@1 96.875 (93.510)	Prec@5 99.219 (99.923)
TRAINING - Epoch: [643][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.2176 (0.1850)	Prec@1 93.750 (93.326)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [643][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1576 (0.1890)	Prec@1 92.969 (93.192)	Prec@5 100.000 (99.933)
EVALUATING - Epoch: [643][0/79]	Time 0.350 (0.350)	Data 0.325 (0.325)	Loss 0.3690 (0.3690)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 644	Training Loss 0.1911 	Training Prec@1 93.124 	Training Prec@5 99.928 	Validation Loss 0.5283 	Validation Prec@1 84.850 	Validation Prec@5 99.350 

lr: 0.028916743327490797
TRAINING - Epoch: [644][0/391]	Time 0.943 (0.943)	Data 0.355 (0.355)	Loss 0.2234 (0.2234)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [644][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.2441 (0.1988)	Prec@1 90.625 (92.884)	Prec@5 99.219 (99.938)
TRAINING - Epoch: [644][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.3200 (0.1930)	Prec@1 89.844 (93.109)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [644][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1599 (0.1895)	Prec@1 93.750 (93.252)	Prec@5 100.000 (99.912)
EVALUATING - Epoch: [644][0/79]	Time 0.368 (0.368)	Data 0.345 (0.345)	Loss 0.4955 (0.4955)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 645	Training Loss 0.1933 	Training Prec@1 93.106 	Training Prec@5 99.918 	Validation Loss 0.5102 	Validation Prec@1 84.730 	Validation Prec@5 99.360 

lr: 0.02877384421397861
TRAINING - Epoch: [645][0/391]	Time 0.937 (0.937)	Data 0.344 (0.344)	Loss 0.2758 (0.2758)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [645][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1656 (0.1775)	Prec@1 95.312 (93.835)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [645][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2216 (0.1844)	Prec@1 92.969 (93.575)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [645][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1887 (0.1870)	Prec@1 92.969 (93.283)	Prec@5 100.000 (99.927)
EVALUATING - Epoch: [645][0/79]	Time 0.395 (0.395)	Data 0.375 (0.375)	Loss 0.4822 (0.4822)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 646	Training Loss 0.1854 	Training Prec@1 93.404 	Training Prec@5 99.924 	Validation Loss 0.5460 	Validation Prec@1 84.930 	Validation Prec@5 99.350 

lr: 0.02863115628011157
TRAINING - Epoch: [646][0/391]	Time 0.930 (0.930)	Data 0.357 (0.357)	Loss 0.1135 (0.1135)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [646][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.2724 (0.1847)	Prec@1 90.625 (93.348)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [646][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2269 (0.1868)	Prec@1 89.062 (93.385)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [646][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1522 (0.1841)	Prec@1 93.750 (93.462)	Prec@5 100.000 (99.938)
EVALUATING - Epoch: [646][0/79]	Time 0.348 (0.348)	Data 0.328 (0.328)	Loss 0.4924 (0.4924)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:53

 Epoch: 647	Training Loss 0.1867 	Training Prec@1 93.382 	Training Prec@5 99.938 	Validation Loss 0.5610 	Validation Prec@1 84.480 	Validation Prec@5 99.420 

lr: 0.02848868094549614
TRAINING - Epoch: [647][0/391]	Time 0.943 (0.943)	Data 0.367 (0.367)	Loss 0.1750 (0.1750)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [647][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1800 (0.1878)	Prec@1 93.750 (93.209)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [647][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1923 (0.1864)	Prec@1 95.312 (93.186)	Prec@5 99.219 (99.938)
TRAINING - Epoch: [647][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1910 (0.1865)	Prec@1 95.312 (93.278)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [647][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.5900 (0.5900)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 648	Training Loss 0.1858 	Training Prec@1 93.302 	Training Prec@5 99.946 	Validation Loss 0.5428 	Validation Prec@1 84.670 	Validation Prec@5 99.200 

lr: 0.028346419627623565
TRAINING - Epoch: [648][0/391]	Time 0.967 (0.967)	Data 0.360 (0.360)	Loss 0.1782 (0.1782)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [648][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2598 (0.1770)	Prec@1 92.188 (93.765)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [648][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2533 (0.1828)	Prec@1 89.844 (93.420)	Prec@5 99.219 (99.918)
TRAINING - Epoch: [648][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1677 (0.1861)	Prec@1 94.531 (93.358)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [648][0/79]	Time 0.393 (0.393)	Data 0.371 (0.371)	Loss 0.4880 (0.4880)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 649	Training Loss 0.1890 	Training Prec@1 93.232 	Training Prec@5 99.934 	Validation Loss 0.5125 	Validation Prec@1 84.980 	Validation Prec@5 99.440 

lr: 0.02820437374185586
TRAINING - Epoch: [649][0/391]	Time 0.934 (0.934)	Data 0.345 (0.345)	Loss 0.2003 (0.2003)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [649][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.3083 (0.1802)	Prec@1 87.500 (93.487)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [649][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2922 (0.1790)	Prec@1 86.719 (93.517)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [649][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1296 (0.1809)	Prec@1 95.312 (93.452)	Prec@5 100.000 (99.933)
EVALUATING - Epoch: [649][0/79]	Time 0.339 (0.339)	Data 0.316 (0.316)	Loss 0.4670 (0.4670)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 650	Training Loss 0.1831 	Training Prec@1 93.400 	Training Prec@5 99.924 	Validation Loss 0.5355 	Validation Prec@1 85.010 	Validation Prec@5 99.310 

lr: 0.02806254470141173
TRAINING - Epoch: [650][0/391]	Time 0.920 (0.920)	Data 0.346 (0.346)	Loss 0.2660 (0.2660)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [650][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1492 (0.1786)	Prec@1 92.969 (93.711)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [650][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1931 (0.1792)	Prec@1 92.188 (93.727)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [650][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2571 (0.1802)	Prec@1 90.625 (93.612)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [650][0/79]	Time 0.358 (0.358)	Data 0.335 (0.335)	Loss 0.3581 (0.3581)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:53

 Epoch: 651	Training Loss 0.1838 	Training Prec@1 93.438 	Training Prec@5 99.948 	Validation Loss 0.4937 	Validation Prec@1 85.790 	Validation Prec@5 99.380 

lr: 0.027920933917352432
TRAINING - Epoch: [651][0/391]	Time 1.024 (1.024)	Data 0.352 (0.352)	Loss 0.1064 (0.1064)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [651][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1595 (0.1768)	Prec@1 94.531 (93.820)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [651][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.2517 (0.1785)	Prec@1 89.844 (93.789)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [651][300/391]	Time 0.062 (0.067)	Data 0.001 (0.001)	Loss 0.1718 (0.1781)	Prec@1 92.188 (93.734)	Prec@5 100.000 (99.948)
EVALUATING - Epoch: [651][0/79]	Time 0.397 (0.397)	Data 0.376 (0.376)	Loss 0.4269 (0.4269)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:43

 Epoch: 652	Training Loss 0.1761 	Training Prec@1 93.734 	Training Prec@5 99.950 	Validation Loss 0.5197 	Validation Prec@1 85.870 	Validation Prec@5 99.400 

lr: 0.027779542798567793
TRAINING - Epoch: [652][0/391]	Time 0.974 (0.974)	Data 0.390 (0.390)	Loss 0.2100 (0.2100)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [652][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1013 (0.1781)	Prec@1 98.438 (93.758)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [652][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2027 (0.1782)	Prec@1 94.531 (93.633)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [652][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2470 (0.1784)	Prec@1 92.188 (93.664)	Prec@5 100.000 (99.961)
EVALUATING - Epoch: [652][0/79]	Time 0.376 (0.376)	Data 0.351 (0.351)	Loss 0.4389 (0.4389)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:21

 Epoch: 653	Training Loss 0.1797 	Training Prec@1 93.582 	Training Prec@5 99.958 	Validation Loss 0.5508 	Validation Prec@1 84.540 	Validation Prec@5 99.200 

lr: 0.02763837275176221
TRAINING - Epoch: [653][0/391]	Time 1.011 (1.011)	Data 0.354 (0.354)	Loss 0.2823 (0.2823)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [653][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1063 (0.1707)	Prec@1 96.094 (93.881)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [653][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.2608 (0.1736)	Prec@1 93.750 (93.816)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [653][300/391]	Time 0.061 (0.067)	Data 0.001 (0.001)	Loss 0.1495 (0.1738)	Prec@1 95.312 (93.807)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [653][0/79]	Time 0.370 (0.370)	Data 0.346 (0.346)	Loss 0.5046 (0.5046)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:37

 Epoch: 654	Training Loss 0.1763 	Training Prec@1 93.676 	Training Prec@5 99.950 	Validation Loss 0.5045 	Validation Prec@1 85.180 	Validation Prec@5 99.420 

lr: 0.027497425181440598
TRAINING - Epoch: [654][0/391]	Time 0.910 (0.910)	Data 0.342 (0.342)	Loss 0.1792 (0.1792)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [654][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1727 (0.1761)	Prec@1 93.750 (93.812)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [654][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1761 (0.1758)	Prec@1 93.750 (93.746)	Prec@5 100.000 (99.934)
TRAINING - Epoch: [654][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1222 (0.1766)	Prec@1 94.531 (93.685)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [654][0/79]	Time 0.346 (0.346)	Data 0.327 (0.327)	Loss 0.3728 (0.3728)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 655	Training Loss 0.1783 	Training Prec@1 93.588 	Training Prec@5 99.936 	Validation Loss 0.5101 	Validation Prec@1 85.530 	Validation Prec@5 99.160 

lr: 0.027356701489894455
TRAINING - Epoch: [655][0/391]	Time 0.947 (0.947)	Data 0.372 (0.372)	Loss 0.2738 (0.2738)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [655][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1428 (0.1731)	Prec@1 95.312 (93.835)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [655][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.3065 (0.1744)	Prec@1 89.062 (93.769)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [655][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.1058 (0.1738)	Prec@1 96.094 (93.781)	Prec@5 100.000 (99.964)
EVALUATING - Epoch: [655][0/79]	Time 0.361 (0.361)	Data 0.339 (0.339)	Loss 0.4964 (0.4964)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 656	Training Loss 0.1764 	Training Prec@1 93.730 	Training Prec@5 99.954 	Validation Loss 0.5581 	Validation Prec@1 83.980 	Validation Prec@5 99.320 

lr: 0.02721620307718792
TRAINING - Epoch: [656][0/391]	Time 0.923 (0.923)	Data 0.353 (0.353)	Loss 0.1073 (0.1073)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [656][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1653 (0.1694)	Prec@1 96.094 (93.974)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [656][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2305 (0.1761)	Prec@1 91.406 (93.801)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [656][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0929 (0.1764)	Prec@1 97.656 (93.760)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [656][0/79]	Time 0.381 (0.381)	Data 0.360 (0.360)	Loss 0.4835 (0.4835)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:42

 Epoch: 657	Training Loss 0.1767 	Training Prec@1 93.728 	Training Prec@5 99.944 	Validation Loss 0.5491 	Validation Prec@1 84.700 	Validation Prec@5 99.260 

lr: 0.0270759313411438
TRAINING - Epoch: [657][0/391]	Time 1.034 (1.034)	Data 0.355 (0.355)	Loss 0.1618 (0.1618)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [657][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.1663 (0.1680)	Prec@1 93.750 (93.897)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [657][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1799 (0.1709)	Prec@1 92.188 (93.855)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [657][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.0621 (0.1696)	Prec@1 100.000 (93.864)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [657][0/79]	Time 0.367 (0.367)	Data 0.344 (0.344)	Loss 0.4714 (0.4714)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:52

 Epoch: 658	Training Loss 0.1696 	Training Prec@1 93.882 	Training Prec@5 99.946 	Validation Loss 0.5340 	Validation Prec@1 85.280 	Validation Prec@5 99.230 

lr: 0.026935887677329712
TRAINING - Epoch: [658][0/391]	Time 1.005 (1.005)	Data 0.385 (0.385)	Loss 0.1928 (0.1928)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [658][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1499 (0.1600)	Prec@1 96.875 (94.168)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [658][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1663 (0.1672)	Prec@1 92.969 (93.995)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [658][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1968 (0.1736)	Prec@1 93.750 (93.737)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [658][0/79]	Time 0.361 (0.361)	Data 0.342 (0.342)	Loss 0.4332 (0.4332)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:57

 Epoch: 659	Training Loss 0.1724 	Training Prec@1 93.818 	Training Prec@5 99.946 	Validation Loss 0.5800 	Validation Prec@1 83.880 	Validation Prec@5 99.190 

lr: 0.026796073479044162
TRAINING - Epoch: [659][0/391]	Time 0.986 (0.986)	Data 0.345 (0.345)	Loss 0.1771 (0.1771)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [659][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1574 (0.1739)	Prec@1 94.531 (93.866)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [659][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.1477 (0.1721)	Prec@1 94.531 (93.781)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [659][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0960 (0.1720)	Prec@1 96.875 (93.903)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [659][0/79]	Time 0.379 (0.379)	Data 0.358 (0.358)	Loss 0.6019 (0.6019)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:44

 Epoch: 660	Training Loss 0.1724 	Training Prec@1 93.926 	Training Prec@5 99.948 	Validation Loss 0.5166 	Validation Prec@1 85.290 	Validation Prec@5 99.140 

lr: 0.026656490137302702
TRAINING - Epoch: [660][0/391]	Time 0.933 (0.933)	Data 0.360 (0.360)	Loss 0.0890 (0.0890)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [660][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1594 (0.1554)	Prec@1 93.750 (94.493)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [660][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1154 (0.1670)	Prec@1 96.875 (93.987)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [660][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.2036 (0.1691)	Prec@1 94.531 (93.888)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [660][0/79]	Time 0.370 (0.370)	Data 0.346 (0.346)	Loss 0.2696 (0.2696)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:54

 Epoch: 661	Training Loss 0.1693 	Training Prec@1 93.884 	Training Prec@5 99.956 	Validation Loss 0.5041 	Validation Prec@1 85.620 	Validation Prec@5 99.260 

lr: 0.02651713904082407
TRAINING - Epoch: [661][0/391]	Time 0.927 (0.927)	Data 0.348 (0.348)	Loss 0.2047 (0.2047)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [661][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1645 (0.1570)	Prec@1 95.312 (94.284)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [661][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0861 (0.1647)	Prec@1 96.875 (94.131)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [661][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.1141 (0.1659)	Prec@1 97.656 (94.103)	Prec@5 100.000 (99.953)
EVALUATING - Epoch: [661][0/79]	Time 0.349 (0.349)	Data 0.326 (0.326)	Loss 0.6491 (0.6491)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 662	Training Loss 0.1686 	Training Prec@1 94.020 	Training Prec@5 99.948 	Validation Loss 0.5278 	Validation Prec@1 85.090 	Validation Prec@5 99.460 

lr: 0.026378021576016434
TRAINING - Epoch: [662][0/391]	Time 0.959 (0.959)	Data 0.358 (0.358)	Loss 0.2509 (0.2509)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [662][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.2052 (0.1663)	Prec@1 94.531 (94.083)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [662][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1171 (0.1657)	Prec@1 95.312 (94.049)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [662][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2816 (0.1648)	Prec@1 88.281 (94.111)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [662][0/79]	Time 0.332 (0.332)	Data 0.313 (0.313)	Loss 0.4294 (0.4294)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:24

 Epoch: 663	Training Loss 0.1649 	Training Prec@1 94.112 	Training Prec@5 99.968 	Validation Loss 0.4949 	Validation Prec@1 86.250 	Validation Prec@5 99.180 

lr: 0.026239139126963507
TRAINING - Epoch: [663][0/391]	Time 0.931 (0.931)	Data 0.358 (0.358)	Loss 0.1431 (0.1431)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [663][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1758 (0.1707)	Prec@1 91.406 (93.982)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [663][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1638 (0.1679)	Prec@1 94.531 (94.022)	Prec@5 100.000 (99.934)
TRAINING - Epoch: [663][300/391]	Time 0.068 (0.066)	Data 0.000 (0.001)	Loss 0.1560 (0.1688)	Prec@1 93.750 (93.981)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [663][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.4123 (0.4123)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:27

 Epoch: 664	Training Loss 0.1711 	Training Prec@1 93.866 	Training Prec@5 99.938 	Validation Loss 0.4948 	Validation Prec@1 86.140 	Validation Prec@5 99.230 

lr: 0.026100493075410857
TRAINING - Epoch: [664][0/391]	Time 1.017 (1.017)	Data 0.359 (0.359)	Loss 0.1206 (0.1206)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [664][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.1573 (0.1611)	Prec@1 94.531 (94.222)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [664][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1204 (0.1622)	Prec@1 95.312 (94.123)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [664][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1503 (0.1643)	Prec@1 96.094 (94.061)	Prec@5 100.000 (99.953)
EVALUATING - Epoch: [664][0/79]	Time 0.389 (0.389)	Data 0.367 (0.367)	Loss 0.3666 (0.3666)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:59

 Epoch: 665	Training Loss 0.1644 	Training Prec@1 94.040 	Training Prec@5 99.958 	Validation Loss 0.5232 	Validation Prec@1 85.340 	Validation Prec@5 99.410 

lr: 0.02596208480075205
TRAINING - Epoch: [665][0/391]	Time 0.951 (0.951)	Data 0.345 (0.345)	Loss 0.1870 (0.1870)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [665][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.2346 (0.1613)	Prec@1 90.625 (94.206)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [665][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1195 (0.1635)	Prec@1 96.094 (94.119)	Prec@5 99.219 (99.946)
TRAINING - Epoch: [665][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1589 (0.1647)	Prec@1 94.531 (94.061)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [665][0/79]	Time 0.338 (0.338)	Data 0.316 (0.316)	Loss 0.5016 (0.5016)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:09

 Epoch: 666	Training Loss 0.1665 	Training Prec@1 93.992 	Training Prec@5 99.952 	Validation Loss 0.6392 	Validation Prec@1 83.490 	Validation Prec@5 99.110 

lr: 0.025823915680015127
TRAINING - Epoch: [666][0/391]	Time 0.953 (0.953)	Data 0.370 (0.370)	Loss 0.1709 (0.1709)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [666][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.1568 (0.1584)	Prec@1 93.750 (94.493)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [666][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1284 (0.1567)	Prec@1 95.312 (94.504)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [666][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2664 (0.1614)	Prec@1 89.844 (94.282)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [666][0/79]	Time 0.384 (0.384)	Data 0.364 (0.364)	Loss 0.4760 (0.4760)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:05

 Epoch: 667	Training Loss 0.1649 	Training Prec@1 94.164 	Training Prec@5 99.954 	Validation Loss 0.4828 	Validation Prec@1 86.570 	Validation Prec@5 99.310 

lr: 0.025685987087848684
TRAINING - Epoch: [667][0/391]	Time 0.994 (0.994)	Data 0.375 (0.375)	Loss 0.1638 (0.1638)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [667][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.1841 (0.1574)	Prec@1 93.750 (94.284)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [667][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1573 (0.1567)	Prec@1 94.531 (94.399)	Prec@5 99.219 (99.969)
TRAINING - Epoch: [667][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0923 (0.1603)	Prec@1 96.094 (94.256)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [667][0/79]	Time 0.353 (0.353)	Data 0.329 (0.329)	Loss 0.4009 (0.4009)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:42

 Epoch: 668	Training Loss 0.1617 	Training Prec@1 94.220 	Training Prec@5 99.958 	Validation Loss 0.5270 	Validation Prec@1 85.630 	Validation Prec@5 99.290 

lr: 0.025548300396508326
TRAINING - Epoch: [668][0/391]	Time 0.941 (0.941)	Data 0.365 (0.365)	Loss 0.2014 (0.2014)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [668][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.1223 (0.1649)	Prec@1 95.312 (94.152)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [668][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1825 (0.1632)	Prec@1 94.531 (94.181)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [668][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1622 (0.1645)	Prec@1 92.969 (94.142)	Prec@5 100.000 (99.948)
EVALUATING - Epoch: [668][0/79]	Time 0.349 (0.349)	Data 0.329 (0.329)	Loss 0.3808 (0.3808)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:11

 Epoch: 669	Training Loss 0.1644 	Training Prec@1 94.150 	Training Prec@5 99.948 	Validation Loss 0.4824 	Validation Prec@1 86.260 	Validation Prec@5 99.240 

lr: 0.025410856975842982
TRAINING - Epoch: [669][0/391]	Time 0.932 (0.932)	Data 0.352 (0.352)	Loss 0.1449 (0.1449)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [669][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1335 (0.1522)	Prec@1 96.094 (94.624)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [669][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1439 (0.1533)	Prec@1 95.312 (94.504)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [669][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.1010 (0.1572)	Prec@1 97.656 (94.399)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [669][0/79]	Time 0.353 (0.353)	Data 0.328 (0.328)	Loss 0.6738 (0.6738)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:08

 Epoch: 670	Training Loss 0.1607 	Training Prec@1 94.220 	Training Prec@5 99.972 	Validation Loss 0.6217 	Validation Prec@1 83.530 	Validation Prec@5 99.110 

lr: 0.025273658193281257
TRAINING - Epoch: [670][0/391]	Time 0.985 (0.985)	Data 0.355 (0.355)	Loss 0.1082 (0.1082)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [670][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1401 (0.1619)	Prec@1 95.312 (94.268)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [670][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.2463 (0.1596)	Prec@1 92.188 (94.282)	Prec@5 99.219 (99.957)
TRAINING - Epoch: [670][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.2364 (0.1617)	Prec@1 92.969 (94.189)	Prec@5 99.219 (99.958)
EVALUATING - Epoch: [670][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.4774 (0.4774)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:44

 Epoch: 671	Training Loss 0.1594 	Training Prec@1 94.306 	Training Prec@5 99.956 	Validation Loss 0.5040 	Validation Prec@1 86.030 	Validation Prec@5 99.290 

lr: 0.025136705413817864
TRAINING - Epoch: [671][0/391]	Time 0.930 (0.930)	Data 0.353 (0.353)	Loss 0.1492 (0.1492)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [671][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1217 (0.1609)	Prec@1 96.094 (94.237)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [671][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1294 (0.1588)	Prec@1 95.312 (94.380)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [671][300/391]	Time 0.066 (0.066)	Data 0.000 (0.001)	Loss 0.2084 (0.1574)	Prec@1 90.625 (94.363)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [671][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.5101 (0.5101)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 672	Training Loss 0.1591 	Training Prec@1 94.308 	Training Prec@5 99.962 	Validation Loss 0.5364 	Validation Prec@1 85.370 	Validation Prec@5 99.360 

lr: 0.02499999999999998
TRAINING - Epoch: [672][0/391]	Time 0.957 (0.957)	Data 0.370 (0.370)	Loss 0.1002 (0.1002)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [672][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.0955 (0.1565)	Prec@1 96.094 (94.237)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [672][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.2050 (0.1535)	Prec@1 92.188 (94.411)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [672][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1387 (0.1561)	Prec@1 95.312 (94.339)	Prec@5 100.000 (99.961)
EVALUATING - Epoch: [672][0/79]	Time 0.358 (0.358)	Data 0.336 (0.336)	Loss 0.2456 (0.2456)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:05

 Epoch: 673	Training Loss 0.1555 	Training Prec@1 94.388 	Training Prec@5 99.962 	Validation Loss 0.4947 	Validation Prec@1 86.160 	Validation Prec@5 99.420 

lr: 0.02486354331191382
TRAINING - Epoch: [673][0/391]	Time 0.943 (0.943)	Data 0.358 (0.358)	Loss 0.0943 (0.0943)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [673][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0917 (0.1480)	Prec@1 96.094 (94.740)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [673][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1715 (0.1492)	Prec@1 94.531 (94.574)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [673][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.1833 (0.1527)	Prec@1 93.750 (94.518)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [673][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.5024 (0.5024)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 674	Training Loss 0.1535 	Training Prec@1 94.548 	Training Prec@5 99.982 	Validation Loss 0.4945 	Validation Prec@1 86.270 	Validation Prec@5 99.440 

lr: 0.024727336707170963
TRAINING - Epoch: [674][0/391]	Time 0.931 (0.931)	Data 0.335 (0.335)	Loss 0.1207 (0.1207)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [674][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2119 (0.1575)	Prec@1 94.531 (94.168)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [674][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.1822 (0.1505)	Prec@1 92.969 (94.403)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [674][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1272 (0.1544)	Prec@1 94.531 (94.326)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [674][0/79]	Time 0.382 (0.382)	Data 0.360 (0.360)	Loss 0.5709 (0.5709)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:55

 Epoch: 675	Training Loss 0.1563 	Training Prec@1 94.338 	Training Prec@5 99.942 	Validation Loss 0.5260 	Validation Prec@1 85.460 	Validation Prec@5 99.130 

lr: 0.024591381540894866
TRAINING - Epoch: [675][0/391]	Time 0.947 (0.947)	Data 0.369 (0.369)	Loss 0.2430 (0.2430)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [675][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1364 (0.1533)	Prec@1 95.312 (94.330)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [675][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1733 (0.1504)	Prec@1 92.188 (94.555)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [675][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1767 (0.1560)	Prec@1 92.969 (94.331)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [675][0/79]	Time 0.368 (0.368)	Data 0.346 (0.346)	Loss 0.5346 (0.5346)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:44

 Epoch: 676	Training Loss 0.1575 	Training Prec@1 94.334 	Training Prec@5 99.946 	Validation Loss 0.4798 	Validation Prec@1 86.380 	Validation Prec@5 99.380 

lr: 0.024455679165707463
TRAINING - Epoch: [676][0/391]	Time 0.928 (0.928)	Data 0.356 (0.356)	Loss 0.1308 (0.1308)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [676][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1849 (0.1514)	Prec@1 93.750 (94.539)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [676][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0898 (0.1587)	Prec@1 96.094 (94.372)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [676][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1177 (0.1592)	Prec@1 96.094 (94.352)	Prec@5 100.000 (99.938)
EVALUATING - Epoch: [676][0/79]	Time 0.357 (0.357)	Data 0.334 (0.334)	Loss 0.4487 (0.4487)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:23

 Epoch: 677	Training Loss 0.1572 	Training Prec@1 94.370 	Training Prec@5 99.936 	Validation Loss 0.5411 	Validation Prec@1 85.510 	Validation Prec@5 99.270 

lr: 0.02432023093171569
TRAINING - Epoch: [677][0/391]	Time 0.946 (0.946)	Data 0.362 (0.362)	Loss 0.2135 (0.2135)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [677][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1455 (0.1549)	Prec@1 94.531 (94.554)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [677][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1805 (0.1522)	Prec@1 93.750 (94.562)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [677][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1497 (0.1553)	Prec@1 93.750 (94.438)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [677][0/79]	Time 0.342 (0.342)	Data 0.320 (0.320)	Loss 0.4711 (0.4711)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:07

 Epoch: 678	Training Loss 0.1564 	Training Prec@1 94.442 	Training Prec@5 99.956 	Validation Loss 0.5157 	Validation Prec@1 85.000 	Validation Prec@5 99.260 

lr: 0.024185038186497965
TRAINING - Epoch: [678][0/391]	Time 0.962 (0.962)	Data 0.347 (0.347)	Loss 0.1829 (0.1829)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [678][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1181 (0.1536)	Prec@1 96.094 (94.500)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [678][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1703 (0.1526)	Prec@1 94.531 (94.395)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [678][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1001 (0.1556)	Prec@1 96.094 (94.355)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [678][0/79]	Time 0.355 (0.355)	Data 0.331 (0.331)	Loss 0.3450 (0.3450)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:23

 Epoch: 679	Training Loss 0.1508 	Training Prec@1 94.550 	Training Prec@5 99.948 	Validation Loss 0.5124 	Validation Prec@1 86.120 	Validation Prec@5 99.250 

lr: 0.0240501022750909
TRAINING - Epoch: [679][0/391]	Time 0.973 (0.973)	Data 0.377 (0.377)	Loss 0.2293 (0.2293)	Prec@1 95.312 (95.312)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [679][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.2406 (0.1595)	Prec@1 92.969 (94.477)	Prec@5 99.219 (99.938)
TRAINING - Epoch: [679][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1988 (0.1580)	Prec@1 94.531 (94.415)	Prec@5 98.438 (99.934)
TRAINING - Epoch: [679][300/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.1331 (0.1572)	Prec@1 96.875 (94.417)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [679][0/79]	Time 0.382 (0.382)	Data 0.358 (0.358)	Loss 0.5243 (0.5243)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:46

 Epoch: 680	Training Loss 0.1580 	Training Prec@1 94.380 	Training Prec@5 99.952 	Validation Loss 0.5810 	Validation Prec@1 83.530 	Validation Prec@5 99.270 

lr: 0.023915424539975767
TRAINING - Epoch: [680][0/391]	Time 1.029 (1.029)	Data 0.352 (0.352)	Loss 0.0960 (0.0960)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [680][100/391]	Time 0.063 (0.074)	Data 0.000 (0.004)	Loss 0.1548 (0.1438)	Prec@1 94.531 (94.709)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [680][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.0727 (0.1462)	Prec@1 98.438 (94.702)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [680][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0858 (0.1507)	Prec@1 96.094 (94.549)	Prec@5 100.000 (99.971)
EVALUATING - Epoch: [680][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.5526 (0.5526)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:22

 Epoch: 681	Training Loss 0.1511 	Training Prec@1 94.560 	Training Prec@5 99.966 	Validation Loss 0.5299 	Validation Prec@1 85.480 	Validation Prec@5 99.280 

lr: 0.02378100632106535
TRAINING - Epoch: [681][0/391]	Time 0.992 (0.992)	Data 0.371 (0.371)	Loss 0.1112 (0.1112)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [681][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.1901 (0.1529)	Prec@1 93.750 (94.578)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [681][200/391]	Time 0.065 (0.069)	Data 0.000 (0.002)	Loss 0.1011 (0.1485)	Prec@1 96.094 (94.757)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [681][300/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.1652 (0.1504)	Prec@1 91.406 (94.729)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [681][0/79]	Time 0.365 (0.365)	Data 0.343 (0.343)	Loss 0.4569 (0.4569)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:26

 Epoch: 682	Training Loss 0.1505 	Training Prec@1 94.704 	Training Prec@5 99.952 	Validation Loss 0.5058 	Validation Prec@1 86.040 	Validation Prec@5 99.390 

lr: 0.023646848955690417
TRAINING - Epoch: [682][0/391]	Time 0.972 (0.972)	Data 0.376 (0.376)	Loss 0.1776 (0.1776)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [682][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.2364 (0.1366)	Prec@1 92.188 (94.910)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [682][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.1020 (0.1426)	Prec@1 96.094 (94.866)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [682][300/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.1863 (0.1444)	Prec@1 92.188 (94.840)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [682][0/79]	Time 0.401 (0.401)	Data 0.376 (0.376)	Loss 0.5703 (0.5703)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:10

 Epoch: 683	Training Loss 0.1465 	Training Prec@1 94.760 	Training Prec@5 99.970 	Validation Loss 0.5292 	Validation Prec@1 85.630 	Validation Prec@5 99.430 

lr: 0.023512953778586514
TRAINING - Epoch: [683][0/391]	Time 1.012 (1.012)	Data 0.391 (0.391)	Loss 0.1734 (0.1734)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [683][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1193 (0.1430)	Prec@1 93.750 (94.771)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [683][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0965 (0.1488)	Prec@1 97.656 (94.718)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [683][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1940 (0.1496)	Prec@1 90.625 (94.736)	Prec@5 100.000 (99.971)
EVALUATING - Epoch: [683][0/79]	Time 0.395 (0.395)	Data 0.376 (0.376)	Loss 0.5329 (0.5329)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:26:09

 Epoch: 684	Training Loss 0.1487 	Training Prec@1 94.732 	Training Prec@5 99.972 	Validation Loss 0.5295 	Validation Prec@1 85.990 	Validation Prec@5 99.350 

lr: 0.023379322121880722
TRAINING - Epoch: [684][0/391]	Time 0.979 (0.979)	Data 0.365 (0.365)	Loss 0.1179 (0.1179)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [684][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.2090 (0.1329)	Prec@1 92.969 (95.204)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [684][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1919 (0.1440)	Prec@1 92.188 (94.900)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [684][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2524 (0.1472)	Prec@1 89.062 (94.739)	Prec@5 100.000 (99.961)
EVALUATING - Epoch: [684][0/79]	Time 0.356 (0.356)	Data 0.336 (0.336)	Loss 0.3770 (0.3770)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:53

 Epoch: 685	Training Loss 0.1467 	Training Prec@1 94.750 	Training Prec@5 99.958 	Validation Loss 0.4782 	Validation Prec@1 86.650 	Validation Prec@5 99.390 

lr: 0.023245955315078257
TRAINING - Epoch: [685][0/391]	Time 0.945 (0.945)	Data 0.351 (0.351)	Loss 0.1619 (0.1619)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [685][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.1541 (0.1389)	Prec@1 94.531 (95.042)	Prec@5 99.219 (99.946)
TRAINING - Epoch: [685][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1408 (0.1430)	Prec@1 95.312 (94.838)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [685][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.1877 (0.1462)	Prec@1 95.312 (94.767)	Prec@5 100.000 (99.953)
EVALUATING - Epoch: [685][0/79]	Time 0.398 (0.398)	Data 0.376 (0.376)	Loss 0.3126 (0.3126)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:49

 Epoch: 686	Training Loss 0.1450 	Training Prec@1 94.836 	Training Prec@5 99.952 	Validation Loss 0.4870 	Validation Prec@1 86.800 	Validation Prec@5 99.320 

lr: 0.023112854685049405
TRAINING - Epoch: [686][0/391]	Time 0.965 (0.965)	Data 0.378 (0.378)	Loss 0.0702 (0.0702)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [686][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1146 (0.1352)	Prec@1 95.312 (95.057)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [686][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1730 (0.1398)	Prec@1 94.531 (94.994)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [686][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.2204 (0.1394)	Prec@1 91.406 (94.967)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [686][0/79]	Time 0.366 (0.366)	Data 0.341 (0.341)	Loss 0.3546 (0.3546)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:25:10

 Epoch: 687	Training Loss 0.1437 	Training Prec@1 94.810 	Training Prec@5 99.982 	Validation Loss 0.5186 	Validation Prec@1 85.800 	Validation Prec@5 99.380 

lr: 0.022980021556016205
TRAINING - Epoch: [687][0/391]	Time 0.935 (0.935)	Data 0.367 (0.367)	Loss 0.1494 (0.1494)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [687][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.2296 (0.1387)	Prec@1 92.969 (94.903)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [687][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1617 (0.1438)	Prec@1 94.531 (94.815)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [687][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1758 (0.1446)	Prec@1 95.312 (94.817)	Prec@5 100.000 (99.971)
EVALUATING - Epoch: [687][0/79]	Time 0.367 (0.367)	Data 0.346 (0.346)	Loss 0.4528 (0.4528)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:23

 Epoch: 688	Training Loss 0.1446 	Training Prec@1 94.872 	Training Prec@5 99.972 	Validation Loss 0.4929 	Validation Prec@1 86.550 	Validation Prec@5 99.290 

lr: 0.02284745724953938
TRAINING - Epoch: [688][0/391]	Time 0.923 (0.923)	Data 0.342 (0.342)	Loss 0.0967 (0.0967)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [688][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1162 (0.1308)	Prec@1 96.875 (95.243)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [688][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1722 (0.1364)	Prec@1 94.531 (95.033)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [688][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1465 (0.1366)	Prec@1 95.312 (95.035)	Prec@5 100.000 (99.961)
EVALUATING - Epoch: [688][0/79]	Time 0.355 (0.355)	Data 0.335 (0.335)	Loss 0.4714 (0.4714)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:03

 Epoch: 689	Training Loss 0.1393 	Training Prec@1 94.970 	Training Prec@5 99.966 	Validation Loss 0.5085 	Validation Prec@1 85.970 	Validation Prec@5 99.340 

lr: 0.0227151630845051
TRAINING - Epoch: [689][0/391]	Time 0.921 (0.921)	Data 0.335 (0.335)	Loss 0.1313 (0.1313)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [689][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.1698 (0.1382)	Prec@1 95.312 (95.166)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [689][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1414 (0.1387)	Prec@1 93.750 (95.060)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [689][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.1015 (0.1370)	Prec@1 96.875 (95.069)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [689][0/79]	Time 0.361 (0.361)	Data 0.336 (0.336)	Loss 0.4353 (0.4353)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 690	Training Loss 0.1369 	Training Prec@1 95.020 	Training Prec@5 99.982 	Validation Loss 0.5096 	Validation Prec@1 86.230 	Validation Prec@5 99.210 

lr: 0.022583140377111847
TRAINING - Epoch: [690][0/391]	Time 0.950 (0.950)	Data 0.373 (0.373)	Loss 0.1524 (0.1524)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [690][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1132 (0.1332)	Prec@1 96.094 (95.042)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [690][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.1841 (0.1373)	Prec@1 93.750 (94.947)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [690][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1136 (0.1365)	Prec@1 96.875 (95.056)	Prec@5 100.000 (99.979)
EVALUATING - Epoch: [690][0/79]	Time 0.385 (0.385)	Data 0.361 (0.361)	Loss 0.3985 (0.3985)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:18

 Epoch: 691	Training Loss 0.1369 	Training Prec@1 95.090 	Training Prec@5 99.980 	Validation Loss 0.5378 	Validation Prec@1 85.820 	Validation Prec@5 99.450 

lr: 0.022451390440857397
TRAINING - Epoch: [691][0/391]	Time 0.935 (0.935)	Data 0.351 (0.351)	Loss 0.0878 (0.0878)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [691][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.2456 (0.1351)	Prec@1 94.531 (95.088)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [691][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.1466 (0.1323)	Prec@1 94.531 (95.211)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [691][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1041 (0.1317)	Prec@1 96.875 (95.232)	Prec@5 100.000 (99.979)
EVALUATING - Epoch: [691][0/79]	Time 0.360 (0.360)	Data 0.341 (0.341)	Loss 0.4664 (0.4664)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:21:59

 Epoch: 692	Training Loss 0.1329 	Training Prec@1 95.238 	Training Prec@5 99.978 	Validation Loss 0.5138 	Validation Prec@1 86.360 	Validation Prec@5 99.410 

lr: 0.022319914586525765
TRAINING - Epoch: [692][0/391]	Time 0.915 (0.915)	Data 0.345 (0.345)	Loss 0.1081 (0.1081)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [692][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0959 (0.1358)	Prec@1 96.875 (95.212)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [692][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1668 (0.1381)	Prec@1 93.750 (95.161)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [692][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1374 (0.1351)	Prec@1 96.094 (95.178)	Prec@5 100.000 (99.953)
EVALUATING - Epoch: [692][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.4446 (0.4446)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:03

 Epoch: 693	Training Loss 0.1352 	Training Prec@1 95.164 	Training Prec@5 99.956 	Validation Loss 0.5392 	Validation Prec@1 85.650 	Validation Prec@5 99.190 

lr: 0.022188714122174054
TRAINING - Epoch: [693][0/391]	Time 0.944 (0.944)	Data 0.371 (0.371)	Loss 0.0729 (0.0729)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [693][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.2375 (0.1267)	Prec@1 92.188 (95.413)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [693][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1111 (0.1317)	Prec@1 96.094 (95.184)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [693][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1580 (0.1307)	Prec@1 95.312 (95.276)	Prec@5 100.000 (99.971)
EVALUATING - Epoch: [693][0/79]	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.4880 (0.4880)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 694	Training Loss 0.1308 	Training Prec@1 95.272 	Training Prec@5 99.976 	Validation Loss 0.5174 	Validation Prec@1 85.890 	Validation Prec@5 99.330 

lr: 0.022057790353119507
TRAINING - Epoch: [694][0/391]	Time 0.898 (0.898)	Data 0.339 (0.339)	Loss 0.1664 (0.1664)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [694][100/391]	Time 0.063 (0.070)	Data 0.000 (0.004)	Loss 0.2215 (0.1245)	Prec@1 92.188 (95.661)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [694][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1346 (0.1315)	Prec@1 92.969 (95.231)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [694][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.0675 (0.1316)	Prec@1 97.656 (95.302)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [694][0/79]	Time 0.379 (0.379)	Data 0.356 (0.356)	Loss 0.4607 (0.4607)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:30

 Epoch: 695	Training Loss 0.1325 	Training Prec@1 95.256 	Training Prec@5 99.978 	Validation Loss 0.5076 	Validation Prec@1 86.200 	Validation Prec@5 99.370 

lr: 0.021927144581926586
TRAINING - Epoch: [695][0/391]	Time 0.958 (0.958)	Data 0.380 (0.380)	Loss 0.2137 (0.2137)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [695][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0418 (0.1388)	Prec@1 100.000 (95.111)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [695][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1535 (0.1328)	Prec@1 95.312 (95.336)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [695][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1261 (0.1305)	Prec@1 95.312 (95.445)	Prec@5 100.000 (99.969)
EVALUATING - Epoch: [695][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.3104 (0.3104)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:23

 Epoch: 696	Training Loss 0.1321 	Training Prec@1 95.362 	Training Prec@5 99.972 	Validation Loss 0.4995 	Validation Prec@1 86.710 	Validation Prec@5 99.360 

lr: 0.021796778108393835
TRAINING - Epoch: [696][0/391]	Time 0.957 (0.957)	Data 0.359 (0.359)	Loss 0.1060 (0.1060)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [696][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0645 (0.1303)	Prec@1 97.656 (95.328)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [696][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1883 (0.1314)	Prec@1 92.188 (95.192)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [696][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0553 (0.1323)	Prec@1 97.656 (95.136)	Prec@5 100.000 (99.979)
EVALUATING - Epoch: [696][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.4708 (0.4708)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 697	Training Loss 0.1327 	Training Prec@1 95.164 	Training Prec@5 99.974 	Validation Loss 0.4899 	Validation Prec@1 86.470 	Validation Prec@5 99.390 

lr: 0.02166669222954113
TRAINING - Epoch: [697][0/391]	Time 0.933 (0.933)	Data 0.363 (0.363)	Loss 0.1219 (0.1219)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [697][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1791 (0.1129)	Prec@1 94.531 (95.800)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [697][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2010 (0.1162)	Prec@1 95.312 (95.736)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [697][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1574 (0.1231)	Prec@1 93.750 (95.572)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [697][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.4350 (0.4350)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 698	Training Loss 0.1247 	Training Prec@1 95.488 	Training Prec@5 99.976 	Validation Loss 0.5165 	Validation Prec@1 86.330 	Validation Prec@5 99.320 

lr: 0.021536888239596683
TRAINING - Epoch: [698][0/391]	Time 0.960 (0.960)	Data 0.357 (0.357)	Loss 0.0885 (0.0885)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [698][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0948 (0.1301)	Prec@1 96.875 (95.382)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [698][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1319 (0.1242)	Prec@1 93.750 (95.476)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [698][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0952 (0.1248)	Prec@1 96.094 (95.481)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [698][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.4005 (0.4005)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:58

 Epoch: 699	Training Loss 0.1243 	Training Prec@1 95.494 	Training Prec@5 99.972 	Validation Loss 0.5460 	Validation Prec@1 85.680 	Validation Prec@5 99.290 

lr: 0.02140736742998422
TRAINING - Epoch: [699][0/391]	Time 0.920 (0.920)	Data 0.339 (0.339)	Loss 0.0979 (0.0979)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [699][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.0419 (0.1220)	Prec@1 99.219 (95.684)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [699][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.2280 (0.1215)	Prec@1 92.188 (95.701)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [699][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0673 (0.1215)	Prec@1 97.656 (95.616)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [699][0/79]	Time 0.387 (0.387)	Data 0.365 (0.365)	Loss 0.4047 (0.4047)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 700	Training Loss 0.1248 	Training Prec@1 95.502 	Training Prec@5 99.982 	Validation Loss 0.4903 	Validation Prec@1 86.450 	Validation Prec@5 99.260 

lr: 0.021278131089310058
TRAINING - Epoch: [700][0/391]	Time 0.936 (0.936)	Data 0.372 (0.372)	Loss 0.1261 (0.1261)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [700][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0783 (0.1218)	Prec@1 96.875 (95.483)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [700][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0599 (0.1212)	Prec@1 97.656 (95.588)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [700][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1600 (0.1234)	Prec@1 95.312 (95.484)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [700][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.4012 (0.4012)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:30

 Epoch: 701	Training Loss 0.1243 	Training Prec@1 95.486 	Training Prec@5 99.982 	Validation Loss 0.4612 	Validation Prec@1 87.550 	Validation Prec@5 99.380 

lr: 0.0211491805033503
TRAINING - Epoch: [701][0/391]	Time 0.950 (0.950)	Data 0.365 (0.365)	Loss 0.1455 (0.1455)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [701][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1025 (0.1277)	Prec@1 97.656 (95.212)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [701][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1340 (0.1274)	Prec@1 93.750 (95.375)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [701][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.1421 (0.1274)	Prec@1 94.531 (95.354)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [701][0/79]	Time 0.370 (0.370)	Data 0.347 (0.347)	Loss 0.3539 (0.3539)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:03

 Epoch: 702	Training Loss 0.1289 	Training Prec@1 95.346 	Training Prec@5 99.982 	Validation Loss 0.4937 	Validation Prec@1 86.690 	Validation Prec@5 99.370 

lr: 0.021020516955038107
TRAINING - Epoch: [702][0/391]	Time 0.920 (0.920)	Data 0.349 (0.349)	Loss 0.1344 (0.1344)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [702][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1173 (0.1250)	Prec@1 96.094 (95.637)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [702][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1891 (0.1236)	Prec@1 92.969 (95.565)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [702][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1509 (0.1258)	Prec@1 96.094 (95.471)	Prec@5 100.000 (99.969)
EVALUATING - Epoch: [702][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.4150 (0.4150)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 703	Training Loss 0.1254 	Training Prec@1 95.548 	Training Prec@5 99.974 	Validation Loss 0.4814 	Validation Prec@1 86.510 	Validation Prec@5 99.470 

lr: 0.020892141724450915
TRAINING - Epoch: [703][0/391]	Time 0.943 (0.943)	Data 0.351 (0.351)	Loss 0.1804 (0.1804)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [703][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1270 (0.1223)	Prec@1 96.875 (95.560)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [703][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1623 (0.1225)	Prec@1 95.312 (95.464)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [703][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0990 (0.1216)	Prec@1 96.094 (95.510)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [703][0/79]	Time 0.353 (0.353)	Data 0.329 (0.329)	Loss 0.3598 (0.3598)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 704	Training Loss 0.1231 	Training Prec@1 95.478 	Training Prec@5 99.980 	Validation Loss 0.5161 	Validation Prec@1 86.160 	Validation Prec@5 99.310 

lr: 0.020764056088797635
TRAINING - Epoch: [704][0/391]	Time 0.946 (0.946)	Data 0.348 (0.348)	Loss 0.0491 (0.0491)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [704][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0471 (0.1235)	Prec@1 97.656 (95.537)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [704][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0901 (0.1195)	Prec@1 96.094 (95.647)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [704][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1026 (0.1185)	Prec@1 96.875 (95.723)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [704][0/79]	Time 0.354 (0.354)	Data 0.332 (0.332)	Loss 0.3570 (0.3570)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:41

 Epoch: 705	Training Loss 0.1211 	Training Prec@1 95.644 	Training Prec@5 99.980 	Validation Loss 0.4951 	Validation Prec@1 86.380 	Validation Prec@5 99.460 

lr: 0.02063626132240601
TRAINING - Epoch: [705][0/391]	Time 0.927 (0.927)	Data 0.347 (0.347)	Loss 0.1593 (0.1593)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [705][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1173 (0.1128)	Prec@1 96.094 (95.947)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [705][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1080 (0.1141)	Prec@1 96.094 (95.931)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [705][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0865 (0.1144)	Prec@1 98.438 (95.959)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [705][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.4299 (0.4299)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:25

 Epoch: 706	Training Loss 0.1163 	Training Prec@1 95.886 	Training Prec@5 99.982 	Validation Loss 0.4990 	Validation Prec@1 86.850 	Validation Prec@5 99.510 

lr: 0.020508758696709904
TRAINING - Epoch: [706][0/391]	Time 0.979 (0.979)	Data 0.344 (0.344)	Loss 0.1073 (0.1073)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [706][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.0635 (0.1218)	Prec@1 97.656 (95.846)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [706][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1168 (0.1181)	Prec@1 96.094 (95.876)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [706][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1545 (0.1173)	Prec@1 96.094 (95.904)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [706][0/79]	Time 0.356 (0.356)	Data 0.335 (0.335)	Loss 0.4233 (0.4233)	Prec@1 86.719 (86.719)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:25

 Epoch: 707	Training Loss 0.1163 	Training Prec@1 95.896 	Training Prec@5 99.976 	Validation Loss 0.5138 	Validation Prec@1 86.510 	Validation Prec@5 99.330 

lr: 0.020381549480236676
TRAINING - Epoch: [707][0/391]	Time 0.943 (0.943)	Data 0.360 (0.360)	Loss 0.0594 (0.0594)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [707][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1015 (0.1157)	Prec@1 96.875 (95.885)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [707][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0555 (0.1136)	Prec@1 99.219 (95.993)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [707][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1653 (0.1136)	Prec@1 95.312 (96.026)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [707][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.3356 (0.3356)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:55

 Epoch: 708	Training Loss 0.1137 	Training Prec@1 95.978 	Training Prec@5 99.972 	Validation Loss 0.4747 	Validation Prec@1 87.220 	Validation Prec@5 99.490 

lr: 0.020254634938594543
TRAINING - Epoch: [708][0/391]	Time 0.947 (0.947)	Data 0.358 (0.358)	Loss 0.1238 (0.1238)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [708][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.1156 (0.1167)	Prec@1 97.656 (95.668)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [708][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0883 (0.1142)	Prec@1 96.094 (95.736)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [708][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1253 (0.1148)	Prec@1 96.875 (95.756)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [708][0/79]	Time 0.358 (0.358)	Data 0.337 (0.337)	Loss 0.3272 (0.3272)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:58

 Epoch: 709	Training Loss 0.1152 	Training Prec@1 95.770 	Training Prec@5 99.980 	Validation Loss 0.4751 	Validation Prec@1 87.340 	Validation Prec@5 99.610 

lr: 0.020128016334459972
TRAINING - Epoch: [709][0/391]	Time 0.930 (0.930)	Data 0.347 (0.347)	Loss 0.0883 (0.0883)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [709][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1959 (0.1056)	Prec@1 93.750 (96.248)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [709][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1009 (0.1097)	Prec@1 96.875 (96.035)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [709][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0992 (0.1103)	Prec@1 96.875 (96.029)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [709][0/79]	Time 0.360 (0.360)	Data 0.334 (0.334)	Loss 0.5701 (0.5701)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 710	Training Loss 0.1109 	Training Prec@1 96.016 	Training Prec@5 99.988 	Validation Loss 0.5116 	Validation Prec@1 86.690 	Validation Prec@5 99.460 

lr: 0.02000169492756522
TRAINING - Epoch: [710][0/391]	Time 0.961 (0.961)	Data 0.367 (0.367)	Loss 0.0717 (0.0717)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [710][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0840 (0.1080)	Prec@1 98.438 (96.202)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [710][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.1279 (0.1134)	Prec@1 92.188 (96.000)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [710][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0651 (0.1118)	Prec@1 97.656 (96.060)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [710][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.4001 (0.4001)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:40

 Epoch: 711	Training Loss 0.1124 	Training Prec@1 95.998 	Training Prec@5 99.988 	Validation Loss 0.5193 	Validation Prec@1 86.750 	Validation Prec@5 99.300 

lr: 0.019875671974685608
TRAINING - Epoch: [711][0/391]	Time 0.920 (0.920)	Data 0.339 (0.339)	Loss 0.0805 (0.0805)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [711][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0678 (0.1120)	Prec@1 96.875 (96.009)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [711][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1200 (0.1116)	Prec@1 95.312 (96.070)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [711][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0865 (0.1096)	Prec@1 95.312 (96.143)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [711][0/79]	Time 0.350 (0.350)	Data 0.329 (0.329)	Loss 0.4071 (0.4071)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:33

 Epoch: 712	Training Loss 0.1121 	Training Prec@1 96.050 	Training Prec@5 99.988 	Validation Loss 0.5151 	Validation Prec@1 86.330 	Validation Prec@5 99.490 

lr: 0.019749948729627195
TRAINING - Epoch: [712][0/391]	Time 0.890 (0.890)	Data 0.336 (0.336)	Loss 0.0304 (0.0304)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [712][100/391]	Time 0.062 (0.070)	Data 0.000 (0.003)	Loss 0.1639 (0.1078)	Prec@1 92.969 (96.233)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [712][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0774 (0.1078)	Prec@1 96.875 (96.206)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [712][300/391]	Time 0.060 (0.064)	Data 0.000 (0.001)	Loss 0.1173 (0.1073)	Prec@1 95.312 (96.156)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [712][0/79]	Time 0.366 (0.366)	Data 0.342 (0.342)	Loss 0.3620 (0.3620)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:20:57

 Epoch: 713	Training Loss 0.1080 	Training Prec@1 96.112 	Training Prec@5 99.990 	Validation Loss 0.5087 	Validation Prec@1 86.950 	Validation Prec@5 99.520 

lr: 0.019624526443214215
TRAINING - Epoch: [713][0/391]	Time 0.916 (0.916)	Data 0.360 (0.360)	Loss 0.0568 (0.0568)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [713][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0460 (0.1112)	Prec@1 98.438 (96.179)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [713][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1462 (0.1095)	Prec@1 95.312 (96.121)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [713][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1473 (0.1079)	Prec@1 96.094 (96.169)	Prec@5 99.219 (99.987)
EVALUATING - Epoch: [713][0/79]	Time 0.346 (0.346)	Data 0.324 (0.324)	Loss 0.5103 (0.5103)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:27

 Epoch: 714	Training Loss 0.1079 	Training Prec@1 96.172 	Training Prec@5 99.984 	Validation Loss 0.5275 	Validation Prec@1 86.420 	Validation Prec@5 99.410 

lr: 0.0194994063632767
TRAINING - Epoch: [714][0/391]	Time 0.955 (0.955)	Data 0.355 (0.355)	Loss 0.1534 (0.1534)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [714][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1230 (0.1044)	Prec@1 94.531 (96.310)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [714][200/391]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.0715 (0.1051)	Prec@1 97.656 (96.296)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [714][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1306 (0.1058)	Prec@1 95.312 (96.229)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [714][0/79]	Time 0.345 (0.345)	Data 0.323 (0.323)	Loss 0.5167 (0.5167)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:03

 Epoch: 715	Training Loss 0.1052 	Training Prec@1 96.240 	Training Prec@5 99.982 	Validation Loss 0.5468 	Validation Prec@1 86.400 	Validation Prec@5 99.420 

lr: 0.019374589734637987
TRAINING - Epoch: [715][0/391]	Time 0.916 (0.916)	Data 0.350 (0.350)	Loss 0.0827 (0.0827)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [715][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1408 (0.0989)	Prec@1 95.312 (96.488)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [715][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1618 (0.1013)	Prec@1 95.312 (96.444)	Prec@5 99.219 (99.981)
TRAINING - Epoch: [715][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0983 (0.1008)	Prec@1 96.875 (96.447)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [715][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.5591 (0.5591)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 716	Training Loss 0.1027 	Training Prec@1 96.376 	Training Prec@5 99.976 	Validation Loss 0.4938 	Validation Prec@1 86.760 	Validation Prec@5 99.430 

lr: 0.01925007779910231
TRAINING - Epoch: [716][0/391]	Time 0.913 (0.913)	Data 0.349 (0.349)	Loss 0.0963 (0.0963)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [716][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.2206 (0.1061)	Prec@1 90.625 (96.148)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [716][200/391]	Time 0.067 (0.067)	Data 0.000 (0.002)	Loss 0.0518 (0.1026)	Prec@1 99.219 (96.276)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [716][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0615 (0.1021)	Prec@1 96.875 (96.312)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [716][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.4770 (0.4770)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 717	Training Loss 0.1022 	Training Prec@1 96.308 	Training Prec@5 99.996 	Validation Loss 0.4977 	Validation Prec@1 87.000 	Validation Prec@5 99.460 

lr: 0.019125871795442617
TRAINING - Epoch: [717][0/391]	Time 0.914 (0.914)	Data 0.349 (0.349)	Loss 0.0741 (0.0741)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [717][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1372 (0.1002)	Prec@1 93.750 (96.519)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [717][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.1040 (0.1013)	Prec@1 96.875 (96.447)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [717][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1606 (0.1006)	Prec@1 94.531 (96.429)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [717][0/79]	Time 0.366 (0.366)	Data 0.346 (0.346)	Loss 0.2901 (0.2901)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 718	Training Loss 0.0997 	Training Prec@1 96.422 	Training Prec@5 99.986 	Validation Loss 0.4815 	Validation Prec@1 87.350 	Validation Prec@5 99.390 

lr: 0.019001972959388057
TRAINING - Epoch: [718][0/391]	Time 0.913 (0.913)	Data 0.343 (0.343)	Loss 0.0941 (0.0941)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [718][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0403 (0.1097)	Prec@1 99.219 (96.040)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [718][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0841 (0.1061)	Prec@1 96.875 (96.203)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [718][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0485 (0.1050)	Prec@1 98.438 (96.203)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [718][0/79]	Time 0.339 (0.339)	Data 0.318 (0.318)	Loss 0.3923 (0.3923)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 719	Training Loss 0.1023 	Training Prec@1 96.324 	Training Prec@5 99.992 	Validation Loss 0.4880 	Validation Prec@1 87.170 	Validation Prec@5 99.390 

lr: 0.018878382523611775
TRAINING - Epoch: [719][0/391]	Time 0.922 (0.922)	Data 0.352 (0.352)	Loss 0.0833 (0.0833)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [719][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0772 (0.0968)	Prec@1 96.875 (96.504)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [719][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1208 (0.1016)	Prec@1 95.312 (96.409)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [719][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0267 (0.1008)	Prec@1 98.438 (96.348)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [719][0/79]	Time 0.357 (0.357)	Data 0.333 (0.333)	Loss 0.4959 (0.4959)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 720	Training Loss 0.1016 	Training Prec@1 96.294 	Training Prec@5 99.988 	Validation Loss 0.5201 	Validation Prec@1 86.660 	Validation Prec@5 99.480 

lr: 0.01875510171771862
TRAINING - Epoch: [720][0/391]	Time 0.919 (0.919)	Data 0.339 (0.339)	Loss 0.1039 (0.1039)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [720][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1116 (0.0952)	Prec@1 94.531 (96.627)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [720][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0941 (0.0984)	Prec@1 96.875 (96.642)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [720][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1433 (0.0996)	Prec@1 95.312 (96.491)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [720][0/79]	Time 0.329 (0.329)	Data 0.309 (0.309)	Loss 0.3802 (0.3802)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 721	Training Loss 0.1003 	Training Prec@1 96.464 	Training Prec@5 99.982 	Validation Loss 0.4820 	Validation Prec@1 87.530 	Validation Prec@5 99.440 

lr: 0.01863213176823298
TRAINING - Epoch: [721][0/391]	Time 0.895 (0.895)	Data 0.343 (0.343)	Loss 0.0613 (0.0613)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [721][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0750 (0.0906)	Prec@1 97.656 (96.829)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [721][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0764 (0.0977)	Prec@1 97.656 (96.533)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [721][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1193 (0.0976)	Prec@1 94.531 (96.499)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [721][0/79]	Time 0.343 (0.343)	Data 0.322 (0.322)	Loss 0.3509 (0.3509)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 722	Training Loss 0.0971 	Training Prec@1 96.502 	Training Prec@5 99.992 	Validation Loss 0.4853 	Validation Prec@1 87.690 	Validation Prec@5 99.520 

lr: 0.018509473898586436
TRAINING - Epoch: [722][0/391]	Time 0.909 (0.909)	Data 0.349 (0.349)	Loss 0.0738 (0.0738)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [722][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0994 (0.0894)	Prec@1 95.312 (96.550)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [722][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1072 (0.0964)	Prec@1 96.875 (96.440)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [722][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0464 (0.0962)	Prec@1 97.656 (96.452)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [722][0/79]	Time 0.372 (0.372)	Data 0.349 (0.349)	Loss 0.4036 (0.4036)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 723	Training Loss 0.0968 	Training Prec@1 96.432 	Training Prec@5 99.992 	Validation Loss 0.5114 	Validation Prec@1 86.750 	Validation Prec@5 99.450 

lr: 0.018387129329105727
TRAINING - Epoch: [723][0/391]	Time 0.899 (0.899)	Data 0.339 (0.339)	Loss 0.0558 (0.0558)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [723][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0552 (0.0868)	Prec@1 98.438 (96.883)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [723][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1617 (0.0920)	Prec@1 95.312 (96.634)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [723][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1211 (0.0956)	Prec@1 95.312 (96.501)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [723][0/79]	Time 0.365 (0.365)	Data 0.341 (0.341)	Loss 0.3513 (0.3513)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 724	Training Loss 0.0962 	Training Prec@1 96.524 	Training Prec@5 99.992 	Validation Loss 0.4840 	Validation Prec@1 87.790 	Validation Prec@5 99.390 

lr: 0.018265099277000582
TRAINING - Epoch: [724][0/391]	Time 0.913 (0.913)	Data 0.356 (0.356)	Loss 0.0916 (0.0916)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [724][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0702 (0.0955)	Prec@1 97.656 (96.635)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [724][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1344 (0.0946)	Prec@1 96.094 (96.661)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [724][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0859 (0.0965)	Prec@1 97.656 (96.577)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [724][0/79]	Time 0.359 (0.359)	Data 0.338 (0.338)	Loss 0.3577 (0.3577)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 725	Training Loss 0.0952 	Training Prec@1 96.652 	Training Prec@5 99.986 	Validation Loss 0.4916 	Validation Prec@1 87.690 	Validation Prec@5 99.470 

lr: 0.018143384956351545
TRAINING - Epoch: [725][0/391]	Time 0.937 (0.937)	Data 0.364 (0.364)	Loss 0.0250 (0.0250)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [725][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1153 (0.0839)	Prec@1 95.312 (96.960)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [725][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0635 (0.0868)	Prec@1 97.656 (96.836)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [725][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1043 (0.0902)	Prec@1 96.875 (96.704)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [725][0/79]	Time 0.353 (0.353)	Data 0.329 (0.329)	Loss 0.3923 (0.3923)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 726	Training Loss 0.0909 	Training Prec@1 96.732 	Training Prec@5 99.988 	Validation Loss 0.5216 	Validation Prec@1 86.750 	Validation Prec@5 99.300 

lr: 0.018021987578097975
TRAINING - Epoch: [726][0/391]	Time 0.898 (0.898)	Data 0.347 (0.347)	Loss 0.1180 (0.1180)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [726][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.0759 (0.0949)	Prec@1 96.875 (96.643)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [726][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0593 (0.0901)	Prec@1 98.438 (96.731)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [726][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0503 (0.0891)	Prec@1 98.438 (96.730)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [726][0/79]	Time 0.341 (0.341)	Data 0.319 (0.319)	Loss 0.4476 (0.4476)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:17

 Epoch: 727	Training Loss 0.0903 	Training Prec@1 96.718 	Training Prec@5 99.984 	Validation Loss 0.5000 	Validation Prec@1 87.810 	Validation Prec@5 99.430 

lr: 0.017900908350025897
TRAINING - Epoch: [727][0/391]	Time 0.952 (0.952)	Data 0.398 (0.398)	Loss 0.0580 (0.0580)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [727][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0995 (0.0904)	Prec@1 96.094 (96.736)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [727][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0321 (0.0895)	Prec@1 98.438 (96.828)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [727][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.1361 (0.0929)	Prec@1 95.312 (96.706)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [727][0/79]	Time 0.352 (0.352)	Data 0.328 (0.328)	Loss 0.4031 (0.4031)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 728	Training Loss 0.0931 	Training Prec@1 96.720 	Training Prec@5 99.996 	Validation Loss 0.4773 	Validation Prec@1 87.590 	Validation Prec@5 99.450 

lr: 0.01778014847675613
TRAINING - Epoch: [728][0/391]	Time 0.919 (0.919)	Data 0.348 (0.348)	Loss 0.0649 (0.0649)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [728][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0512 (0.0943)	Prec@1 98.438 (96.697)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [728][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1563 (0.0956)	Prec@1 96.094 (96.642)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [728][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1155 (0.0939)	Prec@1 94.531 (96.711)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [728][0/79]	Time 0.378 (0.378)	Data 0.356 (0.356)	Loss 0.3713 (0.3713)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:02

 Epoch: 729	Training Loss 0.0919 	Training Prec@1 96.752 	Training Prec@5 99.994 	Validation Loss 0.4908 	Validation Prec@1 87.600 	Validation Prec@5 99.430 

lr: 0.017659709159732185
TRAINING - Epoch: [729][0/391]	Time 0.961 (0.961)	Data 0.374 (0.374)	Loss 0.1307 (0.1307)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [729][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1866 (0.0989)	Prec@1 93.750 (96.334)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [729][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1018 (0.0944)	Prec@1 98.438 (96.541)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [729][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0847 (0.0920)	Prec@1 96.875 (96.634)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [729][0/79]	Time 0.382 (0.382)	Data 0.360 (0.360)	Loss 0.5567 (0.5567)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 730	Training Loss 0.0912 	Training Prec@1 96.656 	Training Prec@5 99.996 	Validation Loss 0.5413 	Validation Prec@1 86.550 	Validation Prec@5 99.360 

lr: 0.017539591597208345
TRAINING - Epoch: [730][0/391]	Time 0.916 (0.916)	Data 0.353 (0.353)	Loss 0.1457 (0.1457)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [730][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1203 (0.0913)	Prec@1 96.094 (96.689)	Prec@5 99.219 (99.992)
TRAINING - Epoch: [730][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1299 (0.0917)	Prec@1 95.312 (96.685)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [730][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1099 (0.0898)	Prec@1 96.094 (96.748)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [730][0/79]	Time 0.372 (0.372)	Data 0.352 (0.352)	Loss 0.4255 (0.4255)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 731	Training Loss 0.0895 	Training Prec@1 96.758 	Training Prec@5 99.992 	Validation Loss 0.5147 	Validation Prec@1 87.180 	Validation Prec@5 99.410 

lr: 0.017419796984237755
TRAINING - Epoch: [731][0/391]	Time 0.916 (0.916)	Data 0.350 (0.350)	Loss 0.0356 (0.0356)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [731][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0303 (0.0849)	Prec@1 99.219 (96.999)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [731][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0648 (0.0846)	Prec@1 96.094 (96.968)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [731][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0934 (0.0842)	Prec@1 96.875 (96.992)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [731][0/79]	Time 0.345 (0.345)	Data 0.326 (0.326)	Loss 0.4445 (0.4445)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 732	Training Loss 0.0863 	Training Prec@1 96.876 	Training Prec@5 99.996 	Validation Loss 0.4993 	Validation Prec@1 87.150 	Validation Prec@5 99.530 

lr: 0.017300326512660526
TRAINING - Epoch: [732][0/391]	Time 0.935 (0.935)	Data 0.362 (0.362)	Loss 0.1258 (0.1258)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [732][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0764 (0.0803)	Prec@1 96.875 (96.937)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [732][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1011 (0.0854)	Prec@1 98.438 (96.871)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [732][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1553 (0.0881)	Prec@1 92.969 (96.740)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [732][0/79]	Time 0.346 (0.346)	Data 0.323 (0.323)	Loss 0.4161 (0.4161)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:48

 Epoch: 733	Training Loss 0.0872 	Training Prec@1 96.764 	Training Prec@5 99.992 	Validation Loss 0.4871 	Validation Prec@1 88.120 	Validation Prec@5 99.510 

lr: 0.017181181371091876
TRAINING - Epoch: [733][0/391]	Time 0.926 (0.926)	Data 0.357 (0.357)	Loss 0.0634 (0.0634)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [733][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0769 (0.0862)	Prec@1 96.875 (96.759)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [733][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1131 (0.0894)	Prec@1 96.094 (96.720)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [733][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1346 (0.0879)	Prec@1 95.312 (96.857)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [733][0/79]	Time 0.346 (0.346)	Data 0.324 (0.324)	Loss 0.4495 (0.4495)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 734	Training Loss 0.0875 	Training Prec@1 96.864 	Training Prec@5 99.988 	Validation Loss 0.5060 	Validation Prec@1 87.470 	Validation Prec@5 99.230 

lr: 0.017062362744910287
TRAINING - Epoch: [734][0/391]	Time 0.944 (0.944)	Data 0.378 (0.378)	Loss 0.0956 (0.0956)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [734][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0143 (0.0889)	Prec@1 100.000 (96.813)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [734][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0404 (0.0905)	Prec@1 98.438 (96.727)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [734][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.0826 (0.0899)	Prec@1 96.875 (96.769)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [734][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.5651 (0.5651)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 735	Training Loss 0.0885 	Training Prec@1 96.800 	Training Prec@5 99.998 	Validation Loss 0.5264 	Validation Prec@1 86.820 	Validation Prec@5 99.430 

lr: 0.016943871816245792
TRAINING - Epoch: [735][0/391]	Time 0.912 (0.912)	Data 0.342 (0.342)	Loss 0.1724 (0.1724)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [735][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0327 (0.0867)	Prec@1 99.219 (96.906)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [735][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0666 (0.0851)	Prec@1 97.656 (96.949)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [735][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1163 (0.0859)	Prec@1 95.312 (96.906)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [735][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.4893 (0.4893)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:21

 Epoch: 736	Training Loss 0.0855 	Training Prec@1 96.924 	Training Prec@5 99.992 	Validation Loss 0.5480 	Validation Prec@1 86.620 	Validation Prec@5 99.550 

lr: 0.016825709763968095
TRAINING - Epoch: [736][0/391]	Time 0.914 (0.914)	Data 0.339 (0.339)	Loss 0.0776 (0.0776)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [736][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0687 (0.0816)	Prec@1 96.875 (97.006)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [736][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0591 (0.0825)	Prec@1 97.656 (96.918)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [736][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.2458 (0.0840)	Prec@1 91.406 (96.961)	Prec@5 99.219 (99.987)
EVALUATING - Epoch: [736][0/79]	Time 0.352 (0.352)	Data 0.328 (0.328)	Loss 0.3541 (0.3541)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 737	Training Loss 0.0844 	Training Prec@1 96.954 	Training Prec@5 99.986 	Validation Loss 0.5576 	Validation Prec@1 86.590 	Validation Prec@5 99.280 

lr: 0.01670787776367489
TRAINING - Epoch: [737][0/391]	Time 0.928 (0.928)	Data 0.349 (0.349)	Loss 0.0791 (0.0791)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [737][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0952 (0.0911)	Prec@1 96.094 (96.612)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [737][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1011 (0.0828)	Prec@1 96.875 (96.984)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [737][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0686 (0.0820)	Prec@1 98.438 (97.049)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [737][0/79]	Time 0.375 (0.375)	Data 0.352 (0.352)	Loss 0.3720 (0.3720)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:58

 Epoch: 738	Training Loss 0.0826 	Training Prec@1 97.044 	Training Prec@5 99.998 	Validation Loss 0.5349 	Validation Prec@1 87.030 	Validation Prec@5 99.430 

lr: 0.016590376987680188
TRAINING - Epoch: [738][0/391]	Time 0.903 (0.903)	Data 0.348 (0.348)	Loss 0.0822 (0.0822)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [738][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0840 (0.0802)	Prec@1 96.094 (97.177)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [738][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1032 (0.0849)	Prec@1 98.438 (96.980)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [738][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.0784 (0.0869)	Prec@1 96.875 (96.872)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [738][0/79]	Time 0.341 (0.341)	Data 0.317 (0.317)	Loss 0.2864 (0.2864)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:50

 Epoch: 739	Training Loss 0.0854 	Training Prec@1 96.906 	Training Prec@5 99.986 	Validation Loss 0.4965 	Validation Prec@1 87.680 	Validation Prec@5 99.490 

lr: 0.016473208605002686
TRAINING - Epoch: [739][0/391]	Time 0.930 (0.930)	Data 0.375 (0.375)	Loss 0.1610 (0.1610)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [739][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0395 (0.0780)	Prec@1 98.438 (97.061)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [739][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.2041 (0.0815)	Prec@1 94.531 (96.968)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [739][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0500 (0.0801)	Prec@1 97.656 (97.051)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [739][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.3626 (0.3626)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:06

 Epoch: 740	Training Loss 0.0805 	Training Prec@1 97.032 	Training Prec@5 100.000 	Validation Loss 0.4837 	Validation Prec@1 87.790 	Validation Prec@5 99.580 

lr: 0.016356373781354037
TRAINING - Epoch: [740][0/391]	Time 0.891 (0.891)	Data 0.342 (0.342)	Loss 0.0411 (0.0411)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [740][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0739 (0.0809)	Prec@1 97.656 (97.037)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [740][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0477 (0.0791)	Prec@1 99.219 (97.097)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [740][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0477 (0.0800)	Prec@1 98.438 (97.116)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [740][0/79]	Time 0.330 (0.330)	Data 0.308 (0.308)	Loss 0.4930 (0.4930)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:48

 Epoch: 741	Training Loss 0.0808 	Training Prec@1 97.106 	Training Prec@5 99.988 	Validation Loss 0.4960 	Validation Prec@1 87.860 	Validation Prec@5 99.450 

lr: 0.016239873679127336
TRAINING - Epoch: [741][0/391]	Time 0.919 (0.919)	Data 0.345 (0.345)	Loss 0.0833 (0.0833)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1020 (0.0826)	Prec@1 96.875 (97.177)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0963 (0.0851)	Prec@1 96.875 (97.077)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1007 (0.0843)	Prec@1 94.531 (97.098)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [741][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.4427 (0.4427)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:47

 Epoch: 742	Training Loss 0.0848 	Training Prec@1 97.050 	Training Prec@5 99.998 	Validation Loss 0.5048 	Validation Prec@1 87.760 	Validation Prec@5 99.320 

lr: 0.01612370945738546
TRAINING - Epoch: [742][0/391]	Time 0.919 (0.919)	Data 0.356 (0.356)	Loss 0.0950 (0.0950)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [742][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0539 (0.0736)	Prec@1 98.438 (97.416)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [742][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0823 (0.0783)	Prec@1 97.656 (97.209)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [742][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0871 (0.0809)	Prec@1 96.094 (97.106)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [742][0/79]	Time 0.360 (0.360)	Data 0.335 (0.335)	Loss 0.3683 (0.3683)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 743	Training Loss 0.0813 	Training Prec@1 97.050 	Training Prec@5 99.996 	Validation Loss 0.4923 	Validation Prec@1 87.110 	Validation Prec@5 99.440 

lr: 0.0160078822718497
TRAINING - Epoch: [743][0/391]	Time 0.937 (0.937)	Data 0.371 (0.371)	Loss 0.0429 (0.0429)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [743][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0382 (0.0866)	Prec@1 97.656 (96.852)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [743][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1026 (0.0817)	Prec@1 96.875 (97.050)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [743][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0434 (0.0821)	Prec@1 98.438 (96.989)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [743][0/79]	Time 0.363 (0.363)	Data 0.339 (0.339)	Loss 0.4639 (0.4639)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:25

 Epoch: 744	Training Loss 0.0827 	Training Prec@1 96.974 	Training Prec@5 99.992 	Validation Loss 0.5064 	Validation Prec@1 87.780 	Validation Prec@5 99.400 

lr: 0.015892393274888103
TRAINING - Epoch: [744][0/391]	Time 0.943 (0.943)	Data 0.343 (0.343)	Loss 0.0433 (0.0433)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [744][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0470 (0.0800)	Prec@1 98.438 (97.300)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [744][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0307 (0.0789)	Prec@1 98.438 (97.256)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [744][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0581 (0.0797)	Prec@1 99.219 (97.231)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [744][0/79]	Time 0.381 (0.381)	Data 0.357 (0.357)	Loss 0.5504 (0.5504)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 745	Training Loss 0.0795 	Training Prec@1 97.208 	Training Prec@5 99.994 	Validation Loss 0.5007 	Validation Prec@1 87.670 	Validation Prec@5 99.540 

lr: 0.015777243615504054
TRAINING - Epoch: [745][0/391]	Time 0.944 (0.944)	Data 0.347 (0.347)	Loss 0.0665 (0.0665)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [745][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1568 (0.0842)	Prec@1 96.094 (97.030)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [745][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1542 (0.0837)	Prec@1 94.531 (97.019)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [745][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0472 (0.0818)	Prec@1 99.219 (97.088)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [745][0/79]	Time 0.336 (0.336)	Data 0.316 (0.316)	Loss 0.3400 (0.3400)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 746	Training Loss 0.0806 	Training Prec@1 97.110 	Training Prec@5 99.996 	Validation Loss 0.4856 	Validation Prec@1 88.090 	Validation Prec@5 99.400 

lr: 0.015662434439324944
TRAINING - Epoch: [746][0/391]	Time 0.936 (0.936)	Data 0.350 (0.350)	Loss 0.0793 (0.0793)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [746][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1029 (0.0740)	Prec@1 96.094 (97.370)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [746][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0827 (0.0797)	Prec@1 96.875 (97.132)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [746][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1356 (0.0813)	Prec@1 96.094 (97.096)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [746][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.4813 (0.4813)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:36

 Epoch: 747	Training Loss 0.0824 	Training Prec@1 97.042 	Training Prec@5 99.994 	Validation Loss 0.5086 	Validation Prec@1 87.410 	Validation Prec@5 99.470 

lr: 0.015547966888590567
TRAINING - Epoch: [747][0/391]	Time 0.932 (0.932)	Data 0.361 (0.361)	Loss 0.0484 (0.0484)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [747][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0936 (0.0772)	Prec@1 96.875 (97.138)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [747][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0506 (0.0758)	Prec@1 98.438 (97.182)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [747][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0842 (0.0746)	Prec@1 97.656 (97.244)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [747][0/79]	Time 0.384 (0.384)	Data 0.362 (0.362)	Loss 0.2965 (0.2965)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 748	Training Loss 0.0760 	Training Prec@1 97.210 	Training Prec@5 99.996 	Validation Loss 0.4813 	Validation Prec@1 88.100 	Validation Prec@5 99.390 

lr: 0.015433842102141961
TRAINING - Epoch: [748][0/391]	Time 0.950 (0.950)	Data 0.366 (0.366)	Loss 0.1322 (0.1322)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [748][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0433 (0.0763)	Prec@1 98.438 (97.123)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [748][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1324 (0.0801)	Prec@1 95.312 (96.999)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [748][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0425 (0.0788)	Prec@1 98.438 (97.044)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [748][0/79]	Time 0.349 (0.349)	Data 0.328 (0.328)	Loss 0.4088 (0.4088)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 749	Training Loss 0.0787 	Training Prec@1 97.064 	Training Prec@5 99.988 	Validation Loss 0.5174 	Validation Prec@1 87.890 	Validation Prec@5 99.410 

lr: 0.015320061215409943
TRAINING - Epoch: [749][0/391]	Time 0.935 (0.935)	Data 0.341 (0.341)	Loss 0.0703 (0.0703)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [749][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0584 (0.0808)	Prec@1 96.875 (97.022)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [749][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1025 (0.0808)	Prec@1 96.875 (97.058)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [749][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0827 (0.0769)	Prec@1 97.656 (97.257)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [749][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.3451 (0.3451)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 750	Training Loss 0.0767 	Training Prec@1 97.280 	Training Prec@5 99.992 	Validation Loss 0.5146 	Validation Prec@1 87.070 	Validation Prec@5 99.560 

lr: 0.015206625360403925
TRAINING - Epoch: [750][0/391]	Time 0.917 (0.917)	Data 0.354 (0.354)	Loss 0.0626 (0.0626)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [750][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0763 (0.0813)	Prec@1 96.094 (97.061)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [750][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0823 (0.0788)	Prec@1 98.438 (97.186)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [750][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0908 (0.0779)	Prec@1 97.656 (97.189)	Prec@5 100.000 (99.979)
EVALUATING - Epoch: [750][0/79]	Time 0.354 (0.354)	Data 0.328 (0.328)	Loss 0.3678 (0.3678)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 751	Training Loss 0.0786 	Training Prec@1 97.148 	Training Prec@5 99.984 	Validation Loss 0.5015 	Validation Prec@1 87.840 	Validation Prec@5 99.470 

lr: 0.015093535665700531
TRAINING - Epoch: [751][0/391]	Time 0.957 (0.957)	Data 0.371 (0.371)	Loss 0.0550 (0.0550)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0752 (0.0837)	Prec@1 98.438 (97.022)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1284 (0.0849)	Prec@1 96.094 (96.914)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0467 (0.0810)	Prec@1 97.656 (97.033)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [751][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.3839 (0.3839)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 752	Training Loss 0.0791 	Training Prec@1 97.094 	Training Prec@5 100.000 	Validation Loss 0.5188 	Validation Prec@1 87.430 	Validation Prec@5 99.450 

lr: 0.014980793256432458
TRAINING - Epoch: [752][0/391]	Time 0.950 (0.950)	Data 0.369 (0.369)	Loss 0.0443 (0.0443)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [752][100/391]	Time 0.065 (0.071)	Data 0.000 (0.004)	Loss 0.0804 (0.0823)	Prec@1 96.875 (97.092)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [752][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1324 (0.0776)	Prec@1 94.531 (97.170)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [752][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0907 (0.0747)	Prec@1 97.656 (97.270)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [752][0/79]	Time 0.364 (0.364)	Data 0.343 (0.343)	Loss 0.3666 (0.3666)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:18

 Epoch: 753	Training Loss 0.0739 	Training Prec@1 97.316 	Training Prec@5 99.998 	Validation Loss 0.5083 	Validation Prec@1 88.010 	Validation Prec@5 99.480 

lr: 0.014868399254277189
TRAINING - Epoch: [753][0/391]	Time 0.998 (0.998)	Data 0.390 (0.390)	Loss 0.0377 (0.0377)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1298 (0.0700)	Prec@1 96.094 (97.548)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1398 (0.0725)	Prec@1 97.656 (97.489)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [753][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0584 (0.0732)	Prec@1 98.438 (97.423)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [753][0/79]	Time 0.351 (0.351)	Data 0.327 (0.327)	Loss 0.4153 (0.4153)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:50

 Epoch: 754	Training Loss 0.0735 	Training Prec@1 97.404 	Training Prec@5 99.996 	Validation Loss 0.5222 	Validation Prec@1 87.390 	Validation Prec@5 99.390 

lr: 0.014756354777445987
TRAINING - Epoch: [754][0/391]	Time 0.912 (0.912)	Data 0.357 (0.357)	Loss 0.0959 (0.0959)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [754][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0391 (0.0812)	Prec@1 98.438 (96.960)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [754][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0729 (0.0785)	Prec@1 96.875 (97.147)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [754][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1383 (0.0787)	Prec@1 95.312 (97.111)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [754][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.4354 (0.4354)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 755	Training Loss 0.0774 	Training Prec@1 97.160 	Training Prec@5 99.992 	Validation Loss 0.5044 	Validation Prec@1 87.510 	Validation Prec@5 99.450 

lr: 0.014644660940672613
TRAINING - Epoch: [755][0/391]	Time 0.963 (0.963)	Data 0.350 (0.350)	Loss 0.0841 (0.0841)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [755][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0255 (0.0776)	Prec@1 99.219 (97.269)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [755][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1105 (0.0793)	Prec@1 96.875 (97.190)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [755][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0583 (0.0793)	Prec@1 98.438 (97.189)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [755][0/79]	Time 0.343 (0.343)	Data 0.323 (0.323)	Loss 0.3478 (0.3478)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:22

 Epoch: 756	Training Loss 0.0799 	Training Prec@1 97.162 	Training Prec@5 99.996 	Validation Loss 0.4855 	Validation Prec@1 88.100 	Validation Prec@5 99.470 

lr: 0.014533318855202308
TRAINING - Epoch: [756][0/391]	Time 0.938 (0.938)	Data 0.359 (0.359)	Loss 0.0810 (0.0810)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [756][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0346 (0.0766)	Prec@1 99.219 (97.239)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [756][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0919 (0.0765)	Prec@1 95.312 (97.299)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [756][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0940 (0.0744)	Prec@1 96.094 (97.332)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [756][0/79]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 0.4695 (0.4695)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:30

 Epoch: 757	Training Loss 0.0749 	Training Prec@1 97.298 	Training Prec@5 99.990 	Validation Loss 0.5017 	Validation Prec@1 87.790 	Validation Prec@5 99.430 

lr: 0.014422329628780784
TRAINING - Epoch: [757][0/391]	Time 0.890 (0.890)	Data 0.335 (0.335)	Loss 0.0147 (0.0147)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [757][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0472 (0.0680)	Prec@1 98.438 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [757][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0930 (0.0709)	Prec@1 96.875 (97.516)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [757][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0534 (0.0713)	Prec@1 97.656 (97.490)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [757][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.3962 (0.3962)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:36

 Epoch: 758	Training Loss 0.0712 	Training Prec@1 97.490 	Training Prec@5 99.996 	Validation Loss 0.4856 	Validation Prec@1 88.140 	Validation Prec@5 99.610 

lr: 0.014311694365643052
TRAINING - Epoch: [758][0/391]	Time 0.920 (0.920)	Data 0.359 (0.359)	Loss 0.1125 (0.1125)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [758][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0327 (0.0764)	Prec@1 99.219 (97.192)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [758][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.1449 (0.0729)	Prec@1 94.531 (97.353)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [758][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0896 (0.0744)	Prec@1 96.875 (97.342)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [758][0/79]	Time 0.351 (0.351)	Data 0.330 (0.330)	Loss 0.4784 (0.4784)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 759	Training Loss 0.0739 	Training Prec@1 97.338 	Training Prec@5 99.994 	Validation Loss 0.5107 	Validation Prec@1 87.600 	Validation Prec@5 99.500 

lr: 0.0142014141665026
TRAINING - Epoch: [759][0/391]	Time 0.989 (0.989)	Data 0.367 (0.367)	Loss 0.0820 (0.0820)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [759][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.0405 (0.0744)	Prec@1 99.219 (97.300)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [759][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.0672 (0.0754)	Prec@1 98.438 (97.233)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [759][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0331 (0.0764)	Prec@1 100.000 (97.199)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [759][0/79]	Time 0.351 (0.351)	Data 0.331 (0.331)	Loss 0.4393 (0.4393)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:28

 Epoch: 760	Training Loss 0.0771 	Training Prec@1 97.208 	Training Prec@5 99.998 	Validation Loss 0.4783 	Validation Prec@1 88.010 	Validation Prec@5 99.630 

lr: 0.014091490128540345
TRAINING - Epoch: [760][0/391]	Time 0.952 (0.952)	Data 0.384 (0.384)	Loss 0.0393 (0.0393)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [760][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0909 (0.0726)	Prec@1 96.875 (97.440)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [760][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0387 (0.0726)	Prec@1 99.219 (97.341)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [760][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0931 (0.0751)	Prec@1 96.094 (97.280)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [760][0/79]	Time 0.340 (0.340)	Data 0.318 (0.318)	Loss 0.4061 (0.4061)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:51

 Epoch: 761	Training Loss 0.0766 	Training Prec@1 97.246 	Training Prec@5 99.994 	Validation Loss 0.4862 	Validation Prec@1 88.190 	Validation Prec@5 99.500 

lr: 0.013981923345393787
TRAINING - Epoch: [761][0/391]	Time 0.910 (0.910)	Data 0.346 (0.346)	Loss 0.0777 (0.0777)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1195 (0.0791)	Prec@1 96.875 (97.153)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0810 (0.0774)	Prec@1 97.656 (97.225)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [761][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0489 (0.0768)	Prec@1 97.656 (97.244)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [761][0/79]	Time 0.359 (0.359)	Data 0.334 (0.334)	Loss 0.3368 (0.3368)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:57

 Epoch: 762	Training Loss 0.0774 	Training Prec@1 97.256 	Training Prec@5 99.998 	Validation Loss 0.4715 	Validation Prec@1 88.400 	Validation Prec@5 99.500 

lr: 0.013872714907146061
TRAINING - Epoch: [762][0/391]	Time 0.976 (0.976)	Data 0.383 (0.383)	Loss 0.0572 (0.0572)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [762][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0701 (0.0721)	Prec@1 97.656 (97.440)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [762][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.0531 (0.0746)	Prec@1 98.438 (97.264)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [762][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0332 (0.0752)	Prec@1 98.438 (97.254)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [762][0/79]	Time 0.376 (0.376)	Data 0.355 (0.355)	Loss 0.3031 (0.3031)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 763	Training Loss 0.0751 	Training Prec@1 97.254 	Training Prec@5 99.998 	Validation Loss 0.4719 	Validation Prec@1 88.280 	Validation Prec@5 99.670 

lr: 0.013763865900315081
TRAINING - Epoch: [763][0/391]	Time 1.038 (1.038)	Data 0.378 (0.378)	Loss 0.0688 (0.0688)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.0642 (0.0722)	Prec@1 97.656 (97.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0582 (0.0737)	Prec@1 98.438 (97.477)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0270 (0.0734)	Prec@1 98.438 (97.436)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [763][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.3617 (0.3617)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:04

 Epoch: 764	Training Loss 0.0723 	Training Prec@1 97.448 	Training Prec@5 100.000 	Validation Loss 0.4974 	Validation Prec@1 88.100 	Validation Prec@5 99.390 

lr: 0.013655377407842801
TRAINING - Epoch: [764][0/391]	Time 0.923 (0.923)	Data 0.365 (0.365)	Loss 0.1091 (0.1091)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [764][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0358 (0.0759)	Prec@1 98.438 (97.308)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [764][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0600 (0.0743)	Prec@1 97.656 (97.361)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [764][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0453 (0.0742)	Prec@1 98.438 (97.368)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [764][0/79]	Time 0.366 (0.366)	Data 0.345 (0.345)	Loss 0.3540 (0.3540)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:18

 Epoch: 765	Training Loss 0.0747 	Training Prec@1 97.304 	Training Prec@5 99.994 	Validation Loss 0.4927 	Validation Prec@1 88.000 	Validation Prec@5 99.530 

lr: 0.013547250509084442
TRAINING - Epoch: [765][0/391]	Time 0.943 (0.943)	Data 0.358 (0.358)	Loss 0.1618 (0.1618)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [765][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1099 (0.0742)	Prec@1 98.438 (97.386)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [765][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0217 (0.0741)	Prec@1 100.000 (97.365)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [765][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0586 (0.0746)	Prec@1 98.438 (97.355)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [765][0/79]	Time 0.353 (0.353)	Data 0.332 (0.332)	Loss 0.5064 (0.5064)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 766	Training Loss 0.0745 	Training Prec@1 97.348 	Training Prec@5 99.994 	Validation Loss 0.5186 	Validation Prec@1 87.440 	Validation Prec@5 99.500 

lr: 0.01343948627979767
TRAINING - Epoch: [766][0/391]	Time 0.912 (0.912)	Data 0.346 (0.346)	Loss 0.0737 (0.0737)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [766][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1314 (0.0756)	Prec@1 94.531 (97.269)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [766][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0675 (0.0770)	Prec@1 97.656 (97.225)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [766][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1659 (0.0758)	Prec@1 93.750 (97.259)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [766][0/79]	Time 0.357 (0.357)	Data 0.335 (0.335)	Loss 0.3286 (0.3286)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 767	Training Loss 0.0750 	Training Prec@1 97.274 	Training Prec@5 99.988 	Validation Loss 0.4840 	Validation Prec@1 88.070 	Validation Prec@5 99.470 

lr: 0.013332085792131954
TRAINING - Epoch: [767][0/391]	Time 0.898 (0.898)	Data 0.336 (0.336)	Loss 0.0523 (0.0523)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1201 (0.0769)	Prec@1 96.094 (97.107)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0331 (0.0748)	Prec@1 99.219 (97.233)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0817 (0.0748)	Prec@1 96.875 (97.259)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [767][0/79]	Time 0.373 (0.373)	Data 0.351 (0.351)	Loss 0.5112 (0.5112)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:45

 Epoch: 768	Training Loss 0.0748 	Training Prec@1 97.276 	Training Prec@5 99.996 	Validation Loss 0.4910 	Validation Prec@1 88.000 	Validation Prec@5 99.450 

lr: 0.013225050114617887
TRAINING - Epoch: [768][0/391]	Time 0.945 (0.945)	Data 0.353 (0.353)	Loss 0.0305 (0.0305)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [768][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0648 (0.0763)	Prec@1 98.438 (97.231)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [768][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0512 (0.0785)	Prec@1 98.438 (97.194)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [768][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0874 (0.0759)	Prec@1 95.312 (97.241)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [768][0/79]	Time 0.351 (0.351)	Data 0.332 (0.332)	Loss 0.4301 (0.4301)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:18

 Epoch: 769	Training Loss 0.0754 	Training Prec@1 97.268 	Training Prec@5 99.992 	Validation Loss 0.4834 	Validation Prec@1 88.570 	Validation Prec@5 99.460 

lr: 0.013118380312156558
TRAINING - Epoch: [769][0/391]	Time 0.925 (0.925)	Data 0.356 (0.356)	Loss 0.0617 (0.0617)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [769][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0711 (0.0707)	Prec@1 97.656 (97.540)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [769][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0753 (0.0698)	Prec@1 97.656 (97.505)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [769][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0692 (0.0740)	Prec@1 96.875 (97.337)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [769][0/79]	Time 0.371 (0.371)	Data 0.348 (0.348)	Loss 0.4783 (0.4783)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 770	Training Loss 0.0745 	Training Prec@1 97.334 	Training Prec@5 99.988 	Validation Loss 0.5059 	Validation Prec@1 87.740 	Validation Prec@5 99.490 

lr: 0.013012077446008958
TRAINING - Epoch: [770][0/391]	Time 0.904 (0.904)	Data 0.346 (0.346)	Loss 0.0566 (0.0566)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [770][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0536 (0.0723)	Prec@1 96.875 (97.331)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [770][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0818 (0.0724)	Prec@1 97.656 (97.388)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [770][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0937 (0.0732)	Prec@1 96.875 (97.386)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [770][0/79]	Time 0.371 (0.371)	Data 0.348 (0.348)	Loss 0.4453 (0.4453)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 771	Training Loss 0.0736 	Training Prec@1 97.386 	Training Prec@5 99.994 	Validation Loss 0.5086 	Validation Prec@1 87.650 	Validation Prec@5 99.550 

lr: 0.01290614257378539
TRAINING - Epoch: [771][0/391]	Time 0.930 (0.930)	Data 0.366 (0.366)	Loss 0.0468 (0.0468)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [771][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0811 (0.0698)	Prec@1 96.875 (97.347)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [771][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1637 (0.0756)	Prec@1 93.750 (97.178)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [771][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0710 (0.0743)	Prec@1 96.875 (97.249)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [771][0/79]	Time 0.358 (0.358)	Data 0.337 (0.337)	Loss 0.4512 (0.4512)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 772	Training Loss 0.0738 	Training Prec@1 97.318 	Training Prec@5 99.994 	Validation Loss 0.4745 	Validation Prec@1 88.100 	Validation Prec@5 99.530 

lr: 0.012800576749435057
TRAINING - Epoch: [772][0/391]	Time 0.919 (0.919)	Data 0.360 (0.360)	Loss 0.0613 (0.0613)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0977 (0.0766)	Prec@1 96.875 (97.153)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0584 (0.0752)	Prec@1 97.656 (97.252)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0654 (0.0753)	Prec@1 98.438 (97.282)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [772][0/79]	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.3976 (0.3976)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 773	Training Loss 0.0739 	Training Prec@1 97.314 	Training Prec@5 99.998 	Validation Loss 0.4911 	Validation Prec@1 87.910 	Validation Prec@5 99.540 

lr: 0.012695381023235376
TRAINING - Epoch: [773][0/391]	Time 0.918 (0.918)	Data 0.346 (0.346)	Loss 0.0889 (0.0889)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [773][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0780 (0.0698)	Prec@1 97.656 (97.455)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [773][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0500 (0.0704)	Prec@1 98.438 (97.439)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [773][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0387 (0.0688)	Prec@1 97.656 (97.563)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [773][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.3691 (0.3691)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 774	Training Loss 0.0709 	Training Prec@1 97.486 	Training Prec@5 99.990 	Validation Loss 0.4909 	Validation Prec@1 88.030 	Validation Prec@5 99.400 

lr: 0.012590556441781725
TRAINING - Epoch: [774][0/391]	Time 0.928 (0.928)	Data 0.369 (0.369)	Loss 0.0662 (0.0662)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [774][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0544 (0.0769)	Prec@1 97.656 (97.177)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [774][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1242 (0.0725)	Prec@1 96.094 (97.361)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [774][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0666 (0.0718)	Prec@1 97.656 (97.386)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [774][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.4136 (0.4136)	Prec@1 90.625 (90.625)	Prec@5 97.656 (97.656)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 775	Training Loss 0.0724 	Training Prec@1 97.364 	Training Prec@5 99.992 	Validation Loss 0.4973 	Validation Prec@1 88.010 	Validation Prec@5 99.520 

lr: 0.012486104047976926
TRAINING - Epoch: [775][0/391]	Time 0.914 (0.914)	Data 0.340 (0.340)	Loss 0.0974 (0.0974)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0378 (0.0709)	Prec@1 99.219 (97.432)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1382 (0.0730)	Prec@1 94.531 (97.357)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [775][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0441 (0.0712)	Prec@1 98.438 (97.392)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [775][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.2956 (0.2956)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:43

 Epoch: 776	Training Loss 0.0731 	Training Prec@1 97.354 	Training Prec@5 99.996 	Validation Loss 0.5034 	Validation Prec@1 88.040 	Validation Prec@5 99.450 

lr: 0.012382024881020925
TRAINING - Epoch: [776][0/391]	Time 0.931 (0.931)	Data 0.376 (0.376)	Loss 0.0558 (0.0558)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [776][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0191 (0.0732)	Prec@1 100.000 (97.362)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [776][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0183 (0.0753)	Prec@1 100.000 (97.275)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [776][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0974 (0.0753)	Prec@1 96.875 (97.301)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [776][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.4238 (0.4238)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 777	Training Loss 0.0750 	Training Prec@1 97.326 	Training Prec@5 99.996 	Validation Loss 0.4916 	Validation Prec@1 87.970 	Validation Prec@5 99.510 

lr: 0.012278319976400397
TRAINING - Epoch: [777][0/391]	Time 0.925 (0.925)	Data 0.360 (0.360)	Loss 0.0985 (0.0985)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0667 (0.0632)	Prec@1 97.656 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0785 (0.0668)	Prec@1 96.875 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0362 (0.0677)	Prec@1 99.219 (97.607)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [777][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.3863 (0.3863)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:50

 Epoch: 778	Training Loss 0.0677 	Training Prec@1 97.600 	Training Prec@5 100.000 	Validation Loss 0.4931 	Validation Prec@1 88.030 	Validation Prec@5 99.430 

lr: 0.012174990365878435
TRAINING - Epoch: [778][0/391]	Time 0.919 (0.919)	Data 0.346 (0.346)	Loss 0.1244 (0.1244)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [778][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0647 (0.0800)	Prec@1 97.656 (97.208)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [778][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0906 (0.0803)	Prec@1 96.875 (97.217)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [778][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0345 (0.0770)	Prec@1 99.219 (97.290)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [778][0/79]	Time 0.353 (0.353)	Data 0.329 (0.329)	Loss 0.4556 (0.4556)	Prec@1 89.844 (89.844)	Prec@5 97.656 (97.656)
Time cost: 00:26	Time of Finish: 2022-03-24 22:21:22

 Epoch: 779	Training Loss 0.0748 	Training Prec@1 97.398 	Training Prec@5 99.994 	Validation Loss 0.5358 	Validation Prec@1 87.410 	Validation Prec@5 99.490 

lr: 0.012072037077484405
TRAINING - Epoch: [779][0/391]	Time 0.922 (0.922)	Data 0.340 (0.340)	Loss 0.0478 (0.0478)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [779][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1374 (0.0701)	Prec@1 96.094 (97.517)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [779][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1214 (0.0709)	Prec@1 98.438 (97.415)	Prec@5 99.219 (99.984)
TRAINING - Epoch: [779][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0921 (0.0705)	Prec@1 97.656 (97.425)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [779][0/79]	Time 0.366 (0.366)	Data 0.343 (0.343)	Loss 0.3924 (0.3924)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 780	Training Loss 0.0709 	Training Prec@1 97.442 	Training Prec@5 99.988 	Validation Loss 0.5094 	Validation Prec@1 87.780 	Validation Prec@5 99.450 

lr: 0.011969461135503562
TRAINING - Epoch: [780][0/391]	Time 0.924 (0.924)	Data 0.358 (0.358)	Loss 0.0441 (0.0441)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [780][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0758 (0.0734)	Prec@1 96.875 (97.494)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [780][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0947 (0.0724)	Prec@1 98.438 (97.466)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [780][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0264 (0.0720)	Prec@1 100.000 (97.506)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [780][0/79]	Time 0.364 (0.364)	Data 0.342 (0.342)	Loss 0.3622 (0.3622)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 781	Training Loss 0.0710 	Training Prec@1 97.504 	Training Prec@5 99.994 	Validation Loss 0.5163 	Validation Prec@1 87.660 	Validation Prec@5 99.480 

lr: 0.011867263560466957
TRAINING - Epoch: [781][0/391]	Time 0.897 (0.897)	Data 0.337 (0.337)	Loss 0.0386 (0.0386)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [781][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0527 (0.0701)	Prec@1 98.438 (97.610)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [781][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0747 (0.0702)	Prec@1 97.656 (97.575)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [781][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0994 (0.0703)	Prec@1 95.312 (97.550)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [781][0/79]	Time 0.360 (0.360)	Data 0.341 (0.341)	Loss 0.5134 (0.5134)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 782	Training Loss 0.0710 	Training Prec@1 97.538 	Training Prec@5 99.984 	Validation Loss 0.5046 	Validation Prec@1 87.860 	Validation Prec@5 99.620 

lr: 0.011765445369141248
TRAINING - Epoch: [782][0/391]	Time 0.952 (0.952)	Data 0.383 (0.383)	Loss 0.1278 (0.1278)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [782][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0857 (0.0743)	Prec@1 96.094 (97.262)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [782][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0260 (0.0741)	Prec@1 99.219 (97.334)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [782][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0770 (0.0739)	Prec@1 96.875 (97.329)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [782][0/79]	Time 0.398 (0.398)	Data 0.373 (0.373)	Loss 0.5019 (0.5019)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 783	Training Loss 0.0739 	Training Prec@1 97.354 	Training Prec@5 99.988 	Validation Loss 0.4799 	Validation Prec@1 87.960 	Validation Prec@5 99.560 

lr: 0.011664007574518643
TRAINING - Epoch: [783][0/391]	Time 0.931 (0.931)	Data 0.359 (0.359)	Loss 0.0724 (0.0724)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [783][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0102 (0.0690)	Prec@1 100.000 (97.463)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [783][200/391]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.0664 (0.0688)	Prec@1 98.438 (97.579)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [783][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0700 (0.0683)	Prec@1 97.656 (97.498)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [783][0/79]	Time 0.380 (0.380)	Data 0.356 (0.356)	Loss 0.2776 (0.2776)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:15

 Epoch: 784	Training Loss 0.0696 	Training Prec@1 97.458 	Training Prec@5 99.998 	Validation Loss 0.4841 	Validation Prec@1 88.040 	Validation Prec@5 99.540 

lr: 0.011562951185806676
TRAINING - Epoch: [784][0/391]	Time 0.978 (0.978)	Data 0.370 (0.370)	Loss 0.0790 (0.0790)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1447 (0.0749)	Prec@1 96.094 (97.262)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0580 (0.0753)	Prec@1 98.438 (97.275)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0613 (0.0736)	Prec@1 98.438 (97.347)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [784][0/79]	Time 0.400 (0.400)	Data 0.375 (0.375)	Loss 0.2712 (0.2712)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:36

 Epoch: 785	Training Loss 0.0724 	Training Prec@1 97.386 	Training Prec@5 100.000 	Validation Loss 0.4860 	Validation Prec@1 88.080 	Validation Prec@5 99.540 

lr: 0.011462277208418343
TRAINING - Epoch: [785][0/391]	Time 0.939 (0.939)	Data 0.370 (0.370)	Loss 0.0569 (0.0569)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [785][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0283 (0.0733)	Prec@1 99.219 (97.331)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [785][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0780 (0.0722)	Prec@1 97.656 (97.392)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [785][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0521 (0.0712)	Prec@1 98.438 (97.441)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [785][0/79]	Time 0.376 (0.376)	Data 0.357 (0.357)	Loss 0.3897 (0.3897)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 786	Training Loss 0.0716 	Training Prec@1 97.404 	Training Prec@5 99.994 	Validation Loss 0.4894 	Validation Prec@1 88.230 	Validation Prec@5 99.510 

lr: 0.01136198664396197
TRAINING - Epoch: [786][0/391]	Time 0.958 (0.958)	Data 0.373 (0.373)	Loss 0.0507 (0.0507)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [786][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1010 (0.0714)	Prec@1 96.094 (97.440)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [786][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.1019 (0.0712)	Prec@1 95.312 (97.470)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [786][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1046 (0.0719)	Prec@1 94.531 (97.425)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [786][0/79]	Time 0.357 (0.357)	Data 0.335 (0.335)	Loss 0.3513 (0.3513)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 787	Training Loss 0.0720 	Training Prec@1 97.426 	Training Prec@5 99.994 	Validation Loss 0.4831 	Validation Prec@1 88.150 	Validation Prec@5 99.590 

lr: 0.011262080490231348
TRAINING - Epoch: [787][0/391]	Time 0.926 (0.926)	Data 0.358 (0.358)	Loss 0.0808 (0.0808)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [787][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0522 (0.0729)	Prec@1 98.438 (97.362)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [787][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0813 (0.0727)	Prec@1 96.875 (97.365)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [787][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0391 (0.0708)	Prec@1 99.219 (97.441)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [787][0/79]	Time 0.372 (0.372)	Data 0.353 (0.353)	Loss 0.3620 (0.3620)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 788	Training Loss 0.0720 	Training Prec@1 97.380 	Training Prec@5 99.990 	Validation Loss 0.4910 	Validation Prec@1 88.110 	Validation Prec@5 99.530 

lr: 0.011162559741195722
TRAINING - Epoch: [788][0/391]	Time 0.927 (0.927)	Data 0.346 (0.346)	Loss 0.0751 (0.0751)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0634 (0.0774)	Prec@1 97.656 (97.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1538 (0.0759)	Prec@1 96.094 (97.252)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.0866 (0.0733)	Prec@1 96.094 (97.337)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [788][0/79]	Time 0.346 (0.346)	Data 0.322 (0.322)	Loss 0.4115 (0.4115)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 789	Training Loss 0.0735 	Training Prec@1 97.374 	Training Prec@5 99.994 	Validation Loss 0.4838 	Validation Prec@1 88.070 	Validation Prec@5 99.430 

lr: 0.011063425386989902
TRAINING - Epoch: [789][0/391]	Time 0.939 (0.939)	Data 0.370 (0.370)	Loss 0.0685 (0.0685)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [789][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0356 (0.0713)	Prec@1 100.000 (97.478)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [789][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0498 (0.0726)	Prec@1 97.656 (97.435)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [789][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0681 (0.0724)	Prec@1 96.875 (97.436)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [789][0/79]	Time 0.349 (0.349)	Data 0.327 (0.327)	Loss 0.3365 (0.3365)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 790	Training Loss 0.0727 	Training Prec@1 97.438 	Training Prec@5 99.998 	Validation Loss 0.4913 	Validation Prec@1 87.610 	Validation Prec@5 99.480 

lr: 0.010964678413904517
TRAINING - Epoch: [790][0/391]	Time 0.931 (0.931)	Data 0.352 (0.352)	Loss 0.1366 (0.1366)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [790][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.0528 (0.0695)	Prec@1 97.656 (97.664)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [790][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0797 (0.0694)	Prec@1 97.656 (97.575)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [790][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0435 (0.0688)	Prec@1 97.656 (97.586)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [790][0/79]	Time 0.352 (0.352)	Data 0.331 (0.331)	Loss 0.3545 (0.3545)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:56

 Epoch: 791	Training Loss 0.0695 	Training Prec@1 97.520 	Training Prec@5 99.996 	Validation Loss 0.4863 	Validation Prec@1 88.330 	Validation Prec@5 99.470 

lr: 0.010866319804376074
TRAINING - Epoch: [791][0/391]	Time 0.952 (0.952)	Data 0.360 (0.360)	Loss 0.0359 (0.0359)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0239 (0.0703)	Prec@1 99.219 (97.486)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1170 (0.0710)	Prec@1 96.875 (97.481)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0231 (0.0710)	Prec@1 99.219 (97.428)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [791][0/79]	Time 0.347 (0.347)	Data 0.325 (0.325)	Loss 0.3605 (0.3605)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:59

 Epoch: 792	Training Loss 0.0706 	Training Prec@1 97.474 	Training Prec@5 100.000 	Validation Loss 0.4871 	Validation Prec@1 88.240 	Validation Prec@5 99.470 

lr: 0.010768350536977268
TRAINING - Epoch: [792][0/391]	Time 0.932 (0.932)	Data 0.380 (0.380)	Loss 0.1168 (0.1168)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [792][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0494 (0.0832)	Prec@1 98.438 (97.254)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [792][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0287 (0.0759)	Prec@1 100.000 (97.423)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [792][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.0984 (0.0746)	Prec@1 94.531 (97.436)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [792][0/79]	Time 0.341 (0.341)	Data 0.319 (0.319)	Loss 0.2762 (0.2762)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 793	Training Loss 0.0727 	Training Prec@1 97.478 	Training Prec@5 99.994 	Validation Loss 0.4798 	Validation Prec@1 88.120 	Validation Prec@5 99.480 

lr: 0.010670771586407196
TRAINING - Epoch: [793][0/391]	Time 0.928 (0.928)	Data 0.351 (0.351)	Loss 0.0592 (0.0592)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [793][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0288 (0.0735)	Prec@1 99.219 (97.308)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [793][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0438 (0.0713)	Prec@1 99.219 (97.427)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [793][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0672 (0.0732)	Prec@1 96.875 (97.379)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [793][0/79]	Time 0.345 (0.345)	Data 0.325 (0.325)	Loss 0.4268 (0.4268)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 794	Training Loss 0.0728 	Training Prec@1 97.414 	Training Prec@5 99.996 	Validation Loss 0.4839 	Validation Prec@1 88.100 	Validation Prec@5 99.490 

lr: 0.0105735839234817
TRAINING - Epoch: [794][0/391]	Time 0.920 (0.920)	Data 0.349 (0.349)	Loss 0.0524 (0.0524)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [794][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0608 (0.0692)	Prec@1 98.438 (97.517)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [794][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0813 (0.0716)	Prec@1 96.094 (97.435)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [794][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0296 (0.0705)	Prec@1 98.438 (97.423)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [794][0/79]	Time 0.345 (0.345)	Data 0.325 (0.325)	Loss 0.2817 (0.2817)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 795	Training Loss 0.0696 	Training Prec@1 97.436 	Training Prec@5 99.996 	Validation Loss 0.5074 	Validation Prec@1 88.110 	Validation Prec@5 99.430 

lr: 0.010476788515123686
TRAINING - Epoch: [795][0/391]	Time 0.951 (0.951)	Data 0.346 (0.346)	Loss 0.0621 (0.0621)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.1011 (0.0780)	Prec@1 97.656 (97.277)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0534 (0.0733)	Prec@1 98.438 (97.373)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0399 (0.0736)	Prec@1 98.438 (97.340)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [795][0/79]	Time 0.333 (0.333)	Data 0.313 (0.313)	Loss 0.4048 (0.4048)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:51

 Epoch: 796	Training Loss 0.0731 	Training Prec@1 97.354 	Training Prec@5 100.000 	Validation Loss 0.5081 	Validation Prec@1 87.800 	Validation Prec@5 99.520 

lr: 0.010380386324353497
TRAINING - Epoch: [796][0/391]	Time 0.917 (0.917)	Data 0.350 (0.350)	Loss 0.0552 (0.0552)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [796][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0312 (0.0675)	Prec@1 99.219 (97.594)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [796][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0235 (0.0701)	Prec@1 99.219 (97.454)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [796][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0370 (0.0717)	Prec@1 98.438 (97.407)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [796][0/79]	Time 0.359 (0.359)	Data 0.333 (0.333)	Loss 0.3920 (0.3920)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:22:00

 Epoch: 797	Training Loss 0.0720 	Training Prec@1 97.376 	Training Prec@5 99.994 	Validation Loss 0.4724 	Validation Prec@1 88.620 	Validation Prec@5 99.490 

lr: 0.010284378310279348
TRAINING - Epoch: [797][0/391]	Time 0.922 (0.922)	Data 0.345 (0.345)	Loss 0.0317 (0.0317)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [797][100/391]	Time 0.066 (0.071)	Data 0.000 (0.004)	Loss 0.0496 (0.0710)	Prec@1 98.438 (97.424)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [797][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0778 (0.0699)	Prec@1 97.656 (97.528)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [797][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0522 (0.0681)	Prec@1 97.656 (97.589)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [797][0/79]	Time 0.348 (0.348)	Data 0.326 (0.326)	Loss 0.3420 (0.3420)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:52

 Epoch: 798	Training Loss 0.0698 	Training Prec@1 97.512 	Training Prec@5 99.998 	Validation Loss 0.4754 	Validation Prec@1 88.370 	Validation Prec@5 99.550 

lr: 0.010188765428087805
TRAINING - Epoch: [798][0/391]	Time 0.928 (0.928)	Data 0.349 (0.349)	Loss 0.0369 (0.0369)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0275 (0.0717)	Prec@1 99.219 (97.393)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0755 (0.0700)	Prec@1 96.875 (97.454)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1190 (0.0712)	Prec@1 96.094 (97.451)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [798][0/79]	Time 0.368 (0.368)	Data 0.345 (0.345)	Loss 0.3908 (0.3908)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 799	Training Loss 0.0716 	Training Prec@1 97.426 	Training Prec@5 99.998 	Validation Loss 0.4674 	Validation Prec@1 88.310 	Validation Prec@5 99.480 

lr: 0.010093548629034206
TRAINING - Epoch: [799][0/391]	Time 0.930 (0.930)	Data 0.354 (0.354)	Loss 0.0795 (0.0795)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [799][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0957 (0.0660)	Prec@1 97.656 (97.563)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [799][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0687 (0.0688)	Prec@1 96.875 (97.481)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [799][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0281 (0.0693)	Prec@1 98.438 (97.469)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [799][0/79]	Time 0.365 (0.365)	Data 0.343 (0.343)	Loss 0.3181 (0.3181)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 800	Training Loss 0.0692 	Training Prec@1 97.486 	Training Prec@5 99.988 	Validation Loss 0.4787 	Validation Prec@1 88.370 	Validation Prec@5 99.500 

lr: 0.009998728860433266
TRAINING - Epoch: [800][0/391]	Time 0.920 (0.920)	Data 0.340 (0.340)	Loss 0.0191 (0.0191)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [800][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0542 (0.0748)	Prec@1 97.656 (97.347)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [800][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0261 (0.0728)	Prec@1 99.219 (97.458)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [800][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0972 (0.0724)	Prec@1 95.312 (97.386)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [800][0/79]	Time 0.332 (0.332)	Data 0.310 (0.310)	Loss 0.4155 (0.4155)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:21:36

 Epoch: 801	Training Loss 0.0718 	Training Prec@1 97.368 	Training Prec@5 99.996 	Validation Loss 0.4670 	Validation Prec@1 88.300 	Validation Prec@5 99.520 

lr: 0.00990430706564966
TRAINING - Epoch: [801][0/391]	Time 0.932 (0.932)	Data 0.359 (0.359)	Loss 0.0609 (0.0609)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [801][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0289 (0.0717)	Prec@1 99.219 (97.517)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [801][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0266 (0.0720)	Prec@1 100.000 (97.474)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [801][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0364 (0.0699)	Prec@1 98.438 (97.534)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [801][0/79]	Time 0.374 (0.374)	Data 0.350 (0.350)	Loss 0.3450 (0.3450)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 802	Training Loss 0.0707 	Training Prec@1 97.462 	Training Prec@5 99.996 	Validation Loss 0.4623 	Validation Prec@1 88.260 	Validation Prec@5 99.520 

lr: 0.009810284184088582
TRAINING - Epoch: [802][0/391]	Time 0.927 (0.927)	Data 0.340 (0.340)	Loss 0.0545 (0.0545)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [802][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0280 (0.0737)	Prec@1 98.438 (97.355)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [802][200/391]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.0898 (0.0744)	Prec@1 98.438 (97.275)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [802][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0584 (0.0707)	Prec@1 96.875 (97.399)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [802][0/79]	Time 0.372 (0.372)	Data 0.349 (0.349)	Loss 0.3362 (0.3362)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:22

 Epoch: 803	Training Loss 0.0709 	Training Prec@1 97.390 	Training Prec@5 99.998 	Validation Loss 0.4771 	Validation Prec@1 88.390 	Validation Prec@5 99.550 

lr: 0.009716661151186447
TRAINING - Epoch: [803][0/391]	Time 0.937 (0.937)	Data 0.350 (0.350)	Loss 0.0446 (0.0446)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [803][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0633 (0.0676)	Prec@1 96.875 (97.525)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [803][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0526 (0.0677)	Prec@1 97.656 (97.532)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [803][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0552 (0.0686)	Prec@1 98.438 (97.524)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [803][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.3921 (0.3921)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 804	Training Loss 0.0681 	Training Prec@1 97.548 	Training Prec@5 99.996 	Validation Loss 0.4772 	Validation Prec@1 88.370 	Validation Prec@5 99.570 

lr: 0.0096234388984015
TRAINING - Epoch: [804][0/391]	Time 0.935 (0.935)	Data 0.349 (0.349)	Loss 0.0701 (0.0701)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [804][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0912 (0.0620)	Prec@1 95.312 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [804][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0511 (0.0681)	Prec@1 98.438 (97.466)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [804][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0452 (0.0678)	Prec@1 98.438 (97.513)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [804][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.4922 (0.4922)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 805	Training Loss 0.0691 	Training Prec@1 97.500 	Training Prec@5 99.994 	Validation Loss 0.5160 	Validation Prec@1 87.750 	Validation Prec@5 99.530 

lr: 0.009530618353204708
TRAINING - Epoch: [805][0/391]	Time 0.922 (0.922)	Data 0.344 (0.344)	Loss 0.0402 (0.0402)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0812 (0.0692)	Prec@1 97.656 (97.532)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0586 (0.0701)	Prec@1 98.438 (97.551)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0583 (0.0723)	Prec@1 98.438 (97.417)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [805][0/79]	Time 0.375 (0.375)	Data 0.356 (0.356)	Loss 0.3285 (0.3285)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 806	Training Loss 0.0723 	Training Prec@1 97.434 	Training Prec@5 99.998 	Validation Loss 0.4598 	Validation Prec@1 88.600 	Validation Prec@5 99.550 

lr: 0.009438200439070378
TRAINING - Epoch: [806][0/391]	Time 0.938 (0.938)	Data 0.350 (0.350)	Loss 0.0716 (0.0716)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [806][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0497 (0.0687)	Prec@1 97.656 (97.532)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [806][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0721 (0.0705)	Prec@1 96.875 (97.481)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [806][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1029 (0.0715)	Prec@1 95.312 (97.459)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [806][0/79]	Time 0.366 (0.366)	Data 0.346 (0.346)	Loss 0.4134 (0.4134)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 807	Training Loss 0.0715 	Training Prec@1 97.418 	Training Prec@5 99.992 	Validation Loss 0.4720 	Validation Prec@1 88.780 	Validation Prec@5 99.480 

lr: 0.009346186075467045
TRAINING - Epoch: [807][0/391]	Time 0.974 (0.974)	Data 0.370 (0.370)	Loss 0.0762 (0.0762)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [807][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0842 (0.0700)	Prec@1 97.656 (97.641)	Prec@5 99.219 (99.992)
TRAINING - Epoch: [807][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0348 (0.0691)	Prec@1 97.656 (97.547)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [807][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0464 (0.0691)	Prec@1 98.438 (97.529)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [807][0/79]	Time 0.345 (0.345)	Data 0.322 (0.322)	Loss 0.3002 (0.3002)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:25

 Epoch: 808	Training Loss 0.0679 	Training Prec@1 97.574 	Training Prec@5 99.996 	Validation Loss 0.4824 	Validation Prec@1 88.120 	Validation Prec@5 99.560 

lr: 0.00925457617784829
TRAINING - Epoch: [808][0/391]	Time 0.927 (0.927)	Data 0.350 (0.350)	Loss 0.0499 (0.0499)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [808][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0305 (0.0707)	Prec@1 98.438 (97.416)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [808][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0816 (0.0685)	Prec@1 98.438 (97.536)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [808][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0580 (0.0696)	Prec@1 97.656 (97.456)	Prec@5 99.219 (99.995)
EVALUATING - Epoch: [808][0/79]	Time 0.357 (0.357)	Data 0.337 (0.337)	Loss 0.2909 (0.2909)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 809	Training Loss 0.0702 	Training Prec@1 97.456 	Training Prec@5 99.996 	Validation Loss 0.4845 	Validation Prec@1 88.160 	Validation Prec@5 99.520 

lr: 0.009163371657643705
TRAINING - Epoch: [809][0/391]	Time 0.933 (0.933)	Data 0.351 (0.351)	Loss 0.0742 (0.0742)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [809][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0258 (0.0691)	Prec@1 99.219 (97.463)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [809][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0769 (0.0695)	Prec@1 97.656 (97.470)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [809][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0761 (0.0709)	Prec@1 95.312 (97.438)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [809][0/79]	Time 0.352 (0.352)	Data 0.329 (0.329)	Loss 0.3706 (0.3706)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:28

 Epoch: 810	Training Loss 0.0691 	Training Prec@1 97.522 	Training Prec@5 99.992 	Validation Loss 0.4612 	Validation Prec@1 88.470 	Validation Prec@5 99.570 

lr: 0.009072573422249692
TRAINING - Epoch: [810][0/391]	Time 0.931 (0.931)	Data 0.354 (0.354)	Loss 0.0252 (0.0252)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0431 (0.0705)	Prec@1 98.438 (97.409)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0422 (0.0690)	Prec@1 98.438 (97.439)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0686 (0.0665)	Prec@1 97.656 (97.547)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [810][0/79]	Time 0.350 (0.350)	Data 0.330 (0.330)	Loss 0.2957 (0.2957)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 811	Training Loss 0.0680 	Training Prec@1 97.516 	Training Prec@5 99.998 	Validation Loss 0.4733 	Validation Prec@1 88.380 	Validation Prec@5 99.470 

lr: 0.008982182375020555
TRAINING - Epoch: [811][0/391]	Time 0.913 (0.913)	Data 0.347 (0.347)	Loss 0.0789 (0.0789)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0858 (0.0733)	Prec@1 96.875 (97.269)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0403 (0.0728)	Prec@1 98.438 (97.326)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0438 (0.0726)	Prec@1 98.438 (97.366)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [811][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.3443 (0.3443)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 812	Training Loss 0.0719 	Training Prec@1 97.416 	Training Prec@5 99.998 	Validation Loss 0.4880 	Validation Prec@1 88.360 	Validation Prec@5 99.390 

lr: 0.00889219941525949
TRAINING - Epoch: [812][0/391]	Time 0.949 (0.949)	Data 0.381 (0.381)	Loss 0.0735 (0.0735)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [812][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1067 (0.0665)	Prec@1 97.656 (97.571)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [812][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1454 (0.0675)	Prec@1 96.094 (97.528)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [812][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0748 (0.0672)	Prec@1 97.656 (97.576)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [812][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.3767 (0.3767)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 813	Training Loss 0.0684 	Training Prec@1 97.494 	Training Prec@5 99.994 	Validation Loss 0.4766 	Validation Prec@1 88.490 	Validation Prec@5 99.520 

lr: 0.008802625438209585
TRAINING - Epoch: [813][0/391]	Time 0.924 (0.924)	Data 0.352 (0.352)	Loss 0.0831 (0.0831)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [813][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0851 (0.0702)	Prec@1 97.656 (97.525)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [813][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0669 (0.0681)	Prec@1 97.656 (97.590)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [813][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0682 (0.0703)	Prec@1 98.438 (97.480)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [813][0/79]	Time 0.373 (0.373)	Data 0.353 (0.353)	Loss 0.4012 (0.4012)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:58

 Epoch: 814	Training Loss 0.0711 	Training Prec@1 97.454 	Training Prec@5 99.988 	Validation Loss 0.4721 	Validation Prec@1 88.270 	Validation Prec@5 99.560 

lr: 0.008713461335044971
TRAINING - Epoch: [814][0/391]	Time 0.933 (0.933)	Data 0.357 (0.357)	Loss 0.0426 (0.0426)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [814][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0944 (0.0695)	Prec@1 96.875 (97.548)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [814][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0651 (0.0711)	Prec@1 96.094 (97.493)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [814][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1045 (0.0712)	Prec@1 95.312 (97.477)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [814][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.3686 (0.3686)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:54

 Epoch: 815	Training Loss 0.0721 	Training Prec@1 97.450 	Training Prec@5 99.986 	Validation Loss 0.4848 	Validation Prec@1 88.200 	Validation Prec@5 99.620 

lr: 0.008624707992861887
TRAINING - Epoch: [815][0/391]	Time 0.993 (0.993)	Data 0.394 (0.394)	Loss 0.1053 (0.1053)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [815][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0881 (0.0705)	Prec@1 95.312 (97.347)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [815][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.0705 (0.0708)	Prec@1 97.656 (97.306)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [815][300/391]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.0647 (0.0696)	Prec@1 96.875 (97.449)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [815][0/79]	Time 0.340 (0.340)	Data 0.319 (0.319)	Loss 0.3650 (0.3650)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:27

 Epoch: 816	Training Loss 0.0702 	Training Prec@1 97.418 	Training Prec@5 99.994 	Validation Loss 0.4600 	Validation Prec@1 88.360 	Validation Prec@5 99.540 

lr: 0.008536366294669969
TRAINING - Epoch: [816][0/391]	Time 0.953 (0.953)	Data 0.377 (0.377)	Loss 0.0734 (0.0734)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [816][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0933 (0.0739)	Prec@1 96.875 (97.347)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [816][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.1263 (0.0692)	Prec@1 97.656 (97.536)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [816][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0606 (0.0706)	Prec@1 96.875 (97.443)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [816][0/79]	Time 0.369 (0.369)	Data 0.346 (0.346)	Loss 0.2946 (0.2946)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:44

 Epoch: 817	Training Loss 0.0711 	Training Prec@1 97.398 	Training Prec@5 99.996 	Validation Loss 0.4797 	Validation Prec@1 88.080 	Validation Prec@5 99.510 

lr: 0.008448437119383341
TRAINING - Epoch: [817][0/391]	Time 0.922 (0.922)	Data 0.354 (0.354)	Loss 0.0998 (0.0998)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0287 (0.0669)	Prec@1 99.219 (97.486)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0981 (0.0699)	Prec@1 96.875 (97.481)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1225 (0.0687)	Prec@1 94.531 (97.511)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [817][0/79]	Time 0.358 (0.358)	Data 0.336 (0.336)	Loss 0.2975 (0.2975)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 818	Training Loss 0.0688 	Training Prec@1 97.498 	Training Prec@5 100.000 	Validation Loss 0.4956 	Validation Prec@1 88.040 	Validation Prec@5 99.500 

lr: 0.008360921341811945
TRAINING - Epoch: [818][0/391]	Time 0.925 (0.925)	Data 0.352 (0.352)	Loss 0.1378 (0.1378)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0897 (0.0690)	Prec@1 96.094 (97.509)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0516 (0.0703)	Prec@1 98.438 (97.501)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1193 (0.0705)	Prec@1 97.656 (97.506)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [818][0/79]	Time 0.367 (0.367)	Data 0.343 (0.343)	Loss 0.4504 (0.4504)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 819	Training Loss 0.0708 	Training Prec@1 97.482 	Training Prec@5 99.996 	Validation Loss 0.5121 	Validation Prec@1 87.440 	Validation Prec@5 99.550 

lr: 0.008273819832652813
TRAINING - Epoch: [819][0/391]	Time 0.945 (0.945)	Data 0.383 (0.383)	Loss 0.0442 (0.0442)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [819][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0585 (0.0644)	Prec@1 96.875 (97.672)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [819][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1202 (0.0621)	Prec@1 94.531 (97.715)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [819][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0454 (0.0650)	Prec@1 98.438 (97.576)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [819][0/79]	Time 0.342 (0.342)	Data 0.322 (0.322)	Loss 0.3497 (0.3497)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:22

 Epoch: 820	Training Loss 0.0676 	Training Prec@1 97.502 	Training Prec@5 99.996 	Validation Loss 0.4866 	Validation Prec@1 88.350 	Validation Prec@5 99.500 

lr: 0.008187133458481407
TRAINING - Epoch: [820][0/391]	Time 0.937 (0.937)	Data 0.337 (0.337)	Loss 0.0518 (0.0518)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [820][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0329 (0.0638)	Prec@1 99.219 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [820][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1083 (0.0687)	Prec@1 94.531 (97.466)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [820][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1108 (0.0692)	Prec@1 95.312 (97.482)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [820][0/79]	Time 0.368 (0.368)	Data 0.348 (0.348)	Loss 0.3672 (0.3672)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:03

 Epoch: 821	Training Loss 0.0676 	Training Prec@1 97.554 	Training Prec@5 99.998 	Validation Loss 0.4860 	Validation Prec@1 88.000 	Validation Prec@5 99.510 

lr: 0.008100863081743
TRAINING - Epoch: [821][0/391]	Time 0.925 (0.925)	Data 0.356 (0.356)	Loss 0.0482 (0.0482)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [821][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0617 (0.0682)	Prec@1 97.656 (97.610)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [821][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1023 (0.0713)	Prec@1 96.094 (97.446)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [821][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0163 (0.0695)	Prec@1 100.000 (97.542)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [821][0/79]	Time 0.374 (0.374)	Data 0.348 (0.348)	Loss 0.3350 (0.3350)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 822	Training Loss 0.0692 	Training Prec@1 97.576 	Training Prec@5 100.000 	Validation Loss 0.4880 	Validation Prec@1 88.210 	Validation Prec@5 99.490 

lr: 0.008015009560744092
TRAINING - Epoch: [822][0/391]	Time 0.910 (0.910)	Data 0.351 (0.351)	Loss 0.0932 (0.0932)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [822][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0560 (0.0745)	Prec@1 96.094 (97.300)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [822][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0541 (0.0715)	Prec@1 98.438 (97.439)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [822][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.0895 (0.0699)	Prec@1 97.656 (97.482)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [822][0/79]	Time 0.335 (0.335)	Data 0.314 (0.314)	Loss 0.4059 (0.4059)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:49

 Epoch: 823	Training Loss 0.0691 	Training Prec@1 97.500 	Training Prec@5 99.996 	Validation Loss 0.4732 	Validation Prec@1 88.640 	Validation Prec@5 99.610 

lr: 0.007929573749643887
TRAINING - Epoch: [823][0/391]	Time 0.930 (0.930)	Data 0.352 (0.352)	Loss 0.0689 (0.0689)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [823][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0954 (0.0681)	Prec@1 97.656 (97.571)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [823][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0931 (0.0707)	Prec@1 96.094 (97.505)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [823][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0197 (0.0693)	Prec@1 100.000 (97.534)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [823][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.4138 (0.4138)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 824	Training Loss 0.0679 	Training Prec@1 97.566 	Training Prec@5 99.998 	Validation Loss 0.4825 	Validation Prec@1 88.130 	Validation Prec@5 99.600 

lr: 0.007844556498445777
TRAINING - Epoch: [824][0/391]	Time 0.908 (0.908)	Data 0.344 (0.344)	Loss 0.0591 (0.0591)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [824][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0656 (0.0616)	Prec@1 97.656 (97.826)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [824][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0713 (0.0638)	Prec@1 98.438 (97.765)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [824][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0424 (0.0653)	Prec@1 98.438 (97.719)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [824][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.4947 (0.4947)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:50

 Epoch: 825	Training Loss 0.0664 	Training Prec@1 97.664 	Training Prec@5 99.998 	Validation Loss 0.4871 	Validation Prec@1 88.260 	Validation Prec@5 99.540 

lr: 0.007759958652988858
TRAINING - Epoch: [825][0/391]	Time 0.929 (0.929)	Data 0.343 (0.343)	Loss 0.0809 (0.0809)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0287 (0.0680)	Prec@1 98.438 (97.478)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0368 (0.0683)	Prec@1 96.875 (97.439)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0701 (0.0693)	Prec@1 96.875 (97.425)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [825][0/79]	Time 0.361 (0.361)	Data 0.339 (0.339)	Loss 0.4614 (0.4614)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 826	Training Loss 0.0694 	Training Prec@1 97.430 	Training Prec@5 99.996 	Validation Loss 0.4915 	Validation Prec@1 88.100 	Validation Prec@5 99.400 

lr: 0.007675781054939574
TRAINING - Epoch: [826][0/391]	Time 0.930 (0.930)	Data 0.342 (0.342)	Loss 0.0784 (0.0784)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [826][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0374 (0.0660)	Prec@1 98.438 (97.649)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [826][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0783 (0.0674)	Prec@1 98.438 (97.555)	Prec@5 99.219 (99.996)
TRAINING - Epoch: [826][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0762 (0.0719)	Prec@1 96.094 (97.392)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [826][0/79]	Time 0.350 (0.350)	Data 0.327 (0.327)	Loss 0.4009 (0.4009)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 827	Training Loss 0.0729 	Training Prec@1 97.384 	Training Prec@5 99.996 	Validation Loss 0.4789 	Validation Prec@1 88.730 	Validation Prec@5 99.460 

lr: 0.007592024541783333
TRAINING - Epoch: [827][0/391]	Time 0.945 (0.945)	Data 0.347 (0.347)	Loss 0.0163 (0.0163)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [827][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0548 (0.0677)	Prec@1 96.875 (97.409)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [827][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.0310 (0.0695)	Prec@1 100.000 (97.435)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [827][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0615 (0.0687)	Prec@1 98.438 (97.516)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [827][0/79]	Time 0.356 (0.356)	Data 0.337 (0.337)	Loss 0.4740 (0.4740)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 828	Training Loss 0.0703 	Training Prec@1 97.472 	Training Prec@5 99.996 	Validation Loss 0.4975 	Validation Prec@1 88.000 	Validation Prec@5 99.550 

lr: 0.007508689946816117
TRAINING - Epoch: [828][0/391]	Time 0.924 (0.924)	Data 0.349 (0.349)	Loss 0.0504 (0.0504)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [828][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0259 (0.0661)	Prec@1 99.219 (97.625)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [828][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0647 (0.0674)	Prec@1 96.875 (97.547)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [828][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1085 (0.0675)	Prec@1 96.094 (97.547)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [828][0/79]	Time 0.378 (0.378)	Data 0.357 (0.357)	Loss 0.4639 (0.4639)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 829	Training Loss 0.0673 	Training Prec@1 97.534 	Training Prec@5 99.994 	Validation Loss 0.4744 	Validation Prec@1 88.310 	Validation Prec@5 99.620 

lr: 0.007425778099136271
TRAINING - Epoch: [829][0/391]	Time 0.921 (0.921)	Data 0.360 (0.360)	Loss 0.0407 (0.0407)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [829][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0813 (0.0739)	Prec@1 98.438 (97.277)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [829][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0793 (0.0685)	Prec@1 96.094 (97.454)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [829][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0506 (0.0682)	Prec@1 98.438 (97.493)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [829][0/79]	Time 0.388 (0.388)	Data 0.363 (0.363)	Loss 0.3851 (0.3851)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 830	Training Loss 0.0693 	Training Prec@1 97.452 	Training Prec@5 99.996 	Validation Loss 0.4697 	Validation Prec@1 88.560 	Validation Prec@5 99.460 

lr: 0.007343289823636157
TRAINING - Epoch: [830][0/391]	Time 0.943 (0.943)	Data 0.362 (0.362)	Loss 0.0552 (0.0552)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [830][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.0339 (0.0687)	Prec@1 97.656 (97.517)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [830][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0265 (0.0702)	Prec@1 99.219 (97.435)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [830][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0852 (0.0704)	Prec@1 96.875 (97.477)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [830][0/79]	Time 0.376 (0.376)	Data 0.356 (0.356)	Loss 0.4019 (0.4019)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:49

 Epoch: 831	Training Loss 0.0685 	Training Prec@1 97.536 	Training Prec@5 99.994 	Validation Loss 0.4970 	Validation Prec@1 87.830 	Validation Prec@5 99.570 

lr: 0.0072612259409940766
TRAINING - Epoch: [831][0/391]	Time 0.958 (0.958)	Data 0.362 (0.362)	Loss 0.0724 (0.0724)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [831][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.0356 (0.0730)	Prec@1 99.219 (97.494)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [831][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0398 (0.0695)	Prec@1 99.219 (97.501)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [831][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0161 (0.0701)	Prec@1 100.000 (97.488)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [831][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.4194 (0.4194)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:31

 Epoch: 832	Training Loss 0.0709 	Training Prec@1 97.448 	Training Prec@5 99.996 	Validation Loss 0.4633 	Validation Prec@1 88.780 	Validation Prec@5 99.560 

lr: 0.007179587267665989
TRAINING - Epoch: [832][0/391]	Time 0.911 (0.911)	Data 0.345 (0.345)	Loss 0.0607 (0.0607)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [832][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0639 (0.0623)	Prec@1 96.875 (97.811)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [832][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1118 (0.0653)	Prec@1 96.094 (97.707)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [832][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0419 (0.0665)	Prec@1 98.438 (97.656)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [832][0/79]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.4104 (0.4104)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 833	Training Loss 0.0655 	Training Prec@1 97.668 	Training Prec@5 99.990 	Validation Loss 0.4648 	Validation Prec@1 88.120 	Validation Prec@5 99.490 

lr: 0.007098374615877429
TRAINING - Epoch: [833][0/391]	Time 0.931 (0.931)	Data 0.344 (0.344)	Loss 0.0396 (0.0396)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [833][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0603 (0.0680)	Prec@1 98.438 (97.571)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [833][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0455 (0.0707)	Prec@1 98.438 (97.454)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [833][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0412 (0.0680)	Prec@1 98.438 (97.545)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [833][0/79]	Time 0.374 (0.374)	Data 0.350 (0.350)	Loss 0.4126 (0.4126)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 834	Training Loss 0.0677 	Training Prec@1 97.570 	Training Prec@5 99.992 	Validation Loss 0.4502 	Validation Prec@1 88.710 	Validation Prec@5 99.530 

lr: 0.0070175887936154875
TRAINING - Epoch: [834][0/391]	Time 1.042 (1.042)	Data 0.359 (0.359)	Loss 0.0496 (0.0496)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [834][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.0819 (0.0683)	Prec@1 98.438 (97.502)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [834][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.0410 (0.0699)	Prec@1 98.438 (97.571)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [834][300/391]	Time 0.064 (0.067)	Data 0.000 (0.001)	Loss 0.0712 (0.0688)	Prec@1 96.094 (97.568)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [834][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 0.3249 (0.3249)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:09

 Epoch: 835	Training Loss 0.0674 	Training Prec@1 97.634 	Training Prec@5 99.992 	Validation Loss 0.4621 	Validation Prec@1 88.250 	Validation Prec@5 99.510 

lr: 0.006937230604620632
TRAINING - Epoch: [835][0/391]	Time 0.927 (0.927)	Data 0.346 (0.346)	Loss 0.0637 (0.0637)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [835][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0692 (0.0680)	Prec@1 99.219 (97.447)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [835][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0527 (0.0671)	Prec@1 97.656 (97.516)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [835][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0599 (0.0679)	Prec@1 99.219 (97.477)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [835][0/79]	Time 0.344 (0.344)	Data 0.326 (0.326)	Loss 0.3251 (0.3251)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 836	Training Loss 0.0691 	Training Prec@1 97.466 	Training Prec@5 99.998 	Validation Loss 0.4567 	Validation Prec@1 88.710 	Validation Prec@5 99.530 

lr: 0.006857300848378856
TRAINING - Epoch: [836][0/391]	Time 0.939 (0.939)	Data 0.378 (0.378)	Loss 0.0562 (0.0562)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [836][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0415 (0.0689)	Prec@1 99.219 (97.509)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [836][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0539 (0.0685)	Prec@1 98.438 (97.485)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [836][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0580 (0.0681)	Prec@1 96.875 (97.547)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [836][0/79]	Time 0.368 (0.368)	Data 0.347 (0.347)	Loss 0.4762 (0.4762)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:30

 Epoch: 837	Training Loss 0.0684 	Training Prec@1 97.528 	Training Prec@5 99.994 	Validation Loss 0.4968 	Validation Prec@1 87.670 	Validation Prec@5 99.500 

lr: 0.006777800320113631
TRAINING - Epoch: [837][0/391]	Time 0.937 (0.937)	Data 0.337 (0.337)	Loss 0.0726 (0.0726)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][100/391]	Time 0.061 (0.072)	Data 0.000 (0.004)	Loss 0.0448 (0.0694)	Prec@1 99.219 (97.347)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0765 (0.0694)	Prec@1 96.875 (97.435)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0538 (0.0686)	Prec@1 98.438 (97.495)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [837][0/79]	Time 0.355 (0.355)	Data 0.336 (0.336)	Loss 0.3448 (0.3448)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:23

 Epoch: 838	Training Loss 0.0683 	Training Prec@1 97.502 	Training Prec@5 100.000 	Validation Loss 0.4674 	Validation Prec@1 88.130 	Validation Prec@5 99.550 

lr: 0.0066987298107780546
TRAINING - Epoch: [838][0/391]	Time 0.933 (0.933)	Data 0.351 (0.351)	Loss 0.0668 (0.0668)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [838][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0356 (0.0648)	Prec@1 99.219 (97.710)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [838][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0993 (0.0658)	Prec@1 96.875 (97.699)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [838][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0593 (0.0670)	Prec@1 97.656 (97.610)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [838][0/79]	Time 0.387 (0.387)	Data 0.363 (0.363)	Loss 0.3431 (0.3431)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 839	Training Loss 0.0663 	Training Prec@1 97.626 	Training Prec@5 99.998 	Validation Loss 0.4615 	Validation Prec@1 88.560 	Validation Prec@5 99.530 

lr: 0.00662009010704694
TRAINING - Epoch: [839][0/391]	Time 0.929 (0.929)	Data 0.350 (0.350)	Loss 0.0688 (0.0688)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [839][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0448 (0.0619)	Prec@1 99.219 (97.803)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [839][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0796 (0.0643)	Prec@1 96.094 (97.707)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [839][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0949 (0.0663)	Prec@1 96.094 (97.643)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [839][0/79]	Time 0.373 (0.373)	Data 0.349 (0.349)	Loss 0.4363 (0.4363)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:34

 Epoch: 840	Training Loss 0.0656 	Training Prec@1 97.638 	Training Prec@5 99.994 	Validation Loss 0.4840 	Validation Prec@1 88.080 	Validation Prec@5 99.470 

lr: 0.006541881991308992
TRAINING - Epoch: [840][0/391]	Time 0.928 (0.928)	Data 0.358 (0.358)	Loss 0.0794 (0.0794)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0859 (0.0630)	Prec@1 97.656 (97.749)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0193 (0.0643)	Prec@1 99.219 (97.625)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [840][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1015 (0.0661)	Prec@1 96.875 (97.560)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [840][0/79]	Time 0.369 (0.369)	Data 0.346 (0.346)	Loss 0.4507 (0.4507)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 841	Training Loss 0.0673 	Training Prec@1 97.538 	Training Prec@5 99.998 	Validation Loss 0.4774 	Validation Prec@1 88.180 	Validation Prec@5 99.430 

lr: 0.0064641062416590424
TRAINING - Epoch: [841][0/391]	Time 0.930 (0.930)	Data 0.363 (0.363)	Loss 0.0972 (0.0972)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [841][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0350 (0.0694)	Prec@1 99.219 (97.494)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [841][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0408 (0.0674)	Prec@1 97.656 (97.524)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [841][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0298 (0.0669)	Prec@1 99.219 (97.620)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [841][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.4382 (0.4382)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 842	Training Loss 0.0669 	Training Prec@1 97.606 	Training Prec@5 99.996 	Validation Loss 0.4699 	Validation Prec@1 88.120 	Validation Prec@5 99.550 

lr: 0.006386763631890305
TRAINING - Epoch: [842][0/391]	Time 0.942 (0.942)	Data 0.367 (0.367)	Loss 0.0354 (0.0354)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [842][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0864 (0.0669)	Prec@1 96.875 (97.602)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [842][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0858 (0.0690)	Prec@1 96.875 (97.512)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [842][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0785 (0.0685)	Prec@1 96.875 (97.558)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [842][0/79]	Time 0.371 (0.371)	Data 0.349 (0.349)	Loss 0.3926 (0.3926)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 843	Training Loss 0.0680 	Training Prec@1 97.544 	Training Prec@5 99.994 	Validation Loss 0.4546 	Validation Prec@1 88.220 	Validation Prec@5 99.560 

lr: 0.006309854931486667
TRAINING - Epoch: [843][0/391]	Time 0.932 (0.932)	Data 0.372 (0.372)	Loss 0.1080 (0.1080)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [843][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0155 (0.0653)	Prec@1 100.000 (97.649)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [843][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0451 (0.0667)	Prec@1 99.219 (97.645)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [843][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0683 (0.0638)	Prec@1 96.094 (97.724)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [843][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.3320 (0.3320)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:31

 Epoch: 844	Training Loss 0.0665 	Training Prec@1 97.574 	Training Prec@5 99.998 	Validation Loss 0.4626 	Validation Prec@1 87.910 	Validation Prec@5 99.600 

lr: 0.006233380905615029
TRAINING - Epoch: [844][0/391]	Time 0.933 (0.933)	Data 0.350 (0.350)	Loss 0.0285 (0.0285)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0521 (0.0631)	Prec@1 99.219 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0776 (0.0603)	Prec@1 96.094 (97.870)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0517 (0.0609)	Prec@1 97.656 (97.838)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [844][0/79]	Time 0.410 (0.410)	Data 0.389 (0.389)	Loss 0.4231 (0.4231)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 845	Training Loss 0.0622 	Training Prec@1 97.780 	Training Prec@5 100.000 	Validation Loss 0.4610 	Validation Prec@1 88.170 	Validation Prec@5 99.630 

lr: 0.006157342315117744
TRAINING - Epoch: [845][0/391]	Time 0.936 (0.936)	Data 0.352 (0.352)	Loss 0.0534 (0.0534)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1183 (0.0728)	Prec@1 95.312 (97.285)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0842 (0.0715)	Prec@1 97.656 (97.454)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1243 (0.0700)	Prec@1 95.312 (97.493)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [845][0/79]	Time 0.340 (0.340)	Data 0.320 (0.320)	Loss 0.4314 (0.4314)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 846	Training Loss 0.0685 	Training Prec@1 97.564 	Training Prec@5 99.994 	Validation Loss 0.4642 	Validation Prec@1 88.180 	Validation Prec@5 99.550 

lr: 0.006081739916504938
TRAINING - Epoch: [846][0/391]	Time 0.928 (0.928)	Data 0.341 (0.341)	Loss 0.0594 (0.0594)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [846][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0666 (0.0660)	Prec@1 96.094 (97.486)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [846][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0891 (0.0646)	Prec@1 98.438 (97.559)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [846][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1192 (0.0654)	Prec@1 94.531 (97.558)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [846][0/79]	Time 0.352 (0.352)	Data 0.329 (0.329)	Loss 0.3929 (0.3929)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 847	Training Loss 0.0660 	Training Prec@1 97.568 	Training Prec@5 99.994 	Validation Loss 0.4465 	Validation Prec@1 88.370 	Validation Prec@5 99.540 

lr: 0.006006574461947109
TRAINING - Epoch: [847][0/391]	Time 0.967 (0.967)	Data 0.365 (0.365)	Loss 0.1068 (0.1068)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [847][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0271 (0.0673)	Prec@1 99.219 (97.703)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [847][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0703 (0.0654)	Prec@1 98.438 (97.734)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [847][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0614 (0.0654)	Prec@1 98.438 (97.682)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [847][0/79]	Time 0.352 (0.352)	Data 0.330 (0.330)	Loss 0.3673 (0.3673)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:29

 Epoch: 848	Training Loss 0.0657 	Training Prec@1 97.658 	Training Prec@5 99.994 	Validation Loss 0.4659 	Validation Prec@1 88.250 	Validation Prec@5 99.490 

lr: 0.0059318466992675485
TRAINING - Epoch: [848][0/391]	Time 0.941 (0.941)	Data 0.365 (0.365)	Loss 0.0237 (0.0237)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [848][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0286 (0.0655)	Prec@1 99.219 (97.633)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [848][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0469 (0.0674)	Prec@1 98.438 (97.602)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [848][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0496 (0.0671)	Prec@1 97.656 (97.617)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [848][0/79]	Time 0.358 (0.358)	Data 0.338 (0.338)	Loss 0.3735 (0.3735)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:59

 Epoch: 849	Training Loss 0.0666 	Training Prec@1 97.624 	Training Prec@5 99.994 	Validation Loss 0.4597 	Validation Prec@1 88.360 	Validation Prec@5 99.570 

lr: 0.005857557371934972
TRAINING - Epoch: [849][0/391]	Time 0.924 (0.924)	Data 0.352 (0.352)	Loss 0.0344 (0.0344)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [849][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0602 (0.0637)	Prec@1 97.656 (97.633)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [849][200/391]	Time 0.060 (0.066)	Data 0.000 (0.002)	Loss 0.0540 (0.0637)	Prec@1 98.438 (97.668)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [849][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.0672 (0.0642)	Prec@1 96.875 (97.674)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [849][0/79]	Time 0.373 (0.373)	Data 0.350 (0.350)	Loss 0.3427 (0.3427)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:36

 Epoch: 850	Training Loss 0.0650 	Training Prec@1 97.632 	Training Prec@5 99.990 	Validation Loss 0.4576 	Validation Prec@1 88.370 	Validation Prec@5 99.580 

lr: 0.00578370721905607
TRAINING - Epoch: [850][0/391]	Time 0.913 (0.913)	Data 0.338 (0.338)	Loss 0.0383 (0.0383)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [850][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1092 (0.0678)	Prec@1 96.094 (97.548)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [850][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0449 (0.0688)	Prec@1 99.219 (97.563)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [850][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0532 (0.0655)	Prec@1 99.219 (97.643)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [850][0/79]	Time 0.363 (0.363)	Data 0.340 (0.340)	Loss 0.3664 (0.3664)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 851	Training Loss 0.0667 	Training Prec@1 97.596 	Training Prec@5 99.998 	Validation Loss 0.4555 	Validation Prec@1 88.030 	Validation Prec@5 99.630 

lr: 0.005710296975368154
TRAINING - Epoch: [851][0/391]	Time 0.929 (0.929)	Data 0.359 (0.359)	Loss 0.0613 (0.0613)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [851][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0341 (0.0648)	Prec@1 99.219 (97.579)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [851][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0925 (0.0654)	Prec@1 96.094 (97.613)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [851][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0922 (0.0671)	Prec@1 96.875 (97.591)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [851][0/79]	Time 0.336 (0.336)	Data 0.316 (0.316)	Loss 0.3410 (0.3410)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 852	Training Loss 0.0666 	Training Prec@1 97.602 	Training Prec@5 100.000 	Validation Loss 0.4451 	Validation Prec@1 88.560 	Validation Prec@5 99.560 

lr: 0.005637327371231913
TRAINING - Epoch: [852][0/391]	Time 0.940 (0.940)	Data 0.345 (0.345)	Loss 0.0729 (0.0729)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [852][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0696 (0.0690)	Prec@1 97.656 (97.571)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [852][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0320 (0.0675)	Prec@1 99.219 (97.664)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [852][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0633 (0.0679)	Prec@1 97.656 (97.620)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [852][0/79]	Time 0.376 (0.376)	Data 0.354 (0.354)	Loss 0.3407 (0.3407)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 853	Training Loss 0.0671 	Training Prec@1 97.676 	Training Prec@5 99.996 	Validation Loss 0.4558 	Validation Prec@1 88.130 	Validation Prec@5 99.470 

lr: 0.005564799132624058
TRAINING - Epoch: [853][0/391]	Time 0.929 (0.929)	Data 0.349 (0.349)	Loss 0.0317 (0.0317)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [853][100/391]	Time 0.060 (0.071)	Data 0.000 (0.004)	Loss 0.0376 (0.0675)	Prec@1 97.656 (97.525)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [853][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1143 (0.0648)	Prec@1 96.094 (97.738)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [853][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0636 (0.0650)	Prec@1 98.438 (97.757)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [853][0/79]	Time 0.368 (0.368)	Data 0.345 (0.345)	Loss 0.4057 (0.4057)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:01

 Epoch: 854	Training Loss 0.0637 	Training Prec@1 97.788 	Training Prec@5 99.996 	Validation Loss 0.4522 	Validation Prec@1 88.230 	Validation Prec@5 99.490 

lr: 0.005492712981130164
TRAINING - Epoch: [854][0/391]	Time 0.951 (0.951)	Data 0.346 (0.346)	Loss 0.0675 (0.0675)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [854][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0388 (0.0649)	Prec@1 98.438 (97.795)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [854][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0483 (0.0654)	Prec@1 99.219 (97.730)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [854][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0273 (0.0681)	Prec@1 99.219 (97.617)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [854][0/79]	Time 0.353 (0.353)	Data 0.331 (0.331)	Loss 0.3369 (0.3369)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 855	Training Loss 0.0680 	Training Prec@1 97.620 	Training Prec@5 99.996 	Validation Loss 0.4501 	Validation Prec@1 88.240 	Validation Prec@5 99.450 

lr: 0.005421069633937463
TRAINING - Epoch: [855][0/391]	Time 0.931 (0.931)	Data 0.360 (0.360)	Loss 0.0649 (0.0649)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [855][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0643 (0.0669)	Prec@1 98.438 (97.718)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [855][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0666 (0.0673)	Prec@1 98.438 (97.722)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [855][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0401 (0.0692)	Prec@1 97.656 (97.641)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [855][0/79]	Time 0.362 (0.362)	Data 0.340 (0.340)	Loss 0.4214 (0.4214)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 856	Training Loss 0.0683 	Training Prec@1 97.640 	Training Prec@5 99.990 	Validation Loss 0.4431 	Validation Prec@1 88.430 	Validation Prec@5 99.560 

lr: 0.00534986980382771
TRAINING - Epoch: [856][0/391]	Time 0.953 (0.953)	Data 0.378 (0.378)	Loss 0.0997 (0.0997)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0376 (0.0610)	Prec@1 98.438 (97.904)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0355 (0.0625)	Prec@1 98.438 (97.835)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0693 (0.0640)	Prec@1 97.656 (97.820)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [856][0/79]	Time 0.349 (0.349)	Data 0.328 (0.328)	Loss 0.4074 (0.4074)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:22:46

 Epoch: 857	Training Loss 0.0653 	Training Prec@1 97.744 	Training Prec@5 99.994 	Validation Loss 0.4488 	Validation Prec@1 88.020 	Validation Prec@5 99.510 

lr: 0.005279114199170097
TRAINING - Epoch: [857][0/391]	Time 0.924 (0.924)	Data 0.353 (0.353)	Loss 0.0384 (0.0384)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [857][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0671 (0.0662)	Prec@1 97.656 (97.703)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [857][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0995 (0.0676)	Prec@1 95.312 (97.629)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [857][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0874 (0.0690)	Prec@1 96.094 (97.547)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [857][0/79]	Time 0.343 (0.343)	Data 0.323 (0.323)	Loss 0.3358 (0.3358)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 858	Training Loss 0.0688 	Training Prec@1 97.566 	Training Prec@5 99.994 	Validation Loss 0.4430 	Validation Prec@1 88.160 	Validation Prec@5 99.530 

lr: 0.005208803523914206
TRAINING - Epoch: [858][0/391]	Time 0.908 (0.908)	Data 0.347 (0.347)	Loss 0.1023 (0.1023)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [858][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0518 (0.0674)	Prec@1 97.656 (97.471)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [858][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0875 (0.0667)	Prec@1 96.875 (97.602)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [858][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0374 (0.0646)	Prec@1 98.438 (97.661)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [858][0/79]	Time 0.380 (0.380)	Data 0.356 (0.356)	Loss 0.3434 (0.3434)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:04

 Epoch: 859	Training Loss 0.0644 	Training Prec@1 97.670 	Training Prec@5 99.996 	Validation Loss 0.4469 	Validation Prec@1 88.180 	Validation Prec@5 99.540 

lr: 0.005138938477582998
TRAINING - Epoch: [859][0/391]	Time 0.916 (0.916)	Data 0.343 (0.343)	Loss 0.0169 (0.0169)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [859][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0615 (0.0634)	Prec@1 97.656 (97.850)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [859][200/391]	Time 0.067 (0.066)	Data 0.000 (0.002)	Loss 0.0436 (0.0633)	Prec@1 98.438 (97.831)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [859][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0713 (0.0640)	Prec@1 98.438 (97.791)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [859][0/79]	Time 0.340 (0.340)	Data 0.319 (0.319)	Loss 0.3871 (0.3871)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 860	Training Loss 0.0645 	Training Prec@1 97.748 	Training Prec@5 99.992 	Validation Loss 0.4543 	Validation Prec@1 88.040 	Validation Prec@5 99.500 

lr: 0.005069519755265894
TRAINING - Epoch: [860][0/391]	Time 0.934 (0.934)	Data 0.347 (0.347)	Loss 0.0472 (0.0472)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [860][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0355 (0.0648)	Prec@1 98.438 (97.795)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [860][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0415 (0.0651)	Prec@1 99.219 (97.730)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [860][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0184 (0.0640)	Prec@1 100.000 (97.713)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [860][0/79]	Time 0.363 (0.363)	Data 0.337 (0.337)	Loss 0.3191 (0.3191)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 861	Training Loss 0.0645 	Training Prec@1 97.676 	Training Prec@5 99.990 	Validation Loss 0.4454 	Validation Prec@1 88.440 	Validation Prec@5 99.450 

lr: 0.005000548047611758
TRAINING - Epoch: [861][0/391]	Time 0.907 (0.907)	Data 0.347 (0.347)	Loss 0.1757 (0.1757)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [861][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0489 (0.0637)	Prec@1 97.656 (97.819)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [861][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1028 (0.0634)	Prec@1 96.875 (97.882)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [861][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0756 (0.0636)	Prec@1 98.438 (97.791)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [861][0/79]	Time 0.356 (0.356)	Data 0.333 (0.333)	Loss 0.3230 (0.3230)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 862	Training Loss 0.0638 	Training Prec@1 97.768 	Training Prec@5 99.996 	Validation Loss 0.4366 	Validation Prec@1 88.460 	Validation Prec@5 99.490 

lr: 0.0049320240408221245
TRAINING - Epoch: [862][0/391]	Time 0.923 (0.923)	Data 0.359 (0.359)	Loss 0.0787 (0.0787)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [862][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0721 (0.0646)	Prec@1 97.656 (97.741)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [862][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0509 (0.0652)	Prec@1 99.219 (97.738)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [862][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0611 (0.0637)	Prec@1 97.656 (97.804)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [862][0/79]	Time 0.369 (0.369)	Data 0.345 (0.345)	Loss 0.3951 (0.3951)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 863	Training Loss 0.0640 	Training Prec@1 97.768 	Training Prec@5 99.994 	Validation Loss 0.4270 	Validation Prec@1 88.480 	Validation Prec@5 99.500 

lr: 0.004863948416644375
TRAINING - Epoch: [863][0/391]	Time 0.924 (0.924)	Data 0.338 (0.338)	Loss 0.0444 (0.0444)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [863][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0310 (0.0670)	Prec@1 97.656 (97.664)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [863][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0591 (0.0692)	Prec@1 99.219 (97.563)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [863][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0820 (0.0700)	Prec@1 98.438 (97.584)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [863][0/79]	Time 0.357 (0.357)	Data 0.336 (0.336)	Loss 0.3582 (0.3582)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 864	Training Loss 0.0690 	Training Prec@1 97.576 	Training Prec@5 99.998 	Validation Loss 0.4418 	Validation Prec@1 88.340 	Validation Prec@5 99.470 

lr: 0.004796321852364871
TRAINING - Epoch: [864][0/391]	Time 0.921 (0.921)	Data 0.347 (0.347)	Loss 0.0532 (0.0532)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [864][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0619 (0.0614)	Prec@1 96.875 (97.896)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [864][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0950 (0.0630)	Prec@1 97.656 (97.773)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [864][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0572 (0.0639)	Prec@1 98.438 (97.760)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [864][0/79]	Time 0.367 (0.367)	Data 0.346 (0.346)	Loss 0.3209 (0.3209)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:00

 Epoch: 865	Training Loss 0.0641 	Training Prec@1 97.732 	Training Prec@5 99.996 	Validation Loss 0.4414 	Validation Prec@1 88.160 	Validation Prec@5 99.480 

lr: 0.004729145020802289
TRAINING - Epoch: [865][0/391]	Time 0.922 (0.922)	Data 0.356 (0.356)	Loss 0.0853 (0.0853)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [865][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0540 (0.0680)	Prec@1 98.438 (97.687)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [865][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0425 (0.0671)	Prec@1 98.438 (97.687)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [865][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0411 (0.0665)	Prec@1 98.438 (97.695)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [865][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.3534 (0.3534)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 866	Training Loss 0.0661 	Training Prec@1 97.724 	Training Prec@5 99.998 	Validation Loss 0.4385 	Validation Prec@1 88.110 	Validation Prec@5 99.530 

lr: 0.004662418590300866
TRAINING - Epoch: [866][0/391]	Time 0.931 (0.931)	Data 0.355 (0.355)	Loss 0.0831 (0.0831)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [866][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1080 (0.0664)	Prec@1 95.312 (97.718)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [866][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0604 (0.0676)	Prec@1 98.438 (97.656)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [866][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0932 (0.0663)	Prec@1 94.531 (97.672)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [866][0/79]	Time 0.386 (0.386)	Data 0.364 (0.364)	Loss 0.2743 (0.2743)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:45

 Epoch: 867	Training Loss 0.0666 	Training Prec@1 97.656 	Training Prec@5 99.990 	Validation Loss 0.4288 	Validation Prec@1 88.390 	Validation Prec@5 99.480 

lr: 0.004596143224723837
TRAINING - Epoch: [867][0/391]	Time 0.971 (0.971)	Data 0.375 (0.375)	Loss 0.0354 (0.0354)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [867][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0417 (0.0653)	Prec@1 98.438 (97.641)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [867][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0256 (0.0665)	Prec@1 100.000 (97.606)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [867][300/391]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.0540 (0.0655)	Prec@1 99.219 (97.672)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [867][0/79]	Time 0.385 (0.385)	Data 0.361 (0.361)	Loss 0.3552 (0.3552)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:37

 Epoch: 868	Training Loss 0.0660 	Training Prec@1 97.628 	Training Prec@5 99.996 	Validation Loss 0.4330 	Validation Prec@1 88.270 	Validation Prec@5 99.560 

lr: 0.004530319583446741
TRAINING - Epoch: [868][0/391]	Time 0.994 (0.994)	Data 0.377 (0.377)	Loss 0.1029 (0.1029)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [868][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0516 (0.0660)	Prec@1 98.438 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [868][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0290 (0.0657)	Prec@1 100.000 (97.761)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [868][300/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.0583 (0.0656)	Prec@1 96.875 (97.724)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [868][0/79]	Time 0.359 (0.359)	Data 0.335 (0.335)	Loss 0.3262 (0.3262)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:40

 Epoch: 869	Training Loss 0.0668 	Training Prec@1 97.662 	Training Prec@5 99.998 	Validation Loss 0.4338 	Validation Prec@1 88.360 	Validation Prec@5 99.520 

lr: 0.004464948321350921
TRAINING - Epoch: [869][0/391]	Time 0.924 (0.924)	Data 0.350 (0.350)	Loss 0.1411 (0.1411)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0728 (0.0645)	Prec@1 97.656 (97.819)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0922 (0.0632)	Prec@1 96.875 (97.878)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0842 (0.0630)	Prec@1 96.094 (97.887)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [869][0/79]	Time 0.367 (0.367)	Data 0.348 (0.348)	Loss 0.4138 (0.4138)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 870	Training Loss 0.0628 	Training Prec@1 97.904 	Training Prec@5 100.000 	Validation Loss 0.4452 	Validation Prec@1 88.050 	Validation Prec@5 99.540 

lr: 0.004400030088816965
TRAINING - Epoch: [870][0/391]	Time 0.969 (0.969)	Data 0.376 (0.376)	Loss 0.0931 (0.0931)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0552 (0.0642)	Prec@1 98.438 (97.795)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.0342 (0.0683)	Prec@1 99.219 (97.613)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [870][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0587 (0.0694)	Prec@1 99.219 (97.545)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [870][0/79]	Time 0.374 (0.374)	Data 0.349 (0.349)	Loss 0.3153 (0.3153)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:41

 Epoch: 871	Training Loss 0.0697 	Training Prec@1 97.532 	Training Prec@5 99.992 	Validation Loss 0.4266 	Validation Prec@1 88.490 	Validation Prec@5 99.480 

lr: 0.00433556553171829
TRAINING - Epoch: [871][0/391]	Time 0.992 (0.992)	Data 0.376 (0.376)	Loss 0.0602 (0.0602)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0889 (0.0680)	Prec@1 96.094 (97.540)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0517 (0.0695)	Prec@1 97.656 (97.470)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0526 (0.0682)	Prec@1 98.438 (97.547)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [871][0/79]	Time 0.389 (0.389)	Data 0.366 (0.366)	Loss 0.2545 (0.2545)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:45

 Epoch: 872	Training Loss 0.0669 	Training Prec@1 97.602 	Training Prec@5 100.000 	Validation Loss 0.4296 	Validation Prec@1 88.410 	Validation Prec@5 99.500 

lr: 0.004271555291414637
TRAINING - Epoch: [872][0/391]	Time 0.977 (0.977)	Data 0.384 (0.384)	Loss 0.0197 (0.0197)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1255 (0.0647)	Prec@1 96.094 (97.788)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1077 (0.0657)	Prec@1 96.094 (97.664)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0712 (0.0642)	Prec@1 97.656 (97.677)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [872][0/79]	Time 0.359 (0.359)	Data 0.337 (0.337)	Loss 0.3125 (0.3125)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 873	Training Loss 0.0646 	Training Prec@1 97.666 	Training Prec@5 100.000 	Validation Loss 0.4333 	Validation Prec@1 88.200 	Validation Prec@5 99.470 

lr: 0.004208000004745767
TRAINING - Epoch: [873][0/391]	Time 0.925 (0.925)	Data 0.355 (0.355)	Loss 0.0725 (0.0725)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [873][100/391]	Time 0.061 (0.070)	Data 0.000 (0.004)	Loss 0.0654 (0.0652)	Prec@1 96.875 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [873][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.0724 (0.0675)	Prec@1 96.875 (97.664)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [873][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1282 (0.0664)	Prec@1 93.750 (97.682)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [873][0/79]	Time 0.384 (0.384)	Data 0.362 (0.362)	Loss 0.3724 (0.3724)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:22:27

 Epoch: 874	Training Loss 0.0662 	Training Prec@1 97.668 	Training Prec@5 99.994 	Validation Loss 0.4342 	Validation Prec@1 88.200 	Validation Prec@5 99.540 

lr: 0.004144900304025097
TRAINING - Epoch: [874][0/391]	Time 0.997 (0.997)	Data 0.387 (0.387)	Loss 0.0657 (0.0657)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [874][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0401 (0.0665)	Prec@1 99.219 (97.649)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [874][200/391]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.1085 (0.0663)	Prec@1 96.094 (97.672)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [874][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0488 (0.0660)	Prec@1 97.656 (97.729)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [874][0/79]	Time 0.364 (0.364)	Data 0.342 (0.342)	Loss 0.3904 (0.3904)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 875	Training Loss 0.0651 	Training Prec@1 97.740 	Training Prec@5 99.994 	Validation Loss 0.4211 	Validation Prec@1 88.510 	Validation Prec@5 99.500 

lr: 0.004082256817033387
TRAINING - Epoch: [875][0/391]	Time 0.953 (0.953)	Data 0.365 (0.365)	Loss 0.0645 (0.0645)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [875][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.1016 (0.0653)	Prec@1 95.312 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [875][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0660 (0.0664)	Prec@1 96.875 (97.726)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [875][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0382 (0.0661)	Prec@1 99.219 (97.719)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [875][0/79]	Time 0.360 (0.360)	Data 0.337 (0.337)	Loss 0.4124 (0.4124)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 876	Training Loss 0.0658 	Training Prec@1 97.666 	Training Prec@5 100.000 	Validation Loss 0.4381 	Validation Prec@1 88.000 	Validation Prec@5 99.540 

lr: 0.004020070167012536
TRAINING - Epoch: [876][0/391]	Time 0.945 (0.945)	Data 0.362 (0.362)	Loss 0.0510 (0.0510)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0540 (0.0719)	Prec@1 98.438 (97.455)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0468 (0.0688)	Prec@1 99.219 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0907 (0.0661)	Prec@1 95.312 (97.739)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [876][0/79]	Time 0.383 (0.383)	Data 0.360 (0.360)	Loss 0.3425 (0.3425)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 877	Training Loss 0.0666 	Training Prec@1 97.700 	Training Prec@5 99.998 	Validation Loss 0.4239 	Validation Prec@1 88.430 	Validation Prec@5 99.560 

lr: 0.003958340972659321
TRAINING - Epoch: [877][0/391]	Time 0.952 (0.952)	Data 0.368 (0.368)	Loss 0.0437 (0.0437)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0624 (0.0680)	Prec@1 96.875 (97.664)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1209 (0.0655)	Prec@1 96.094 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0951 (0.0651)	Prec@1 96.094 (97.773)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [877][0/79]	Time 0.372 (0.372)	Data 0.350 (0.350)	Loss 0.3191 (0.3191)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:03

 Epoch: 878	Training Loss 0.0653 	Training Prec@1 97.778 	Training Prec@5 99.998 	Validation Loss 0.4181 	Validation Prec@1 88.530 	Validation Prec@5 99.470 

lr: 0.0038970698481193182
TRAINING - Epoch: [878][0/391]	Time 0.961 (0.961)	Data 0.365 (0.365)	Loss 0.0592 (0.0592)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [878][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1141 (0.0662)	Prec@1 96.094 (97.741)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [878][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0522 (0.0645)	Prec@1 98.438 (97.761)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [878][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0858 (0.0651)	Prec@1 96.094 (97.719)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [878][0/79]	Time 0.355 (0.355)	Data 0.334 (0.334)	Loss 0.3388 (0.3388)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:22:23

 Epoch: 879	Training Loss 0.0651 	Training Prec@1 97.734 	Training Prec@5 99.996 	Validation Loss 0.4184 	Validation Prec@1 88.530 	Validation Prec@5 99.560 

lr: 0.0038362574029807434
TRAINING - Epoch: [879][0/391]	Time 0.951 (0.951)	Data 0.359 (0.359)	Loss 0.0530 (0.0530)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [879][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1192 (0.0636)	Prec@1 95.312 (97.935)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [879][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0703 (0.0655)	Prec@1 96.094 (97.765)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [879][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0616 (0.0665)	Prec@1 98.438 (97.703)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [879][0/79]	Time 0.388 (0.388)	Data 0.367 (0.367)	Loss 0.3664 (0.3664)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 880	Training Loss 0.0669 	Training Prec@1 97.668 	Training Prec@5 99.998 	Validation Loss 0.4215 	Validation Prec@1 88.370 	Validation Prec@5 99.470 

lr: 0.003775904242268387
TRAINING - Epoch: [880][0/391]	Time 0.931 (0.931)	Data 0.347 (0.347)	Loss 0.0321 (0.0321)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [880][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0676 (0.0636)	Prec@1 97.656 (97.904)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [880][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0734 (0.0636)	Prec@1 98.438 (97.858)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [880][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1380 (0.0655)	Prec@1 95.312 (97.799)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [880][0/79]	Time 0.357 (0.357)	Data 0.338 (0.338)	Loss 0.2981 (0.2981)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 881	Training Loss 0.0648 	Training Prec@1 97.782 	Training Prec@5 99.994 	Validation Loss 0.4225 	Validation Prec@1 88.460 	Validation Prec@5 99.580 

lr: 0.0037160109664376067
TRAINING - Epoch: [881][0/391]	Time 0.934 (0.934)	Data 0.361 (0.361)	Loss 0.0950 (0.0950)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0618 (0.0628)	Prec@1 96.875 (97.865)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0615 (0.0642)	Prec@1 96.875 (97.831)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0413 (0.0658)	Prec@1 99.219 (97.724)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [881][0/79]	Time 0.370 (0.370)	Data 0.350 (0.350)	Loss 0.3077 (0.3077)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 882	Training Loss 0.0655 	Training Prec@1 97.722 	Training Prec@5 99.998 	Validation Loss 0.4223 	Validation Prec@1 88.210 	Validation Prec@5 99.470 

lr: 0.003656578171368365
TRAINING - Epoch: [882][0/391]	Time 0.947 (0.947)	Data 0.368 (0.368)	Loss 0.0801 (0.0801)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [882][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0424 (0.0650)	Prec@1 99.219 (97.772)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [882][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0548 (0.0649)	Prec@1 96.875 (97.726)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [882][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0793 (0.0664)	Prec@1 96.875 (97.698)	Prec@5 99.219 (99.995)
EVALUATING - Epoch: [882][0/79]	Time 0.384 (0.384)	Data 0.363 (0.363)	Loss 0.3633 (0.3633)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:22

 Epoch: 883	Training Loss 0.0658 	Training Prec@1 97.720 	Training Prec@5 99.996 	Validation Loss 0.4222 	Validation Prec@1 88.390 	Validation Prec@5 99.490 

lr: 0.003597606448359277
TRAINING - Epoch: [883][0/391]	Time 1.009 (1.009)	Data 0.399 (0.399)	Loss 0.0349 (0.0349)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [883][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0380 (0.0668)	Prec@1 99.219 (97.826)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [883][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0520 (0.0647)	Prec@1 98.438 (97.866)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [883][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0487 (0.0644)	Prec@1 99.219 (97.825)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [883][0/79]	Time 0.362 (0.362)	Data 0.338 (0.338)	Loss 0.4169 (0.4169)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:25

 Epoch: 884	Training Loss 0.0661 	Training Prec@1 97.750 	Training Prec@5 99.992 	Validation Loss 0.4209 	Validation Prec@1 88.390 	Validation Prec@5 99.520 

lr: 0.0035390963841217334
TRAINING - Epoch: [884][0/391]	Time 1.032 (1.032)	Data 0.375 (0.375)	Loss 0.0793 (0.0793)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [884][100/391]	Time 0.062 (0.073)	Data 0.000 (0.004)	Loss 0.0829 (0.0665)	Prec@1 97.656 (97.703)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [884][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.1092 (0.0687)	Prec@1 96.094 (97.668)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [884][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0584 (0.0676)	Prec@1 96.094 (97.648)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [884][0/79]	Time 0.365 (0.365)	Data 0.344 (0.344)	Loss 0.3012 (0.3012)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:10

 Epoch: 885	Training Loss 0.0671 	Training Prec@1 97.686 	Training Prec@5 99.998 	Validation Loss 0.4178 	Validation Prec@1 88.360 	Validation Prec@5 99.500 

lr: 0.003481048560774088
TRAINING - Epoch: [885][0/391]	Time 0.982 (0.982)	Data 0.379 (0.379)	Loss 0.0714 (0.0714)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [885][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.1547 (0.0653)	Prec@1 93.750 (97.633)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [885][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.0871 (0.0627)	Prec@1 96.875 (97.827)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [885][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0590 (0.0638)	Prec@1 98.438 (97.768)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [885][0/79]	Time 0.405 (0.405)	Data 0.385 (0.385)	Loss 0.2638 (0.2638)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:17

 Epoch: 886	Training Loss 0.0632 	Training Prec@1 97.796 	Training Prec@5 99.996 	Validation Loss 0.4183 	Validation Prec@1 88.420 	Validation Prec@5 99.590 

lr: 0.0034234635558358394
TRAINING - Epoch: [886][0/391]	Time 0.969 (0.969)	Data 0.375 (0.375)	Loss 0.0379 (0.0379)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.1075 (0.0664)	Prec@1 96.094 (97.718)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][200/391]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.0438 (0.0671)	Prec@1 98.438 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0754 (0.0694)	Prec@1 98.438 (97.589)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [886][0/79]	Time 0.367 (0.367)	Data 0.346 (0.346)	Loss 0.3204 (0.3204)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:16

 Epoch: 887	Training Loss 0.0674 	Training Prec@1 97.674 	Training Prec@5 100.000 	Validation Loss 0.4219 	Validation Prec@1 88.830 	Validation Prec@5 99.540 

lr: 0.0033663419422218645
TRAINING - Epoch: [887][0/391]	Time 0.961 (0.961)	Data 0.349 (0.349)	Loss 0.0625 (0.0625)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.0557 (0.0647)	Prec@1 97.656 (97.757)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0314 (0.0653)	Prec@1 99.219 (97.742)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [887][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0962 (0.0658)	Prec@1 96.094 (97.729)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [887][0/79]	Time 0.382 (0.382)	Data 0.359 (0.359)	Loss 0.3317 (0.3317)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:47

 Epoch: 888	Training Loss 0.0668 	Training Prec@1 97.702 	Training Prec@5 99.994 	Validation Loss 0.4177 	Validation Prec@1 88.350 	Validation Prec@5 99.610 

lr: 0.003309684288236772
TRAINING - Epoch: [888][0/391]	Time 0.976 (0.976)	Data 0.370 (0.370)	Loss 0.1015 (0.1015)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [888][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.0627 (0.0660)	Prec@1 99.219 (97.641)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [888][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0443 (0.0673)	Prec@1 99.219 (97.602)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [888][300/391]	Time 0.068 (0.067)	Data 0.000 (0.002)	Loss 0.1030 (0.0662)	Prec@1 96.875 (97.703)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [888][0/79]	Time 0.374 (0.374)	Data 0.350 (0.350)	Loss 0.2630 (0.2630)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:08

 Epoch: 889	Training Loss 0.0666 	Training Prec@1 97.682 	Training Prec@5 99.994 	Validation Loss 0.4202 	Validation Prec@1 88.250 	Validation Prec@5 99.620 

lr: 0.0032534911575692405
TRAINING - Epoch: [889][0/391]	Time 0.965 (0.965)	Data 0.372 (0.372)	Loss 0.0793 (0.0793)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [889][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.0913 (0.0681)	Prec@1 97.656 (97.571)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [889][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0620 (0.0690)	Prec@1 97.656 (97.536)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [889][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0436 (0.0679)	Prec@1 98.438 (97.597)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [889][0/79]	Time 0.365 (0.365)	Data 0.340 (0.340)	Loss 0.3131 (0.3131)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:04

 Epoch: 890	Training Loss 0.0678 	Training Prec@1 97.636 	Training Prec@5 99.992 	Validation Loss 0.4227 	Validation Prec@1 88.390 	Validation Prec@5 99.550 

lr: 0.003197763109286358
TRAINING - Epoch: [890][0/391]	Time 1.016 (1.016)	Data 0.379 (0.379)	Loss 0.1409 (0.1409)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [890][100/391]	Time 0.064 (0.074)	Data 0.000 (0.004)	Loss 0.0732 (0.0645)	Prec@1 96.875 (97.610)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [890][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.0868 (0.0654)	Prec@1 96.094 (97.641)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [890][300/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0640 (0.0649)	Prec@1 96.094 (97.695)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [890][0/79]	Time 0.381 (0.381)	Data 0.357 (0.357)	Loss 0.3494 (0.3494)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:13

 Epoch: 891	Training Loss 0.0658 	Training Prec@1 97.668 	Training Prec@5 99.996 	Validation Loss 0.4320 	Validation Prec@1 88.230 	Validation Prec@5 99.550 

lr: 0.0031425006978281177
TRAINING - Epoch: [891][0/391]	Time 0.936 (0.936)	Data 0.361 (0.361)	Loss 0.1052 (0.1052)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [891][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0432 (0.0687)	Prec@1 98.438 (97.563)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [891][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0362 (0.0703)	Prec@1 99.219 (97.551)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [891][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.0521 (0.0691)	Prec@1 98.438 (97.620)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [891][0/79]	Time 0.356 (0.356)	Data 0.332 (0.332)	Loss 0.4497 (0.4497)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:44

 Epoch: 892	Training Loss 0.0684 	Training Prec@1 97.626 	Training Prec@5 99.998 	Validation Loss 0.4206 	Validation Prec@1 88.370 	Validation Prec@5 99.470 

lr: 0.0030877044730018475
TRAINING - Epoch: [892][0/391]	Time 0.964 (0.964)	Data 0.350 (0.350)	Loss 0.0688 (0.0688)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [892][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.1318 (0.0673)	Prec@1 97.656 (97.780)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [892][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1010 (0.0666)	Prec@1 96.094 (97.792)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [892][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0880 (0.0693)	Prec@1 94.531 (97.633)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [892][0/79]	Time 0.391 (0.391)	Data 0.368 (0.368)	Loss 0.3747 (0.3747)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:40

 Epoch: 893	Training Loss 0.0705 	Training Prec@1 97.558 	Training Prec@5 99.996 	Validation Loss 0.4164 	Validation Prec@1 88.100 	Validation Prec@5 99.560 

lr: 0.0030333749799768073
TRAINING - Epoch: [893][0/391]	Time 0.910 (0.910)	Data 0.348 (0.348)	Loss 0.0941 (0.0941)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [893][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1770 (0.0656)	Prec@1 95.312 (97.780)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [893][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0152 (0.0681)	Prec@1 100.000 (97.652)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [893][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0608 (0.0693)	Prec@1 96.875 (97.581)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [893][0/79]	Time 0.362 (0.362)	Data 0.342 (0.342)	Loss 0.3297 (0.3297)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 894	Training Loss 0.0698 	Training Prec@1 97.588 	Training Prec@5 99.998 	Validation Loss 0.4254 	Validation Prec@1 88.150 	Validation Prec@5 99.570 

lr: 0.002979512759278715
TRAINING - Epoch: [894][0/391]	Time 0.997 (0.997)	Data 0.371 (0.371)	Loss 0.0706 (0.0706)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][100/391]	Time 0.063 (0.074)	Data 0.000 (0.004)	Loss 0.0306 (0.0725)	Prec@1 100.000 (97.316)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][200/391]	Time 0.063 (0.069)	Data 0.000 (0.002)	Loss 0.0691 (0.0693)	Prec@1 98.438 (97.532)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [894][300/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0330 (0.0695)	Prec@1 99.219 (97.547)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [894][0/79]	Time 0.399 (0.399)	Data 0.380 (0.380)	Loss 0.2935 (0.2935)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:07

 Epoch: 895	Training Loss 0.0689 	Training Prec@1 97.592 	Training Prec@5 99.998 	Validation Loss 0.4033 	Validation Prec@1 88.620 	Validation Prec@5 99.560 

lr: 0.0029261183467843696
TRAINING - Epoch: [895][0/391]	Time 0.956 (0.956)	Data 0.356 (0.356)	Loss 0.1184 (0.1184)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [895][100/391]	Time 0.065 (0.072)	Data 0.000 (0.004)	Loss 0.0375 (0.0686)	Prec@1 99.219 (97.649)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [895][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0820 (0.0678)	Prec@1 97.656 (97.645)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [895][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0785 (0.0685)	Prec@1 96.875 (97.584)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [895][0/79]	Time 0.436 (0.436)	Data 0.415 (0.415)	Loss 0.3693 (0.3693)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:55

 Epoch: 896	Training Loss 0.0689 	Training Prec@1 97.548 	Training Prec@5 99.992 	Validation Loss 0.4279 	Validation Prec@1 88.230 	Validation Prec@5 99.580 

lr: 0.0028731922737163596
TRAINING - Epoch: [896][0/391]	Time 1.045 (1.045)	Data 0.421 (0.421)	Loss 0.0851 (0.0851)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [896][100/391]	Time 0.064 (0.074)	Data 0.000 (0.004)	Loss 0.0428 (0.0753)	Prec@1 98.438 (97.347)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [896][200/391]	Time 0.062 (0.069)	Data 0.000 (0.002)	Loss 0.0841 (0.0720)	Prec@1 96.875 (97.497)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [896][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0465 (0.0712)	Prec@1 98.438 (97.537)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [896][0/79]	Time 0.360 (0.360)	Data 0.342 (0.342)	Loss 0.4129 (0.4129)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:53

 Epoch: 897	Training Loss 0.0700 	Training Prec@1 97.606 	Training Prec@5 99.996 	Validation Loss 0.4230 	Validation Prec@1 88.090 	Validation Prec@5 99.570 

lr: 0.002820735066637733
TRAINING - Epoch: [897][0/391]	Time 0.971 (0.971)	Data 0.368 (0.368)	Loss 0.0431 (0.0431)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [897][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0817 (0.0661)	Prec@1 96.875 (97.656)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [897][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.1335 (0.0693)	Prec@1 94.531 (97.575)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [897][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0617 (0.0686)	Prec@1 98.438 (97.602)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [897][0/79]	Time 0.361 (0.361)	Data 0.340 (0.340)	Loss 0.2759 (0.2759)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 898	Training Loss 0.0688 	Training Prec@1 97.620 	Training Prec@5 99.998 	Validation Loss 0.4132 	Validation Prec@1 88.390 	Validation Prec@5 99.640 

lr: 0.002768747247446759
TRAINING - Epoch: [898][0/391]	Time 0.978 (0.978)	Data 0.380 (0.380)	Loss 0.0653 (0.0653)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [898][100/391]	Time 0.065 (0.073)	Data 0.000 (0.004)	Loss 0.0621 (0.0713)	Prec@1 99.219 (97.517)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [898][200/391]	Time 0.064 (0.069)	Data 0.000 (0.002)	Loss 0.0656 (0.0721)	Prec@1 96.875 (97.489)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [898][300/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.0761 (0.0715)	Prec@1 96.094 (97.493)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [898][0/79]	Time 0.380 (0.380)	Data 0.362 (0.362)	Loss 0.3439 (0.3439)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:24:03

 Epoch: 899	Training Loss 0.0712 	Training Prec@1 97.512 	Training Prec@5 99.998 	Validation Loss 0.4238 	Validation Prec@1 88.280 	Validation Prec@5 99.560 

lr: 0.0027172293333717814
TRAINING - Epoch: [899][0/391]	Time 1.053 (1.053)	Data 0.391 (0.391)	Loss 0.0556 (0.0556)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][100/391]	Time 0.064 (0.073)	Data 0.000 (0.004)	Loss 0.0413 (0.0753)	Prec@1 99.219 (97.416)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][200/391]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.0643 (0.0723)	Prec@1 97.656 (97.571)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][300/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0899 (0.0699)	Prec@1 96.875 (97.667)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [899][0/79]	Time 0.379 (0.379)	Data 0.358 (0.358)	Loss 0.3338 (0.3338)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:49

 Epoch: 900	Training Loss 0.0704 	Training Prec@1 97.636 	Training Prec@5 100.000 	Validation Loss 0.4238 	Validation Prec@1 87.860 	Validation Prec@5 99.560 

lr: 0.00266618183696605
TRAINING - Epoch: [900][0/391]	Time 0.926 (0.926)	Data 0.360 (0.360)	Loss 0.1243 (0.1243)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [900][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0881 (0.0690)	Prec@1 96.875 (97.455)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [900][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0305 (0.0689)	Prec@1 98.438 (97.571)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [900][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0513 (0.0679)	Prec@1 97.656 (97.633)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [900][0/79]	Time 0.384 (0.384)	Data 0.363 (0.363)	Loss 0.3229 (0.3229)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 901	Training Loss 0.0683 	Training Prec@1 97.610 	Training Prec@5 99.994 	Validation Loss 0.4192 	Validation Prec@1 88.060 	Validation Prec@5 99.630 

lr: 0.0026156052661025857
TRAINING - Epoch: [901][0/391]	Time 1.007 (1.007)	Data 0.365 (0.365)	Loss 0.0726 (0.0726)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [901][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.0614 (0.0683)	Prec@1 98.438 (97.571)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [901][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0913 (0.0666)	Prec@1 98.438 (97.606)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [901][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0430 (0.0669)	Prec@1 98.438 (97.602)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [901][0/79]	Time 0.370 (0.370)	Data 0.350 (0.350)	Loss 0.3387 (0.3387)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:39

 Epoch: 902	Training Loss 0.0691 	Training Prec@1 97.534 	Training Prec@5 99.994 	Validation Loss 0.4236 	Validation Prec@1 88.220 	Validation Prec@5 99.580 

lr: 0.0025655001239691805
TRAINING - Epoch: [902][0/391]	Time 0.938 (0.938)	Data 0.347 (0.347)	Loss 0.0764 (0.0764)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [902][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1163 (0.0770)	Prec@1 96.875 (97.486)	Prec@5 99.219 (99.985)
TRAINING - Epoch: [902][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0678 (0.0754)	Prec@1 98.438 (97.427)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [902][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0392 (0.0755)	Prec@1 100.000 (97.368)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [902][0/79]	Time 0.357 (0.357)	Data 0.337 (0.337)	Loss 0.3074 (0.3074)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:17

 Epoch: 903	Training Loss 0.0755 	Training Prec@1 97.372 	Training Prec@5 99.990 	Validation Loss 0.4324 	Validation Prec@1 88.030 	Validation Prec@5 99.520 

lr: 0.002515866909063344
TRAINING - Epoch: [903][0/391]	Time 0.976 (0.976)	Data 0.355 (0.355)	Loss 0.1015 (0.1015)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [903][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.0734 (0.0707)	Prec@1 96.875 (97.679)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [903][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0734 (0.0743)	Prec@1 97.656 (97.509)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [903][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0683 (0.0725)	Prec@1 97.656 (97.490)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [903][0/79]	Time 0.375 (0.375)	Data 0.355 (0.355)	Loss 0.3322 (0.3322)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:20

 Epoch: 904	Training Loss 0.0727 	Training Prec@1 97.482 	Training Prec@5 99.994 	Validation Loss 0.4292 	Validation Prec@1 88.120 	Validation Prec@5 99.460 

lr: 0.0024667061151874034
TRAINING - Epoch: [904][0/391]	Time 0.972 (0.972)	Data 0.384 (0.384)	Loss 0.0360 (0.0360)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [904][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0426 (0.0742)	Prec@1 99.219 (97.548)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [904][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0956 (0.0749)	Prec@1 96.875 (97.384)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [904][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0685 (0.0747)	Prec@1 97.656 (97.389)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [904][0/79]	Time 0.348 (0.348)	Data 0.328 (0.328)	Loss 0.2995 (0.2995)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 905	Training Loss 0.0741 	Training Prec@1 97.450 	Training Prec@5 99.998 	Validation Loss 0.4387 	Validation Prec@1 87.650 	Validation Prec@5 99.540 

lr: 0.002418018231443528
TRAINING - Epoch: [905][0/391]	Time 0.919 (0.919)	Data 0.363 (0.363)	Loss 0.0410 (0.0410)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [905][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1347 (0.0703)	Prec@1 95.312 (97.548)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [905][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0789 (0.0707)	Prec@1 97.656 (97.586)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [905][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0320 (0.0706)	Prec@1 99.219 (97.607)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [905][0/79]	Time 0.385 (0.385)	Data 0.361 (0.361)	Loss 0.2580 (0.2580)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 906	Training Loss 0.0710 	Training Prec@1 97.568 	Training Prec@5 99.996 	Validation Loss 0.4136 	Validation Prec@1 88.180 	Validation Prec@5 99.520 

lr: 0.002369803742228891
TRAINING - Epoch: [906][0/391]	Time 0.936 (0.936)	Data 0.346 (0.346)	Loss 0.1519 (0.1519)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0319 (0.0721)	Prec@1 99.219 (97.401)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0622 (0.0701)	Prec@1 97.656 (97.489)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0659 (0.0714)	Prec@1 96.875 (97.490)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [906][0/79]	Time 0.343 (0.343)	Data 0.324 (0.324)	Loss 0.3146 (0.3146)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 907	Training Loss 0.0719 	Training Prec@1 97.466 	Training Prec@5 100.000 	Validation Loss 0.4303 	Validation Prec@1 87.930 	Validation Prec@5 99.570 

lr: 0.0023220631272308757
TRAINING - Epoch: [907][0/391]	Time 0.960 (0.960)	Data 0.397 (0.397)	Loss 0.0602 (0.0602)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0691 (0.0762)	Prec@1 98.438 (97.239)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0884 (0.0734)	Prec@1 95.312 (97.404)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [907][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.1159 (0.0719)	Prec@1 95.312 (97.482)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [907][0/79]	Time 0.370 (0.370)	Data 0.347 (0.347)	Loss 0.3839 (0.3839)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:18

 Epoch: 908	Training Loss 0.0722 	Training Prec@1 97.486 	Training Prec@5 99.996 	Validation Loss 0.4279 	Validation Prec@1 87.960 	Validation Prec@5 99.550 

lr: 0.002274796861422244
TRAINING - Epoch: [908][0/391]	Time 0.923 (0.923)	Data 0.356 (0.356)	Loss 0.1211 (0.1211)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [908][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0796 (0.0743)	Prec@1 97.656 (97.494)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [908][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0937 (0.0754)	Prec@1 95.312 (97.384)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [908][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1420 (0.0720)	Prec@1 94.531 (97.493)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [908][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.2359 (0.2359)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 909	Training Loss 0.0718 	Training Prec@1 97.528 	Training Prec@5 99.994 	Validation Loss 0.4158 	Validation Prec@1 88.580 	Validation Prec@5 99.560 

lr: 0.0022280054150564535
TRAINING - Epoch: [909][0/391]	Time 0.925 (0.925)	Data 0.354 (0.354)	Loss 0.0457 (0.0457)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [909][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0839 (0.0712)	Prec@1 96.875 (97.540)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [909][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0491 (0.0687)	Prec@1 98.438 (97.598)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [909][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0206 (0.0705)	Prec@1 100.000 (97.495)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [909][0/79]	Time 0.331 (0.331)	Data 0.312 (0.312)	Loss 0.3239 (0.3239)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 910	Training Loss 0.0711 	Training Prec@1 97.504 	Training Prec@5 99.996 	Validation Loss 0.4143 	Validation Prec@1 88.510 	Validation Prec@5 99.560 

lr: 0.0021816892536629753
TRAINING - Epoch: [910][0/391]	Time 0.936 (0.936)	Data 0.378 (0.378)	Loss 0.0444 (0.0444)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [910][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1080 (0.0662)	Prec@1 96.094 (97.726)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [910][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0502 (0.0699)	Prec@1 98.438 (97.516)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [910][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.0544 (0.0713)	Prec@1 98.438 (97.482)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [910][0/79]	Time 0.332 (0.332)	Data 0.312 (0.312)	Loss 0.3145 (0.3145)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 911	Training Loss 0.0720 	Training Prec@1 97.444 	Training Prec@5 99.996 	Validation Loss 0.4281 	Validation Prec@1 88.210 	Validation Prec@5 99.510 

lr: 0.002135848838042668
TRAINING - Epoch: [911][0/391]	Time 0.933 (0.933)	Data 0.368 (0.368)	Loss 0.0622 (0.0622)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [911][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0545 (0.0724)	Prec@1 98.438 (97.525)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [911][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0642 (0.0716)	Prec@1 97.656 (97.579)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [911][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0563 (0.0728)	Prec@1 98.438 (97.475)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [911][0/79]	Time 0.347 (0.347)	Data 0.324 (0.324)	Loss 0.3078 (0.3078)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 912	Training Loss 0.0721 	Training Prec@1 97.494 	Training Prec@5 99.998 	Validation Loss 0.4247 	Validation Prec@1 88.390 	Validation Prec@5 99.590 

lr: 0.002090484624263165
TRAINING - Epoch: [912][0/391]	Time 0.930 (0.930)	Data 0.365 (0.365)	Loss 0.0534 (0.0534)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [912][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0195 (0.0749)	Prec@1 100.000 (97.362)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [912][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1200 (0.0745)	Prec@1 95.312 (97.384)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [912][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0773 (0.0729)	Prec@1 98.438 (97.459)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [912][0/79]	Time 0.353 (0.353)	Data 0.331 (0.331)	Loss 0.2790 (0.2790)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 913	Training Loss 0.0715 	Training Prec@1 97.498 	Training Prec@5 99.990 	Validation Loss 0.4149 	Validation Prec@1 88.400 	Validation Prec@5 99.600 

lr: 0.00204559706365434
TRAINING - Epoch: [913][0/391]	Time 0.937 (0.937)	Data 0.355 (0.355)	Loss 0.0707 (0.0707)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [913][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0803 (0.0716)	Prec@1 96.094 (97.532)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [913][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1090 (0.0712)	Prec@1 96.875 (97.505)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [913][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0583 (0.0716)	Prec@1 97.656 (97.503)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [913][0/79]	Time 0.350 (0.350)	Data 0.329 (0.329)	Loss 0.3182 (0.3182)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 914	Training Loss 0.0719 	Training Prec@1 97.482 	Training Prec@5 99.998 	Validation Loss 0.4216 	Validation Prec@1 88.580 	Validation Prec@5 99.510 

lr: 0.00200118660280386
TRAINING - Epoch: [914][0/391]	Time 0.952 (0.952)	Data 0.369 (0.369)	Loss 0.0268 (0.0268)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [914][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.1007 (0.0726)	Prec@1 97.656 (97.502)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [914][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0512 (0.0699)	Prec@1 97.656 (97.602)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [914][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0554 (0.0700)	Prec@1 98.438 (97.568)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [914][0/79]	Time 0.365 (0.365)	Data 0.339 (0.339)	Loss 0.4057 (0.4057)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 915	Training Loss 0.0702 	Training Prec@1 97.564 	Training Prec@5 100.000 	Validation Loss 0.4306 	Validation Prec@1 88.100 	Validation Prec@5 99.550 

lr: 0.0019572536835526996
TRAINING - Epoch: [915][0/391]	Time 0.923 (0.923)	Data 0.353 (0.353)	Loss 0.1078 (0.1078)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0545 (0.0708)	Prec@1 97.656 (97.494)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0672 (0.0680)	Prec@1 98.438 (97.648)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [915][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1013 (0.0697)	Prec@1 95.312 (97.526)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [915][0/79]	Time 0.337 (0.337)	Data 0.315 (0.315)	Loss 0.3125 (0.3125)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 916	Training Loss 0.0706 	Training Prec@1 97.444 	Training Prec@5 99.992 	Validation Loss 0.4275 	Validation Prec@1 87.950 	Validation Prec@5 99.540 

lr: 0.001913798742990762
TRAINING - Epoch: [916][0/391]	Time 0.945 (0.945)	Data 0.346 (0.346)	Loss 0.0319 (0.0319)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [916][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0804 (0.0706)	Prec@1 96.875 (97.618)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [916][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0786 (0.0717)	Prec@1 97.656 (97.509)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [916][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0579 (0.0726)	Prec@1 96.875 (97.407)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [916][0/79]	Time 0.352 (0.352)	Data 0.333 (0.333)	Loss 0.2868 (0.2868)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:02

 Epoch: 917	Training Loss 0.0720 	Training Prec@1 97.460 	Training Prec@5 99.990 	Validation Loss 0.4290 	Validation Prec@1 88.330 	Validation Prec@5 99.570 

lr: 0.0018708222134525153
TRAINING - Epoch: [917][0/391]	Time 0.934 (0.934)	Data 0.339 (0.339)	Loss 0.0542 (0.0542)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0442 (0.0727)	Prec@1 98.438 (97.416)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.1082 (0.0723)	Prec@1 94.531 (97.450)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [917][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.0428 (0.0730)	Prec@1 99.219 (97.423)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [917][0/79]	Time 0.363 (0.363)	Data 0.341 (0.341)	Loss 0.2521 (0.2521)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 918	Training Loss 0.0721 	Training Prec@1 97.462 	Training Prec@5 99.998 	Validation Loss 0.4344 	Validation Prec@1 87.940 	Validation Prec@5 99.420 

lr: 0.001828324522512713
TRAINING - Epoch: [918][0/391]	Time 0.925 (0.925)	Data 0.348 (0.348)	Loss 0.0738 (0.0738)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [918][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0441 (0.0707)	Prec@1 99.219 (97.540)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [918][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0521 (0.0722)	Prec@1 98.438 (97.481)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [918][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0523 (0.0706)	Prec@1 98.438 (97.534)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [918][0/79]	Time 0.360 (0.360)	Data 0.338 (0.338)	Loss 0.3559 (0.3559)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 919	Training Loss 0.0711 	Training Prec@1 97.486 	Training Prec@5 99.992 	Validation Loss 0.4248 	Validation Prec@1 88.360 	Validation Prec@5 99.490 

lr: 0.001786306092982125
TRAINING - Epoch: [919][0/391]	Time 0.925 (0.925)	Data 0.343 (0.343)	Loss 0.0933 (0.0933)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [919][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1284 (0.0689)	Prec@1 95.312 (97.602)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [919][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0639 (0.0710)	Prec@1 98.438 (97.524)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [919][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0824 (0.0710)	Prec@1 96.094 (97.542)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [919][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.2684 (0.2684)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 920	Training Loss 0.0717 	Training Prec@1 97.524 	Training Prec@5 99.996 	Validation Loss 0.4342 	Validation Prec@1 88.010 	Validation Prec@5 99.500 

lr: 0.0017447673429033348
TRAINING - Epoch: [920][0/391]	Time 0.922 (0.922)	Data 0.344 (0.344)	Loss 0.0221 (0.0221)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [920][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0362 (0.0678)	Prec@1 98.438 (97.594)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [920][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0518 (0.0723)	Prec@1 97.656 (97.365)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [920][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0555 (0.0705)	Prec@1 99.219 (97.506)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [920][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.2853 (0.2853)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 921	Training Loss 0.0700 	Training Prec@1 97.516 	Training Prec@5 99.998 	Validation Loss 0.4286 	Validation Prec@1 88.070 	Validation Prec@5 99.490 

lr: 0.001703708685546583
TRAINING - Epoch: [921][0/391]	Time 0.924 (0.924)	Data 0.362 (0.362)	Loss 0.0377 (0.0377)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [921][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1155 (0.0697)	Prec@1 95.312 (97.532)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [921][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0664 (0.0715)	Prec@1 99.219 (97.501)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [921][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0464 (0.0706)	Prec@1 100.000 (97.545)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [921][0/79]	Time 0.341 (0.341)	Data 0.319 (0.319)	Loss 0.3399 (0.3399)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 922	Training Loss 0.0701 	Training Prec@1 97.552 	Training Prec@5 99.996 	Validation Loss 0.4196 	Validation Prec@1 88.480 	Validation Prec@5 99.480 

lr: 0.001663130529405664
TRAINING - Epoch: [922][0/391]	Time 0.925 (0.925)	Data 0.361 (0.361)	Loss 0.0739 (0.0739)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [922][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0844 (0.0720)	Prec@1 97.656 (97.471)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [922][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0337 (0.0702)	Prec@1 98.438 (97.481)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [922][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0986 (0.0717)	Prec@1 96.875 (97.464)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [922][0/79]	Time 0.343 (0.343)	Data 0.323 (0.323)	Loss 0.3023 (0.3023)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 923	Training Loss 0.0716 	Training Prec@1 97.462 	Training Prec@5 99.990 	Validation Loss 0.4252 	Validation Prec@1 87.960 	Validation Prec@5 99.530 

lr: 0.0016230332781938237
TRAINING - Epoch: [923][0/391]	Time 0.940 (0.940)	Data 0.375 (0.375)	Loss 0.0440 (0.0440)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][100/391]	Time 0.063 (0.072)	Data 0.000 (0.004)	Loss 0.0276 (0.0745)	Prec@1 100.000 (97.355)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0865 (0.0739)	Prec@1 96.875 (97.376)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [923][300/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0461 (0.0741)	Prec@1 99.219 (97.355)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [923][0/79]	Time 0.335 (0.335)	Data 0.313 (0.313)	Loss 0.2894 (0.2894)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 924	Training Loss 0.0747 	Training Prec@1 97.358 	Training Prec@5 99.992 	Validation Loss 0.4331 	Validation Prec@1 88.170 	Validation Prec@5 99.530 

lr: 0.0015834173308398023
TRAINING - Epoch: [924][0/391]	Time 0.945 (0.945)	Data 0.373 (0.373)	Loss 0.0546 (0.0546)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [924][100/391]	Time 0.060 (0.071)	Data 0.000 (0.004)	Loss 0.0310 (0.0717)	Prec@1 99.219 (97.556)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [924][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0731 (0.0713)	Prec@1 96.875 (97.520)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [924][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1098 (0.0724)	Prec@1 96.875 (97.454)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [924][0/79]	Time 0.346 (0.346)	Data 0.327 (0.327)	Loss 0.4249 (0.4249)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 925	Training Loss 0.0721 	Training Prec@1 97.454 	Training Prec@5 99.996 	Validation Loss 0.4221 	Validation Prec@1 88.270 	Validation Prec@5 99.610 

lr: 0.0015442830814838037
TRAINING - Epoch: [925][0/391]	Time 0.911 (0.911)	Data 0.354 (0.354)	Loss 0.0562 (0.0562)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [925][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0667 (0.0676)	Prec@1 96.875 (97.672)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [925][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0491 (0.0681)	Prec@1 99.219 (97.761)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [925][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0246 (0.0702)	Prec@1 99.219 (97.612)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [925][0/79]	Time 0.350 (0.350)	Data 0.326 (0.326)	Loss 0.3336 (0.3336)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 926	Training Loss 0.0704 	Training Prec@1 97.600 	Training Prec@5 99.996 	Validation Loss 0.4219 	Validation Prec@1 88.510 	Validation Prec@5 99.450 

lr: 0.0015056309194736372
TRAINING - Epoch: [926][0/391]	Time 0.950 (0.950)	Data 0.379 (0.379)	Loss 0.0436 (0.0436)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [926][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0495 (0.0719)	Prec@1 98.438 (97.540)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [926][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0916 (0.0712)	Prec@1 97.656 (97.555)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [926][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1343 (0.0724)	Prec@1 97.656 (97.521)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [926][0/79]	Time 0.374 (0.374)	Data 0.351 (0.351)	Loss 0.2712 (0.2712)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:21

 Epoch: 927	Training Loss 0.0716 	Training Prec@1 97.544 	Training Prec@5 99.996 	Validation Loss 0.4311 	Validation Prec@1 88.410 	Validation Prec@5 99.570 

lr: 0.001467461229360788
TRAINING - Epoch: [927][0/391]	Time 0.958 (0.958)	Data 0.370 (0.370)	Loss 0.0498 (0.0498)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [927][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0699 (0.0694)	Prec@1 98.438 (97.734)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [927][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0468 (0.0701)	Prec@1 98.438 (97.586)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [927][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0637 (0.0705)	Prec@1 98.438 (97.571)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [927][0/79]	Time 0.367 (0.367)	Data 0.344 (0.344)	Loss 0.3472 (0.3472)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 928	Training Loss 0.0711 	Training Prec@1 97.542 	Training Prec@5 99.990 	Validation Loss 0.4120 	Validation Prec@1 88.300 	Validation Prec@5 99.540 

lr: 0.0014297743908966197
TRAINING - Epoch: [928][0/391]	Time 0.938 (0.938)	Data 0.363 (0.363)	Loss 0.0817 (0.0817)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [928][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0706 (0.0730)	Prec@1 96.875 (97.378)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [928][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1012 (0.0683)	Prec@1 95.312 (97.613)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [928][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0924 (0.0683)	Prec@1 97.656 (97.633)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [928][0/79]	Time 0.380 (0.380)	Data 0.358 (0.358)	Loss 0.2967 (0.2967)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 929	Training Loss 0.0686 	Training Prec@1 97.638 	Training Prec@5 99.996 	Validation Loss 0.4214 	Validation Prec@1 88.380 	Validation Prec@5 99.550 

lr: 0.0013925707790285835
TRAINING - Epoch: [929][0/391]	Time 0.925 (0.925)	Data 0.347 (0.347)	Loss 0.0370 (0.0370)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [929][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0370 (0.0723)	Prec@1 98.438 (97.386)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [929][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0275 (0.0703)	Prec@1 99.219 (97.509)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [929][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1129 (0.0698)	Prec@1 95.312 (97.508)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [929][0/79]	Time 0.372 (0.372)	Data 0.348 (0.348)	Loss 0.3416 (0.3416)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 930	Training Loss 0.0708 	Training Prec@1 97.490 	Training Prec@5 99.996 	Validation Loss 0.4231 	Validation Prec@1 88.480 	Validation Prec@5 99.550 

lr: 0.0013558507638965144
TRAINING - Epoch: [930][0/391]	Time 0.950 (0.950)	Data 0.354 (0.354)	Loss 0.0954 (0.0954)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [930][100/391]	Time 0.062 (0.072)	Data 0.000 (0.004)	Loss 0.1480 (0.0748)	Prec@1 92.969 (97.347)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [930][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0358 (0.0719)	Prec@1 99.219 (97.462)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [930][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.1013 (0.0733)	Prec@1 96.875 (97.425)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [930][0/79]	Time 0.371 (0.371)	Data 0.345 (0.345)	Loss 0.3445 (0.3445)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:16

 Epoch: 931	Training Loss 0.0729 	Training Prec@1 97.426 	Training Prec@5 99.988 	Validation Loss 0.4230 	Validation Prec@1 88.520 	Validation Prec@5 99.520 

lr: 0.0013196147108289135
TRAINING - Epoch: [931][0/391]	Time 0.912 (0.912)	Data 0.340 (0.340)	Loss 0.0658 (0.0658)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0628 (0.0701)	Prec@1 98.438 (97.502)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0977 (0.0708)	Prec@1 97.656 (97.579)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0693 (0.0710)	Prec@1 97.656 (97.555)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [931][0/79]	Time 0.345 (0.345)	Data 0.324 (0.324)	Loss 0.2610 (0.2610)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:13

 Epoch: 932	Training Loss 0.0712 	Training Prec@1 97.522 	Training Prec@5 99.994 	Validation Loss 0.4327 	Validation Prec@1 88.060 	Validation Prec@5 99.520 

lr: 0.0012838629803393275
TRAINING - Epoch: [932][0/391]	Time 0.933 (0.933)	Data 0.364 (0.364)	Loss 0.0907 (0.0907)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0319 (0.0652)	Prec@1 99.219 (97.718)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1210 (0.0665)	Prec@1 97.656 (97.633)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0901 (0.0673)	Prec@1 95.312 (97.610)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [932][0/79]	Time 0.376 (0.376)	Data 0.352 (0.352)	Loss 0.2437 (0.2437)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 933	Training Loss 0.0688 	Training Prec@1 97.548 	Training Prec@5 99.992 	Validation Loss 0.4284 	Validation Prec@1 88.530 	Validation Prec@5 99.540 

lr: 0.0012485959281227854
TRAINING - Epoch: [933][0/391]	Time 0.935 (0.935)	Data 0.352 (0.352)	Loss 0.0381 (0.0381)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [933][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0456 (0.0727)	Prec@1 99.219 (97.409)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [933][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0814 (0.0718)	Prec@1 98.438 (97.466)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [933][300/391]	Time 0.061 (0.066)	Data 0.000 (0.001)	Loss 0.0819 (0.0703)	Prec@1 96.875 (97.550)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [933][0/79]	Time 0.342 (0.342)	Data 0.321 (0.321)	Loss 0.2769 (0.2769)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 934	Training Loss 0.0710 	Training Prec@1 97.540 	Training Prec@5 99.998 	Validation Loss 0.4312 	Validation Prec@1 88.220 	Validation Prec@5 99.430 

lr: 0.0012138139050522012
TRAINING - Epoch: [934][0/391]	Time 0.924 (0.924)	Data 0.349 (0.349)	Loss 0.0440 (0.0440)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0623 (0.0699)	Prec@1 98.438 (97.602)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0876 (0.0699)	Prec@1 96.875 (97.613)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0243 (0.0705)	Prec@1 100.000 (97.584)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [934][0/79]	Time 0.364 (0.364)	Data 0.341 (0.341)	Loss 0.3516 (0.3516)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 935	Training Loss 0.0706 	Training Prec@1 97.572 	Training Prec@5 99.994 	Validation Loss 0.4210 	Validation Prec@1 88.490 	Validation Prec@5 99.500 

lr: 0.0011795172571749547
TRAINING - Epoch: [935][0/391]	Time 0.916 (0.916)	Data 0.341 (0.341)	Loss 0.0777 (0.0777)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [935][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0660 (0.0666)	Prec@1 96.875 (97.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [935][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0501 (0.0674)	Prec@1 97.656 (97.586)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [935][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0293 (0.0696)	Prec@1 99.219 (97.501)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [935][0/79]	Time 0.348 (0.348)	Data 0.328 (0.328)	Loss 0.2550 (0.2550)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 936	Training Loss 0.0699 	Training Prec@1 97.524 	Training Prec@5 99.996 	Validation Loss 0.4302 	Validation Prec@1 88.250 	Validation Prec@5 99.570 

lr: 0.001145706325709388
TRAINING - Epoch: [936][0/391]	Time 0.939 (0.939)	Data 0.381 (0.381)	Loss 0.0515 (0.0515)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0753 (0.0655)	Prec@1 97.656 (97.703)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0798 (0.0695)	Prec@1 96.875 (97.544)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1036 (0.0711)	Prec@1 96.094 (97.513)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [936][0/79]	Time 0.376 (0.376)	Data 0.351 (0.351)	Loss 0.2351 (0.2351)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:14

 Epoch: 937	Training Loss 0.0708 	Training Prec@1 97.516 	Training Prec@5 100.000 	Validation Loss 0.4133 	Validation Prec@1 88.250 	Validation Prec@5 99.540 

lr: 0.0011123814470414596
TRAINING - Epoch: [937][0/391]	Time 0.918 (0.918)	Data 0.325 (0.325)	Loss 0.0507 (0.0507)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [937][100/391]	Time 0.063 (0.071)	Data 0.000 (0.003)	Loss 0.0428 (0.0705)	Prec@1 98.438 (97.525)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [937][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0923 (0.0709)	Prec@1 96.875 (97.594)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [937][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0429 (0.0700)	Prec@1 99.219 (97.594)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [937][0/79]	Time 0.347 (0.347)	Data 0.327 (0.327)	Loss 0.2491 (0.2491)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 938	Training Loss 0.0699 	Training Prec@1 97.586 	Training Prec@5 99.994 	Validation Loss 0.4215 	Validation Prec@1 88.420 	Validation Prec@5 99.610 

lr: 0.0010795429527213675
TRAINING - Epoch: [938][0/391]	Time 0.944 (0.944)	Data 0.362 (0.362)	Loss 0.0803 (0.0803)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [938][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0776 (0.0736)	Prec@1 98.438 (97.447)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [938][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0441 (0.0719)	Prec@1 98.438 (97.466)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [938][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0632 (0.0730)	Prec@1 98.438 (97.353)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [938][0/79]	Time 0.362 (0.362)	Data 0.343 (0.343)	Loss 0.2693 (0.2693)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 939	Training Loss 0.0723 	Training Prec@1 97.424 	Training Prec@5 99.990 	Validation Loss 0.4447 	Validation Prec@1 88.070 	Validation Prec@5 99.520 

lr: 0.001047191169460231
TRAINING - Epoch: [939][0/391]	Time 0.914 (0.914)	Data 0.359 (0.359)	Loss 0.0953 (0.0953)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [939][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0328 (0.0715)	Prec@1 99.219 (97.509)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [939][200/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.1179 (0.0701)	Prec@1 94.531 (97.598)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [939][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0574 (0.0696)	Prec@1 98.438 (97.576)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [939][0/79]	Time 0.377 (0.377)	Data 0.354 (0.354)	Loss 0.3282 (0.3282)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 940	Training Loss 0.0705 	Training Prec@1 97.532 	Training Prec@5 99.994 	Validation Loss 0.4198 	Validation Prec@1 88.290 	Validation Prec@5 99.630 

lr: 0.0010153264191269042
TRAINING - Epoch: [940][0/391]	Time 0.913 (0.913)	Data 0.352 (0.352)	Loss 0.0566 (0.0566)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [940][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0655 (0.0697)	Prec@1 97.656 (97.571)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [940][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0329 (0.0700)	Prec@1 99.219 (97.559)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [940][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0732 (0.0691)	Prec@1 97.656 (97.656)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [940][0/79]	Time 0.372 (0.372)	Data 0.351 (0.351)	Loss 0.2999 (0.2999)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 941	Training Loss 0.0687 	Training Prec@1 97.660 	Training Prec@5 99.992 	Validation Loss 0.4320 	Validation Prec@1 88.070 	Validation Prec@5 99.600 

lr: 0.0009839490187447165
TRAINING - Epoch: [941][0/391]	Time 0.919 (0.919)	Data 0.354 (0.354)	Loss 0.0743 (0.0743)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [941][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1281 (0.0712)	Prec@1 94.531 (97.525)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [941][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0321 (0.0688)	Prec@1 99.219 (97.590)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [941][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1330 (0.0694)	Prec@1 96.875 (97.576)	Prec@5 99.219 (99.995)
EVALUATING - Epoch: [941][0/79]	Time 0.351 (0.351)	Data 0.329 (0.329)	Loss 0.3601 (0.3601)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:05

 Epoch: 942	Training Loss 0.0697 	Training Prec@1 97.574 	Training Prec@5 99.994 	Validation Loss 0.4148 	Validation Prec@1 88.320 	Validation Prec@5 99.560 

lr: 0.0009530592804883488
TRAINING - Epoch: [942][0/391]	Time 0.937 (0.937)	Data 0.376 (0.376)	Loss 0.1208 (0.1208)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [942][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0354 (0.0731)	Prec@1 99.219 (97.339)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [942][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0618 (0.0739)	Prec@1 96.875 (97.322)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [942][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0553 (0.0709)	Prec@1 98.438 (97.449)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [942][0/79]	Time 0.369 (0.369)	Data 0.348 (0.348)	Loss 0.2651 (0.2651)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 943	Training Loss 0.0714 	Training Prec@1 97.444 	Training Prec@5 99.996 	Validation Loss 0.4276 	Validation Prec@1 88.310 	Validation Prec@5 99.620 

lr: 0.0009226575116807014
TRAINING - Epoch: [943][0/391]	Time 0.934 (0.934)	Data 0.376 (0.376)	Loss 0.0877 (0.0877)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [943][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0713 (0.0744)	Prec@1 97.656 (97.447)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [943][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0355 (0.0730)	Prec@1 99.219 (97.540)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [943][300/391]	Time 0.064 (0.065)	Data 0.000 (0.001)	Loss 0.0583 (0.0736)	Prec@1 98.438 (97.495)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [943][0/79]	Time 0.349 (0.349)	Data 0.328 (0.328)	Loss 0.3480 (0.3480)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 944	Training Loss 0.0731 	Training Prec@1 97.436 	Training Prec@5 99.996 	Validation Loss 0.4265 	Validation Prec@1 88.250 	Validation Prec@5 99.560 

lr: 0.0008927440147898693
TRAINING - Epoch: [944][0/391]	Time 0.956 (0.956)	Data 0.402 (0.402)	Loss 0.1426 (0.1426)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [944][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0692 (0.0718)	Prec@1 98.438 (97.486)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [944][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0537 (0.0695)	Prec@1 97.656 (97.629)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [944][300/391]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.0911 (0.0674)	Prec@1 96.094 (97.729)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [944][0/79]	Time 0.346 (0.346)	Data 0.325 (0.325)	Loss 0.3713 (0.3713)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:15

 Epoch: 945	Training Loss 0.0689 	Training Prec@1 97.646 	Training Prec@5 99.992 	Validation Loss 0.4235 	Validation Prec@1 88.390 	Validation Prec@5 99.660 

lr: 0.0008633190874261002
TRAINING - Epoch: [945][0/391]	Time 0.911 (0.911)	Data 0.342 (0.342)	Loss 0.0340 (0.0340)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [945][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0963 (0.0676)	Prec@1 96.875 (97.734)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [945][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0826 (0.0698)	Prec@1 96.875 (97.617)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [945][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0502 (0.0704)	Prec@1 98.438 (97.576)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [945][0/79]	Time 0.356 (0.356)	Data 0.337 (0.337)	Loss 0.3521 (0.3521)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 946	Training Loss 0.0700 	Training Prec@1 97.588 	Training Prec@5 99.994 	Validation Loss 0.4255 	Validation Prec@1 88.570 	Validation Prec@5 99.600 

lr: 0.0008343830223388686
TRAINING - Epoch: [946][0/391]	Time 0.889 (0.889)	Data 0.332 (0.332)	Loss 0.0358 (0.0358)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [946][100/391]	Time 0.061 (0.070)	Data 0.000 (0.003)	Loss 0.0224 (0.0734)	Prec@1 100.000 (97.416)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [946][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0821 (0.0723)	Prec@1 96.875 (97.497)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [946][300/391]	Time 0.062 (0.064)	Data 0.000 (0.001)	Loss 0.0706 (0.0720)	Prec@1 97.656 (97.506)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [946][0/79]	Time 0.335 (0.335)	Data 0.316 (0.316)	Loss 0.3257 (0.3257)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:22:44

 Epoch: 947	Training Loss 0.0722 	Training Prec@1 97.462 	Training Prec@5 99.998 	Validation Loss 0.4352 	Validation Prec@1 88.070 	Validation Prec@5 99.520 

lr: 0.000805936107413923
TRAINING - Epoch: [947][0/391]	Time 0.928 (0.928)	Data 0.373 (0.373)	Loss 0.0870 (0.0870)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0934 (0.0665)	Prec@1 96.094 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0802 (0.0653)	Prec@1 97.656 (97.851)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0650 (0.0680)	Prec@1 96.875 (97.680)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [947][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.3263 (0.3263)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 948	Training Loss 0.0684 	Training Prec@1 97.652 	Training Prec@5 99.998 	Validation Loss 0.4248 	Validation Prec@1 88.350 	Validation Prec@5 99.570 

lr: 0.000777978625670466
TRAINING - Epoch: [948][0/391]	Time 0.915 (0.915)	Data 0.355 (0.355)	Loss 0.0665 (0.0665)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [948][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0282 (0.0718)	Prec@1 99.219 (97.378)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [948][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0458 (0.0692)	Prec@1 98.438 (97.489)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [948][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1380 (0.0711)	Prec@1 95.312 (97.423)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [948][0/79]	Time 0.358 (0.358)	Data 0.338 (0.338)	Loss 0.3903 (0.3903)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 949	Training Loss 0.0712 	Training Prec@1 97.468 	Training Prec@5 100.000 	Validation Loss 0.4256 	Validation Prec@1 88.180 	Validation Prec@5 99.550 

lr: 0.0007505108552582842
TRAINING - Epoch: [949][0/391]	Time 0.908 (0.908)	Data 0.337 (0.337)	Loss 0.0544 (0.0544)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [949][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0534 (0.0694)	Prec@1 98.438 (97.695)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [949][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0957 (0.0716)	Prec@1 96.094 (97.555)	Prec@5 99.219 (99.988)
TRAINING - Epoch: [949][300/391]	Time 0.065 (0.066)	Data 0.000 (0.001)	Loss 0.0920 (0.0719)	Prec@1 96.875 (97.508)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [949][0/79]	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.2915 (0.2915)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 950	Training Loss 0.0715 	Training Prec@1 97.516 	Training Prec@5 99.994 	Validation Loss 0.4278 	Validation Prec@1 88.250 	Validation Prec@5 99.580 

lr: 0.0007235330694550393
TRAINING - Epoch: [950][0/391]	Time 0.911 (0.911)	Data 0.347 (0.347)	Loss 0.0435 (0.0435)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [950][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1043 (0.0714)	Prec@1 95.312 (97.393)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [950][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0774 (0.0719)	Prec@1 96.875 (97.446)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [950][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0900 (0.0712)	Prec@1 96.094 (97.464)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [950][0/79]	Time 0.363 (0.363)	Data 0.340 (0.340)	Loss 0.3694 (0.3694)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 951	Training Loss 0.0711 	Training Prec@1 97.488 	Training Prec@5 99.996 	Validation Loss 0.4295 	Validation Prec@1 88.400 	Validation Prec@5 99.580 

lr: 0.0006970455366635145
TRAINING - Epoch: [951][0/391]	Time 0.906 (0.906)	Data 0.345 (0.345)	Loss 0.0714 (0.0714)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [951][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1123 (0.0677)	Prec@1 96.875 (97.563)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [951][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0385 (0.0682)	Prec@1 99.219 (97.629)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [951][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0315 (0.0673)	Prec@1 99.219 (97.615)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [951][0/79]	Time 0.346 (0.346)	Data 0.327 (0.327)	Loss 0.2886 (0.2886)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 952	Training Loss 0.0674 	Training Prec@1 97.640 	Training Prec@5 99.992 	Validation Loss 0.4386 	Validation Prec@1 88.230 	Validation Prec@5 99.550 

lr: 0.0006710485204089448
TRAINING - Epoch: [952][0/391]	Time 0.898 (0.898)	Data 0.337 (0.337)	Loss 0.0463 (0.0463)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [952][100/391]	Time 0.062 (0.070)	Data 0.000 (0.003)	Loss 0.1170 (0.0654)	Prec@1 94.531 (97.765)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [952][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.1324 (0.0673)	Prec@1 94.531 (97.726)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [952][300/391]	Time 0.062 (0.064)	Data 0.000 (0.001)	Loss 0.0604 (0.0672)	Prec@1 97.656 (97.700)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [952][0/79]	Time 0.354 (0.354)	Data 0.334 (0.334)	Loss 0.2960 (0.2960)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:26	Time of Finish: 2022-03-24 22:22:54

 Epoch: 953	Training Loss 0.0690 	Training Prec@1 97.662 	Training Prec@5 99.994 	Validation Loss 0.4361 	Validation Prec@1 88.160 	Validation Prec@5 99.560 

lr: 0.0006455422793364078
TRAINING - Epoch: [953][0/391]	Time 0.917 (0.917)	Data 0.348 (0.348)	Loss 0.0265 (0.0265)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [953][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0382 (0.0680)	Prec@1 97.656 (97.548)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [953][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0544 (0.0687)	Prec@1 98.438 (97.505)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [953][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0580 (0.0701)	Prec@1 97.656 (97.490)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [953][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.2565 (0.2565)	Prec@1 93.750 (93.750)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 954	Training Loss 0.0687 	Training Prec@1 97.536 	Training Prec@5 100.000 	Validation Loss 0.4383 	Validation Prec@1 88.100 	Validation Prec@5 99.530 

lr: 0.0006205270672082312
TRAINING - Epoch: [954][0/391]	Time 0.931 (0.931)	Data 0.368 (0.368)	Loss 0.0630 (0.0630)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [954][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1189 (0.0671)	Prec@1 96.094 (97.649)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [954][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0854 (0.0676)	Prec@1 97.656 (97.579)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [954][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0515 (0.0684)	Prec@1 98.438 (97.594)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [954][0/79]	Time 0.344 (0.344)	Data 0.323 (0.323)	Loss 0.2341 (0.2341)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 955	Training Loss 0.0692 	Training Prec@1 97.568 	Training Prec@5 99.996 	Validation Loss 0.4290 	Validation Prec@1 88.530 	Validation Prec@5 99.540 

lr: 0.0005960031329015063
TRAINING - Epoch: [955][0/391]	Time 0.920 (0.920)	Data 0.344 (0.344)	Loss 0.0535 (0.0535)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [955][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0216 (0.0680)	Prec@1 100.000 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [955][200/391]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.0409 (0.0654)	Prec@1 99.219 (97.742)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [955][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0661 (0.0679)	Prec@1 97.656 (97.651)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [955][0/79]	Time 0.351 (0.351)	Data 0.328 (0.328)	Loss 0.3272 (0.3272)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 956	Training Loss 0.0687 	Training Prec@1 97.600 	Training Prec@5 99.998 	Validation Loss 0.4332 	Validation Prec@1 88.390 	Validation Prec@5 99.520 

lr: 0.0005719707204055729
TRAINING - Epoch: [956][0/391]	Time 0.903 (0.903)	Data 0.344 (0.344)	Loss 0.0814 (0.0814)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [956][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0600 (0.0672)	Prec@1 98.438 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [956][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0531 (0.0678)	Prec@1 98.438 (97.656)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [956][300/391]	Time 0.065 (0.065)	Data 0.000 (0.001)	Loss 0.0773 (0.0685)	Prec@1 98.438 (97.623)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [956][0/79]	Time 0.342 (0.342)	Data 0.321 (0.321)	Loss 0.2910 (0.2910)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 957	Training Loss 0.0677 	Training Prec@1 97.636 	Training Prec@5 99.998 	Validation Loss 0.4254 	Validation Prec@1 88.560 	Validation Prec@5 99.560 

lr: 0.0005484300688195991
TRAINING - Epoch: [957][0/391]	Time 0.914 (0.914)	Data 0.351 (0.351)	Loss 0.0238 (0.0238)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [957][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0624 (0.0689)	Prec@1 97.656 (97.780)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [957][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0795 (0.0666)	Prec@1 96.094 (97.781)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [957][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0539 (0.0670)	Prec@1 97.656 (97.763)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [957][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.3010 (0.3010)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 958	Training Loss 0.0667 	Training Prec@1 97.730 	Training Prec@5 99.996 	Validation Loss 0.4342 	Validation Prec@1 88.130 	Validation Prec@5 99.540 

lr: 0.000525381412350217
TRAINING - Epoch: [958][0/391]	Time 0.920 (0.920)	Data 0.367 (0.367)	Loss 0.0272 (0.0272)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [958][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0579 (0.0719)	Prec@1 97.656 (97.463)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [958][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0674 (0.0682)	Prec@1 99.219 (97.571)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [958][300/391]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.1350 (0.0682)	Prec@1 96.094 (97.615)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [958][0/79]	Time 0.353 (0.353)	Data 0.328 (0.328)	Loss 0.3189 (0.3189)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 959	Training Loss 0.0691 	Training Prec@1 97.564 	Training Prec@5 99.992 	Validation Loss 0.4197 	Validation Prec@1 88.420 	Validation Prec@5 99.670 

lr: 0.000502824980309196
TRAINING - Epoch: [959][0/391]	Time 0.945 (0.945)	Data 0.374 (0.374)	Loss 0.0782 (0.0782)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [959][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0844 (0.0674)	Prec@1 96.875 (97.610)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [959][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0444 (0.0668)	Prec@1 99.219 (97.695)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [959][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0390 (0.0659)	Prec@1 98.438 (97.726)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [959][0/79]	Time 0.371 (0.371)	Data 0.347 (0.347)	Loss 0.3225 (0.3225)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 960	Training Loss 0.0658 	Training Prec@1 97.764 	Training Prec@5 99.992 	Validation Loss 0.4222 	Validation Prec@1 88.430 	Validation Prec@5 99.560 

lr: 0.00048076099711112316
TRAINING - Epoch: [960][0/391]	Time 0.926 (0.926)	Data 0.355 (0.355)	Loss 0.0262 (0.0262)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [960][100/391]	Time 0.064 (0.072)	Data 0.000 (0.004)	Loss 0.0986 (0.0672)	Prec@1 95.312 (97.525)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [960][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0772 (0.0657)	Prec@1 96.094 (97.668)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [960][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0426 (0.0655)	Prec@1 99.219 (97.661)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [960][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.2975 (0.2975)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 961	Training Loss 0.0675 	Training Prec@1 97.596 	Training Prec@5 99.996 	Validation Loss 0.4273 	Validation Prec@1 88.190 	Validation Prec@5 99.460 

lr: 0.000459189682271221
TRAINING - Epoch: [961][0/391]	Time 0.917 (0.917)	Data 0.365 (0.365)	Loss 0.0842 (0.0842)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [961][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0684 (0.0738)	Prec@1 97.656 (97.355)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [961][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0494 (0.0690)	Prec@1 98.438 (97.516)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [961][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.0407 (0.0680)	Prec@1 97.656 (97.607)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [961][0/79]	Time 0.367 (0.367)	Data 0.345 (0.345)	Loss 0.3612 (0.3612)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 962	Training Loss 0.0678 	Training Prec@1 97.594 	Training Prec@5 99.996 	Validation Loss 0.4226 	Validation Prec@1 88.340 	Validation Prec@5 99.560 

lr: 0.00043811125040313316
TRAINING - Epoch: [962][0/391]	Time 0.909 (0.909)	Data 0.346 (0.346)	Loss 0.0659 (0.0659)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [962][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0843 (0.0658)	Prec@1 98.438 (97.772)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [962][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0268 (0.0665)	Prec@1 100.000 (97.757)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [962][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0506 (0.0672)	Prec@1 99.219 (97.729)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [962][0/79]	Time 0.373 (0.373)	Data 0.350 (0.350)	Loss 0.3251 (0.3251)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 963	Training Loss 0.0682 	Training Prec@1 97.682 	Training Prec@5 99.994 	Validation Loss 0.4397 	Validation Prec@1 88.340 	Validation Prec@5 99.560 

lr: 0.0004175259112167868
TRAINING - Epoch: [963][0/391]	Time 0.911 (0.911)	Data 0.345 (0.345)	Loss 0.0642 (0.0642)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [963][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0234 (0.0675)	Prec@1 100.000 (97.672)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [963][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0250 (0.0647)	Prec@1 100.000 (97.792)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [963][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0555 (0.0659)	Prec@1 97.656 (97.734)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [963][0/79]	Time 0.378 (0.378)	Data 0.355 (0.355)	Loss 0.2324 (0.2324)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 964	Training Loss 0.0657 	Training Prec@1 97.750 	Training Prec@5 99.996 	Validation Loss 0.4314 	Validation Prec@1 87.920 	Validation Prec@5 99.560 

lr: 0.00039743386951633886
TRAINING - Epoch: [964][0/391]	Time 0.900 (0.900)	Data 0.336 (0.336)	Loss 0.0764 (0.0764)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [964][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0716 (0.0687)	Prec@1 96.875 (97.679)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [964][200/391]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.0318 (0.0678)	Prec@1 99.219 (97.683)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [964][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0754 (0.0675)	Prec@1 97.656 (97.672)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [964][0/79]	Time 0.361 (0.361)	Data 0.340 (0.340)	Loss 0.2742 (0.2742)	Prec@1 95.312 (95.312)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 965	Training Loss 0.0682 	Training Prec@1 97.674 	Training Prec@5 99.998 	Validation Loss 0.4268 	Validation Prec@1 88.250 	Validation Prec@5 99.520 

lr: 0.0003778353251980833
TRAINING - Epoch: [965][0/391]	Time 1.153 (1.153)	Data 0.346 (0.346)	Loss 0.0207 (0.0207)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][100/391]	Time 0.063 (0.073)	Data 0.000 (0.004)	Loss 0.0666 (0.0642)	Prec@1 97.656 (97.633)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][200/391]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.0586 (0.0651)	Prec@1 97.656 (97.660)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [965][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0304 (0.0649)	Prec@1 100.000 (97.651)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [965][0/79]	Time 0.359 (0.359)	Data 0.340 (0.340)	Loss 0.2791 (0.2791)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:19

 Epoch: 966	Training Loss 0.0647 	Training Prec@1 97.712 	Training Prec@5 99.996 	Validation Loss 0.4120 	Validation Prec@1 88.650 	Validation Prec@5 99.630 

lr: 0.0003587304732485248
TRAINING - Epoch: [966][0/391]	Time 0.939 (0.939)	Data 0.357 (0.357)	Loss 0.0633 (0.0633)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [966][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0559 (0.0658)	Prec@1 98.438 (97.788)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [966][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0227 (0.0683)	Prec@1 100.000 (97.711)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [966][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0827 (0.0689)	Prec@1 96.094 (97.633)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [966][0/79]	Time 0.370 (0.370)	Data 0.350 (0.350)	Loss 0.3419 (0.3419)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 967	Training Loss 0.0668 	Training Prec@1 97.676 	Training Prec@5 99.988 	Validation Loss 0.4212 	Validation Prec@1 88.480 	Validation Prec@5 99.510 

lr: 0.00034011950374238613
TRAINING - Epoch: [967][0/391]	Time 0.898 (0.898)	Data 0.344 (0.344)	Loss 0.0996 (0.0996)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [967][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0474 (0.0659)	Prec@1 98.438 (97.656)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [967][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0427 (0.0679)	Prec@1 98.438 (97.586)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [967][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0856 (0.0668)	Prec@1 96.094 (97.654)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [967][0/79]	Time 0.353 (0.353)	Data 0.331 (0.331)	Loss 0.3002 (0.3002)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 968	Training Loss 0.0667 	Training Prec@1 97.668 	Training Prec@5 99.994 	Validation Loss 0.4256 	Validation Prec@1 88.370 	Validation Prec@5 99.580 

lr: 0.00032200260184075366
TRAINING - Epoch: [968][0/391]	Time 0.929 (0.929)	Data 0.373 (0.373)	Loss 0.0772 (0.0772)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [968][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0711 (0.0642)	Prec@1 97.656 (97.710)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [968][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0495 (0.0672)	Prec@1 99.219 (97.563)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [968][300/391]	Time 0.062 (0.065)	Data 0.000 (0.002)	Loss 0.0600 (0.0658)	Prec@1 98.438 (97.648)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [968][0/79]	Time 0.375 (0.375)	Data 0.349 (0.349)	Loss 0.2267 (0.2267)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 969	Training Loss 0.0668 	Training Prec@1 97.630 	Training Prec@5 99.996 	Validation Loss 0.4376 	Validation Prec@1 87.900 	Validation Prec@5 99.600 

lr: 0.0003043799477892125
TRAINING - Epoch: [969][0/391]	Time 0.921 (0.921)	Data 0.360 (0.360)	Loss 0.0177 (0.0177)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [969][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.1008 (0.0618)	Prec@1 96.875 (97.888)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [969][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0666 (0.0631)	Prec@1 99.219 (97.819)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [969][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1409 (0.0632)	Prec@1 92.969 (97.809)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [969][0/79]	Time 0.344 (0.344)	Data 0.321 (0.321)	Loss 0.3359 (0.3359)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:12

 Epoch: 970	Training Loss 0.0631 	Training Prec@1 97.820 	Training Prec@5 99.994 	Validation Loss 0.4289 	Validation Prec@1 88.300 	Validation Prec@5 99.630 

lr: 0.000287251716916059
TRAINING - Epoch: [970][0/391]	Time 0.910 (0.910)	Data 0.354 (0.354)	Loss 0.0827 (0.0827)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0458 (0.0616)	Prec@1 98.438 (97.873)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0785 (0.0657)	Prec@1 96.094 (97.645)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [970][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0594 (0.0669)	Prec@1 97.656 (97.610)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [970][0/79]	Time 0.378 (0.378)	Data 0.357 (0.357)	Loss 0.3456 (0.3456)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 971	Training Loss 0.0677 	Training Prec@1 97.542 	Training Prec@5 99.998 	Validation Loss 0.4336 	Validation Prec@1 88.440 	Validation Prec@5 99.500 

lr: 0.0002706180796305687
TRAINING - Epoch: [971][0/391]	Time 0.939 (0.939)	Data 0.344 (0.344)	Loss 0.1319 (0.1319)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [971][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0569 (0.0647)	Prec@1 97.656 (97.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [971][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0830 (0.0677)	Prec@1 96.094 (97.567)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [971][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0591 (0.0675)	Prec@1 96.875 (97.571)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [971][0/79]	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.3034 (0.3034)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 972	Training Loss 0.0679 	Training Prec@1 97.578 	Training Prec@5 99.998 	Validation Loss 0.4299 	Validation Prec@1 88.170 	Validation Prec@5 99.560 

lr: 0.00025447920142128677
TRAINING - Epoch: [972][0/391]	Time 0.922 (0.922)	Data 0.341 (0.341)	Loss 0.0607 (0.0607)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [972][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0895 (0.0699)	Prec@1 96.094 (97.386)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [972][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0711 (0.0675)	Prec@1 97.656 (97.567)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [972][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1137 (0.0672)	Prec@1 96.875 (97.597)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [972][0/79]	Time 0.361 (0.361)	Data 0.338 (0.338)	Loss 0.2996 (0.2996)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:11

 Epoch: 973	Training Loss 0.0671 	Training Prec@1 97.604 	Training Prec@5 99.994 	Validation Loss 0.4188 	Validation Prec@1 88.550 	Validation Prec@5 99.560 

lr: 0.0002388352428543791
TRAINING - Epoch: [973][0/391]	Time 0.943 (0.943)	Data 0.379 (0.379)	Loss 0.1375 (0.1375)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [973][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0608 (0.0646)	Prec@1 97.656 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [973][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0819 (0.0661)	Prec@1 97.656 (97.683)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [973][300/391]	Time 0.064 (0.066)	Data 0.000 (0.001)	Loss 0.1063 (0.0672)	Prec@1 95.312 (97.641)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [973][0/79]	Time 0.363 (0.363)	Data 0.342 (0.342)	Loss 0.3013 (0.3013)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:10

 Epoch: 974	Training Loss 0.0670 	Training Prec@1 97.648 	Training Prec@5 99.990 	Validation Loss 0.4327 	Validation Prec@1 88.370 	Validation Prec@5 99.520 

lr: 0.0002236863595720559
TRAINING - Epoch: [974][0/391]	Time 0.889 (0.889)	Data 0.340 (0.340)	Loss 0.0375 (0.0375)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0868 (0.0633)	Prec@1 98.438 (97.757)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0785 (0.0661)	Prec@1 96.875 (97.676)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1076 (0.0658)	Prec@1 96.875 (97.706)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [974][0/79]	Time 0.352 (0.352)	Data 0.331 (0.331)	Loss 0.3391 (0.3391)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 975	Training Loss 0.0654 	Training Prec@1 97.726 	Training Prec@5 100.000 	Validation Loss 0.4287 	Validation Prec@1 88.370 	Validation Prec@5 99.520 

lr: 0.00020903270229098966
TRAINING - Epoch: [975][0/391]	Time 0.906 (0.906)	Data 0.335 (0.335)	Loss 0.0505 (0.0505)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [975][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0596 (0.0624)	Prec@1 98.438 (97.811)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [975][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0890 (0.0661)	Prec@1 96.875 (97.703)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [975][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0547 (0.0666)	Prec@1 97.656 (97.695)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [975][0/79]	Time 0.348 (0.348)	Data 0.327 (0.327)	Loss 0.2931 (0.2931)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 976	Training Loss 0.0668 	Training Prec@1 97.668 	Training Prec@5 99.996 	Validation Loss 0.4236 	Validation Prec@1 88.500 	Validation Prec@5 99.560 

lr: 0.00019487441680084958
TRAINING - Epoch: [976][0/391]	Time 0.918 (0.918)	Data 0.334 (0.334)	Loss 0.0904 (0.0904)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [976][100/391]	Time 0.062 (0.071)	Data 0.000 (0.003)	Loss 0.0307 (0.0652)	Prec@1 99.219 (97.842)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [976][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.1066 (0.0650)	Prec@1 96.094 (97.847)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [976][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0681 (0.0639)	Prec@1 97.656 (97.872)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [976][0/79]	Time 0.363 (0.363)	Data 0.343 (0.343)	Loss 0.2997 (0.2997)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:06

 Epoch: 977	Training Loss 0.0649 	Training Prec@1 97.810 	Training Prec@5 99.996 	Validation Loss 0.4434 	Validation Prec@1 87.890 	Validation Prec@5 99.570 

lr: 0.00018121164396283615
TRAINING - Epoch: [977][0/391]	Time 0.928 (0.928)	Data 0.346 (0.346)	Loss 0.0693 (0.0693)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [977][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0505 (0.0675)	Prec@1 97.656 (97.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [977][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0594 (0.0688)	Prec@1 97.656 (97.625)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [977][300/391]	Time 0.066 (0.065)	Data 0.000 (0.001)	Loss 0.1035 (0.0687)	Prec@1 96.094 (97.630)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [977][0/79]	Time 0.355 (0.355)	Data 0.330 (0.330)	Loss 0.3297 (0.3297)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 978	Training Loss 0.0682 	Training Prec@1 97.640 	Training Prec@5 99.994 	Validation Loss 0.4276 	Validation Prec@1 88.510 	Validation Prec@5 99.570 

lr: 0.00016804451970827672
TRAINING - Epoch: [978][0/391]	Time 0.920 (0.920)	Data 0.358 (0.358)	Loss 0.0355 (0.0355)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0673 (0.0643)	Prec@1 97.656 (97.679)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0582 (0.0655)	Prec@1 97.656 (97.648)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0536 (0.0659)	Prec@1 98.438 (97.623)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [978][0/79]	Time 0.360 (0.360)	Data 0.340 (0.340)	Loss 0.2726 (0.2726)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 979	Training Loss 0.0671 	Training Prec@1 97.574 	Training Prec@5 99.996 	Validation Loss 0.4326 	Validation Prec@1 88.200 	Validation Prec@5 99.560 

lr: 0.0001553731750372709
TRAINING - Epoch: [979][0/391]	Time 0.922 (0.922)	Data 0.352 (0.352)	Loss 0.0910 (0.0910)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [979][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0843 (0.0701)	Prec@1 95.312 (97.618)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [979][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0228 (0.0673)	Prec@1 100.000 (97.680)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [979][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0696 (0.0672)	Prec@1 97.656 (97.659)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [979][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.3417 (0.3417)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 980	Training Loss 0.0681 	Training Prec@1 97.636 	Training Prec@5 99.996 	Validation Loss 0.4362 	Validation Prec@1 88.140 	Validation Prec@5 99.530 

lr: 0.0001431977360173973
TRAINING - Epoch: [980][0/391]	Time 0.923 (0.923)	Data 0.344 (0.344)	Loss 0.0521 (0.0521)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [980][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0449 (0.0634)	Prec@1 98.438 (97.819)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [980][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0677 (0.0648)	Prec@1 96.875 (97.699)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [980][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0773 (0.0662)	Prec@1 96.875 (97.633)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [980][0/79]	Time 0.376 (0.376)	Data 0.356 (0.356)	Loss 0.2552 (0.2552)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 981	Training Loss 0.0657 	Training Prec@1 97.662 	Training Prec@5 99.996 	Validation Loss 0.4301 	Validation Prec@1 88.190 	Validation Prec@5 99.430 

lr: 0.00013151832378245892
TRAINING - Epoch: [981][0/391]	Time 0.916 (0.916)	Data 0.347 (0.347)	Loss 0.1032 (0.1032)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [981][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0584 (0.0659)	Prec@1 96.875 (97.710)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [981][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0852 (0.0666)	Prec@1 96.875 (97.617)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [981][300/391]	Time 0.061 (0.065)	Data 0.000 (0.001)	Loss 0.0340 (0.0658)	Prec@1 99.219 (97.677)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [981][0/79]	Time 0.352 (0.352)	Data 0.331 (0.331)	Loss 0.2809 (0.2809)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 982	Training Loss 0.0658 	Training Prec@1 97.688 	Training Prec@5 99.996 	Validation Loss 0.4297 	Validation Prec@1 88.500 	Validation Prec@5 99.550 

lr: 0.00012033505453127298
TRAINING - Epoch: [982][0/391]	Time 0.929 (0.929)	Data 0.366 (0.366)	Loss 0.0353 (0.0353)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [982][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0457 (0.0694)	Prec@1 98.438 (97.455)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [982][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0608 (0.0677)	Prec@1 97.656 (97.610)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [982][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0597 (0.0675)	Prec@1 96.875 (97.620)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [982][0/79]	Time 0.342 (0.342)	Data 0.319 (0.319)	Loss 0.3069 (0.3069)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 983	Training Loss 0.0667 	Training Prec@1 97.654 	Training Prec@5 99.996 	Validation Loss 0.4384 	Validation Prec@1 88.300 	Validation Prec@5 99.570 

lr: 0.00010964803952649967
TRAINING - Epoch: [983][0/391]	Time 0.918 (0.918)	Data 0.343 (0.343)	Loss 0.0487 (0.0487)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [983][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0317 (0.0674)	Prec@1 99.219 (97.432)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [983][200/391]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.0736 (0.0669)	Prec@1 98.438 (97.629)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [983][300/391]	Time 0.062 (0.064)	Data 0.000 (0.001)	Loss 0.0532 (0.0661)	Prec@1 99.219 (97.698)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [983][0/79]	Time 0.368 (0.368)	Data 0.346 (0.346)	Loss 0.3032 (0.3032)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:26	Time of Finish: 2022-03-24 22:23:02

 Epoch: 984	Training Loss 0.0669 	Training Prec@1 97.688 	Training Prec@5 99.994 	Validation Loss 0.4181 	Validation Prec@1 88.480 	Validation Prec@5 99.490 

lr: 9.945738509358191e-05
TRAINING - Epoch: [984][0/391]	Time 0.912 (0.912)	Data 0.354 (0.354)	Loss 0.0461 (0.0461)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [984][100/391]	Time 0.062 (0.070)	Data 0.000 (0.004)	Loss 0.0678 (0.0639)	Prec@1 98.438 (97.857)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [984][200/391]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.0600 (0.0663)	Prec@1 97.656 (97.835)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [984][300/391]	Time 0.061 (0.064)	Data 0.000 (0.001)	Loss 0.0383 (0.0651)	Prec@1 98.438 (97.820)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [984][0/79]	Time 0.357 (0.357)	Data 0.334 (0.334)	Loss 0.2923 (0.2923)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:26	Time of Finish: 2022-03-24 22:23:02

 Epoch: 985	Training Loss 0.0650 	Training Prec@1 97.784 	Training Prec@5 99.994 	Validation Loss 0.4271 	Validation Prec@1 88.340 	Validation Prec@5 99.530 

lr: 8.976319261962395e-05
TRAINING - Epoch: [985][0/391]	Time 0.903 (0.903)	Data 0.349 (0.349)	Loss 0.0431 (0.0431)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [985][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0953 (0.0694)	Prec@1 95.312 (97.532)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [985][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0846 (0.0671)	Prec@1 96.875 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [985][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0756 (0.0658)	Prec@1 97.656 (97.719)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [985][0/79]	Time 0.345 (0.345)	Data 0.322 (0.322)	Loss 0.3918 (0.3918)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 986	Training Loss 0.0654 	Training Prec@1 97.744 	Training Prec@5 99.998 	Validation Loss 0.4237 	Validation Prec@1 88.380 	Validation Prec@5 99.550 

lr: 8.056555855243664e-05
TRAINING - Epoch: [986][0/391]	Time 0.940 (0.940)	Data 0.376 (0.376)	Loss 0.0293 (0.0293)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [986][100/391]	Time 0.067 (0.072)	Data 0.000 (0.004)	Loss 0.1055 (0.0608)	Prec@1 94.531 (97.912)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [986][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0598 (0.0609)	Prec@1 98.438 (97.948)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [986][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0522 (0.0620)	Prec@1 99.219 (97.890)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [986][0/79]	Time 0.388 (0.388)	Data 0.365 (0.365)	Loss 0.2796 (0.2796)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 987	Training Loss 0.0640 	Training Prec@1 97.788 	Training Prec@5 99.994 	Validation Loss 0.4245 	Validation Prec@1 88.360 	Validation Prec@5 99.610 

lr: 7.186457439954932e-05
TRAINING - Epoch: [987][0/391]	Time 0.920 (0.920)	Data 0.371 (0.371)	Loss 0.0712 (0.0712)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [987][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.0837 (0.0710)	Prec@1 96.875 (97.494)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [987][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0779 (0.0693)	Prec@1 96.094 (97.551)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [987][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0505 (0.0672)	Prec@1 98.438 (97.690)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [987][0/79]	Time 0.346 (0.346)	Data 0.324 (0.324)	Loss 0.2716 (0.2716)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 988	Training Loss 0.0664 	Training Prec@1 97.722 	Training Prec@5 99.996 	Validation Loss 0.4202 	Validation Prec@1 88.580 	Validation Prec@5 99.560 

lr: 6.366032672731051e-05
TRAINING - Epoch: [988][0/391]	Time 0.913 (0.913)	Data 0.364 (0.364)	Loss 0.0370 (0.0370)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [988][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0261 (0.0664)	Prec@1 99.219 (97.602)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [988][200/391]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.0474 (0.0639)	Prec@1 98.438 (97.711)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [988][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0763 (0.0641)	Prec@1 96.875 (97.755)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [988][0/79]	Time 0.373 (0.373)	Data 0.349 (0.349)	Loss 0.2940 (0.2940)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 989	Training Loss 0.0642 	Training Prec@1 97.768 	Training Prec@5 99.994 	Validation Loss 0.4216 	Validation Prec@1 88.830 	Validation Prec@5 99.540 

lr: 5.595289716001644e-05
TRAINING - Epoch: [989][0/391]	Time 0.898 (0.898)	Data 0.338 (0.338)	Loss 0.0355 (0.0355)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [989][100/391]	Time 0.062 (0.071)	Data 0.000 (0.004)	Loss 0.1255 (0.0611)	Prec@1 94.531 (97.981)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [989][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0914 (0.0646)	Prec@1 96.875 (97.796)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [989][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.1285 (0.0647)	Prec@1 96.094 (97.778)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [989][0/79]	Time 0.377 (0.377)	Data 0.356 (0.356)	Loss 0.2120 (0.2120)	Prec@1 96.094 (96.094)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 990	Training Loss 0.0642 	Training Prec@1 97.786 	Training Prec@5 99.996 	Validation Loss 0.4269 	Validation Prec@1 88.450 	Validation Prec@5 99.540 

lr: 4.874236237911717e-05
TRAINING - Epoch: [990][0/391]	Time 0.922 (0.922)	Data 0.348 (0.348)	Loss 0.0548 (0.0548)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0807 (0.0642)	Prec@1 98.438 (97.710)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0899 (0.0622)	Prec@1 96.875 (97.808)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [990][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0556 (0.0627)	Prec@1 98.438 (97.812)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [990][0/79]	Time 0.338 (0.338)	Data 0.318 (0.318)	Loss 0.2608 (0.2608)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:07

 Epoch: 991	Training Loss 0.0631 	Training Prec@1 97.766 	Training Prec@5 99.990 	Validation Loss 0.4291 	Validation Prec@1 88.490 	Validation Prec@5 99.530 

lr: 4.202879412242284e-05
TRAINING - Epoch: [991][0/391]	Time 0.910 (0.910)	Data 0.339 (0.339)	Loss 0.0370 (0.0370)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [991][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0681 (0.0657)	Prec@1 97.656 (97.749)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [991][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.1095 (0.0647)	Prec@1 97.656 (97.796)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [991][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0490 (0.0646)	Prec@1 98.438 (97.755)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [991][0/79]	Time 0.337 (0.337)	Data 0.316 (0.316)	Loss 0.2990 (0.2990)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 992	Training Loss 0.0645 	Training Prec@1 97.752 	Training Prec@5 99.994 	Validation Loss 0.4300 	Validation Prec@1 88.290 	Validation Prec@5 99.590 

lr: 3.581225918342642e-05
TRAINING - Epoch: [992][0/391]	Time 0.941 (0.941)	Data 0.375 (0.375)	Loss 0.0467 (0.0467)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [992][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0491 (0.0680)	Prec@1 97.656 (97.718)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [992][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0596 (0.0668)	Prec@1 99.219 (97.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [992][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.1240 (0.0655)	Prec@1 95.312 (97.791)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [992][0/79]	Time 0.369 (0.369)	Data 0.347 (0.347)	Loss 0.2418 (0.2418)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:09

 Epoch: 993	Training Loss 0.0656 	Training Prec@1 97.732 	Training Prec@5 100.000 	Validation Loss 0.4257 	Validation Prec@1 88.350 	Validation Prec@5 99.570 

lr: 3.009281941062089e-05
TRAINING - Epoch: [993][0/391]	Time 0.908 (0.908)	Data 0.350 (0.350)	Loss 0.0226 (0.0226)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [993][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0323 (0.0652)	Prec@1 98.438 (97.625)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [993][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0617 (0.0648)	Prec@1 96.875 (97.648)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [993][300/391]	Time 0.062 (0.066)	Data 0.000 (0.001)	Loss 0.0453 (0.0636)	Prec@1 99.219 (97.739)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [993][0/79]	Time 0.331 (0.331)	Data 0.311 (0.311)	Loss 0.2912 (0.2912)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 994	Training Loss 0.0641 	Training Prec@1 97.682 	Training Prec@5 99.994 	Validation Loss 0.4233 	Validation Prec@1 88.370 	Validation Prec@5 99.500 

lr: 2.487053170686646e-05
TRAINING - Epoch: [994][0/391]	Time 0.908 (0.908)	Data 0.341 (0.341)	Loss 0.0381 (0.0381)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0330 (0.0667)	Prec@1 99.219 (97.471)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][200/391]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.0854 (0.0650)	Prec@1 97.656 (97.590)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][300/391]	Time 0.063 (0.065)	Data 0.000 (0.001)	Loss 0.0651 (0.0642)	Prec@1 96.875 (97.690)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [994][0/79]	Time 0.344 (0.344)	Data 0.325 (0.325)	Loss 0.2458 (0.2458)	Prec@1 93.750 (93.750)	Prec@5 98.438 (98.438)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 995	Training Loss 0.0644 	Training Prec@1 97.700 	Training Prec@5 99.998 	Validation Loss 0.4209 	Validation Prec@1 88.290 	Validation Prec@5 99.630 

lr: 2.0145448028874282e-05
TRAINING - Epoch: [995][0/391]	Time 0.917 (0.917)	Data 0.351 (0.351)	Loss 0.0680 (0.0680)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [995][100/391]	Time 0.064 (0.071)	Data 0.000 (0.004)	Loss 0.0572 (0.0641)	Prec@1 98.438 (97.741)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [995][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0568 (0.0624)	Prec@1 98.438 (97.897)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [995][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0658 (0.0630)	Prec@1 97.656 (97.882)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [995][0/79]	Time 0.350 (0.350)	Data 0.328 (0.328)	Loss 0.2344 (0.2344)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 996	Training Loss 0.0631 	Training Prec@1 97.844 	Training Prec@5 99.996 	Validation Loss 0.4301 	Validation Prec@1 88.180 	Validation Prec@5 99.540 

lr: 1.5917615386623604e-05
TRAINING - Epoch: [996][0/391]	Time 0.932 (0.932)	Data 0.371 (0.371)	Loss 0.0988 (0.0988)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [996][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0494 (0.0633)	Prec@1 98.438 (97.788)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [996][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0348 (0.0632)	Prec@1 99.219 (97.800)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [996][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.0396 (0.0628)	Prec@1 97.656 (97.802)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [996][0/79]	Time 0.366 (0.366)	Data 0.344 (0.344)	Loss 0.2589 (0.2589)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 997	Training Loss 0.0620 	Training Prec@1 97.778 	Training Prec@5 100.000 	Validation Loss 0.4215 	Validation Prec@1 88.290 	Validation Prec@5 99.630 

lr: 1.2187075842956519e-05
TRAINING - Epoch: [997][0/391]	Time 0.919 (0.919)	Data 0.346 (0.346)	Loss 0.0602 (0.0602)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.0634 (0.0637)	Prec@1 96.875 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0531 (0.0627)	Prec@1 96.875 (97.660)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0398 (0.0637)	Prec@1 99.219 (97.685)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [997][0/79]	Time 0.372 (0.372)	Data 0.351 (0.351)	Loss 0.2533 (0.2533)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 998	Training Loss 0.0647 	Training Prec@1 97.666 	Training Prec@5 99.996 	Validation Loss 0.4231 	Validation Prec@1 88.340 	Validation Prec@5 99.560 

lr: 8.95386651311169e-06
TRAINING - Epoch: [998][0/391]	Time 0.922 (0.922)	Data 0.352 (0.352)	Loss 0.0245 (0.0245)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [998][100/391]	Time 0.063 (0.071)	Data 0.000 (0.004)	Loss 0.1083 (0.0657)	Prec@1 94.531 (97.679)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [998][200/391]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.0917 (0.0652)	Prec@1 96.094 (97.773)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [998][300/391]	Time 0.062 (0.065)	Data 0.000 (0.001)	Loss 0.1036 (0.0632)	Prec@1 95.312 (97.815)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [998][0/79]	Time 0.389 (0.389)	Data 0.368 (0.368)	Loss 0.3208 (0.3208)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 999	Training Loss 0.0637 	Training Prec@1 97.822 	Training Prec@5 99.998 	Validation Loss 0.4270 	Validation Prec@1 88.280 	Validation Prec@5 99.580 

lr: 6.218019564391271e-06
TRAINING - Epoch: [999][0/391]	Time 0.919 (0.919)	Data 0.351 (0.351)	Loss 0.0772 (0.0772)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [999][100/391]	Time 0.061 (0.071)	Data 0.000 (0.004)	Loss 0.0407 (0.0624)	Prec@1 98.438 (97.795)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [999][200/391]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.0344 (0.0619)	Prec@1 99.219 (97.870)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [999][300/391]	Time 0.063 (0.066)	Data 0.000 (0.001)	Loss 0.0997 (0.0617)	Prec@1 95.312 (97.877)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [999][0/79]	Time 0.380 (0.380)	Data 0.359 (0.359)	Loss 0.2566 (0.2566)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:27	Time of Finish: 2022-03-24 22:23:08

 Epoch: 1000	Training Loss 0.0627 	Training Prec@1 97.792 	Training Prec@5 99.996 	Validation Loss 0.4233 	Validation Prec@1 88.420 	Validation Prec@5 99.560 

**************************************************DONE**************************************************

 Best_Epoch: 887	Best_Prec1 88.8300 	Best_Loss 0.422 	
