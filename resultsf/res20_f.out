saving to [DIR]/
creating model resnet20_1w1a
model structure: ResNet(
  (conv1): BinarizeConv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(48, 94, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): BinarizeConv2d(48, 94, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(94, 94, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(94, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(94, 186, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): BinarizeConv2d(94, 186, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(186, 186, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): bilinear(in_features=186, out_features=10, bias=True)
)
number of parameters: 2311559
Files already downloaded and verified
Files already downloaded and verified
criterion: CrossEntropyLoss()
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f6dc61b2d30>
EVALUATING - Epoch: [0][0/79]	Time 0.700 (0.700)	Data 0.289 (0.289)	Loss 2.3095 (2.3095)	Prec@1 7.031 (7.031)	Prec@5 43.750 (43.750)
lr: 0.02
TRAINING - Epoch: [0][0/391]	Time 1.769 (1.769)	Data 0.347 (0.347)	Loss 2.3005 (2.3005)	Prec@1 11.719 (11.719)	Prec@5 50.000 (50.000)
TRAINING - Epoch: [0][100/391]	Time 0.121 (0.134)	Data 0.001 (0.004)	Loss 2.1013 (2.1379)	Prec@1 23.438 (22.587)	Prec@5 77.344 (75.348)
TRAINING - Epoch: [0][200/391]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 1.8973 (2.0519)	Prec@1 28.125 (24.666)	Prec@5 81.250 (78.168)
TRAINING - Epoch: [0][300/391]	Time 0.119 (0.127)	Data 0.001 (0.002)	Loss 1.8277 (2.0064)	Prec@1 33.594 (25.968)	Prec@5 80.469 (79.698)
EVALUATING - Epoch: [0][0/79]	Time 0.458 (0.458)	Data 0.408 (0.408)	Loss 1.9047 (1.9047)	Prec@1 28.906 (28.906)	Prec@5 84.375 (84.375)
Time cost: 00:51	Time of Finish: 2022-03-24 03:30:27

 Epoch: 1	Training Loss 1.9777 	Training Prec@1 26.780 	Training Prec@5 80.580 	Validation Loss 1.9596 	Validation Prec@1 30.010 	Validation Prec@5 80.340 

lr: 0.04
TRAINING - Epoch: [1][0/391]	Time 1.304 (1.304)	Data 0.361 (0.361)	Loss 2.1276 (2.1276)	Prec@1 19.531 (19.531)	Prec@5 76.562 (76.562)
TRAINING - Epoch: [1][100/391]	Time 0.108 (0.125)	Data 0.000 (0.004)	Loss 1.9528 (1.9519)	Prec@1 28.125 (27.498)	Prec@5 79.688 (81.745)
TRAINING - Epoch: [1][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 1.8066 (1.9233)	Prec@1 26.562 (28.335)	Prec@5 85.938 (82.513)
TRAINING - Epoch: [1][300/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 1.7935 (1.9074)	Prec@1 35.938 (28.849)	Prec@5 84.375 (83.075)
EVALUATING - Epoch: [1][0/79]	Time 0.426 (0.426)	Data 0.383 (0.383)	Loss 1.7743 (1.7743)	Prec@1 32.812 (32.812)	Prec@5 89.062 (89.062)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:09

 Epoch: 2	Training Loss 1.8927 	Training Prec@1 29.412 	Training Prec@5 83.622 	Validation Loss 1.8814 	Validation Prec@1 31.120 	Validation Prec@5 83.730 

lr: 0.06000000000000001
TRAINING - Epoch: [2][0/391]	Time 1.330 (1.330)	Data 0.441 (0.441)	Loss 2.0893 (2.0893)	Prec@1 32.812 (32.812)	Prec@5 75.000 (75.000)
TRAINING - Epoch: [2][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 1.8574 (1.8960)	Prec@1 35.156 (29.045)	Prec@5 83.594 (83.586)
TRAINING - Epoch: [2][200/391]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 1.6853 (1.8698)	Prec@1 38.281 (30.084)	Prec@5 91.406 (83.998)
TRAINING - Epoch: [2][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 1.8008 (1.8508)	Prec@1 30.469 (30.721)	Prec@5 87.500 (84.474)
EVALUATING - Epoch: [2][0/79]	Time 0.417 (0.417)	Data 0.386 (0.386)	Loss 1.7073 (1.7073)	Prec@1 38.281 (38.281)	Prec@5 88.281 (88.281)
Time cost: 00:47	Time of Finish: 2022-03-24 02:18:58

 Epoch: 3	Training Loss 1.8363 	Training Prec@1 31.296 	Training Prec@5 84.920 	Validation Loss 1.8292 	Validation Prec@1 33.210 	Validation Prec@5 86.020 

lr: 0.08
TRAINING - Epoch: [3][0/391]	Time 1.288 (1.288)	Data 0.360 (0.360)	Loss 1.7961 (1.7961)	Prec@1 33.594 (33.594)	Prec@5 82.812 (82.812)
TRAINING - Epoch: [3][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 1.9408 (1.8159)	Prec@1 24.219 (31.931)	Prec@5 78.906 (85.357)
TRAINING - Epoch: [3][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 1.8186 (1.7958)	Prec@1 32.812 (32.704)	Prec@5 85.938 (85.728)
TRAINING - Epoch: [3][300/391]	Time 0.107 (0.114)	Data 0.000 (0.001)	Loss 1.8051 (1.7763)	Prec@1 32.812 (33.531)	Prec@5 84.375 (86.127)
EVALUATING - Epoch: [3][0/79]	Time 0.414 (0.414)	Data 0.388 (0.388)	Loss 1.7179 (1.7179)	Prec@1 38.281 (38.281)	Prec@5 86.719 (86.719)
Time cost: 00:46	Time of Finish: 2022-03-24 02:10:41

 Epoch: 4	Training Loss 1.7667 	Training Prec@1 33.986 	Training Prec@5 86.380 	Validation Loss 1.8367 	Validation Prec@1 32.770 	Validation Prec@5 84.830 

lr: 0.1
TRAINING - Epoch: [4][0/391]	Time 1.335 (1.335)	Data 0.438 (0.438)	Loss 1.7304 (1.7304)	Prec@1 36.719 (36.719)	Prec@5 89.062 (89.062)
TRAINING - Epoch: [4][100/391]	Time 0.106 (0.124)	Data 0.000 (0.005)	Loss 1.6765 (1.7590)	Prec@1 34.375 (34.066)	Prec@5 91.406 (86.989)
TRAINING - Epoch: [4][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 1.8183 (1.7711)	Prec@1 32.031 (33.500)	Prec@5 87.500 (86.785)
TRAINING - Epoch: [4][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 1.7201 (1.7675)	Prec@1 29.688 (33.814)	Prec@5 87.500 (86.719)
EVALUATING - Epoch: [4][0/79]	Time 0.443 (0.443)	Data 0.408 (0.408)	Loss 1.9097 (1.9097)	Prec@1 35.938 (35.938)	Prec@5 84.375 (84.375)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:14

 Epoch: 5	Training Loss 1.7607 	Training Prec@1 34.234 	Training Prec@5 86.818 	Validation Loss 1.9704 	Validation Prec@1 30.880 	Validation Prec@5 80.900 

lr: 0.1000017411147667
TRAINING - Epoch: [5][0/391]	Time 1.303 (1.303)	Data 0.442 (0.442)	Loss 1.9352 (1.9352)	Prec@1 27.344 (27.344)	Prec@5 81.250 (81.250)
TRAINING - Epoch: [5][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 1.8875 (1.7544)	Prec@1 25.000 (34.058)	Prec@5 85.938 (86.649)
TRAINING - Epoch: [5][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 1.7304 (1.7388)	Prec@1 32.031 (34.869)	Prec@5 87.500 (87.146)
TRAINING - Epoch: [5][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 1.6896 (1.7322)	Prec@1 33.594 (35.110)	Prec@5 89.062 (87.165)
EVALUATING - Epoch: [5][0/79]	Time 0.473 (0.473)	Data 0.429 (0.429)	Loss 1.9129 (1.9129)	Prec@1 28.125 (28.125)	Prec@5 79.688 (79.688)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:20

 Epoch: 6	Training Loss 1.7399 	Training Prec@1 34.898 	Training Prec@5 87.040 	Validation Loss 1.9254 	Validation Prec@1 33.240 	Validation Prec@5 83.490 

lr: 0.10000298478054478
TRAINING - Epoch: [6][0/391]	Time 1.273 (1.273)	Data 0.425 (0.425)	Loss 1.7766 (1.7766)	Prec@1 25.781 (25.781)	Prec@5 85.938 (85.938)
TRAINING - Epoch: [6][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 1.7121 (1.7372)	Prec@1 35.938 (35.056)	Prec@5 85.938 (87.330)
TRAINING - Epoch: [6][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 1.7910 (1.7208)	Prec@1 35.156 (35.864)	Prec@5 90.625 (87.702)
TRAINING - Epoch: [6][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 1.6095 (1.7165)	Prec@1 38.281 (35.912)	Prec@5 91.406 (87.687)
EVALUATING - Epoch: [6][0/79]	Time 0.440 (0.440)	Data 0.403 (0.403)	Loss 1.6684 (1.6684)	Prec@1 41.406 (41.406)	Prec@5 85.938 (85.938)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:13

 Epoch: 7	Training Loss 1.7076 	Training Prec@1 36.096 	Training Prec@5 87.820 	Validation Loss 1.7673 	Validation Prec@1 35.430 	Validation Prec@5 86.080 

lr: 0.10000373098496097
TRAINING - Epoch: [7][0/391]	Time 1.315 (1.315)	Data 0.443 (0.443)	Loss 1.6749 (1.6749)	Prec@1 36.719 (36.719)	Prec@5 91.406 (91.406)
TRAINING - Epoch: [7][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 1.6139 (1.6932)	Prec@1 36.719 (37.051)	Prec@5 88.281 (88.405)
TRAINING - Epoch: [7][200/391]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 1.4548 (1.6736)	Prec@1 47.656 (37.974)	Prec@5 93.750 (88.740)
TRAINING - Epoch: [7][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 1.3675 (1.6607)	Prec@1 48.438 (38.634)	Prec@5 96.094 (88.941)
EVALUATING - Epoch: [7][0/79]	Time 0.456 (0.456)	Data 0.409 (0.409)	Loss 1.5076 (1.5076)	Prec@1 47.656 (47.656)	Prec@5 87.500 (87.500)
Time cost: 00:48	Time of Finish: 2022-03-24 02:43:24

 Epoch: 8	Training Loss 1.6551 	Training Prec@1 38.988 	Training Prec@5 88.976 	Validation Loss 1.6776 	Validation Prec@1 39.040 	Validation Prec@5 87.540 

lr: 0.1
TRAINING - Epoch: [8][0/391]	Time 1.295 (1.295)	Data 0.408 (0.408)	Loss 1.6765 (1.6765)	Prec@1 36.719 (36.719)	Prec@5 93.750 (93.750)
TRAINING - Epoch: [8][100/391]	Time 0.109 (0.126)	Data 0.000 (0.004)	Loss 1.6604 (1.6284)	Prec@1 35.938 (39.991)	Prec@5 86.719 (89.333)
TRAINING - Epoch: [8][200/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 1.4330 (1.6092)	Prec@1 47.656 (40.742)	Prec@5 92.969 (89.750)
TRAINING - Epoch: [8][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 1.4965 (1.5977)	Prec@1 44.531 (41.297)	Prec@5 91.406 (89.935)
EVALUATING - Epoch: [8][0/79]	Time 0.432 (0.432)	Data 0.404 (0.404)	Loss 1.6645 (1.6645)	Prec@1 40.625 (40.625)	Prec@5 87.500 (87.500)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:21

 Epoch: 9	Training Loss 1.5894 	Training Prec@1 41.490 	Training Prec@5 90.036 	Validation Loss 1.7465 	Validation Prec@1 38.780 	Validation Prec@5 87.970 

lr: 0.0999997512742683
TRAINING - Epoch: [9][0/391]	Time 1.326 (1.326)	Data 0.435 (0.435)	Loss 1.5790 (1.5790)	Prec@1 43.750 (43.750)	Prec@5 85.938 (85.938)
TRAINING - Epoch: [9][100/391]	Time 0.125 (0.132)	Data 0.001 (0.005)	Loss 1.5495 (1.5662)	Prec@1 45.312 (43.201)	Prec@5 91.406 (90.277)
TRAINING - Epoch: [9][200/391]	Time 0.121 (0.126)	Data 0.000 (0.003)	Loss 1.4330 (1.5475)	Prec@1 48.438 (43.719)	Prec@5 92.969 (90.613)
TRAINING - Epoch: [9][300/391]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 1.4981 (1.5347)	Prec@1 45.312 (44.155)	Prec@5 90.625 (90.949)
EVALUATING - Epoch: [9][0/79]	Time 0.476 (0.476)	Data 0.438 (0.438)	Loss 1.4726 (1.4726)	Prec@1 42.969 (42.969)	Prec@5 89.844 (89.844)
Time cost: 00:50	Time of Finish: 2022-03-24 03:18:12

 Epoch: 10	Training Loss 1.5268 	Training Prec@1 44.404 	Training Prec@5 91.176 	Validation Loss 1.6343 	Validation Prec@1 42.030 	Validation Prec@5 90.300 

lr: 0.09999900509954777
TRAINING - Epoch: [10][0/391]	Time 1.309 (1.309)	Data 0.419 (0.419)	Loss 1.6291 (1.6291)	Prec@1 39.844 (39.844)	Prec@5 93.750 (93.750)
TRAINING - Epoch: [10][100/391]	Time 0.118 (0.130)	Data 0.000 (0.005)	Loss 1.5207 (1.5079)	Prec@1 39.062 (45.336)	Prec@5 92.969 (91.406)
TRAINING - Epoch: [10][200/391]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 1.5214 (1.4889)	Prec@1 49.219 (45.810)	Prec@5 89.844 (91.760)
TRAINING - Epoch: [10][300/391]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 1.3301 (1.4672)	Prec@1 48.438 (46.358)	Prec@5 97.656 (92.226)
EVALUATING - Epoch: [10][0/79]	Time 0.427 (0.427)	Data 0.395 (0.395)	Loss 1.5924 (1.5924)	Prec@1 44.531 (44.531)	Prec@5 87.500 (87.500)
Time cost: 00:50	Time of Finish: 2022-03-24 03:07:16

 Epoch: 11	Training Loss 1.4578 	Training Prec@1 46.856 	Training Prec@5 92.288 	Validation Loss 1.7131 	Validation Prec@1 41.530 	Validation Prec@5 89.330 

lr: 0.09999776148326214
TRAINING - Epoch: [11][0/391]	Time 1.314 (1.314)	Data 0.465 (0.465)	Loss 1.5330 (1.5330)	Prec@1 46.094 (46.094)	Prec@5 90.625 (90.625)
TRAINING - Epoch: [11][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 1.5876 (1.4281)	Prec@1 37.500 (48.306)	Prec@5 92.969 (92.543)
TRAINING - Epoch: [11][200/391]	Time 0.104 (0.110)	Data 0.000 (0.003)	Loss 1.3353 (1.4178)	Prec@1 47.656 (48.535)	Prec@5 96.094 (92.615)
TRAINING - Epoch: [11][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 1.4243 (1.3986)	Prec@1 46.875 (49.320)	Prec@5 91.406 (92.870)
EVALUATING - Epoch: [11][0/79]	Time 0.429 (0.429)	Data 0.394 (0.394)	Loss 1.4595 (1.4595)	Prec@1 50.781 (50.781)	Prec@5 88.281 (88.281)
Time cost: 00:44	Time of Finish: 2022-03-24 01:32:44

 Epoch: 12	Training Loss 1.3895 	Training Prec@1 49.798 	Training Prec@5 93.016 	Validation Loss 1.5119 	Validation Prec@1 48.280 	Validation Prec@5 92.010 

lr: 0.09999602043778419
TRAINING - Epoch: [12][0/391]	Time 1.259 (1.259)	Data 0.408 (0.408)	Loss 1.5060 (1.5060)	Prec@1 48.438 (48.438)	Prec@5 88.281 (88.281)
TRAINING - Epoch: [12][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 1.3233 (1.3596)	Prec@1 54.688 (51.423)	Prec@5 92.188 (93.286)
TRAINING - Epoch: [12][200/391]	Time 0.119 (0.121)	Data 0.001 (0.002)	Loss 1.1030 (1.3478)	Prec@1 64.062 (51.947)	Prec@5 95.312 (93.346)
TRAINING - Epoch: [12][300/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 1.2262 (1.3384)	Prec@1 52.344 (52.406)	Prec@5 96.875 (93.638)
EVALUATING - Epoch: [12][0/79]	Time 0.434 (0.434)	Data 0.400 (0.400)	Loss 1.6153 (1.6153)	Prec@1 50.781 (50.781)	Prec@5 89.062 (89.062)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:19

 Epoch: 13	Training Loss 1.3279 	Training Prec@1 52.706 	Training Prec@5 93.782 	Validation Loss 1.6909 	Validation Prec@1 48.750 	Validation Prec@5 88.790 

lr: 0.0999937819804356
TRAINING - Epoch: [13][0/391]	Time 1.299 (1.299)	Data 0.440 (0.440)	Loss 1.3856 (1.3856)	Prec@1 56.250 (56.250)	Prec@5 92.188 (92.188)
TRAINING - Epoch: [13][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 1.2028 (1.2924)	Prec@1 55.469 (54.146)	Prec@5 94.531 (94.477)
TRAINING - Epoch: [13][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 1.4393 (1.2849)	Prec@1 42.969 (54.384)	Prec@5 95.312 (94.434)
TRAINING - Epoch: [13][300/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 1.2666 (1.2673)	Prec@1 57.812 (55.038)	Prec@5 94.531 (94.461)
EVALUATING - Epoch: [13][0/79]	Time 0.431 (0.431)	Data 0.399 (0.399)	Loss 1.2382 (1.2382)	Prec@1 57.031 (57.031)	Prec@5 92.969 (92.969)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:09

 Epoch: 14	Training Loss 1.2573 	Training Prec@1 55.490 	Training Prec@5 94.560 	Validation Loss 1.4558 	Validation Prec@1 50.470 	Validation Prec@5 92.430 

lr: 0.09999104613348687
TRAINING - Epoch: [14][0/391]	Time 1.296 (1.296)	Data 0.412 (0.412)	Loss 1.4327 (1.4327)	Prec@1 48.438 (48.438)	Prec@5 91.406 (91.406)
TRAINING - Epoch: [14][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 1.0795 (1.2151)	Prec@1 62.500 (56.327)	Prec@5 95.312 (94.825)
TRAINING - Epoch: [14][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 1.3148 (1.1912)	Prec@1 54.688 (57.494)	Prec@5 94.531 (95.126)
TRAINING - Epoch: [14][300/391]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 1.1737 (1.1821)	Prec@1 63.281 (57.911)	Prec@5 93.750 (95.209)
EVALUATING - Epoch: [14][0/79]	Time 0.440 (0.440)	Data 0.400 (0.400)	Loss 1.3238 (1.3238)	Prec@1 61.719 (61.719)	Prec@5 90.625 (90.625)
Time cost: 00:44	Time of Finish: 2022-03-24 01:32:53

 Epoch: 15	Training Loss 1.1763 	Training Prec@1 58.110 	Training Prec@5 95.268 	Validation Loss 1.5098 	Validation Prec@1 52.420 	Validation Prec@5 92.560 

lr: 0.09998781292415702
TRAINING - Epoch: [15][0/391]	Time 1.259 (1.259)	Data 0.417 (0.417)	Loss 1.3521 (1.3521)	Prec@1 57.031 (57.031)	Prec@5 92.969 (92.969)
TRAINING - Epoch: [15][100/391]	Time 0.115 (0.128)	Data 0.000 (0.004)	Loss 1.0455 (1.1255)	Prec@1 61.719 (60.265)	Prec@5 96.875 (95.769)
TRAINING - Epoch: [15][200/391]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 1.1478 (1.1279)	Prec@1 60.156 (60.211)	Prec@5 95.312 (95.631)
TRAINING - Epoch: [15][300/391]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 1.1763 (1.1163)	Prec@1 59.375 (60.413)	Prec@5 95.312 (95.694)
EVALUATING - Epoch: [15][0/79]	Time 0.437 (0.437)	Data 0.404 (0.404)	Loss 1.4172 (1.4172)	Prec@1 56.250 (56.250)	Prec@5 88.281 (88.281)
Time cost: 00:49	Time of Finish: 2022-03-24 03:00:14

 Epoch: 16	Training Loss 1.1151 	Training Prec@1 60.386 	Training Prec@5 95.744 	Validation Loss 1.6616 	Validation Prec@1 49.820 	Validation Prec@5 89.620 

lr: 0.09998408238461337
TRAINING - Epoch: [16][0/391]	Time 1.286 (1.286)	Data 0.420 (0.420)	Loss 0.8986 (0.8986)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [16][100/391]	Time 0.117 (0.128)	Data 0.000 (0.004)	Loss 0.9609 (1.0905)	Prec@1 67.969 (61.255)	Prec@5 96.094 (96.163)
TRAINING - Epoch: [16][200/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 1.1966 (1.0928)	Prec@1 60.156 (61.217)	Prec@5 93.750 (95.993)
TRAINING - Epoch: [16][300/391]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.9971 (1.0846)	Prec@1 63.281 (61.425)	Prec@5 95.312 (96.070)
EVALUATING - Epoch: [16][0/79]	Time 0.425 (0.425)	Data 0.388 (0.388)	Loss 1.0747 (1.0747)	Prec@1 60.156 (60.156)	Prec@5 96.094 (96.094)
Time cost: 00:49	Time of Finish: 2022-03-24 03:02:06

 Epoch: 17	Training Loss 1.0689 	Training Prec@1 62.068 	Training Prec@5 96.208 	Validation Loss 1.1022 	Validation Prec@1 61.290 	Validation Prec@5 96.620 

lr: 0.09997985455197111
TRAINING - Epoch: [17][0/391]	Time 1.290 (1.290)	Data 0.431 (0.431)	Loss 1.1405 (1.1405)	Prec@1 58.594 (58.594)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [17][100/391]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 1.0894 (1.0523)	Prec@1 66.406 (62.237)	Prec@5 96.094 (96.395)
TRAINING - Epoch: [17][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.9507 (1.0331)	Prec@1 67.969 (63.172)	Prec@5 95.312 (96.490)
TRAINING - Epoch: [17][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.9613 (1.0264)	Prec@1 62.500 (63.463)	Prec@5 99.219 (96.522)
EVALUATING - Epoch: [17][0/79]	Time 0.476 (0.476)	Data 0.444 (0.444)	Loss 1.1729 (1.1729)	Prec@1 59.375 (59.375)	Prec@5 93.750 (93.750)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:02

 Epoch: 18	Training Loss 1.0213 	Training Prec@1 63.658 	Training Prec@5 96.492 	Validation Loss 1.2653 	Validation Prec@1 58.390 	Validation Prec@5 94.540 

lr: 0.09997512946829312
TRAINING - Epoch: [18][0/391]	Time 1.327 (1.327)	Data 0.438 (0.438)	Loss 0.9706 (0.9706)	Prec@1 61.719 (61.719)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [18][100/391]	Time 0.113 (0.129)	Data 0.000 (0.005)	Loss 1.0872 (0.9871)	Prec@1 62.500 (65.292)	Prec@5 93.750 (96.612)
TRAINING - Epoch: [18][200/391]	Time 0.110 (0.121)	Data 0.000 (0.003)	Loss 0.9730 (0.9810)	Prec@1 67.188 (65.516)	Prec@5 98.438 (96.743)
TRAINING - Epoch: [18][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.8919 (0.9757)	Prec@1 67.188 (65.690)	Prec@5 97.656 (96.769)
EVALUATING - Epoch: [18][0/79]	Time 0.475 (0.475)	Data 0.437 (0.437)	Loss 1.4713 (1.4713)	Prec@1 54.688 (54.688)	Prec@5 94.531 (94.531)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:43

 Epoch: 19	Training Loss 0.9752 	Training Prec@1 65.624 	Training Prec@5 96.854 	Validation Loss 1.5832 	Validation Prec@1 51.790 	Validation Prec@5 94.330 

lr: 0.09996990718058936
TRAINING - Epoch: [19][0/391]	Time 1.271 (1.271)	Data 0.412 (0.412)	Loss 1.1504 (1.1504)	Prec@1 54.688 (54.688)	Prec@5 94.531 (94.531)
TRAINING - Epoch: [19][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.7921 (0.9563)	Prec@1 71.094 (66.313)	Prec@5 96.875 (96.860)
TRAINING - Epoch: [19][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.7485 (0.9504)	Prec@1 75.000 (66.694)	Prec@5 98.438 (97.027)
TRAINING - Epoch: [19][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.9750 (0.9524)	Prec@1 71.094 (66.622)	Prec@5 97.656 (96.981)
EVALUATING - Epoch: [19][0/79]	Time 0.438 (0.438)	Data 0.398 (0.398)	Loss 1.3135 (1.3135)	Prec@1 52.344 (52.344)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:19

 Epoch: 20	Training Loss 0.9464 	Training Prec@1 66.834 	Training Prec@5 97.048 	Validation Loss 1.2397 	Validation Prec@1 59.030 	Validation Prec@5 95.650 

lr: 0.09996418774081654
TRAINING - Epoch: [20][0/391]	Time 1.265 (1.265)	Data 0.414 (0.414)	Loss 1.0069 (1.0069)	Prec@1 63.281 (63.281)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [20][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.8906 (0.9193)	Prec@1 64.844 (67.806)	Prec@5 96.094 (97.076)
TRAINING - Epoch: [20][200/391]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.9209 (0.9169)	Prec@1 71.875 (67.806)	Prec@5 92.969 (97.100)
TRAINING - Epoch: [20][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.8076 (0.9144)	Prec@1 74.219 (67.990)	Prec@5 96.094 (97.184)
EVALUATING - Epoch: [20][0/79]	Time 0.420 (0.420)	Data 0.374 (0.374)	Loss 1.1277 (1.1277)	Prec@1 60.156 (60.156)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:03

 Epoch: 21	Training Loss 0.9082 	Training Prec@1 68.190 	Training Prec@5 97.248 	Validation Loss 1.3433 	Validation Prec@1 58.150 	Validation Prec@5 95.470 

lr: 0.09995797120587754
TRAINING - Epoch: [21][0/391]	Time 1.271 (1.271)	Data 0.425 (0.425)	Loss 0.9973 (0.9973)	Prec@1 65.625 (65.625)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [21][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.8069 (0.8808)	Prec@1 71.094 (69.346)	Prec@5 96.875 (97.509)
TRAINING - Epoch: [21][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.8450 (0.8817)	Prec@1 71.094 (69.403)	Prec@5 97.656 (97.481)
TRAINING - Epoch: [21][300/391]	Time 0.120 (0.116)	Data 0.000 (0.002)	Loss 0.8355 (0.8831)	Prec@1 65.625 (69.212)	Prec@5 99.219 (97.410)
EVALUATING - Epoch: [21][0/79]	Time 0.418 (0.418)	Data 0.374 (0.374)	Loss 0.8422 (0.8422)	Prec@1 72.656 (72.656)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:26

 Epoch: 22	Training Loss 0.8751 	Training Prec@1 69.462 	Training Prec@5 97.456 	Validation Loss 0.9694 	Validation Prec@1 67.110 	Validation Prec@5 97.200 

lr: 0.09995125763762085
TRAINING - Epoch: [22][0/391]	Time 1.357 (1.357)	Data 0.450 (0.450)	Loss 0.7849 (0.7849)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [22][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 1.0022 (0.8608)	Prec@1 64.844 (69.825)	Prec@5 94.531 (97.765)
TRAINING - Epoch: [22][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 1.0779 (0.8558)	Prec@1 60.156 (69.994)	Prec@5 99.219 (97.753)
TRAINING - Epoch: [22][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.8384 (0.8516)	Prec@1 71.094 (70.232)	Prec@5 99.219 (97.747)
EVALUATING - Epoch: [22][0/79]	Time 0.433 (0.433)	Data 0.398 (0.398)	Loss 0.8609 (0.8609)	Prec@1 69.531 (69.531)	Prec@5 96.094 (96.094)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:30

 Epoch: 23	Training Loss 0.8430 	Training Prec@1 70.478 	Training Prec@5 97.772 	Validation Loss 1.0505 	Validation Prec@1 65.720 	Validation Prec@5 96.290 

lr: 0.09994404710283995
TRAINING - Epoch: [23][0/391]	Time 1.299 (1.299)	Data 0.416 (0.416)	Loss 0.7834 (0.7834)	Prec@1 70.312 (70.312)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [23][100/391]	Time 0.120 (0.126)	Data 0.000 (0.004)	Loss 0.7982 (0.8063)	Prec@1 72.656 (71.983)	Prec@5 96.875 (97.881)
TRAINING - Epoch: [23][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.9618 (0.8077)	Prec@1 72.656 (71.976)	Prec@5 96.875 (97.921)
TRAINING - Epoch: [23][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.7041 (0.8119)	Prec@1 77.344 (71.867)	Prec@5 99.219 (97.892)
EVALUATING - Epoch: [23][0/79]	Time 0.405 (0.405)	Data 0.372 (0.372)	Loss 0.9234 (0.9234)	Prec@1 66.406 (66.406)	Prec@5 95.312 (95.312)
Time cost: 00:48	Time of Finish: 2022-03-24 02:46:41

 Epoch: 24	Training Loss 0.8089 	Training Prec@1 71.918 	Training Prec@5 97.892 	Validation Loss 0.9489 	Validation Prec@1 68.870 	Validation Prec@5 97.140 

lr: 0.09993633967327266
TRAINING - Epoch: [24][0/391]	Time 1.294 (1.294)	Data 0.413 (0.413)	Loss 0.8112 (0.8112)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [24][100/391]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.7219 (0.8106)	Prec@1 75.781 (71.527)	Prec@5 99.219 (98.120)
TRAINING - Epoch: [24][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.7968 (0.7914)	Prec@1 75.781 (72.256)	Prec@5 96.875 (98.115)
TRAINING - Epoch: [24][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.7795 (0.7897)	Prec@1 71.875 (72.270)	Prec@5 98.438 (98.105)
EVALUATING - Epoch: [24][0/79]	Time 0.423 (0.423)	Data 0.384 (0.384)	Loss 0.7023 (0.7023)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:15

 Epoch: 25	Training Loss 0.7839 	Training Prec@1 72.504 	Training Prec@5 98.086 	Validation Loss 0.8348 	Validation Prec@1 71.350 	Validation Prec@5 97.680 

lr: 0.09992813542560042
TRAINING - Epoch: [25][0/391]	Time 1.312 (1.312)	Data 0.448 (0.448)	Loss 0.6697 (0.6697)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [25][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.8148 (0.7523)	Prec@1 70.312 (73.291)	Prec@5 97.656 (98.391)
TRAINING - Epoch: [25][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.7276 (0.7565)	Prec@1 74.219 (73.585)	Prec@5 98.438 (98.243)
TRAINING - Epoch: [25][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.6670 (0.7569)	Prec@1 73.438 (73.645)	Prec@5 100.000 (98.178)
EVALUATING - Epoch: [25][0/79]	Time 0.409 (0.409)	Data 0.373 (0.373)	Loss 0.7657 (0.7657)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:44	Time of Finish: 2022-03-24 01:33:32

 Epoch: 26	Training Loss 0.7579 	Training Prec@1 73.484 	Training Prec@5 98.182 	Validation Loss 0.9094 	Validation Prec@1 69.550 	Validation Prec@5 97.640 

lr: 0.09991943444144753
TRAINING - Epoch: [26][0/391]	Time 1.326 (1.326)	Data 0.436 (0.436)	Loss 0.5869 (0.5869)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [26][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.8424 (0.7411)	Prec@1 71.875 (74.211)	Prec@5 97.656 (98.012)
TRAINING - Epoch: [26][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.5820 (0.7430)	Prec@1 77.344 (74.087)	Prec@5 100.000 (98.193)
TRAINING - Epoch: [26][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.7427 (0.7419)	Prec@1 72.656 (74.172)	Prec@5 97.656 (98.144)
EVALUATING - Epoch: [26][0/79]	Time 0.427 (0.427)	Data 0.401 (0.401)	Loss 0.6644 (0.6644)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:48

 Epoch: 27	Training Loss 0.7346 	Training Prec@1 74.396 	Training Prec@5 98.200 	Validation Loss 0.8761 	Validation Prec@1 71.210 	Validation Prec@5 97.880 

lr: 0.09991023680738036
TRAINING - Epoch: [27][0/391]	Time 1.284 (1.284)	Data 0.368 (0.368)	Loss 0.5447 (0.5447)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [27][100/391]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.7280 (0.7209)	Prec@1 74.219 (74.969)	Prec@5 97.656 (98.492)
TRAINING - Epoch: [27][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.7063 (0.7194)	Prec@1 74.219 (74.806)	Prec@5 99.219 (98.472)
TRAINING - Epoch: [27][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.6301 (0.7122)	Prec@1 77.344 (75.039)	Prec@5 97.656 (98.469)
EVALUATING - Epoch: [27][0/79]	Time 0.429 (0.429)	Data 0.385 (0.385)	Loss 0.7169 (0.7169)	Prec@1 74.219 (74.219)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:01

 Epoch: 28	Training Loss 0.7113 	Training Prec@1 75.174 	Training Prec@5 98.452 	Validation Loss 0.8327 	Validation Prec@1 71.510 	Validation Prec@5 97.570 

lr: 0.09990054261490638
TRAINING - Epoch: [28][0/391]	Time 1.359 (1.359)	Data 0.457 (0.457)	Loss 0.7013 (0.7013)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [28][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.7506 (0.6754)	Prec@1 70.312 (76.555)	Prec@5 99.219 (98.445)
TRAINING - Epoch: [28][200/391]	Time 0.120 (0.119)	Data 0.001 (0.003)	Loss 0.8056 (0.6904)	Prec@1 72.656 (75.929)	Prec@5 97.656 (98.399)
TRAINING - Epoch: [28][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.8002 (0.6906)	Prec@1 76.562 (75.924)	Prec@5 97.656 (98.422)
EVALUATING - Epoch: [28][0/79]	Time 0.423 (0.423)	Data 0.392 (0.392)	Loss 0.7749 (0.7749)	Prec@1 70.312 (70.312)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:58

 Epoch: 29	Training Loss 0.6874 	Training Prec@1 76.092 	Training Prec@5 98.466 	Validation Loss 0.8218 	Validation Prec@1 72.190 	Validation Prec@5 98.040 

lr: 0.09989035196047345
TRAINING - Epoch: [29][0/391]	Time 1.324 (1.324)	Data 0.414 (0.414)	Loss 0.7035 (0.7035)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [29][100/391]	Time 0.120 (0.128)	Data 0.000 (0.004)	Loss 0.5938 (0.6789)	Prec@1 75.781 (76.717)	Prec@5 100.000 (98.615)
TRAINING - Epoch: [29][200/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.8470 (0.6861)	Prec@1 71.094 (76.174)	Prec@5 98.438 (98.535)
TRAINING - Epoch: [29][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.6580 (0.6832)	Prec@1 74.219 (76.280)	Prec@5 96.875 (98.492)
EVALUATING - Epoch: [29][0/79]	Time 0.441 (0.441)	Data 0.408 (0.408)	Loss 1.0558 (1.0558)	Prec@1 61.719 (61.719)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:53:31

 Epoch: 30	Training Loss 0.6809 	Training Prec@1 76.406 	Training Prec@5 98.502 	Validation Loss 1.1613 	Validation Prec@1 62.460 	Validation Prec@5 96.910 

lr: 0.0998796649454687
TRAINING - Epoch: [30][0/391]	Time 1.332 (1.332)	Data 0.431 (0.431)	Loss 0.5205 (0.5205)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [30][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.5714 (0.6590)	Prec@1 77.344 (77.367)	Prec@5 99.219 (98.561)
TRAINING - Epoch: [30][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.5743 (0.6602)	Prec@1 84.375 (77.212)	Prec@5 97.656 (98.480)
TRAINING - Epoch: [30][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.7032 (0.6588)	Prec@1 73.438 (77.276)	Prec@5 97.656 (98.541)
EVALUATING - Epoch: [30][0/79]	Time 0.459 (0.459)	Data 0.423 (0.423)	Loss 0.6965 (0.6965)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:33

 Epoch: 31	Training Loss 0.6616 	Training Prec@1 77.300 	Training Prec@5 98.532 	Validation Loss 0.7780 	Validation Prec@1 73.070 	Validation Prec@5 98.080 

lr: 0.09986848167621751
TRAINING - Epoch: [31][0/391]	Time 1.289 (1.289)	Data 0.413 (0.413)	Loss 0.5967 (0.5967)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [31][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.7798 (0.6370)	Prec@1 77.344 (77.970)	Prec@5 97.656 (98.700)
TRAINING - Epoch: [31][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.5724 (0.6422)	Prec@1 82.031 (77.989)	Prec@5 97.656 (98.574)
TRAINING - Epoch: [31][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.4889 (0.6443)	Prec@1 83.594 (77.769)	Prec@5 99.219 (98.572)
EVALUATING - Epoch: [31][0/79]	Time 0.444 (0.444)	Data 0.405 (0.405)	Loss 0.6974 (0.6974)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:01

 Epoch: 32	Training Loss 0.6468 	Training Prec@1 77.646 	Training Prec@5 98.562 	Validation Loss 0.8368 	Validation Prec@1 71.770 	Validation Prec@5 97.370 

lr: 0.09985680226398258
TRAINING - Epoch: [32][0/391]	Time 1.298 (1.298)	Data 0.448 (0.448)	Loss 0.6520 (0.6520)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [32][100/391]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.7251 (0.6230)	Prec@1 77.344 (78.752)	Prec@5 96.875 (98.677)
TRAINING - Epoch: [32][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.5585 (0.6220)	Prec@1 81.250 (78.549)	Prec@5 98.438 (98.690)
TRAINING - Epoch: [32][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.8352 (0.6266)	Prec@1 71.094 (78.509)	Prec@5 96.094 (98.637)
EVALUATING - Epoch: [32][0/79]	Time 0.426 (0.426)	Data 0.391 (0.391)	Loss 0.5575 (0.5575)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:04

 Epoch: 33	Training Loss 0.6325 	Training Prec@1 78.254 	Training Prec@5 98.638 	Validation Loss 0.7718 	Validation Prec@1 74.260 	Validation Prec@5 97.980 

lr: 0.0998446268249627
TRAINING - Epoch: [33][0/391]	Time 1.311 (1.311)	Data 0.443 (0.443)	Loss 0.5695 (0.5695)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [33][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.7525 (0.6308)	Prec@1 71.875 (78.403)	Prec@5 96.094 (98.554)
TRAINING - Epoch: [33][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.6908 (0.6262)	Prec@1 76.562 (78.541)	Prec@5 99.219 (98.612)
TRAINING - Epoch: [33][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.5882 (0.6314)	Prec@1 77.344 (78.369)	Prec@5 98.438 (98.588)
EVALUATING - Epoch: [33][0/79]	Time 0.440 (0.440)	Data 0.411 (0.411)	Loss 0.8946 (0.8946)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:17:31

 Epoch: 34	Training Loss 0.6284 	Training Prec@1 78.470 	Training Prec@5 98.602 	Validation Loss 0.7949 	Validation Prec@1 73.780 	Validation Prec@5 98.270 

lr: 0.0998319554802917
TRAINING - Epoch: [34][0/391]	Time 1.314 (1.314)	Data 0.414 (0.414)	Loss 0.5743 (0.5743)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [34][100/391]	Time 0.112 (0.127)	Data 0.000 (0.005)	Loss 0.6176 (0.6064)	Prec@1 82.812 (78.906)	Prec@5 99.219 (98.770)
TRAINING - Epoch: [34][200/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.5842 (0.6133)	Prec@1 77.344 (78.817)	Prec@5 99.219 (98.741)
TRAINING - Epoch: [34][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.6077 (0.6150)	Prec@1 81.250 (78.789)	Prec@5 97.656 (98.692)
EVALUATING - Epoch: [34][0/79]	Time 0.420 (0.420)	Data 0.386 (0.386)	Loss 1.0478 (1.0478)	Prec@1 68.750 (68.750)	Prec@5 94.531 (94.531)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:16

 Epoch: 35	Training Loss 0.6153 	Training Prec@1 78.834 	Training Prec@5 98.700 	Validation Loss 1.1597 	Validation Prec@1 66.230 	Validation Prec@5 94.460 

lr: 0.09981878835603715
TRAINING - Epoch: [35][0/391]	Time 1.289 (1.289)	Data 0.403 (0.403)	Loss 0.4333 (0.4333)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [35][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.5441 (0.5950)	Prec@1 82.812 (79.858)	Prec@5 98.438 (98.801)
TRAINING - Epoch: [35][200/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.7494 (0.5908)	Prec@1 74.219 (79.948)	Prec@5 99.219 (98.877)
TRAINING - Epoch: [35][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.5411 (0.5932)	Prec@1 82.812 (79.729)	Prec@5 99.219 (98.819)
EVALUATING - Epoch: [35][0/79]	Time 0.431 (0.431)	Data 0.402 (0.402)	Loss 0.8073 (0.8073)	Prec@1 74.219 (74.219)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:19

 Epoch: 36	Training Loss 0.5938 	Training Prec@1 79.672 	Training Prec@5 98.832 	Validation Loss 0.8472 	Validation Prec@1 72.950 	Validation Prec@5 97.020 

lr: 0.09980512558319914
TRAINING - Epoch: [36][0/391]	Time 1.307 (1.307)	Data 0.436 (0.436)	Loss 0.5110 (0.5110)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [36][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.4843 (0.5807)	Prec@1 84.375 (80.415)	Prec@5 98.438 (98.948)
TRAINING - Epoch: [36][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.5710 (0.5830)	Prec@1 78.125 (80.290)	Prec@5 100.000 (98.853)
TRAINING - Epoch: [36][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.6457 (0.5890)	Prec@1 78.906 (80.035)	Prec@5 96.875 (98.801)
EVALUATING - Epoch: [36][0/79]	Time 0.417 (0.417)	Data 0.389 (0.389)	Loss 0.7636 (0.7636)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:15:28

 Epoch: 37	Training Loss 0.5897 	Training Prec@1 79.996 	Training Prec@5 98.790 	Validation Loss 0.9424 	Validation Prec@1 70.440 	Validation Prec@5 97.880 

lr: 0.09979096729770899
TRAINING - Epoch: [37][0/391]	Time 1.293 (1.293)	Data 0.412 (0.412)	Loss 0.6236 (0.6236)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [37][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.4878 (0.5836)	Prec@1 84.375 (79.927)	Prec@5 99.219 (98.940)
TRAINING - Epoch: [37][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.4337 (0.5838)	Prec@1 80.469 (80.030)	Prec@5 100.000 (98.912)
TRAINING - Epoch: [37][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.5598 (0.5805)	Prec@1 78.906 (79.952)	Prec@5 99.219 (98.900)
EVALUATING - Epoch: [37][0/79]	Time 0.421 (0.421)	Data 0.384 (0.384)	Loss 1.0036 (1.0036)	Prec@1 70.312 (70.312)	Prec@5 96.094 (96.094)
Time cost: 00:44	Time of Finish: 2022-03-24 01:34:12

 Epoch: 38	Training Loss 0.5826 	Training Prec@1 79.990 	Training Prec@5 98.912 	Validation Loss 1.0547 	Validation Prec@1 68.450 	Validation Prec@5 95.210 

lr: 0.09977631364042792
TRAINING - Epoch: [38][0/391]	Time 1.279 (1.279)	Data 0.430 (0.430)	Loss 0.6626 (0.6626)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [38][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.4540 (0.5675)	Prec@1 82.812 (80.028)	Prec@5 100.000 (98.956)
TRAINING - Epoch: [38][200/391]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.7007 (0.5600)	Prec@1 78.125 (80.523)	Prec@5 98.438 (98.939)
TRAINING - Epoch: [38][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.5976 (0.5670)	Prec@1 77.344 (80.326)	Prec@5 100.000 (98.967)
EVALUATING - Epoch: [38][0/79]	Time 0.472 (0.472)	Data 0.429 (0.429)	Loss 1.0141 (1.0141)	Prec@1 67.969 (67.969)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:53

 Epoch: 39	Training Loss 0.5695 	Training Prec@1 80.354 	Training Prec@5 98.894 	Validation Loss 1.2287 	Validation Prec@1 62.580 	Validation Prec@5 96.690 

lr: 0.09976116475714561
TRAINING - Epoch: [39][0/391]	Time 1.279 (1.279)	Data 0.424 (0.424)	Loss 0.5191 (0.5191)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [39][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.6879 (0.5650)	Prec@1 76.562 (80.453)	Prec@5 98.438 (98.925)
TRAINING - Epoch: [39][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.4890 (0.5709)	Prec@1 80.469 (80.146)	Prec@5 100.000 (98.931)
TRAINING - Epoch: [39][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.5597 (0.5756)	Prec@1 82.812 (80.069)	Prec@5 99.219 (98.892)
EVALUATING - Epoch: [39][0/79]	Time 0.413 (0.413)	Data 0.368 (0.368)	Loss 0.9315 (0.9315)	Prec@1 69.531 (69.531)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:15:24

 Epoch: 40	Training Loss 0.5744 	Training Prec@1 80.196 	Training Prec@5 98.884 	Validation Loss 0.8805 	Validation Prec@1 70.830 	Validation Prec@5 97.330 

lr: 0.0997455207985787
TRAINING - Epoch: [40][0/391]	Time 1.269 (1.269)	Data 0.416 (0.416)	Loss 0.4869 (0.4869)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [40][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.6441 (0.5529)	Prec@1 72.656 (80.786)	Prec@5 99.219 (99.025)
TRAINING - Epoch: [40][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.6733 (0.5529)	Prec@1 78.125 (81.009)	Prec@5 100.000 (98.947)
TRAINING - Epoch: [40][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4987 (0.5599)	Prec@1 82.812 (80.708)	Prec@5 99.219 (98.951)
EVALUATING - Epoch: [40][0/79]	Time 0.441 (0.441)	Data 0.400 (0.400)	Loss 0.7258 (0.7258)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:18

 Epoch: 41	Training Loss 0.5598 	Training Prec@1 80.744 	Training Prec@5 98.960 	Validation Loss 0.8294 	Validation Prec@1 72.100 	Validation Prec@5 97.950 

lr: 0.09972938192036941
TRAINING - Epoch: [41][0/391]	Time 1.547 (1.547)	Data 0.412 (0.412)	Loss 0.6341 (0.6341)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [41][100/391]	Time 0.122 (0.132)	Data 0.000 (0.004)	Loss 0.5355 (0.5534)	Prec@1 82.812 (80.770)	Prec@5 98.438 (98.979)
TRAINING - Epoch: [41][200/391]	Time 0.117 (0.125)	Data 0.000 (0.002)	Loss 0.5154 (0.5504)	Prec@1 83.594 (80.877)	Prec@5 99.219 (98.970)
TRAINING - Epoch: [41][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.4851 (0.5515)	Prec@1 85.156 (80.918)	Prec@5 99.219 (98.993)
EVALUATING - Epoch: [41][0/79]	Time 0.441 (0.441)	Data 0.400 (0.400)	Loss 0.6723 (0.6723)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 03:02:58

 Epoch: 42	Training Loss 0.5480 	Training Prec@1 81.056 	Training Prec@5 98.968 	Validation Loss 0.7302 	Validation Prec@1 76.060 	Validation Prec@5 98.800 

lr: 0.09971274828308392
TRAINING - Epoch: [42][0/391]	Time 1.294 (1.294)	Data 0.452 (0.452)	Loss 0.7317 (0.7317)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [42][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.5664 (0.5344)	Prec@1 79.688 (81.791)	Prec@5 100.000 (98.948)
TRAINING - Epoch: [42][200/391]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.5397 (0.5378)	Prec@1 79.688 (81.530)	Prec@5 98.438 (98.974)
TRAINING - Epoch: [42][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.4774 (0.5408)	Prec@1 82.031 (81.380)	Prec@5 100.000 (98.983)
EVALUATING - Epoch: [42][0/79]	Time 0.430 (0.430)	Data 0.382 (0.382)	Loss 1.1054 (1.1054)	Prec@1 64.844 (64.844)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:16:53

 Epoch: 43	Training Loss 0.5469 	Training Prec@1 81.176 	Training Prec@5 98.988 	Validation Loss 1.2625 	Validation Prec@1 62.100 	Validation Prec@5 96.480 

lr: 0.09969562005221076
TRAINING - Epoch: [43][0/391]	Time 1.295 (1.295)	Data 0.444 (0.444)	Loss 0.5792 (0.5792)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [43][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.4682 (0.5233)	Prec@1 83.594 (81.776)	Prec@5 99.219 (99.072)
TRAINING - Epoch: [43][200/391]	Time 0.111 (0.117)	Data 0.000 (0.003)	Loss 0.5239 (0.5357)	Prec@1 84.375 (81.604)	Prec@5 97.656 (99.036)
TRAINING - Epoch: [43][300/391]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.5599 (0.5414)	Prec@1 75.781 (81.408)	Prec@5 99.219 (99.029)
EVALUATING - Epoch: [43][0/79]	Time 0.461 (0.461)	Data 0.433 (0.433)	Loss 0.6372 (0.6372)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:32

 Epoch: 44	Training Loss 0.5439 	Training Prec@1 81.330 	Training Prec@5 98.994 	Validation Loss 0.7240 	Validation Prec@1 76.510 	Validation Prec@5 98.580 

lr: 0.09967799739815922
TRAINING - Epoch: [44][0/391]	Time 1.256 (1.256)	Data 0.413 (0.413)	Loss 0.5478 (0.5478)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [44][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.4196 (0.5400)	Prec@1 82.812 (81.335)	Prec@5 99.219 (99.041)
TRAINING - Epoch: [44][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.5941 (0.5354)	Prec@1 81.250 (81.444)	Prec@5 97.656 (99.087)
TRAINING - Epoch: [44][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.5592 (0.5394)	Prec@1 81.250 (81.380)	Prec@5 98.438 (99.050)
EVALUATING - Epoch: [44][0/79]	Time 0.444 (0.444)	Data 0.409 (0.409)	Loss 1.2348 (1.2348)	Prec@1 67.188 (67.188)	Prec@5 93.750 (93.750)
Time cost: 00:46	Time of Finish: 2022-03-24 02:14:45

 Epoch: 45	Training Loss 0.5379 	Training Prec@1 81.468 	Training Prec@5 99.032 	Validation Loss 1.1020 	Validation Prec@1 67.780 	Validation Prec@5 96.350 

lr: 0.09965988049625758
TRAINING - Epoch: [45][0/391]	Time 1.251 (1.251)	Data 0.411 (0.411)	Loss 0.4206 (0.4206)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [45][100/391]	Time 0.118 (0.125)	Data 0.000 (0.004)	Loss 0.4981 (0.5158)	Prec@1 83.594 (82.170)	Prec@5 100.000 (99.149)
TRAINING - Epoch: [45][200/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.5282 (0.5264)	Prec@1 81.250 (81.837)	Prec@5 100.000 (99.075)
TRAINING - Epoch: [45][300/391]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.8114 (0.5298)	Prec@1 75.000 (81.772)	Prec@5 98.438 (99.021)
EVALUATING - Epoch: [45][0/79]	Time 0.413 (0.413)	Data 0.386 (0.386)	Loss 0.8841 (0.8841)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:54

 Epoch: 46	Training Loss 0.5349 	Training Prec@1 81.638 	Training Prec@5 99.032 	Validation Loss 0.9342 	Validation Prec@1 70.990 	Validation Prec@5 97.130 

lr: 0.09964126952675145
TRAINING - Epoch: [46][0/391]	Time 1.279 (1.279)	Data 0.414 (0.414)	Loss 0.4599 (0.4599)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [46][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.4875 (0.5302)	Prec@1 82.812 (81.691)	Prec@5 99.219 (99.010)
TRAINING - Epoch: [46][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.4507 (0.5315)	Prec@1 85.938 (81.821)	Prec@5 99.219 (99.017)
TRAINING - Epoch: [46][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3989 (0.5314)	Prec@1 89.062 (81.772)	Prec@5 99.219 (99.040)
EVALUATING - Epoch: [46][0/79]	Time 0.441 (0.441)	Data 0.404 (0.404)	Loss 0.6256 (0.6256)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:15:53

 Epoch: 47	Training Loss 0.5278 	Training Prec@1 81.834 	Training Prec@5 99.050 	Validation Loss 0.7501 	Validation Prec@1 75.360 	Validation Prec@5 98.390 

lr: 0.0996221646748019
TRAINING - Epoch: [47][0/391]	Time 1.263 (1.263)	Data 0.413 (0.413)	Loss 0.4191 (0.4191)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [47][100/391]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.5041 (0.5276)	Prec@1 82.812 (82.093)	Prec@5 100.000 (99.056)
TRAINING - Epoch: [47][200/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.5197 (0.5283)	Prec@1 82.812 (81.938)	Prec@5 100.000 (99.114)
TRAINING - Epoch: [47][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.6710 (0.5258)	Prec@1 80.469 (82.125)	Prec@5 98.438 (99.094)
EVALUATING - Epoch: [47][0/79]	Time 0.433 (0.433)	Data 0.395 (0.395)	Loss 0.9510 (0.9510)	Prec@1 69.531 (69.531)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:12:28

 Epoch: 48	Training Loss 0.5243 	Training Prec@1 82.208 	Training Prec@5 99.050 	Validation Loss 1.0204 	Validation Prec@1 68.510 	Validation Prec@5 98.090 

lr: 0.09960256613048364
TRAINING - Epoch: [48][0/391]	Time 1.266 (1.266)	Data 0.416 (0.416)	Loss 0.4160 (0.4160)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [48][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.5605 (0.5110)	Prec@1 82.031 (82.310)	Prec@5 98.438 (99.134)
TRAINING - Epoch: [48][200/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.4436 (0.5059)	Prec@1 86.719 (82.505)	Prec@5 97.656 (99.153)
TRAINING - Epoch: [48][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.5672 (0.5068)	Prec@1 79.688 (82.493)	Prec@5 99.219 (99.175)
EVALUATING - Epoch: [48][0/79]	Time 0.424 (0.424)	Data 0.380 (0.380)	Loss 0.8029 (0.8029)	Prec@1 67.188 (67.188)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:58

 Epoch: 49	Training Loss 0.5147 	Training Prec@1 82.186 	Training Prec@5 99.130 	Validation Loss 0.8653 	Validation Prec@1 71.380 	Validation Prec@5 97.890 

lr: 0.0995824740887832
TRAINING - Epoch: [49][0/391]	Time 1.318 (1.318)	Data 0.427 (0.427)	Loss 0.5046 (0.5046)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [49][100/391]	Time 0.120 (0.125)	Data 0.000 (0.005)	Loss 0.5096 (0.5268)	Prec@1 82.812 (81.606)	Prec@5 100.000 (99.226)
TRAINING - Epoch: [49][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.4089 (0.5141)	Prec@1 88.281 (82.012)	Prec@5 100.000 (99.207)
TRAINING - Epoch: [49][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.6375 (0.5141)	Prec@1 76.562 (82.010)	Prec@5 99.219 (99.151)
EVALUATING - Epoch: [49][0/79]	Time 0.410 (0.410)	Data 0.383 (0.383)	Loss 0.6427 (0.6427)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:00

 Epoch: 50	Training Loss 0.5164 	Training Prec@1 81.920 	Training Prec@5 99.152 	Validation Loss 0.7812 	Validation Prec@1 73.530 	Validation Prec@5 98.070 

lr: 0.09956188874959684
TRAINING - Epoch: [50][0/391]	Time 1.296 (1.296)	Data 0.459 (0.459)	Loss 0.6091 (0.6091)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [50][100/391]	Time 0.105 (0.116)	Data 0.000 (0.005)	Loss 0.5256 (0.5025)	Prec@1 82.031 (82.921)	Prec@5 99.219 (99.056)
TRAINING - Epoch: [50][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.5276 (0.5057)	Prec@1 81.250 (82.781)	Prec@5 99.219 (99.083)
TRAINING - Epoch: [50][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.4953 (0.5085)	Prec@1 82.031 (82.553)	Prec@5 100.000 (99.115)
EVALUATING - Epoch: [50][0/79]	Time 0.447 (0.447)	Data 0.408 (0.408)	Loss 0.5863 (0.5863)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:36:07

 Epoch: 51	Training Loss 0.5119 	Training Prec@1 82.488 	Training Prec@5 99.080 	Validation Loss 0.6957 	Validation Prec@1 77.060 	Validation Prec@5 98.690 

lr: 0.09954081031772875
TRAINING - Epoch: [51][0/391]	Time 1.304 (1.304)	Data 0.447 (0.447)	Loss 0.3846 (0.3846)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [51][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.3823 (0.4924)	Prec@1 85.938 (83.137)	Prec@5 100.000 (99.157)
TRAINING - Epoch: [51][200/391]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.3661 (0.5000)	Prec@1 87.500 (82.871)	Prec@5 100.000 (99.164)
TRAINING - Epoch: [51][300/391]	Time 0.125 (0.119)	Data 0.000 (0.002)	Loss 0.4545 (0.5040)	Prec@1 84.375 (82.802)	Prec@5 100.000 (99.172)
EVALUATING - Epoch: [51][0/79]	Time 0.415 (0.415)	Data 0.379 (0.379)	Loss 0.7921 (0.7921)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:50

 Epoch: 52	Training Loss 0.5053 	Training Prec@1 82.680 	Training Prec@5 99.144 	Validation Loss 0.8609 	Validation Prec@1 72.930 	Validation Prec@5 98.100 

lr: 0.09951923900288887
TRAINING - Epoch: [52][0/391]	Time 1.322 (1.322)	Data 0.427 (0.427)	Loss 0.5853 (0.5853)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [52][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.4914 (0.5039)	Prec@1 85.156 (82.836)	Prec@5 98.438 (99.002)
TRAINING - Epoch: [52][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.4505 (0.5093)	Prec@1 85.938 (82.412)	Prec@5 98.438 (99.067)
TRAINING - Epoch: [52][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.5698 (0.5072)	Prec@1 82.031 (82.561)	Prec@5 97.656 (99.068)
EVALUATING - Epoch: [52][0/79]	Time 0.431 (0.431)	Data 0.397 (0.397)	Loss 0.5775 (0.5775)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:19

 Epoch: 53	Training Loss 0.5073 	Training Prec@1 82.544 	Training Prec@5 99.074 	Validation Loss 0.6337 	Validation Prec@1 78.890 	Validation Prec@5 98.760 

lr: 0.09949717501969077
TRAINING - Epoch: [53][0/391]	Time 1.362 (1.362)	Data 0.445 (0.445)	Loss 0.4817 (0.4817)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [53][100/391]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.4977 (0.5016)	Prec@1 79.688 (82.921)	Prec@5 100.000 (99.033)
TRAINING - Epoch: [53][200/391]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.4996 (0.4921)	Prec@1 85.156 (83.057)	Prec@5 100.000 (99.098)
TRAINING - Epoch: [53][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.5140 (0.4901)	Prec@1 81.250 (83.165)	Prec@5 99.219 (99.115)
EVALUATING - Epoch: [53][0/79]	Time 0.416 (0.416)	Data 0.365 (0.365)	Loss 0.7027 (0.7027)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:46

 Epoch: 54	Training Loss 0.4963 	Training Prec@1 82.984 	Training Prec@5 99.128 	Validation Loss 0.7883 	Validation Prec@1 74.650 	Validation Prec@5 97.580 

lr: 0.09947461858764975
TRAINING - Epoch: [54][0/391]	Time 1.369 (1.369)	Data 0.437 (0.437)	Loss 0.4782 (0.4782)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [54][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.5163 (0.4837)	Prec@1 83.594 (83.161)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [54][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.5105 (0.4988)	Prec@1 85.156 (82.987)	Prec@5 97.656 (99.203)
TRAINING - Epoch: [54][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3973 (0.4954)	Prec@1 85.156 (82.989)	Prec@5 99.219 (99.198)
EVALUATING - Epoch: [54][0/79]	Time 0.448 (0.448)	Data 0.405 (0.405)	Loss 1.1444 (1.1444)	Prec@1 66.406 (66.406)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:01

 Epoch: 55	Training Loss 0.4990 	Training Prec@1 82.860 	Training Prec@5 99.172 	Validation Loss 1.2045 	Validation Prec@1 64.600 	Validation Prec@5 96.190 

lr: 0.09945156993118039
TRAINING - Epoch: [55][0/391]	Time 1.329 (1.329)	Data 0.439 (0.439)	Loss 0.5030 (0.5030)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [55][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.5329 (0.4705)	Prec@1 82.031 (83.950)	Prec@5 100.000 (99.203)
TRAINING - Epoch: [55][200/391]	Time 0.110 (0.119)	Data 0.000 (0.003)	Loss 0.5015 (0.4858)	Prec@1 82.812 (83.392)	Prec@5 100.000 (99.141)
TRAINING - Epoch: [55][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.6065 (0.4914)	Prec@1 78.906 (83.197)	Prec@5 100.000 (99.188)
EVALUATING - Epoch: [55][0/79]	Time 0.515 (0.515)	Data 0.482 (0.482)	Loss 0.4752 (0.4752)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:09

 Epoch: 56	Training Loss 0.4914 	Training Prec@1 83.178 	Training Prec@5 99.210 	Validation Loss 0.6215 	Validation Prec@1 79.550 	Validation Prec@5 98.510 

lr: 0.0994280292795944
TRAINING - Epoch: [56][0/391]	Time 1.314 (1.314)	Data 0.417 (0.417)	Loss 0.5873 (0.5873)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [56][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.4093 (0.4905)	Prec@1 83.594 (83.671)	Prec@5 100.000 (99.080)
TRAINING - Epoch: [56][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4849 (0.4862)	Prec@1 85.938 (83.399)	Prec@5 99.219 (99.106)
TRAINING - Epoch: [56][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.4824 (0.4886)	Prec@1 85.156 (83.269)	Prec@5 97.656 (99.102)
EVALUATING - Epoch: [56][0/79]	Time 0.438 (0.438)	Data 0.406 (0.406)	Loss 0.7211 (0.7211)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:20

 Epoch: 57	Training Loss 0.4883 	Training Prec@1 83.256 	Training Prec@5 99.124 	Validation Loss 0.7678 	Validation Prec@1 74.320 	Validation Prec@5 98.480 

lr: 0.09940399686709847
TRAINING - Epoch: [57][0/391]	Time 1.313 (1.313)	Data 0.420 (0.420)	Loss 0.3942 (0.3942)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [57][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.4028 (0.4852)	Prec@1 87.500 (83.540)	Prec@5 100.000 (99.242)
TRAINING - Epoch: [57][200/391]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.4228 (0.4830)	Prec@1 88.281 (83.489)	Prec@5 100.000 (99.258)
TRAINING - Epoch: [57][300/391]	Time 0.126 (0.120)	Data 0.001 (0.002)	Loss 0.6363 (0.4811)	Prec@1 79.688 (83.570)	Prec@5 97.656 (99.247)
EVALUATING - Epoch: [57][0/79]	Time 0.437 (0.437)	Data 0.409 (0.409)	Loss 0.7021 (0.7021)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 03:00:28

 Epoch: 58	Training Loss 0.4878 	Training Prec@1 83.394 	Training Prec@5 99.184 	Validation Loss 0.7790 	Validation Prec@1 74.580 	Validation Prec@5 97.970 

lr: 0.09937947293279176
TRAINING - Epoch: [58][0/391]	Time 1.331 (1.331)	Data 0.427 (0.427)	Loss 0.4407 (0.4407)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [58][100/391]	Time 0.107 (0.126)	Data 0.000 (0.005)	Loss 0.4905 (0.4808)	Prec@1 85.156 (83.555)	Prec@5 100.000 (99.350)
TRAINING - Epoch: [58][200/391]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.4473 (0.4844)	Prec@1 83.594 (83.353)	Prec@5 99.219 (99.250)
TRAINING - Epoch: [58][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.5372 (0.4887)	Prec@1 82.812 (83.223)	Prec@5 99.219 (99.211)
EVALUATING - Epoch: [58][0/79]	Time 0.437 (0.437)	Data 0.410 (0.410)	Loss 0.7345 (0.7345)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:03

 Epoch: 59	Training Loss 0.4871 	Training Prec@1 83.338 	Training Prec@5 99.220 	Validation Loss 0.6607 	Validation Prec@1 78.100 	Validation Prec@5 98.590 

lr: 0.09935445772066359
TRAINING - Epoch: [59][0/391]	Time 1.343 (1.343)	Data 0.416 (0.416)	Loss 0.3829 (0.3829)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [59][100/391]	Time 0.112 (0.127)	Data 0.000 (0.005)	Loss 0.4182 (0.4715)	Prec@1 88.281 (83.872)	Prec@5 100.000 (99.312)
TRAINING - Epoch: [59][200/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.6561 (0.4740)	Prec@1 78.906 (83.738)	Prec@5 99.219 (99.211)
TRAINING - Epoch: [59][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3836 (0.4784)	Prec@1 83.594 (83.477)	Prec@5 99.219 (99.136)
EVALUATING - Epoch: [59][0/79]	Time 0.455 (0.455)	Data 0.417 (0.417)	Loss 0.7194 (0.7194)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:35

 Epoch: 60	Training Loss 0.4838 	Training Prec@1 83.348 	Training Prec@5 99.116 	Validation Loss 0.8312 	Validation Prec@1 72.430 	Validation Prec@5 98.320 

lr: 0.09932895147959105
TRAINING - Epoch: [60][0/391]	Time 1.340 (1.340)	Data 0.430 (0.430)	Loss 0.5352 (0.5352)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [60][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.4190 (0.4862)	Prec@1 85.156 (83.161)	Prec@5 98.438 (99.281)
TRAINING - Epoch: [60][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.6456 (0.4830)	Prec@1 73.438 (83.392)	Prec@5 100.000 (99.238)
TRAINING - Epoch: [60][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.4089 (0.4821)	Prec@1 88.281 (83.490)	Prec@5 100.000 (99.250)
EVALUATING - Epoch: [60][0/79]	Time 0.443 (0.443)	Data 0.407 (0.407)	Loss 0.6428 (0.6428)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:14

 Epoch: 61	Training Loss 0.4846 	Training Prec@1 83.422 	Training Prec@5 99.224 	Validation Loss 0.6920 	Validation Prec@1 77.320 	Validation Prec@5 98.380 

lr: 0.09930295446333648
TRAINING - Epoch: [61][0/391]	Time 1.346 (1.346)	Data 0.428 (0.428)	Loss 0.5711 (0.5711)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [61][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.4158 (0.4672)	Prec@1 85.938 (83.540)	Prec@5 100.000 (99.257)
TRAINING - Epoch: [61][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.5676 (0.4741)	Prec@1 83.594 (83.570)	Prec@5 100.000 (99.304)
TRAINING - Epoch: [61][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3805 (0.4801)	Prec@1 87.500 (83.373)	Prec@5 100.000 (99.229)
EVALUATING - Epoch: [61][0/79]	Time 0.436 (0.436)	Data 0.397 (0.397)	Loss 0.9440 (0.9440)	Prec@1 68.750 (68.750)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:16

 Epoch: 62	Training Loss 0.4807 	Training Prec@1 83.350 	Training Prec@5 99.246 	Validation Loss 1.0614 	Validation Prec@1 69.290 	Validation Prec@5 94.270 

lr: 0.09927646693054495
TRAINING - Epoch: [62][0/391]	Time 1.340 (1.340)	Data 0.424 (0.424)	Loss 0.5134 (0.5134)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [62][100/391]	Time 0.116 (0.129)	Data 0.000 (0.005)	Loss 0.4402 (0.4724)	Prec@1 84.375 (83.826)	Prec@5 99.219 (99.288)
TRAINING - Epoch: [62][200/391]	Time 0.113 (0.123)	Data 0.000 (0.002)	Loss 0.4476 (0.4802)	Prec@1 85.156 (83.392)	Prec@5 99.219 (99.180)
TRAINING - Epoch: [62][300/391]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.4840 (0.4834)	Prec@1 83.594 (83.306)	Prec@5 98.438 (99.133)
EVALUATING - Epoch: [62][0/79]	Time 0.438 (0.438)	Data 0.401 (0.401)	Loss 0.7839 (0.7839)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:49	Time of Finish: 2022-03-24 02:55:12

 Epoch: 63	Training Loss 0.4831 	Training Prec@1 83.228 	Training Prec@5 99.154 	Validation Loss 0.7219 	Validation Prec@1 75.840 	Validation Prec@5 98.580 

lr: 0.09924948914474171
TRAINING - Epoch: [63][0/391]	Time 1.357 (1.357)	Data 0.434 (0.434)	Loss 0.4693 (0.4693)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [63][100/391]	Time 0.119 (0.131)	Data 0.000 (0.005)	Loss 0.3533 (0.4604)	Prec@1 85.938 (83.772)	Prec@5 100.000 (99.366)
TRAINING - Epoch: [63][200/391]	Time 0.107 (0.123)	Data 0.000 (0.003)	Loss 0.4443 (0.4667)	Prec@1 82.812 (83.730)	Prec@5 99.219 (99.296)
TRAINING - Epoch: [63][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4850 (0.4682)	Prec@1 76.562 (83.687)	Prec@5 100.000 (99.297)
EVALUATING - Epoch: [63][0/79]	Time 0.415 (0.415)	Data 0.372 (0.372)	Loss 0.8292 (0.8292)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:43

 Epoch: 64	Training Loss 0.4767 	Training Prec@1 83.524 	Training Prec@5 99.224 	Validation Loss 0.7493 	Validation Prec@1 76.660 	Validation Prec@5 97.100 

lr: 0.09922202137432953
TRAINING - Epoch: [64][0/391]	Time 1.311 (1.311)	Data 0.439 (0.439)	Loss 0.4391 (0.4391)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [64][100/391]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.4376 (0.4591)	Prec@1 86.719 (84.406)	Prec@5 100.000 (99.265)
TRAINING - Epoch: [64][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.5045 (0.4573)	Prec@1 81.250 (84.305)	Prec@5 98.438 (99.304)
TRAINING - Epoch: [64][300/391]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.4106 (0.4667)	Prec@1 85.156 (83.978)	Prec@5 100.000 (99.299)
EVALUATING - Epoch: [64][0/79]	Time 0.416 (0.416)	Data 0.375 (0.375)	Loss 0.6575 (0.6575)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:49:12

 Epoch: 65	Training Loss 0.4698 	Training Prec@1 83.840 	Training Prec@5 99.288 	Validation Loss 0.8329 	Validation Prec@1 73.340 	Validation Prec@5 98.240 

lr: 0.09919406389258606
TRAINING - Epoch: [65][0/391]	Time 1.620 (1.620)	Data 0.454 (0.454)	Loss 0.3782 (0.3782)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [65][100/391]	Time 0.112 (0.133)	Data 0.000 (0.005)	Loss 0.5632 (0.4750)	Prec@1 78.906 (83.710)	Prec@5 98.438 (99.188)
TRAINING - Epoch: [65][200/391]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.4569 (0.4725)	Prec@1 85.156 (83.811)	Prec@5 99.219 (99.242)
TRAINING - Epoch: [65][300/391]	Time 0.110 (0.123)	Data 0.000 (0.002)	Loss 0.6320 (0.4695)	Prec@1 79.688 (83.887)	Prec@5 98.438 (99.284)
EVALUATING - Epoch: [65][0/79]	Time 0.447 (0.447)	Data 0.408 (0.408)	Loss 1.2376 (1.2376)	Prec@1 65.625 (65.625)	Prec@5 95.312 (95.312)
Time cost: 00:50	Time of Finish: 2022-03-24 03:04:45

 Epoch: 66	Training Loss 0.4692 	Training Prec@1 83.822 	Training Prec@5 99.270 	Validation Loss 1.2441 	Validation Prec@1 65.300 	Validation Prec@5 94.800 

lr: 0.09916561697766112
TRAINING - Epoch: [66][0/391]	Time 1.626 (1.626)	Data 0.426 (0.426)	Loss 0.3702 (0.3702)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [66][100/391]	Time 0.118 (0.132)	Data 0.000 (0.005)	Loss 0.3440 (0.4691)	Prec@1 89.062 (83.648)	Prec@5 100.000 (99.226)
TRAINING - Epoch: [66][200/391]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.4405 (0.4768)	Prec@1 82.812 (83.329)	Prec@5 100.000 (99.230)
TRAINING - Epoch: [66][300/391]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.5404 (0.4765)	Prec@1 78.906 (83.550)	Prec@5 99.219 (99.206)
EVALUATING - Epoch: [66][0/79]	Time 0.450 (0.450)	Data 0.410 (0.410)	Loss 1.4420 (1.4420)	Prec@1 65.625 (65.625)	Prec@5 91.406 (91.406)
Time cost: 00:50	Time of Finish: 2022-03-24 03:06:52

 Epoch: 67	Training Loss 0.4768 	Training Prec@1 83.600 	Training Prec@5 99.212 	Validation Loss 1.4505 	Validation Prec@1 62.660 	Validation Prec@5 91.560 

lr: 0.09913668091257388
TRAINING - Epoch: [67][0/391]	Time 1.308 (1.308)	Data 0.424 (0.424)	Loss 0.4979 (0.4979)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [67][100/391]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.3784 (0.4719)	Prec@1 87.500 (83.694)	Prec@5 100.000 (99.203)
TRAINING - Epoch: [67][200/391]	Time 0.109 (0.121)	Data 0.000 (0.003)	Loss 0.4261 (0.4684)	Prec@1 83.594 (83.909)	Prec@5 99.219 (99.215)
TRAINING - Epoch: [67][300/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.5600 (0.4680)	Prec@1 82.031 (83.884)	Prec@5 100.000 (99.214)
EVALUATING - Epoch: [67][0/79]	Time 0.419 (0.419)	Data 0.386 (0.386)	Loss 0.6633 (0.6633)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:53

 Epoch: 68	Training Loss 0.4712 	Training Prec@1 83.790 	Training Prec@5 99.226 	Validation Loss 0.7614 	Validation Prec@1 74.820 	Validation Prec@5 98.050 

lr: 0.09910725598521011
TRAINING - Epoch: [68][0/391]	Time 1.387 (1.387)	Data 0.461 (0.461)	Loss 0.5125 (0.5125)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [68][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.4315 (0.4530)	Prec@1 88.281 (84.847)	Prec@5 99.219 (99.234)
TRAINING - Epoch: [68][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.4313 (0.4580)	Prec@1 83.594 (84.554)	Prec@5 100.000 (99.242)
TRAINING - Epoch: [68][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.4269 (0.4645)	Prec@1 84.375 (84.149)	Prec@5 100.000 (99.234)
EVALUATING - Epoch: [68][0/79]	Time 0.447 (0.447)	Data 0.409 (0.409)	Loss 1.0816 (1.0816)	Prec@1 66.406 (66.406)	Prec@5 94.531 (94.531)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:00

 Epoch: 69	Training Loss 0.4683 	Training Prec@1 83.966 	Training Prec@5 99.224 	Validation Loss 1.0194 	Validation Prec@1 69.030 	Validation Prec@5 95.380 

lr: 0.09907734248831929
TRAINING - Epoch: [69][0/391]	Time 1.322 (1.322)	Data 0.420 (0.420)	Loss 0.4663 (0.4663)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [69][100/391]	Time 0.115 (0.125)	Data 0.000 (0.005)	Loss 0.4506 (0.4600)	Prec@1 83.594 (84.112)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [69][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.4346 (0.4645)	Prec@1 86.719 (83.936)	Prec@5 100.000 (99.293)
TRAINING - Epoch: [69][300/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.5369 (0.4668)	Prec@1 83.594 (83.820)	Prec@5 99.219 (99.271)
EVALUATING - Epoch: [69][0/79]	Time 0.436 (0.436)	Data 0.402 (0.402)	Loss 0.7538 (0.7538)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:40

 Epoch: 70	Training Loss 0.4704 	Training Prec@1 83.742 	Training Prec@5 99.272 	Validation Loss 0.7923 	Validation Prec@1 75.540 	Validation Prec@5 98.210 

lr: 0.09904694071951164
TRAINING - Epoch: [70][0/391]	Time 1.344 (1.344)	Data 0.450 (0.450)	Loss 0.4615 (0.4615)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [70][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.4771 (0.4693)	Prec@1 83.594 (83.996)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [70][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.6741 (0.4647)	Prec@1 77.344 (84.185)	Prec@5 98.438 (99.335)
TRAINING - Epoch: [70][300/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.3377 (0.4703)	Prec@1 90.625 (84.058)	Prec@5 100.000 (99.286)
EVALUATING - Epoch: [70][0/79]	Time 0.423 (0.423)	Data 0.378 (0.378)	Loss 0.7059 (0.7059)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:22

 Epoch: 71	Training Loss 0.4706 	Training Prec@1 83.970 	Training Prec@5 99.282 	Validation Loss 0.7910 	Validation Prec@1 74.760 	Validation Prec@5 98.370 

lr: 0.09901605098125527
TRAINING - Epoch: [71][0/391]	Time 1.354 (1.354)	Data 0.435 (0.435)	Loss 0.5195 (0.5195)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [71][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.4059 (0.4584)	Prec@1 87.500 (84.437)	Prec@5 98.438 (99.288)
TRAINING - Epoch: [71][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.3821 (0.4633)	Prec@1 84.375 (84.072)	Prec@5 100.000 (99.343)
TRAINING - Epoch: [71][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.5520 (0.4683)	Prec@1 81.250 (84.006)	Prec@5 99.219 (99.258)
EVALUATING - Epoch: [71][0/79]	Time 0.485 (0.485)	Data 0.447 (0.447)	Loss 0.6549 (0.6549)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:09

 Epoch: 72	Training Loss 0.4675 	Training Prec@1 84.134 	Training Prec@5 99.278 	Validation Loss 0.7349 	Validation Prec@1 77.970 	Validation Prec@5 97.230 

lr: 0.09898467358087308
TRAINING - Epoch: [72][0/391]	Time 1.328 (1.328)	Data 0.444 (0.444)	Loss 0.5203 (0.5203)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [72][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.3362 (0.4495)	Prec@1 89.062 (84.452)	Prec@5 98.438 (99.397)
TRAINING - Epoch: [72][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.5732 (0.4581)	Prec@1 77.344 (84.196)	Prec@5 98.438 (99.312)
TRAINING - Epoch: [72][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.6022 (0.4631)	Prec@1 78.906 (84.066)	Prec@5 100.000 (99.291)
EVALUATING - Epoch: [72][0/79]	Time 0.433 (0.433)	Data 0.399 (0.399)	Loss 0.6007 (0.6007)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:51

 Epoch: 73	Training Loss 0.4645 	Training Prec@1 84.046 	Training Prec@5 99.308 	Validation Loss 0.6688 	Validation Prec@1 79.360 	Validation Prec@5 98.660 

lr: 0.09895280883053975
TRAINING - Epoch: [73][0/391]	Time 1.358 (1.358)	Data 0.441 (0.441)	Loss 0.4006 (0.4006)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [73][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.5543 (0.4628)	Prec@1 82.031 (83.926)	Prec@5 98.438 (99.196)
TRAINING - Epoch: [73][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.3387 (0.4587)	Prec@1 89.844 (84.122)	Prec@5 100.000 (99.293)
TRAINING - Epoch: [73][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.4673 (0.4659)	Prec@1 83.594 (83.949)	Prec@5 100.000 (99.208)
EVALUATING - Epoch: [73][0/79]	Time 0.442 (0.442)	Data 0.407 (0.407)	Loss 0.6515 (0.6515)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:21

 Epoch: 74	Training Loss 0.4656 	Training Prec@1 83.922 	Training Prec@5 99.192 	Validation Loss 0.7951 	Validation Prec@1 75.610 	Validation Prec@5 98.280 

lr: 0.09892045704727861
TRAINING - Epoch: [74][0/391]	Time 1.340 (1.340)	Data 0.441 (0.441)	Loss 0.3570 (0.3570)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [74][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.5132 (0.4537)	Prec@1 79.688 (84.375)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [74][200/391]	Time 0.110 (0.118)	Data 0.000 (0.003)	Loss 0.3759 (0.4590)	Prec@1 88.281 (84.196)	Prec@5 99.219 (99.289)
TRAINING - Epoch: [74][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.4373 (0.4566)	Prec@1 86.719 (84.282)	Prec@5 99.219 (99.273)
EVALUATING - Epoch: [74][0/79]	Time 0.426 (0.426)	Data 0.384 (0.384)	Loss 0.5610 (0.5610)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:26

 Epoch: 75	Training Loss 0.4601 	Training Prec@1 84.142 	Training Prec@5 99.246 	Validation Loss 0.6241 	Validation Prec@1 79.780 	Validation Prec@5 98.860 

lr: 0.09888761855295852
TRAINING - Epoch: [75][0/391]	Time 1.367 (1.367)	Data 0.459 (0.459)	Loss 0.4262 (0.4262)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [75][100/391]	Time 0.118 (0.129)	Data 0.000 (0.005)	Loss 0.5261 (0.4585)	Prec@1 81.250 (84.259)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [75][200/391]	Time 0.112 (0.123)	Data 0.000 (0.003)	Loss 0.3229 (0.4545)	Prec@1 89.062 (84.488)	Prec@5 99.219 (99.339)
TRAINING - Epoch: [75][300/391]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.4642 (0.4563)	Prec@1 81.250 (84.344)	Prec@5 99.219 (99.338)
EVALUATING - Epoch: [75][0/79]	Time 0.454 (0.454)	Data 0.413 (0.413)	Loss 0.6181 (0.6181)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:54:20

 Epoch: 76	Training Loss 0.4545 	Training Prec@1 84.388 	Training Prec@5 99.340 	Validation Loss 0.7109 	Validation Prec@1 75.920 	Validation Prec@5 98.020 

lr: 0.0988542936742906
TRAINING - Epoch: [76][0/391]	Time 1.374 (1.374)	Data 0.441 (0.441)	Loss 0.3872 (0.3872)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [76][100/391]	Time 0.121 (0.132)	Data 0.001 (0.005)	Loss 0.5627 (0.4574)	Prec@1 82.812 (84.298)	Prec@5 100.000 (99.250)
TRAINING - Epoch: [76][200/391]	Time 0.109 (0.124)	Data 0.000 (0.003)	Loss 0.5606 (0.4538)	Prec@1 82.031 (84.270)	Prec@5 98.438 (99.312)
TRAINING - Epoch: [76][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.3251 (0.4588)	Prec@1 90.625 (84.139)	Prec@5 100.000 (99.317)
EVALUATING - Epoch: [76][0/79]	Time 0.443 (0.443)	Data 0.398 (0.398)	Loss 1.0723 (1.0723)	Prec@1 67.188 (67.188)	Prec@5 96.094 (96.094)
Time cost: 00:48	Time of Finish: 2022-03-24 02:43:14

 Epoch: 77	Training Loss 0.4602 	Training Prec@1 84.128 	Training Prec@5 99.322 	Validation Loss 0.9476 	Validation Prec@1 71.850 	Validation Prec@5 97.390 

lr: 0.09882048274282504
TRAINING - Epoch: [77][0/391]	Time 1.356 (1.356)	Data 0.438 (0.438)	Loss 0.5219 (0.5219)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [77][100/391]	Time 0.119 (0.128)	Data 0.000 (0.005)	Loss 0.5247 (0.4491)	Prec@1 81.250 (84.460)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [77][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.5487 (0.4490)	Prec@1 76.562 (84.620)	Prec@5 98.438 (99.366)
TRAINING - Epoch: [77][300/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.4463 (0.4508)	Prec@1 82.031 (84.427)	Prec@5 98.438 (99.315)
EVALUATING - Epoch: [77][0/79]	Time 0.442 (0.442)	Data 0.391 (0.391)	Loss 0.6223 (0.6223)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:31

 Epoch: 78	Training Loss 0.4567 	Training Prec@1 84.248 	Training Prec@5 99.302 	Validation Loss 0.7573 	Validation Prec@1 75.930 	Validation Prec@5 97.580 

lr: 0.0987861860949478
TRAINING - Epoch: [78][0/391]	Time 1.286 (1.286)	Data 0.366 (0.366)	Loss 0.5440 (0.5440)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [78][100/391]	Time 0.109 (0.124)	Data 0.000 (0.004)	Loss 0.4409 (0.4494)	Prec@1 84.375 (84.445)	Prec@5 99.219 (99.257)
TRAINING - Epoch: [78][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.4037 (0.4584)	Prec@1 86.719 (83.947)	Prec@5 99.219 (99.289)
TRAINING - Epoch: [78][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3506 (0.4584)	Prec@1 87.500 (84.035)	Prec@5 100.000 (99.297)
EVALUATING - Epoch: [78][0/79]	Time 0.447 (0.447)	Data 0.419 (0.419)	Loss 0.6796 (0.6796)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:24

 Epoch: 79	Training Loss 0.4561 	Training Prec@1 84.132 	Training Prec@5 99.324 	Validation Loss 0.7490 	Validation Prec@1 77.300 	Validation Prec@5 98.740 

lr: 0.09875140407187721
TRAINING - Epoch: [79][0/391]	Time 1.354 (1.354)	Data 0.444 (0.444)	Loss 0.4137 (0.4137)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [79][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.4483 (0.4609)	Prec@1 85.156 (84.437)	Prec@5 100.000 (99.041)
TRAINING - Epoch: [79][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.4635 (0.4627)	Prec@1 86.719 (84.157)	Prec@5 99.219 (99.176)
TRAINING - Epoch: [79][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4820 (0.4615)	Prec@1 85.156 (84.230)	Prec@5 99.219 (99.211)
EVALUATING - Epoch: [79][0/79]	Time 0.467 (0.467)	Data 0.422 (0.422)	Loss 0.8154 (0.8154)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:20

 Epoch: 80	Training Loss 0.4602 	Training Prec@1 84.246 	Training Prec@5 99.248 	Validation Loss 0.8340 	Validation Prec@1 74.930 	Validation Prec@5 98.060 

lr: 0.09871613701966067
TRAINING - Epoch: [80][0/391]	Time 1.400 (1.400)	Data 0.468 (0.468)	Loss 0.4534 (0.4534)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [80][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.6219 (0.4608)	Prec@1 79.688 (84.174)	Prec@5 99.219 (99.265)
TRAINING - Epoch: [80][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.4447 (0.4635)	Prec@1 86.719 (84.200)	Prec@5 100.000 (99.230)
TRAINING - Epoch: [80][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3478 (0.4562)	Prec@1 86.719 (84.346)	Prec@5 100.000 (99.304)
EVALUATING - Epoch: [80][0/79]	Time 0.433 (0.433)	Data 0.406 (0.406)	Loss 0.5936 (0.5936)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:11

 Epoch: 81	Training Loss 0.4569 	Training Prec@1 84.280 	Training Prec@5 99.314 	Validation Loss 0.6921 	Validation Prec@1 78.810 	Validation Prec@5 98.710 

lr: 0.0986803852891711
TRAINING - Epoch: [81][0/391]	Time 1.318 (1.318)	Data 0.418 (0.418)	Loss 0.5001 (0.5001)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [81][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.4765 (0.4300)	Prec@1 83.594 (85.365)	Prec@5 100.000 (99.304)
TRAINING - Epoch: [81][200/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.3250 (0.4435)	Prec@1 85.156 (84.803)	Prec@5 100.000 (99.316)
TRAINING - Epoch: [81][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.4679 (0.4431)	Prec@1 83.594 (84.824)	Prec@5 99.219 (99.354)
EVALUATING - Epoch: [81][0/79]	Time 0.430 (0.430)	Data 0.389 (0.389)	Loss 1.0512 (1.0512)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:37

 Epoch: 82	Training Loss 0.4440 	Training Prec@1 84.758 	Training Prec@5 99.344 	Validation Loss 0.9558 	Validation Prec@1 73.110 	Validation Prec@5 97.380 

lr: 0.0986441492361035
TRAINING - Epoch: [82][0/391]	Time 1.310 (1.310)	Data 0.406 (0.406)	Loss 0.4281 (0.4281)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [82][100/391]	Time 0.119 (0.128)	Data 0.000 (0.004)	Loss 0.3926 (0.4386)	Prec@1 88.281 (85.017)	Prec@5 98.438 (99.312)
TRAINING - Epoch: [82][200/391]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.5730 (0.4489)	Prec@1 78.906 (84.593)	Prec@5 99.219 (99.262)
TRAINING - Epoch: [82][300/391]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.3546 (0.4507)	Prec@1 86.719 (84.411)	Prec@5 100.000 (99.268)
EVALUATING - Epoch: [82][0/79]	Time 0.438 (0.438)	Data 0.394 (0.394)	Loss 0.5713 (0.5713)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 03:06:26

 Epoch: 83	Training Loss 0.4529 	Training Prec@1 84.372 	Training Prec@5 99.242 	Validation Loss 0.6682 	Validation Prec@1 77.240 	Validation Prec@5 98.670 

lr: 0.09860742922097143
TRAINING - Epoch: [83][0/391]	Time 1.320 (1.320)	Data 0.440 (0.440)	Loss 0.4041 (0.4041)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [83][100/391]	Time 0.109 (0.126)	Data 0.000 (0.005)	Loss 0.5078 (0.4344)	Prec@1 81.250 (84.831)	Prec@5 99.219 (99.397)
TRAINING - Epoch: [83][200/391]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.3546 (0.4429)	Prec@1 86.719 (84.795)	Prec@5 100.000 (99.355)
TRAINING - Epoch: [83][300/391]	Time 0.110 (0.122)	Data 0.000 (0.002)	Loss 0.3961 (0.4434)	Prec@1 85.938 (84.770)	Prec@5 99.219 (99.377)
EVALUATING - Epoch: [83][0/79]	Time 0.430 (0.430)	Data 0.386 (0.386)	Loss 0.5959 (0.5959)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:58:28

 Epoch: 84	Training Loss 0.4450 	Training Prec@1 84.674 	Training Prec@5 99.344 	Validation Loss 0.7502 	Validation Prec@1 75.880 	Validation Prec@5 98.120 

lr: 0.0985702256091034
TRAINING - Epoch: [84][0/391]	Time 1.346 (1.346)	Data 0.446 (0.446)	Loss 0.3528 (0.3528)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [84][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.4744 (0.4441)	Prec@1 82.812 (84.630)	Prec@5 99.219 (99.319)
TRAINING - Epoch: [84][200/391]	Time 0.104 (0.115)	Data 0.000 (0.003)	Loss 0.5929 (0.4470)	Prec@1 79.688 (84.538)	Prec@5 99.219 (99.335)
TRAINING - Epoch: [84][300/391]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.4837 (0.4511)	Prec@1 82.031 (84.331)	Prec@5 99.219 (99.328)
EVALUATING - Epoch: [84][0/79]	Time 0.438 (0.438)	Data 0.408 (0.408)	Loss 0.6767 (0.6767)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:45	Time of Finish: 2022-03-24 01:52:50

 Epoch: 85	Training Loss 0.4495 	Training Prec@1 84.462 	Training Prec@5 99.350 	Validation Loss 0.7103 	Validation Prec@1 76.500 	Validation Prec@5 98.640 

lr: 0.09853253877063924
TRAINING - Epoch: [85][0/391]	Time 1.333 (1.333)	Data 0.418 (0.418)	Loss 0.3659 (0.3659)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [85][100/391]	Time 0.110 (0.124)	Data 0.000 (0.004)	Loss 0.4414 (0.4251)	Prec@1 85.938 (85.373)	Prec@5 99.219 (99.319)
TRAINING - Epoch: [85][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.5183 (0.4436)	Prec@1 84.375 (84.787)	Prec@5 98.438 (99.211)
TRAINING - Epoch: [85][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4602 (0.4511)	Prec@1 83.594 (84.461)	Prec@5 98.438 (99.211)
EVALUATING - Epoch: [85][0/79]	Time 0.429 (0.429)	Data 0.379 (0.379)	Loss 1.1765 (1.1765)	Prec@1 70.312 (70.312)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:15

 Epoch: 86	Training Loss 0.4481 	Training Prec@1 84.530 	Training Prec@5 99.232 	Validation Loss 0.9533 	Validation Prec@1 71.960 	Validation Prec@5 98.520 

lr: 0.09849436908052638
TRAINING - Epoch: [86][0/391]	Time 1.328 (1.328)	Data 0.427 (0.427)	Loss 0.2748 (0.2748)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [86][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.3601 (0.4444)	Prec@1 85.156 (84.561)	Prec@5 99.219 (99.343)
TRAINING - Epoch: [86][200/391]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3620 (0.4457)	Prec@1 89.062 (84.655)	Prec@5 98.438 (99.316)
TRAINING - Epoch: [86][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.5290 (0.4430)	Prec@1 83.594 (84.733)	Prec@5 98.438 (99.349)
EVALUATING - Epoch: [86][0/79]	Time 0.421 (0.421)	Data 0.379 (0.379)	Loss 0.5668 (0.5668)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:11

 Epoch: 87	Training Loss 0.4459 	Training Prec@1 84.616 	Training Prec@5 99.328 	Validation Loss 0.6612 	Validation Prec@1 78.520 	Validation Prec@5 98.570 

lr: 0.09845571691851622
TRAINING - Epoch: [87][0/391]	Time 1.331 (1.331)	Data 0.434 (0.434)	Loss 0.5432 (0.5432)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [87][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.4780 (0.4422)	Prec@1 85.156 (84.932)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [87][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.5088 (0.4448)	Prec@1 82.812 (84.717)	Prec@5 97.656 (99.300)
TRAINING - Epoch: [87][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.4505 (0.4445)	Prec@1 86.719 (84.757)	Prec@5 97.656 (99.304)
EVALUATING - Epoch: [87][0/79]	Time 0.494 (0.494)	Data 0.467 (0.467)	Loss 0.8081 (0.8081)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:55

 Epoch: 88	Training Loss 0.4408 	Training Prec@1 84.878 	Training Prec@5 99.310 	Validation Loss 0.8054 	Validation Prec@1 73.600 	Validation Prec@5 98.070 

lr: 0.09841658266916022
TRAINING - Epoch: [88][0/391]	Time 1.307 (1.307)	Data 0.415 (0.415)	Loss 0.3574 (0.3574)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [88][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.5033 (0.4212)	Prec@1 82.812 (85.311)	Prec@5 99.219 (99.327)
TRAINING - Epoch: [88][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4971 (0.4440)	Prec@1 83.594 (84.845)	Prec@5 98.438 (99.308)
TRAINING - Epoch: [88][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.4076 (0.4443)	Prec@1 84.375 (84.798)	Prec@5 99.219 (99.323)
EVALUATING - Epoch: [88][0/79]	Time 0.457 (0.457)	Data 0.417 (0.417)	Loss 0.6432 (0.6432)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:22

 Epoch: 89	Training Loss 0.4491 	Training Prec@1 84.606 	Training Prec@5 99.308 	Validation Loss 0.6566 	Validation Prec@1 78.130 	Validation Prec@5 98.730 

lr: 0.0983769667218062
TRAINING - Epoch: [89][0/391]	Time 1.354 (1.354)	Data 0.450 (0.450)	Loss 0.4124 (0.4124)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [89][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.3568 (0.4442)	Prec@1 84.375 (84.383)	Prec@5 99.219 (99.335)
TRAINING - Epoch: [89][200/391]	Time 0.120 (0.121)	Data 0.000 (0.003)	Loss 0.4030 (0.4352)	Prec@1 85.156 (84.822)	Prec@5 100.000 (99.331)
TRAINING - Epoch: [89][300/391]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3151 (0.4370)	Prec@1 89.844 (84.858)	Prec@5 100.000 (99.317)
EVALUATING - Epoch: [89][0/79]	Time 0.446 (0.446)	Data 0.410 (0.410)	Loss 0.5594 (0.5594)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:30

 Epoch: 90	Training Loss 0.4365 	Training Prec@1 84.876 	Training Prec@5 99.316 	Validation Loss 0.6595 	Validation Prec@1 78.530 	Validation Prec@5 98.790 

lr: 0.09833686947059436
TRAINING - Epoch: [90][0/391]	Time 1.317 (1.317)	Data 0.429 (0.429)	Loss 0.5379 (0.5379)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [90][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.3886 (0.4474)	Prec@1 88.281 (84.499)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [90][200/391]	Time 0.113 (0.122)	Data 0.000 (0.003)	Loss 0.3564 (0.4444)	Prec@1 86.719 (84.756)	Prec@5 100.000 (99.374)
TRAINING - Epoch: [90][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2676 (0.4449)	Prec@1 91.406 (84.718)	Prec@5 99.219 (99.362)
EVALUATING - Epoch: [90][0/79]	Time 0.426 (0.426)	Data 0.384 (0.384)	Loss 0.4933 (0.4933)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:17

 Epoch: 91	Training Loss 0.4461 	Training Prec@1 84.640 	Training Prec@5 99.334 	Validation Loss 0.5793 	Validation Prec@1 81.070 	Validation Prec@5 98.730 

lr: 0.09829629131445343
TRAINING - Epoch: [91][0/391]	Time 1.335 (1.335)	Data 0.442 (0.442)	Loss 0.4526 (0.4526)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [91][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.4027 (0.4068)	Prec@1 83.594 (85.930)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [91][200/391]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.4088 (0.4287)	Prec@1 84.375 (85.176)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [91][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3472 (0.4364)	Prec@1 88.281 (84.956)	Prec@5 99.219 (99.369)
EVALUATING - Epoch: [91][0/79]	Time 0.443 (0.443)	Data 0.404 (0.404)	Loss 0.5725 (0.5725)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:25

 Epoch: 92	Training Loss 0.4391 	Training Prec@1 84.868 	Training Prec@5 99.352 	Validation Loss 0.6256 	Validation Prec@1 79.630 	Validation Prec@5 98.690 

lr: 0.09825523265709668
TRAINING - Epoch: [92][0/391]	Time 1.347 (1.347)	Data 0.449 (0.449)	Loss 0.5161 (0.5161)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [92][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.2802 (0.4308)	Prec@1 89.844 (85.249)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [92][200/391]	Time 0.118 (0.122)	Data 0.000 (0.003)	Loss 0.3854 (0.4282)	Prec@1 86.719 (85.378)	Prec@5 99.219 (99.363)
TRAINING - Epoch: [92][300/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.4110 (0.4328)	Prec@1 85.156 (85.110)	Prec@5 99.219 (99.338)
EVALUATING - Epoch: [92][0/79]	Time 0.434 (0.434)	Data 0.397 (0.397)	Loss 0.6018 (0.6018)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:51:00

 Epoch: 93	Training Loss 0.4354 	Training Prec@1 85.050 	Training Prec@5 99.324 	Validation Loss 0.7954 	Validation Prec@1 75.370 	Validation Prec@5 97.600 

lr: 0.09821369390701791
TRAINING - Epoch: [93][0/391]	Time 1.333 (1.333)	Data 0.435 (0.435)	Loss 0.4110 (0.4110)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [93][100/391]	Time 0.112 (0.125)	Data 0.000 (0.005)	Loss 0.3486 (0.4434)	Prec@1 89.062 (84.568)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [93][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.6217 (0.4410)	Prec@1 78.125 (84.764)	Prec@5 98.438 (99.405)
TRAINING - Epoch: [93][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3393 (0.4383)	Prec@1 90.625 (84.980)	Prec@5 100.000 (99.385)
EVALUATING - Epoch: [93][0/79]	Time 0.445 (0.445)	Data 0.404 (0.404)	Loss 0.6030 (0.6030)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:13

 Epoch: 94	Training Loss 0.4381 	Training Prec@1 84.930 	Training Prec@5 99.360 	Validation Loss 0.7994 	Validation Prec@1 74.750 	Validation Prec@5 98.380 

lr: 0.09817167547748731
TRAINING - Epoch: [94][0/391]	Time 1.291 (1.291)	Data 0.412 (0.412)	Loss 0.3459 (0.3459)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [94][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.2512 (0.4210)	Prec@1 91.406 (85.713)	Prec@5 100.000 (99.312)
TRAINING - Epoch: [94][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3829 (0.4339)	Prec@1 85.938 (85.257)	Prec@5 97.656 (99.347)
TRAINING - Epoch: [94][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.4488 (0.4331)	Prec@1 82.812 (85.270)	Prec@5 100.000 (99.369)
EVALUATING - Epoch: [94][0/79]	Time 0.437 (0.437)	Data 0.398 (0.398)	Loss 0.6136 (0.6136)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:30

 Epoch: 95	Training Loss 0.4323 	Training Prec@1 85.184 	Training Prec@5 99.366 	Validation Loss 0.6397 	Validation Prec@1 78.940 	Validation Prec@5 98.690 

lr: 0.0981291777865475
TRAINING - Epoch: [95][0/391]	Time 1.300 (1.300)	Data 0.413 (0.413)	Loss 0.3858 (0.3858)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [95][100/391]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.4126 (0.4320)	Prec@1 87.500 (85.288)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [95][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.5432 (0.4329)	Prec@1 79.688 (85.218)	Prec@5 98.438 (99.366)
TRAINING - Epoch: [95][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.5044 (0.4286)	Prec@1 82.812 (85.244)	Prec@5 98.438 (99.385)
EVALUATING - Epoch: [95][0/79]	Time 0.406 (0.406)	Data 0.372 (0.372)	Loss 0.8768 (0.8768)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:16

 Epoch: 96	Training Loss 0.4332 	Training Prec@1 85.068 	Training Prec@5 99.372 	Validation Loss 0.8856 	Validation Prec@1 74.410 	Validation Prec@5 98.290 

lr: 0.09808620125700927
TRAINING - Epoch: [96][0/391]	Time 1.302 (1.302)	Data 0.411 (0.411)	Loss 0.5197 (0.5197)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [96][100/391]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.3794 (0.4375)	Prec@1 85.156 (84.916)	Prec@5 100.000 (99.319)
TRAINING - Epoch: [96][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4594 (0.4332)	Prec@1 82.812 (84.892)	Prec@5 100.000 (99.386)
TRAINING - Epoch: [96][300/391]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.4559 (0.4366)	Prec@1 84.375 (84.956)	Prec@5 100.000 (99.369)
EVALUATING - Epoch: [96][0/79]	Time 0.471 (0.471)	Data 0.433 (0.433)	Loss 1.5758 (1.5758)	Prec@1 56.250 (56.250)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:55

 Epoch: 97	Training Loss 0.4335 	Training Prec@1 85.160 	Training Prec@5 99.366 	Validation Loss 1.4111 	Validation Prec@1 63.390 	Validation Prec@5 96.070 

lr: 0.09804274631644733
TRAINING - Epoch: [97][0/391]	Time 1.336 (1.336)	Data 0.435 (0.435)	Loss 0.3039 (0.3039)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [97][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.5565 (0.4212)	Prec@1 84.375 (85.342)	Prec@5 96.875 (99.466)
TRAINING - Epoch: [97][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.4253 (0.4205)	Prec@1 86.719 (85.479)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [97][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2798 (0.4275)	Prec@1 90.625 (85.343)	Prec@5 99.219 (99.429)
EVALUATING - Epoch: [97][0/79]	Time 0.419 (0.419)	Data 0.385 (0.385)	Loss 0.6405 (0.6405)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:51

 Epoch: 98	Training Loss 0.4283 	Training Prec@1 85.330 	Training Prec@5 99.418 	Validation Loss 0.7030 	Validation Prec@1 77.630 	Validation Prec@5 98.730 

lr: 0.09799881339719617
TRAINING - Epoch: [98][0/391]	Time 1.316 (1.316)	Data 0.412 (0.412)	Loss 0.3333 (0.3333)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [98][100/391]	Time 0.116 (0.127)	Data 0.000 (0.004)	Loss 0.3806 (0.4288)	Prec@1 87.500 (85.063)	Prec@5 100.000 (99.381)
TRAINING - Epoch: [98][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4757 (0.4358)	Prec@1 84.375 (84.939)	Prec@5 99.219 (99.316)
TRAINING - Epoch: [98][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6531 (0.4363)	Prec@1 81.250 (84.988)	Prec@5 98.438 (99.294)
EVALUATING - Epoch: [98][0/79]	Time 0.457 (0.457)	Data 0.411 (0.411)	Loss 0.6303 (0.6303)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:34

 Epoch: 99	Training Loss 0.4355 	Training Prec@1 84.912 	Training Prec@5 99.330 	Validation Loss 0.7341 	Validation Prec@1 75.810 	Validation Prec@5 97.390 

lr: 0.0979544029363457
TRAINING - Epoch: [99][0/391]	Time 1.313 (1.313)	Data 0.429 (0.429)	Loss 0.4070 (0.4070)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [99][100/391]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.3834 (0.4216)	Prec@1 84.375 (85.381)	Prec@5 100.000 (99.412)
TRAINING - Epoch: [99][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.4187 (0.4228)	Prec@1 82.031 (85.285)	Prec@5 100.000 (99.464)
TRAINING - Epoch: [99][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3484 (0.4321)	Prec@1 85.938 (85.001)	Prec@5 100.000 (99.419)
EVALUATING - Epoch: [99][0/79]	Time 0.457 (0.457)	Data 0.419 (0.419)	Loss 0.9231 (0.9231)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:59

 Epoch: 100	Training Loss 0.4343 	Training Prec@1 84.950 	Training Prec@5 99.380 	Validation Loss 0.8779 	Validation Prec@1 72.880 	Validation Prec@5 96.130 

lr: 0.09790951537573689
TRAINING - Epoch: [100][0/391]	Time 1.354 (1.354)	Data 0.459 (0.459)	Loss 0.4147 (0.4147)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [100][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.4030 (0.4383)	Prec@1 82.031 (84.855)	Prec@5 99.219 (99.350)
TRAINING - Epoch: [100][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.4127 (0.4340)	Prec@1 84.375 (85.082)	Prec@5 98.438 (99.335)
TRAINING - Epoch: [100][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.5188 (0.4412)	Prec@1 81.250 (84.801)	Prec@5 100.000 (99.307)
EVALUATING - Epoch: [100][0/79]	Time 0.440 (0.440)	Data 0.396 (0.396)	Loss 0.8531 (0.8531)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:23

 Epoch: 101	Training Loss 0.4388 	Training Prec@1 84.822 	Training Prec@5 99.350 	Validation Loss 0.9115 	Validation Prec@1 71.370 	Validation Prec@5 98.020 

lr: 0.09786415116195736
TRAINING - Epoch: [101][0/391]	Time 1.335 (1.335)	Data 0.419 (0.419)	Loss 0.3869 (0.3869)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [101][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.4316 (0.4267)	Prec@1 85.938 (85.450)	Prec@5 99.219 (99.281)
TRAINING - Epoch: [101][200/391]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.4590 (0.4210)	Prec@1 85.156 (85.630)	Prec@5 100.000 (99.343)
TRAINING - Epoch: [101][300/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.5423 (0.4305)	Prec@1 80.469 (85.374)	Prec@5 99.219 (99.338)
EVALUATING - Epoch: [101][0/79]	Time 0.414 (0.414)	Data 0.386 (0.386)	Loss 0.7555 (0.7555)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:17

 Epoch: 102	Training Loss 0.4339 	Training Prec@1 85.204 	Training Prec@5 99.372 	Validation Loss 0.7011 	Validation Prec@1 76.750 	Validation Prec@5 98.410 

lr: 0.09781831074633705
TRAINING - Epoch: [102][0/391]	Time 1.285 (1.285)	Data 0.417 (0.417)	Loss 0.4410 (0.4410)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [102][100/391]	Time 0.108 (0.124)	Data 0.000 (0.004)	Loss 0.5428 (0.4303)	Prec@1 84.375 (85.172)	Prec@5 98.438 (99.373)
TRAINING - Epoch: [102][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.3657 (0.4263)	Prec@1 84.375 (85.250)	Prec@5 100.000 (99.398)
TRAINING - Epoch: [102][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4395 (0.4266)	Prec@1 85.156 (85.273)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [102][0/79]	Time 0.440 (0.440)	Data 0.398 (0.398)	Loss 0.9601 (0.9601)	Prec@1 69.531 (69.531)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:54

 Epoch: 103	Training Loss 0.4321 	Training Prec@1 85.090 	Training Prec@5 99.358 	Validation Loss 0.9811 	Validation Prec@1 71.230 	Validation Prec@5 97.860 

lr: 0.09777199458494357
TRAINING - Epoch: [103][0/391]	Time 1.332 (1.332)	Data 0.412 (0.412)	Loss 0.4632 (0.4632)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [103][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.4884 (0.4219)	Prec@1 88.281 (85.172)	Prec@5 99.219 (99.373)
TRAINING - Epoch: [103][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4869 (0.4260)	Prec@1 82.812 (85.117)	Prec@5 99.219 (99.335)
TRAINING - Epoch: [103][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.4640 (0.4315)	Prec@1 82.031 (85.032)	Prec@5 99.219 (99.333)
EVALUATING - Epoch: [103][0/79]	Time 0.445 (0.445)	Data 0.407 (0.407)	Loss 0.5240 (0.5240)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:24

 Epoch: 104	Training Loss 0.4323 	Training Prec@1 84.988 	Training Prec@5 99.356 	Validation Loss 0.6219 	Validation Prec@1 79.510 	Validation Prec@5 98.580 

lr: 0.09772520313857778
TRAINING - Epoch: [104][0/391]	Time 1.302 (1.302)	Data 0.417 (0.417)	Loss 0.3950 (0.3950)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [104][100/391]	Time 0.108 (0.124)	Data 0.000 (0.004)	Loss 0.5076 (0.4303)	Prec@1 81.250 (85.032)	Prec@5 99.219 (99.319)
TRAINING - Epoch: [104][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.5263 (0.4318)	Prec@1 83.594 (85.106)	Prec@5 99.219 (99.370)
TRAINING - Epoch: [104][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.4962 (0.4335)	Prec@1 84.375 (85.013)	Prec@5 99.219 (99.317)
EVALUATING - Epoch: [104][0/79]	Time 0.448 (0.448)	Data 0.400 (0.400)	Loss 0.4722 (0.4722)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:15

 Epoch: 105	Training Loss 0.4337 	Training Prec@1 84.988 	Training Prec@5 99.338 	Validation Loss 0.6299 	Validation Prec@1 78.690 	Validation Prec@5 98.720 

lr: 0.09767793687276916
TRAINING - Epoch: [105][0/391]	Time 1.380 (1.380)	Data 0.422 (0.422)	Loss 0.2890 (0.2890)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [105][100/391]	Time 0.117 (0.128)	Data 0.001 (0.005)	Loss 0.3875 (0.4188)	Prec@1 88.281 (85.760)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [105][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.4379 (0.4220)	Prec@1 84.375 (85.452)	Prec@5 99.219 (99.460)
TRAINING - Epoch: [105][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.5582 (0.4270)	Prec@1 87.500 (85.268)	Prec@5 96.094 (99.429)
EVALUATING - Epoch: [105][0/79]	Time 0.406 (0.406)	Data 0.371 (0.371)	Loss 0.7048 (0.7048)	Prec@1 75.781 (75.781)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:30

 Epoch: 106	Training Loss 0.4303 	Training Prec@1 85.306 	Training Prec@5 99.390 	Validation Loss 0.9022 	Validation Prec@1 71.560 	Validation Prec@5 97.480 

lr: 0.09763019625777113
TRAINING - Epoch: [106][0/391]	Time 1.619 (1.619)	Data 0.417 (0.417)	Loss 0.7020 (0.7020)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [106][100/391]	Time 0.125 (0.134)	Data 0.000 (0.004)	Loss 0.4858 (0.4225)	Prec@1 83.594 (85.265)	Prec@5 100.000 (99.412)
TRAINING - Epoch: [106][200/391]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.2815 (0.4282)	Prec@1 89.062 (85.152)	Prec@5 100.000 (99.433)
TRAINING - Epoch: [106][300/391]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.3835 (0.4322)	Prec@1 82.031 (85.076)	Prec@5 100.000 (99.398)
EVALUATING - Epoch: [106][0/79]	Time 0.445 (0.445)	Data 0.405 (0.405)	Loss 0.7597 (0.7597)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:51	Time of Finish: 2022-03-24 03:20:12

 Epoch: 107	Training Loss 0.4329 	Training Prec@1 85.052 	Training Prec@5 99.396 	Validation Loss 0.7682 	Validation Prec@1 73.760 	Validation Prec@5 98.770 

lr: 0.0975819817685565
TRAINING - Epoch: [107][0/391]	Time 1.312 (1.312)	Data 0.415 (0.415)	Loss 0.4257 (0.4257)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [107][100/391]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.3817 (0.4268)	Prec@1 86.719 (85.659)	Prec@5 100.000 (99.412)
TRAINING - Epoch: [107][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3947 (0.4380)	Prec@1 87.500 (85.024)	Prec@5 99.219 (99.331)
TRAINING - Epoch: [107][300/391]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.5768 (0.4318)	Prec@1 78.125 (85.172)	Prec@5 99.219 (99.336)
EVALUATING - Epoch: [107][0/79]	Time 0.441 (0.441)	Data 0.404 (0.404)	Loss 0.6480 (0.6480)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:43:08

 Epoch: 108	Training Loss 0.4370 	Training Prec@1 84.978 	Training Prec@5 99.322 	Validation Loss 0.6660 	Validation Prec@1 76.560 	Validation Prec@5 98.480 

lr: 0.09753329388481262
TRAINING - Epoch: [108][0/391]	Time 1.644 (1.644)	Data 0.423 (0.423)	Loss 0.5150 (0.5150)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [108][100/391]	Time 0.116 (0.136)	Data 0.000 (0.004)	Loss 0.4138 (0.4269)	Prec@1 85.938 (85.241)	Prec@5 100.000 (99.381)
TRAINING - Epoch: [108][200/391]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6557 (0.4304)	Prec@1 78.125 (85.137)	Prec@5 98.438 (99.359)
TRAINING - Epoch: [108][300/391]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.4407 (0.4332)	Prec@1 86.719 (85.128)	Prec@5 99.219 (99.328)
EVALUATING - Epoch: [108][0/79]	Time 0.438 (0.438)	Data 0.399 (0.399)	Loss 0.6698 (0.6698)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:51	Time of Finish: 2022-03-24 03:20:54

 Epoch: 109	Training Loss 0.4346 	Training Prec@1 85.062 	Training Prec@5 99.292 	Validation Loss 0.6331 	Validation Prec@1 79.020 	Validation Prec@5 98.540 

lr: 0.09748413309093668
TRAINING - Epoch: [109][0/391]	Time 1.378 (1.378)	Data 0.421 (0.421)	Loss 0.4044 (0.4044)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [109][100/391]	Time 0.116 (0.131)	Data 0.000 (0.005)	Loss 0.3407 (0.4186)	Prec@1 87.500 (85.535)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [109][200/391]	Time 0.118 (0.124)	Data 0.000 (0.003)	Loss 0.3129 (0.4302)	Prec@1 90.625 (85.164)	Prec@5 100.000 (99.390)
TRAINING - Epoch: [109][300/391]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.5965 (0.4348)	Prec@1 78.125 (85.068)	Prec@5 98.438 (99.385)
EVALUATING - Epoch: [109][0/79]	Time 0.441 (0.441)	Data 0.412 (0.412)	Loss 0.7190 (0.7190)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:55:20

 Epoch: 110	Training Loss 0.4305 	Training Prec@1 85.186 	Training Prec@5 99.384 	Validation Loss 0.7903 	Validation Prec@1 75.520 	Validation Prec@5 97.730 

lr: 0.09743449987603084
TRAINING - Epoch: [110][0/391]	Time 1.322 (1.322)	Data 0.420 (0.420)	Loss 0.3315 (0.3315)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [110][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.3180 (0.4111)	Prec@1 91.406 (86.216)	Prec@5 98.438 (99.397)
TRAINING - Epoch: [110][200/391]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.4398 (0.4204)	Prec@1 85.156 (85.731)	Prec@5 100.000 (99.374)
TRAINING - Epoch: [110][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2961 (0.4238)	Prec@1 92.969 (85.665)	Prec@5 100.000 (99.362)
EVALUATING - Epoch: [110][0/79]	Time 0.440 (0.440)	Data 0.400 (0.400)	Loss 0.7030 (0.7030)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:32

 Epoch: 111	Training Loss 0.4281 	Training Prec@1 85.458 	Training Prec@5 99.334 	Validation Loss 0.7386 	Validation Prec@1 75.850 	Validation Prec@5 98.570 

lr: 0.09738439473389743
TRAINING - Epoch: [111][0/391]	Time 1.335 (1.335)	Data 0.418 (0.418)	Loss 0.4702 (0.4702)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [111][100/391]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.3348 (0.4186)	Prec@1 86.719 (85.342)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [111][200/391]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.3732 (0.4217)	Prec@1 87.500 (85.269)	Prec@5 99.219 (99.386)
TRAINING - Epoch: [111][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.4190 (0.4253)	Prec@1 83.594 (85.193)	Prec@5 98.438 (99.380)
EVALUATING - Epoch: [111][0/79]	Time 0.446 (0.446)	Data 0.412 (0.412)	Loss 0.6853 (0.6853)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:25

 Epoch: 112	Training Loss 0.4299 	Training Prec@1 85.102 	Training Prec@5 99.370 	Validation Loss 0.7479 	Validation Prec@1 75.710 	Validation Prec@5 98.300 

lr: 0.09733381816303395
TRAINING - Epoch: [112][0/391]	Time 1.342 (1.342)	Data 0.414 (0.414)	Loss 0.4439 (0.4439)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [112][100/391]	Time 0.115 (0.124)	Data 0.000 (0.004)	Loss 0.4036 (0.4030)	Prec@1 89.062 (86.286)	Prec@5 99.219 (99.420)
TRAINING - Epoch: [112][200/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.3356 (0.4139)	Prec@1 89.062 (85.817)	Prec@5 100.000 (99.421)
TRAINING - Epoch: [112][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3804 (0.4227)	Prec@1 87.500 (85.452)	Prec@5 100.000 (99.426)
EVALUATING - Epoch: [112][0/79]	Time 0.439 (0.439)	Data 0.405 (0.405)	Loss 0.5807 (0.5807)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:03

 Epoch: 113	Training Loss 0.4227 	Training Prec@1 85.474 	Training Prec@5 99.418 	Validation Loss 0.6623 	Validation Prec@1 77.790 	Validation Prec@5 98.540 

lr: 0.0972827706666282
TRAINING - Epoch: [113][0/391]	Time 1.339 (1.339)	Data 0.444 (0.444)	Loss 0.4021 (0.4021)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [113][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.5884 (0.4344)	Prec@1 76.562 (85.009)	Prec@5 98.438 (99.366)
TRAINING - Epoch: [113][200/391]	Time 0.112 (0.119)	Data 0.000 (0.003)	Loss 0.4088 (0.4251)	Prec@1 85.156 (85.331)	Prec@5 100.000 (99.456)
TRAINING - Epoch: [113][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3887 (0.4277)	Prec@1 83.594 (85.226)	Prec@5 99.219 (99.445)
EVALUATING - Epoch: [113][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.5096 (0.5096)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:46

 Epoch: 114	Training Loss 0.4305 	Training Prec@1 85.142 	Training Prec@5 99.418 	Validation Loss 0.6227 	Validation Prec@1 78.580 	Validation Prec@5 98.910 

lr: 0.09723125275255325
TRAINING - Epoch: [114][0/391]	Time 1.329 (1.329)	Data 0.423 (0.423)	Loss 0.3332 (0.3332)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [114][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.4205 (0.4255)	Prec@1 83.594 (84.947)	Prec@5 100.000 (99.459)
TRAINING - Epoch: [114][200/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.4010 (0.4257)	Prec@1 88.281 (85.137)	Prec@5 100.000 (99.440)
TRAINING - Epoch: [114][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4444 (0.4311)	Prec@1 79.688 (85.011)	Prec@5 100.000 (99.403)
EVALUATING - Epoch: [114][0/79]	Time 0.444 (0.444)	Data 0.414 (0.414)	Loss 0.7526 (0.7526)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:48:13

 Epoch: 115	Training Loss 0.4313 	Training Prec@1 85.048 	Training Prec@5 99.396 	Validation Loss 0.6833 	Validation Prec@1 77.540 	Validation Prec@5 98.610 

lr: 0.09717926493336226
TRAINING - Epoch: [115][0/391]	Time 1.627 (1.627)	Data 0.454 (0.454)	Loss 0.5001 (0.5001)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [115][100/391]	Time 0.117 (0.128)	Data 0.000 (0.005)	Loss 0.3163 (0.4231)	Prec@1 89.844 (85.280)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [115][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.5275 (0.4324)	Prec@1 81.250 (85.020)	Prec@5 100.000 (99.421)
TRAINING - Epoch: [115][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.5293 (0.4334)	Prec@1 85.156 (85.045)	Prec@5 98.438 (99.349)
EVALUATING - Epoch: [115][0/79]	Time 0.451 (0.451)	Data 0.413 (0.413)	Loss 0.6926 (0.6926)	Prec@1 80.469 (80.469)	Prec@5 96.094 (96.094)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:16

 Epoch: 116	Training Loss 0.4328 	Training Prec@1 85.158 	Training Prec@5 99.338 	Validation Loss 0.8094 	Validation Prec@1 75.880 	Validation Prec@5 98.230 

lr: 0.09712680772628364
TRAINING - Epoch: [116][0/391]	Time 1.573 (1.573)	Data 0.406 (0.406)	Loss 0.4642 (0.4642)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [116][100/391]	Time 0.114 (0.129)	Data 0.000 (0.004)	Loss 0.3665 (0.4392)	Prec@1 88.281 (85.063)	Prec@5 100.000 (99.373)
TRAINING - Epoch: [116][200/391]	Time 0.109 (0.121)	Data 0.000 (0.002)	Loss 0.6287 (0.4426)	Prec@1 81.250 (84.966)	Prec@5 98.438 (99.331)
TRAINING - Epoch: [116][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3309 (0.4386)	Prec@1 87.500 (85.011)	Prec@5 100.000 (99.356)
EVALUATING - Epoch: [116][0/79]	Time 0.438 (0.438)	Data 0.396 (0.396)	Loss 0.5956 (0.5956)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:11

 Epoch: 117	Training Loss 0.4406 	Training Prec@1 84.952 	Training Prec@5 99.326 	Validation Loss 0.7127 	Validation Prec@1 75.760 	Validation Prec@5 98.410 

lr: 0.09707388165321562
TRAINING - Epoch: [117][0/391]	Time 1.321 (1.321)	Data 0.431 (0.431)	Loss 0.3240 (0.3240)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [117][100/391]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.3095 (0.4056)	Prec@1 90.625 (86.324)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [117][200/391]	Time 0.117 (0.123)	Data 0.000 (0.003)	Loss 0.4816 (0.4146)	Prec@1 85.938 (85.813)	Prec@5 97.656 (99.398)
TRAINING - Epoch: [117][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.4333 (0.4254)	Prec@1 82.031 (85.395)	Prec@5 100.000 (99.369)
EVALUATING - Epoch: [117][0/79]	Time 0.414 (0.414)	Data 0.377 (0.377)	Loss 0.7893 (0.7893)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:27

 Epoch: 118	Training Loss 0.4252 	Training Prec@1 85.404 	Training Prec@5 99.372 	Validation Loss 0.9879 	Validation Prec@1 72.820 	Validation Prec@5 98.170 

lr: 0.09702048724072126
TRAINING - Epoch: [118][0/391]	Time 1.355 (1.355)	Data 0.455 (0.455)	Loss 0.3344 (0.3344)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [118][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.4952 (0.4108)	Prec@1 77.344 (85.876)	Prec@5 100.000 (99.544)
TRAINING - Epoch: [118][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.3443 (0.4130)	Prec@1 85.156 (85.801)	Prec@5 99.219 (99.448)
TRAINING - Epoch: [118][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4746 (0.4276)	Prec@1 82.812 (85.239)	Prec@5 99.219 (99.390)
EVALUATING - Epoch: [118][0/79]	Time 0.493 (0.493)	Data 0.449 (0.449)	Loss 0.8789 (0.8789)	Prec@1 70.312 (70.312)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:14

 Epoch: 119	Training Loss 0.4309 	Training Prec@1 85.232 	Training Prec@5 99.382 	Validation Loss 0.9627 	Validation Prec@1 71.170 	Validation Prec@5 97.290 

lr: 0.09696662502002318
TRAINING - Epoch: [119][0/391]	Time 1.366 (1.366)	Data 0.472 (0.472)	Loss 0.3065 (0.3065)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [119][100/391]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.2950 (0.4164)	Prec@1 91.406 (85.396)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [119][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.4893 (0.4195)	Prec@1 85.156 (85.611)	Prec@5 99.219 (99.405)
TRAINING - Epoch: [119][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.4716 (0.4265)	Prec@1 85.156 (85.465)	Prec@5 100.000 (99.387)
EVALUATING - Epoch: [119][0/79]	Time 0.447 (0.447)	Data 0.408 (0.408)	Loss 0.5596 (0.5596)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:44

 Epoch: 120	Training Loss 0.4290 	Training Prec@1 85.378 	Training Prec@5 99.390 	Validation Loss 0.5914 	Validation Prec@1 81.020 	Validation Prec@5 98.730 

lr: 0.09691229552699815
TRAINING - Epoch: [120][0/391]	Time 1.337 (1.337)	Data 0.423 (0.423)	Loss 0.3623 (0.3623)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [120][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.4105 (0.4254)	Prec@1 85.938 (85.698)	Prec@5 100.000 (99.327)
TRAINING - Epoch: [120][200/391]	Time 0.122 (0.122)	Data 0.001 (0.003)	Loss 0.3364 (0.4256)	Prec@1 89.844 (85.665)	Prec@5 100.000 (99.351)
TRAINING - Epoch: [120][300/391]	Time 0.121 (0.121)	Data 0.001 (0.002)	Loss 0.4422 (0.4297)	Prec@1 85.156 (85.390)	Prec@5 99.219 (99.341)
EVALUATING - Epoch: [120][0/79]	Time 0.420 (0.420)	Data 0.378 (0.378)	Loss 0.6036 (0.6036)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:49:34

 Epoch: 121	Training Loss 0.4303 	Training Prec@1 85.356 	Training Prec@5 99.358 	Validation Loss 0.7667 	Validation Prec@1 75.920 	Validation Prec@5 98.350 

lr: 0.09685749930217188
TRAINING - Epoch: [121][0/391]	Time 1.325 (1.325)	Data 0.429 (0.429)	Loss 0.3740 (0.3740)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [121][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.4045 (0.4237)	Prec@1 84.375 (85.388)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [121][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.5429 (0.4218)	Prec@1 83.594 (85.564)	Prec@5 99.219 (99.394)
TRAINING - Epoch: [121][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3245 (0.4245)	Prec@1 87.500 (85.468)	Prec@5 100.000 (99.380)
EVALUATING - Epoch: [121][0/79]	Time 0.428 (0.428)	Data 0.385 (0.385)	Loss 0.7417 (0.7417)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:59

 Epoch: 122	Training Loss 0.4273 	Training Prec@1 85.366 	Training Prec@5 99.382 	Validation Loss 0.8697 	Validation Prec@1 74.210 	Validation Prec@5 96.910 

lr: 0.09680223689071363
TRAINING - Epoch: [122][0/391]	Time 1.290 (1.290)	Data 0.409 (0.409)	Loss 0.5601 (0.5601)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [122][100/391]	Time 0.107 (0.125)	Data 0.000 (0.004)	Loss 0.5085 (0.4139)	Prec@1 82.812 (86.030)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [122][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.4434 (0.4227)	Prec@1 85.938 (85.704)	Prec@5 99.219 (99.394)
TRAINING - Epoch: [122][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3896 (0.4271)	Prec@1 86.719 (85.447)	Prec@5 99.219 (99.356)
EVALUATING - Epoch: [122][0/79]	Time 0.450 (0.450)	Data 0.409 (0.409)	Loss 0.4950 (0.4950)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:12

 Epoch: 123	Training Loss 0.4276 	Training Prec@1 85.396 	Training Prec@5 99.362 	Validation Loss 0.7388 	Validation Prec@1 74.810 	Validation Prec@5 98.100 

lr: 0.09674650884243076
TRAINING - Epoch: [123][0/391]	Time 1.367 (1.367)	Data 0.406 (0.406)	Loss 0.4392 (0.4392)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [123][100/391]	Time 0.115 (0.129)	Data 0.000 (0.004)	Loss 0.3820 (0.4183)	Prec@1 85.938 (85.435)	Prec@5 99.219 (99.459)
TRAINING - Epoch: [123][200/391]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.4358 (0.4240)	Prec@1 89.062 (85.335)	Prec@5 98.438 (99.456)
TRAINING - Epoch: [123][300/391]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3208 (0.4235)	Prec@1 88.281 (85.429)	Prec@5 99.219 (99.395)
EVALUATING - Epoch: [123][0/79]	Time 0.439 (0.439)	Data 0.397 (0.397)	Loss 1.0005 (1.0005)	Prec@1 66.406 (66.406)	Prec@5 96.875 (96.875)
Time cost: 00:50	Time of Finish: 2022-03-24 03:06:23

 Epoch: 124	Training Loss 0.4258 	Training Prec@1 85.342 	Training Prec@5 99.386 	Validation Loss 1.0781 	Validation Prec@1 67.180 	Validation Prec@5 95.680 

lr: 0.09669031571176322
TRAINING - Epoch: [124][0/391]	Time 1.262 (1.262)	Data 0.371 (0.371)	Loss 0.3065 (0.3065)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [124][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.4195 (0.4092)	Prec@1 85.938 (86.046)	Prec@5 100.000 (99.373)
TRAINING - Epoch: [124][200/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.5791 (0.4211)	Prec@1 78.125 (85.549)	Prec@5 99.219 (99.382)
TRAINING - Epoch: [124][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3809 (0.4258)	Prec@1 88.281 (85.426)	Prec@5 99.219 (99.367)
EVALUATING - Epoch: [124][0/79]	Time 0.436 (0.436)	Data 0.390 (0.390)	Loss 0.7473 (0.7473)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:19

 Epoch: 125	Training Loss 0.4298 	Training Prec@1 85.314 	Training Prec@5 99.340 	Validation Loss 0.6721 	Validation Prec@1 78.360 	Validation Prec@5 98.450 

lr: 0.09663365805777813
TRAINING - Epoch: [125][0/391]	Time 1.314 (1.314)	Data 0.402 (0.402)	Loss 0.3757 (0.3757)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [125][100/391]	Time 0.114 (0.127)	Data 0.000 (0.004)	Loss 0.4035 (0.4203)	Prec@1 82.812 (85.241)	Prec@5 100.000 (99.327)
TRAINING - Epoch: [125][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3687 (0.4260)	Prec@1 85.938 (85.207)	Prec@5 100.000 (99.351)
TRAINING - Epoch: [125][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.4771 (0.4292)	Prec@1 85.938 (85.224)	Prec@5 100.000 (99.291)
EVALUATING - Epoch: [125][0/79]	Time 0.414 (0.414)	Data 0.376 (0.376)	Loss 0.4646 (0.4646)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:55

 Epoch: 126	Training Loss 0.4278 	Training Prec@1 85.252 	Training Prec@5 99.320 	Validation Loss 0.6324 	Validation Prec@1 79.450 	Validation Prec@5 98.980 

lr: 0.09657653644416415
TRAINING - Epoch: [126][0/391]	Time 1.330 (1.330)	Data 0.418 (0.418)	Loss 0.4174 (0.4174)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [126][100/391]	Time 0.121 (0.126)	Data 0.001 (0.005)	Loss 0.4059 (0.4227)	Prec@1 85.156 (85.597)	Prec@5 100.000 (99.350)
TRAINING - Epoch: [126][200/391]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.6564 (0.4271)	Prec@1 75.000 (85.483)	Prec@5 96.875 (99.289)
TRAINING - Epoch: [126][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.6633 (0.4331)	Prec@1 77.344 (85.252)	Prec@5 99.219 (99.310)
EVALUATING - Epoch: [126][0/79]	Time 0.418 (0.418)	Data 0.382 (0.382)	Loss 0.8518 (0.8518)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:43:39

 Epoch: 127	Training Loss 0.4304 	Training Prec@1 85.284 	Training Prec@5 99.344 	Validation Loss 0.7817 	Validation Prec@1 75.740 	Validation Prec@5 97.760 

lr: 0.0965189514392259
TRAINING - Epoch: [127][0/391]	Time 1.322 (1.322)	Data 0.426 (0.426)	Loss 0.4798 (0.4798)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [127][100/391]	Time 0.111 (0.127)	Data 0.000 (0.005)	Loss 0.3282 (0.4170)	Prec@1 91.406 (85.736)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [127][200/391]	Time 0.110 (0.120)	Data 0.000 (0.003)	Loss 0.4220 (0.4214)	Prec@1 86.719 (85.549)	Prec@5 100.000 (99.370)
TRAINING - Epoch: [127][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.4985 (0.4233)	Prec@1 82.812 (85.496)	Prec@5 99.219 (99.364)
EVALUATING - Epoch: [127][0/79]	Time 0.491 (0.491)	Data 0.458 (0.458)	Loss 0.7272 (0.7272)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:35

 Epoch: 128	Training Loss 0.4294 	Training Prec@1 85.270 	Training Prec@5 99.336 	Validation Loss 0.8062 	Validation Prec@1 74.910 	Validation Prec@5 97.790 

lr: 0.09646090361587825
TRAINING - Epoch: [128][0/391]	Time 1.283 (1.283)	Data 0.368 (0.368)	Loss 0.4371 (0.4371)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [128][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.4975 (0.4192)	Prec@1 80.469 (85.497)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [128][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3723 (0.4228)	Prec@1 86.719 (85.386)	Prec@5 99.219 (99.421)
TRAINING - Epoch: [128][300/391]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.4078 (0.4302)	Prec@1 85.156 (85.185)	Prec@5 100.000 (99.372)
EVALUATING - Epoch: [128][0/79]	Time 0.432 (0.432)	Data 0.399 (0.399)	Loss 0.6182 (0.6182)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:44	Time of Finish: 2022-03-24 01:41:06

 Epoch: 129	Training Loss 0.4362 	Training Prec@1 85.010 	Training Prec@5 99.358 	Validation Loss 0.7240 	Validation Prec@1 77.570 	Validation Prec@5 98.220 

lr: 0.09640239355164071
TRAINING - Epoch: [129][0/391]	Time 1.288 (1.288)	Data 0.409 (0.409)	Loss 0.4157 (0.4157)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [129][100/391]	Time 0.115 (0.129)	Data 0.000 (0.004)	Loss 0.5087 (0.4303)	Prec@1 85.156 (85.373)	Prec@5 100.000 (99.312)
TRAINING - Epoch: [129][200/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.4662 (0.4327)	Prec@1 85.938 (85.327)	Prec@5 98.438 (99.347)
TRAINING - Epoch: [129][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4863 (0.4330)	Prec@1 81.250 (85.174)	Prec@5 100.000 (99.359)
EVALUATING - Epoch: [129][0/79]	Time 0.438 (0.438)	Data 0.401 (0.401)	Loss 0.6737 (0.6737)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:49:37

 Epoch: 130	Training Loss 0.4312 	Training Prec@1 85.272 	Training Prec@5 99.336 	Validation Loss 0.6555 	Validation Prec@1 78.740 	Validation Prec@5 98.670 

lr: 0.0963434218286316
TRAINING - Epoch: [130][0/391]	Time 1.300 (1.300)	Data 0.415 (0.415)	Loss 0.3089 (0.3089)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [130][100/391]	Time 0.119 (0.125)	Data 0.000 (0.004)	Loss 0.4826 (0.4141)	Prec@1 82.812 (85.535)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [130][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3044 (0.4314)	Prec@1 88.281 (85.051)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [130][300/391]	Time 0.108 (0.119)	Data 0.000 (0.002)	Loss 0.4260 (0.4319)	Prec@1 86.719 (85.052)	Prec@5 97.656 (99.356)
EVALUATING - Epoch: [130][0/79]	Time 0.428 (0.428)	Data 0.383 (0.383)	Loss 0.6442 (0.6442)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:21

 Epoch: 131	Training Loss 0.4356 	Training Prec@1 84.912 	Training Prec@5 99.334 	Validation Loss 0.6547 	Validation Prec@1 78.960 	Validation Prec@5 98.810 

lr: 0.09628398903356236
TRAINING - Epoch: [131][0/391]	Time 1.340 (1.340)	Data 0.444 (0.444)	Loss 0.4207 (0.4207)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [131][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.4432 (0.4207)	Prec@1 87.500 (85.713)	Prec@5 97.656 (99.474)
TRAINING - Epoch: [131][200/391]	Time 0.110 (0.120)	Data 0.000 (0.003)	Loss 0.4972 (0.4206)	Prec@1 84.375 (85.700)	Prec@5 99.219 (99.456)
TRAINING - Epoch: [131][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.3706 (0.4223)	Prec@1 86.719 (85.623)	Prec@5 100.000 (99.442)
EVALUATING - Epoch: [131][0/79]	Time 0.439 (0.439)	Data 0.404 (0.404)	Loss 0.5201 (0.5201)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:50

 Epoch: 132	Training Loss 0.4292 	Training Prec@1 85.422 	Training Prec@5 99.424 	Validation Loss 0.6023 	Validation Prec@1 80.160 	Validation Prec@5 98.640 

lr: 0.09622409575773158
TRAINING - Epoch: [132][0/391]	Time 1.313 (1.313)	Data 0.419 (0.419)	Loss 0.2936 (0.2936)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [132][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.3163 (0.4179)	Prec@1 87.500 (85.582)	Prec@5 100.000 (99.389)
TRAINING - Epoch: [132][200/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3777 (0.4238)	Prec@1 87.500 (85.560)	Prec@5 98.438 (99.382)
TRAINING - Epoch: [132][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3782 (0.4223)	Prec@1 87.500 (85.649)	Prec@5 100.000 (99.421)
EVALUATING - Epoch: [132][0/79]	Time 0.437 (0.437)	Data 0.399 (0.399)	Loss 0.8221 (0.8221)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:51

 Epoch: 133	Training Loss 0.4239 	Training Prec@1 85.584 	Training Prec@5 99.410 	Validation Loss 0.9253 	Validation Prec@1 71.490 	Validation Prec@5 97.880 

lr: 0.09616374259701922
TRAINING - Epoch: [133][0/391]	Time 1.267 (1.267)	Data 0.414 (0.414)	Loss 0.4306 (0.4306)	Prec@1 85.938 (85.938)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [133][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.4409 (0.4255)	Prec@1 85.938 (85.427)	Prec@5 100.000 (99.319)
TRAINING - Epoch: [133][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.3581 (0.4350)	Prec@1 85.938 (85.125)	Prec@5 100.000 (99.370)
TRAINING - Epoch: [133][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3797 (0.4312)	Prec@1 87.500 (85.224)	Prec@5 100.000 (99.380)
EVALUATING - Epoch: [133][0/79]	Time 0.438 (0.438)	Data 0.400 (0.400)	Loss 0.9737 (0.9737)	Prec@1 72.656 (72.656)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:18:27

 Epoch: 134	Training Loss 0.4357 	Training Prec@1 85.082 	Training Prec@5 99.378 	Validation Loss 1.0071 	Validation Prec@1 72.140 	Validation Prec@5 98.560 

lr: 0.09610293015188064
TRAINING - Epoch: [134][0/391]	Time 1.327 (1.327)	Data 0.443 (0.443)	Loss 0.4274 (0.4274)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [134][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.4072 (0.4194)	Prec@1 85.938 (85.605)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [134][200/391]	Time 0.116 (0.118)	Data 0.000 (0.003)	Loss 0.3589 (0.4185)	Prec@1 86.719 (85.541)	Prec@5 100.000 (99.347)
TRAINING - Epoch: [134][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4400 (0.4213)	Prec@1 82.812 (85.527)	Prec@5 99.219 (99.330)
EVALUATING - Epoch: [134][0/79]	Time 0.423 (0.423)	Data 0.381 (0.381)	Loss 0.7325 (0.7325)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:19

 Epoch: 135	Training Loss 0.4244 	Training Prec@1 85.506 	Training Prec@5 99.316 	Validation Loss 0.7399 	Validation Prec@1 77.370 	Validation Prec@5 98.370 

lr: 0.09604165902734065
TRAINING - Epoch: [135][0/391]	Time 1.332 (1.332)	Data 0.441 (0.441)	Loss 0.3098 (0.3098)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [135][100/391]	Time 0.111 (0.127)	Data 0.000 (0.005)	Loss 0.3544 (0.4341)	Prec@1 88.281 (84.855)	Prec@5 99.219 (99.381)
TRAINING - Epoch: [135][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.2963 (0.4281)	Prec@1 89.062 (85.145)	Prec@5 100.000 (99.363)
TRAINING - Epoch: [135][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.4401 (0.4326)	Prec@1 82.812 (85.058)	Prec@5 100.000 (99.341)
EVALUATING - Epoch: [135][0/79]	Time 0.442 (0.442)	Data 0.410 (0.410)	Loss 0.4957 (0.4957)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:53

 Epoch: 136	Training Loss 0.4334 	Training Prec@1 85.128 	Training Prec@5 99.340 	Validation Loss 0.6167 	Validation Prec@1 79.730 	Validation Prec@5 98.740 

lr: 0.09597992983298743
TRAINING - Epoch: [136][0/391]	Time 1.326 (1.326)	Data 0.422 (0.422)	Loss 0.3983 (0.3983)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [136][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.5317 (0.4150)	Prec@1 82.812 (85.442)	Prec@5 98.438 (99.373)
TRAINING - Epoch: [136][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.4008 (0.4238)	Prec@1 87.500 (85.121)	Prec@5 98.438 (99.363)
TRAINING - Epoch: [136][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.3649 (0.4264)	Prec@1 89.062 (85.143)	Prec@5 100.000 (99.377)
EVALUATING - Epoch: [136][0/79]	Time 0.454 (0.454)	Data 0.407 (0.407)	Loss 0.9068 (0.9068)	Prec@1 72.656 (72.656)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:02

 Epoch: 137	Training Loss 0.4281 	Training Prec@1 85.096 	Training Prec@5 99.384 	Validation Loss 0.8475 	Validation Prec@1 73.170 	Validation Prec@5 96.860 

lr: 0.09591774318296659
TRAINING - Epoch: [137][0/391]	Time 1.348 (1.348)	Data 0.432 (0.432)	Loss 0.5565 (0.5565)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [137][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.3664 (0.4274)	Prec@1 86.719 (85.419)	Prec@5 100.000 (99.281)
TRAINING - Epoch: [137][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3942 (0.4240)	Prec@1 84.375 (85.514)	Prec@5 98.438 (99.304)
TRAINING - Epoch: [137][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3636 (0.4288)	Prec@1 89.844 (85.447)	Prec@5 100.000 (99.307)
EVALUATING - Epoch: [137][0/79]	Time 0.444 (0.444)	Data 0.410 (0.410)	Loss 0.6215 (0.6215)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:19:48

 Epoch: 138	Training Loss 0.4275 	Training Prec@1 85.476 	Training Prec@5 99.324 	Validation Loss 0.7258 	Validation Prec@1 76.310 	Validation Prec@5 98.610 

lr: 0.09585509969597487
TRAINING - Epoch: [138][0/391]	Time 1.341 (1.341)	Data 0.456 (0.456)	Loss 0.3768 (0.3768)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [138][100/391]	Time 0.109 (0.125)	Data 0.000 (0.005)	Loss 0.3801 (0.4158)	Prec@1 87.500 (86.092)	Prec@5 98.438 (99.412)
TRAINING - Epoch: [138][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.3816 (0.4198)	Prec@1 85.156 (85.720)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [138][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.4353 (0.4208)	Prec@1 89.062 (85.745)	Prec@5 99.219 (99.380)
EVALUATING - Epoch: [138][0/79]	Time 0.424 (0.424)	Data 0.384 (0.384)	Loss 0.6559 (0.6559)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:51

 Epoch: 139	Training Loss 0.4248 	Training Prec@1 85.534 	Training Prec@5 99.380 	Validation Loss 0.6752 	Validation Prec@1 78.540 	Validation Prec@5 98.340 

lr: 0.0957919999952542
TRAINING - Epoch: [139][0/391]	Time 1.357 (1.357)	Data 0.459 (0.459)	Loss 0.3157 (0.3157)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [139][100/391]	Time 0.108 (0.125)	Data 0.000 (0.005)	Loss 0.2346 (0.4055)	Prec@1 90.625 (85.968)	Prec@5 100.000 (99.366)
TRAINING - Epoch: [139][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.4192 (0.4119)	Prec@1 84.375 (85.957)	Prec@5 100.000 (99.398)
TRAINING - Epoch: [139][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3618 (0.4144)	Prec@1 87.500 (85.725)	Prec@5 97.656 (99.359)
EVALUATING - Epoch: [139][0/79]	Time 0.452 (0.452)	Data 0.413 (0.413)	Loss 0.7003 (0.7003)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:37

 Epoch: 140	Training Loss 0.4214 	Training Prec@1 85.594 	Training Prec@5 99.330 	Validation Loss 0.6516 	Validation Prec@1 78.430 	Validation Prec@5 98.720 

lr: 0.09572844470858534
TRAINING - Epoch: [140][0/391]	Time 1.301 (1.301)	Data 0.422 (0.422)	Loss 0.3924 (0.3924)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [140][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.3902 (0.4004)	Prec@1 85.938 (86.286)	Prec@5 100.000 (99.343)
TRAINING - Epoch: [140][200/391]	Time 0.109 (0.120)	Data 0.000 (0.003)	Loss 0.4696 (0.4090)	Prec@1 79.688 (86.004)	Prec@5 100.000 (99.363)
TRAINING - Epoch: [140][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3195 (0.4195)	Prec@1 87.500 (85.766)	Prec@5 99.219 (99.341)
EVALUATING - Epoch: [140][0/79]	Time 0.455 (0.455)	Data 0.412 (0.412)	Loss 0.4964 (0.4964)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:18

 Epoch: 141	Training Loss 0.4215 	Training Prec@1 85.680 	Training Prec@5 99.342 	Validation Loss 0.5742 	Validation Prec@1 80.700 	Validation Prec@5 99.040 

lr: 0.09566443446828168
TRAINING - Epoch: [141][0/391]	Time 1.623 (1.623)	Data 0.467 (0.467)	Loss 0.4127 (0.4127)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [141][100/391]	Time 0.114 (0.134)	Data 0.000 (0.005)	Loss 0.3497 (0.4149)	Prec@1 89.062 (85.767)	Prec@5 99.219 (99.381)
TRAINING - Epoch: [141][200/391]	Time 0.118 (0.126)	Data 0.000 (0.003)	Loss 0.4604 (0.4191)	Prec@1 84.375 (85.568)	Prec@5 100.000 (99.405)
TRAINING - Epoch: [141][300/391]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.3469 (0.4240)	Prec@1 87.500 (85.525)	Prec@5 100.000 (99.356)
EVALUATING - Epoch: [141][0/79]	Time 0.419 (0.419)	Data 0.386 (0.386)	Loss 0.5956 (0.5956)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:56:43

 Epoch: 142	Training Loss 0.4232 	Training Prec@1 85.560 	Training Prec@5 99.366 	Validation Loss 0.6697 	Validation Prec@1 78.040 	Validation Prec@5 98.590 

lr: 0.095599969911183
TRAINING - Epoch: [142][0/391]	Time 1.301 (1.301)	Data 0.416 (0.416)	Loss 0.3502 (0.3502)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [142][100/391]	Time 0.114 (0.125)	Data 0.000 (0.004)	Loss 0.3086 (0.4144)	Prec@1 90.625 (85.566)	Prec@5 99.219 (99.381)
TRAINING - Epoch: [142][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3290 (0.4196)	Prec@1 88.281 (85.525)	Prec@5 99.219 (99.398)
TRAINING - Epoch: [142][300/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.5539 (0.4257)	Prec@1 83.594 (85.351)	Prec@5 98.438 (99.390)
EVALUATING - Epoch: [142][0/79]	Time 0.461 (0.461)	Data 0.427 (0.427)	Loss 0.6817 (0.6817)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:54

 Epoch: 143	Training Loss 0.4287 	Training Prec@1 85.314 	Training Prec@5 99.356 	Validation Loss 0.8583 	Validation Prec@1 74.870 	Validation Prec@5 98.390 

lr: 0.09553505167864906
TRAINING - Epoch: [143][0/391]	Time 1.343 (1.343)	Data 0.465 (0.465)	Loss 0.4092 (0.4092)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [143][100/391]	Time 0.116 (0.129)	Data 0.000 (0.005)	Loss 0.4583 (0.4121)	Prec@1 82.031 (85.922)	Prec@5 100.000 (99.319)
TRAINING - Epoch: [143][200/391]	Time 0.119 (0.123)	Data 0.000 (0.003)	Loss 0.3741 (0.4167)	Prec@1 85.156 (85.809)	Prec@5 99.219 (99.409)
TRAINING - Epoch: [143][300/391]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.4403 (0.4213)	Prec@1 84.375 (85.507)	Prec@5 100.000 (99.408)
EVALUATING - Epoch: [143][0/79]	Time 0.419 (0.419)	Data 0.384 (0.384)	Loss 0.7283 (0.7283)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:50:16

 Epoch: 144	Training Loss 0.4192 	Training Prec@1 85.582 	Training Prec@5 99.406 	Validation Loss 0.8610 	Validation Prec@1 74.510 	Validation Prec@5 98.660 

lr: 0.09546968041655324
TRAINING - Epoch: [144][0/391]	Time 1.337 (1.337)	Data 0.438 (0.438)	Loss 0.4955 (0.4955)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [144][100/391]	Time 0.112 (0.127)	Data 0.000 (0.005)	Loss 0.3798 (0.4099)	Prec@1 86.719 (86.092)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [144][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.4307 (0.4289)	Prec@1 86.719 (85.580)	Prec@5 99.219 (99.324)
TRAINING - Epoch: [144][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.3425 (0.4265)	Prec@1 89.062 (85.527)	Prec@5 100.000 (99.289)
EVALUATING - Epoch: [144][0/79]	Time 0.439 (0.439)	Data 0.402 (0.402)	Loss 0.4465 (0.4465)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:32

 Epoch: 145	Training Loss 0.4266 	Training Prec@1 85.502 	Training Prec@5 99.300 	Validation Loss 0.5580 	Validation Prec@1 81.470 	Validation Prec@5 98.940 

lr: 0.09540385677527613
TRAINING - Epoch: [145][0/391]	Time 1.330 (1.330)	Data 0.438 (0.438)	Loss 0.3433 (0.3433)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [145][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.5278 (0.4039)	Prec@1 83.594 (86.270)	Prec@5 98.438 (99.474)
TRAINING - Epoch: [145][200/391]	Time 0.112 (0.120)	Data 0.000 (0.003)	Loss 0.4883 (0.4129)	Prec@1 80.469 (85.903)	Prec@5 99.219 (99.464)
TRAINING - Epoch: [145][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4991 (0.4121)	Prec@1 85.938 (85.860)	Prec@5 100.000 (99.403)
EVALUATING - Epoch: [145][0/79]	Time 0.437 (0.437)	Data 0.389 (0.389)	Loss 0.7065 (0.7065)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:32

 Epoch: 146	Training Loss 0.4174 	Training Prec@1 85.730 	Training Prec@5 99.394 	Validation Loss 0.7338 	Validation Prec@1 76.180 	Validation Prec@5 98.010 

lr: 0.09533758140969908
TRAINING - Epoch: [146][0/391]	Time 1.279 (1.279)	Data 0.354 (0.354)	Loss 0.3458 (0.3458)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [146][100/391]	Time 0.111 (0.127)	Data 0.000 (0.004)	Loss 0.3076 (0.4138)	Prec@1 89.844 (86.139)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [146][200/391]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3218 (0.4194)	Prec@1 90.625 (85.821)	Prec@5 100.000 (99.370)
TRAINING - Epoch: [146][300/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.5962 (0.4174)	Prec@1 82.812 (85.727)	Prec@5 98.438 (99.385)
EVALUATING - Epoch: [146][0/79]	Time 0.421 (0.421)	Data 0.394 (0.394)	Loss 0.5654 (0.5654)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:46

 Epoch: 147	Training Loss 0.4218 	Training Prec@1 85.534 	Training Prec@5 99.354 	Validation Loss 0.6878 	Validation Prec@1 78.600 	Validation Prec@5 98.640 

lr: 0.09527085497919767
TRAINING - Epoch: [147][0/391]	Time 1.311 (1.311)	Data 0.446 (0.446)	Loss 0.3851 (0.3851)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [147][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.4498 (0.4037)	Prec@1 85.156 (86.231)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [147][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.4026 (0.4103)	Prec@1 85.938 (85.875)	Prec@5 98.438 (99.464)
TRAINING - Epoch: [147][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4813 (0.4167)	Prec@1 82.031 (85.725)	Prec@5 99.219 (99.387)
EVALUATING - Epoch: [147][0/79]	Time 0.444 (0.444)	Data 0.403 (0.403)	Loss 0.4977 (0.4977)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:58

 Epoch: 148	Training Loss 0.4195 	Training Prec@1 85.680 	Training Prec@5 99.394 	Validation Loss 0.6251 	Validation Prec@1 79.330 	Validation Prec@5 98.920 

lr: 0.09520367814763508
TRAINING - Epoch: [148][0/391]	Time 1.231 (1.231)	Data 0.376 (0.376)	Loss 0.3133 (0.3133)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [148][100/391]	Time 0.115 (0.128)	Data 0.000 (0.004)	Loss 0.3827 (0.4108)	Prec@1 85.938 (86.216)	Prec@5 99.219 (99.312)
TRAINING - Epoch: [148][200/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.4523 (0.4144)	Prec@1 85.938 (85.887)	Prec@5 98.438 (99.328)
TRAINING - Epoch: [148][300/391]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3896 (0.4181)	Prec@1 88.281 (85.727)	Prec@5 100.000 (99.323)
EVALUATING - Epoch: [148][0/79]	Time 0.446 (0.446)	Data 0.410 (0.410)	Loss 0.7743 (0.7743)	Prec@1 73.438 (73.438)	Prec@5 95.312 (95.312)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:39

 Epoch: 149	Training Loss 0.4219 	Training Prec@1 85.636 	Training Prec@5 99.322 	Validation Loss 0.7703 	Validation Prec@1 76.070 	Validation Prec@5 98.170 

lr: 0.09513605158335557
TRAINING - Epoch: [149][0/391]	Time 1.334 (1.334)	Data 0.417 (0.417)	Loss 0.3095 (0.3095)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [149][100/391]	Time 0.104 (0.125)	Data 0.000 (0.005)	Loss 0.4387 (0.3988)	Prec@1 85.938 (86.711)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [149][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4420 (0.4172)	Prec@1 85.938 (85.965)	Prec@5 100.000 (99.382)
TRAINING - Epoch: [149][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.3705 (0.4214)	Prec@1 85.938 (85.652)	Prec@5 99.219 (99.359)
EVALUATING - Epoch: [149][0/79]	Time 0.442 (0.442)	Data 0.399 (0.399)	Loss 0.7575 (0.7575)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:40

 Epoch: 150	Training Loss 0.4253 	Training Prec@1 85.524 	Training Prec@5 99.372 	Validation Loss 0.6715 	Validation Prec@1 78.530 	Validation Prec@5 98.710 

lr: 0.09506797595917782
TRAINING - Epoch: [150][0/391]	Time 1.298 (1.298)	Data 0.445 (0.445)	Loss 0.4295 (0.4295)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [150][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.2982 (0.4145)	Prec@1 88.281 (86.038)	Prec@5 100.000 (99.404)
TRAINING - Epoch: [150][200/391]	Time 0.112 (0.116)	Data 0.000 (0.003)	Loss 0.4500 (0.4184)	Prec@1 82.812 (85.914)	Prec@5 99.219 (99.398)
TRAINING - Epoch: [150][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.6078 (0.4185)	Prec@1 82.031 (85.841)	Prec@5 100.000 (99.374)
EVALUATING - Epoch: [150][0/79]	Time 0.445 (0.445)	Data 0.413 (0.413)	Loss 0.6410 (0.6410)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:15:35

 Epoch: 151	Training Loss 0.4173 	Training Prec@1 85.812 	Training Prec@5 99.412 	Validation Loss 0.6676 	Validation Prec@1 78.150 	Validation Prec@5 98.470 

lr: 0.09499945195238821
TRAINING - Epoch: [151][0/391]	Time 1.280 (1.280)	Data 0.415 (0.415)	Loss 0.4160 (0.4160)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [151][100/391]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 0.3594 (0.4065)	Prec@1 88.281 (86.023)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [151][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.5217 (0.4122)	Prec@1 82.812 (85.868)	Prec@5 98.438 (99.452)
TRAINING - Epoch: [151][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.4540 (0.4134)	Prec@1 84.375 (85.995)	Prec@5 100.000 (99.426)
EVALUATING - Epoch: [151][0/79]	Time 0.441 (0.441)	Data 0.405 (0.405)	Loss 0.4559 (0.4559)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:08

 Epoch: 152	Training Loss 0.4144 	Training Prec@1 85.988 	Training Prec@5 99.404 	Validation Loss 0.5545 	Validation Prec@1 81.610 	Validation Prec@5 99.060 

lr: 0.09493048024473406
TRAINING - Epoch: [152][0/391]	Time 1.313 (1.313)	Data 0.412 (0.412)	Loss 0.4037 (0.4037)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [152][100/391]	Time 0.114 (0.127)	Data 0.000 (0.004)	Loss 0.4318 (0.4047)	Prec@1 86.719 (86.270)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [152][200/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.4193 (0.4100)	Prec@1 85.938 (85.949)	Prec@5 100.000 (99.464)
TRAINING - Epoch: [152][300/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3754 (0.4135)	Prec@1 87.500 (85.906)	Prec@5 99.219 (99.476)
EVALUATING - Epoch: [152][0/79]	Time 0.422 (0.422)	Data 0.383 (0.383)	Loss 0.6977 (0.6977)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:49	Time of Finish: 2022-03-24 02:58:28

 Epoch: 153	Training Loss 0.4179 	Training Prec@1 85.802 	Training Prec@5 99.432 	Validation Loss 0.6876 	Validation Prec@1 78.610 	Validation Prec@5 98.660 

lr: 0.09486106152241695
TRAINING - Epoch: [153][0/391]	Time 1.354 (1.354)	Data 0.445 (0.445)	Loss 0.4585 (0.4585)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [153][100/391]	Time 0.111 (0.129)	Data 0.000 (0.005)	Loss 0.3852 (0.4034)	Prec@1 87.500 (86.077)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [153][200/391]	Time 0.113 (0.122)	Data 0.000 (0.003)	Loss 0.3862 (0.4139)	Prec@1 88.281 (85.922)	Prec@5 97.656 (99.386)
TRAINING - Epoch: [153][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.5016 (0.4143)	Prec@1 83.594 (85.925)	Prec@5 99.219 (99.387)
EVALUATING - Epoch: [153][0/79]	Time 0.435 (0.435)	Data 0.394 (0.394)	Loss 0.6577 (0.6577)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)
Time cost: 00:49	Time of Finish: 2022-03-24 02:47:12

 Epoch: 154	Training Loss 0.4235 	Training Prec@1 85.660 	Training Prec@5 99.356 	Validation Loss 0.8358 	Validation Prec@1 76.160 	Validation Prec@5 97.060 

lr: 0.09479119647608575
TRAINING - Epoch: [154][0/391]	Time 1.352 (1.352)	Data 0.425 (0.425)	Loss 0.4119 (0.4119)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [154][100/391]	Time 0.114 (0.130)	Data 0.000 (0.005)	Loss 0.4184 (0.4060)	Prec@1 89.844 (86.200)	Prec@5 98.438 (99.497)
TRAINING - Epoch: [154][200/391]	Time 0.118 (0.122)	Data 0.000 (0.003)	Loss 0.3781 (0.4107)	Prec@1 85.938 (86.144)	Prec@5 98.438 (99.409)
TRAINING - Epoch: [154][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4771 (0.4208)	Prec@1 82.031 (85.732)	Prec@5 100.000 (99.390)
EVALUATING - Epoch: [154][0/79]	Time 0.447 (0.447)	Data 0.410 (0.410)	Loss 0.7834 (0.7834)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:35

 Epoch: 155	Training Loss 0.4267 	Training Prec@1 85.532 	Training Prec@5 99.374 	Validation Loss 0.7907 	Validation Prec@1 75.440 	Validation Prec@5 98.410 

lr: 0.09472088580082985
TRAINING - Epoch: [155][0/391]	Time 1.270 (1.270)	Data 0.420 (0.420)	Loss 0.3149 (0.3149)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [155][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.4151 (0.4213)	Prec@1 86.719 (85.497)	Prec@5 98.438 (99.335)
TRAINING - Epoch: [155][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4375 (0.4248)	Prec@1 88.281 (85.502)	Prec@5 99.219 (99.347)
TRAINING - Epoch: [155][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.5032 (0.4253)	Prec@1 81.250 (85.559)	Prec@5 98.438 (99.369)
EVALUATING - Epoch: [155][0/79]	Time 0.440 (0.440)	Data 0.411 (0.411)	Loss 0.4744 (0.4744)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:02

 Epoch: 156	Training Loss 0.4248 	Training Prec@1 85.586 	Training Prec@5 99.380 	Validation Loss 0.6207 	Validation Prec@1 79.910 	Validation Prec@5 98.820 

lr: 0.09465013019617224
TRAINING - Epoch: [156][0/391]	Time 1.271 (1.271)	Data 0.417 (0.417)	Loss 0.2922 (0.2922)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [156][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.4986 (0.4034)	Prec@1 83.594 (86.317)	Prec@5 99.219 (99.451)
TRAINING - Epoch: [156][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4406 (0.4155)	Prec@1 82.031 (85.918)	Prec@5 99.219 (99.347)
TRAINING - Epoch: [156][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.5065 (0.4187)	Prec@1 85.156 (85.686)	Prec@5 100.000 (99.362)
EVALUATING - Epoch: [156][0/79]	Time 0.454 (0.454)	Data 0.415 (0.415)	Loss 0.4292 (0.4292)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:45

 Epoch: 157	Training Loss 0.4205 	Training Prec@1 85.616 	Training Prec@5 99.366 	Validation Loss 0.5832 	Validation Prec@1 81.050 	Validation Prec@5 98.820 

lr: 0.09457893036606248
TRAINING - Epoch: [157][0/391]	Time 1.330 (1.330)	Data 0.475 (0.475)	Loss 0.4194 (0.4194)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [157][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.3141 (0.3891)	Prec@1 86.719 (86.433)	Prec@5 99.219 (99.459)
TRAINING - Epoch: [157][200/391]	Time 0.118 (0.118)	Data 0.000 (0.003)	Loss 0.3933 (0.4035)	Prec@1 83.594 (86.221)	Prec@5 99.219 (99.471)
TRAINING - Epoch: [157][300/391]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.4471 (0.4110)	Prec@1 84.375 (85.930)	Prec@5 99.219 (99.437)
EVALUATING - Epoch: [157][0/79]	Time 0.427 (0.427)	Data 0.381 (0.381)	Loss 0.9625 (0.9625)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:34

 Epoch: 158	Training Loss 0.4171 	Training Prec@1 85.738 	Training Prec@5 99.412 	Validation Loss 0.8692 	Validation Prec@1 73.900 	Validation Prec@5 97.400 

lr: 0.09450728701886979
TRAINING - Epoch: [158][0/391]	Time 1.288 (1.288)	Data 0.436 (0.436)	Loss 0.3383 (0.3383)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [158][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.3893 (0.4058)	Prec@1 85.156 (85.845)	Prec@5 99.219 (99.327)
TRAINING - Epoch: [158][200/391]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.4560 (0.4046)	Prec@1 87.500 (86.015)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [158][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.4115 (0.4106)	Prec@1 85.156 (85.904)	Prec@5 100.000 (99.390)
EVALUATING - Epoch: [158][0/79]	Time 0.410 (0.410)	Data 0.383 (0.383)	Loss 0.5326 (0.5326)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 01:42:18

 Epoch: 159	Training Loss 0.4145 	Training Prec@1 85.770 	Training Prec@5 99.352 	Validation Loss 0.7130 	Validation Prec@1 76.000 	Validation Prec@5 98.420 

lr: 0.09443520086737589
TRAINING - Epoch: [159][0/391]	Time 1.321 (1.321)	Data 0.416 (0.416)	Loss 0.3905 (0.3905)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [159][100/391]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.4633 (0.4066)	Prec@1 87.500 (85.968)	Prec@5 96.875 (99.497)
TRAINING - Epoch: [159][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4831 (0.4096)	Prec@1 83.594 (85.953)	Prec@5 98.438 (99.460)
TRAINING - Epoch: [159][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3221 (0.4126)	Prec@1 89.062 (85.938)	Prec@5 100.000 (99.445)
EVALUATING - Epoch: [159][0/79]	Time 0.484 (0.484)	Data 0.449 (0.449)	Loss 0.7751 (0.7751)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:09

 Epoch: 160	Training Loss 0.4153 	Training Prec@1 85.818 	Training Prec@5 99.424 	Validation Loss 0.8454 	Validation Prec@1 74.240 	Validation Prec@5 97.000 

lr: 0.09436267262876803
TRAINING - Epoch: [160][0/391]	Time 1.623 (1.623)	Data 0.434 (0.434)	Loss 0.5313 (0.5313)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [160][100/391]	Time 0.121 (0.135)	Data 0.000 (0.005)	Loss 0.4772 (0.3983)	Prec@1 82.812 (86.386)	Prec@5 98.438 (99.559)
TRAINING - Epoch: [160][200/391]	Time 0.109 (0.124)	Data 0.000 (0.003)	Loss 0.3557 (0.4122)	Prec@1 86.719 (85.914)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [160][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3597 (0.4135)	Prec@1 88.281 (85.826)	Prec@5 97.656 (99.437)
EVALUATING - Epoch: [160][0/79]	Time 0.430 (0.430)	Data 0.396 (0.396)	Loss 0.5683 (0.5683)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:38

 Epoch: 161	Training Loss 0.4156 	Training Prec@1 85.764 	Training Prec@5 99.398 	Validation Loss 0.5713 	Validation Prec@1 81.300 	Validation Prec@5 98.980 

lr: 0.09428970302463179
TRAINING - Epoch: [161][0/391]	Time 1.309 (1.309)	Data 0.421 (0.421)	Loss 0.3356 (0.3356)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [161][100/391]	Time 0.128 (0.129)	Data 0.001 (0.005)	Loss 0.4569 (0.4117)	Prec@1 87.500 (85.682)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [161][200/391]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.3462 (0.4126)	Prec@1 88.281 (85.747)	Prec@5 99.219 (99.440)
TRAINING - Epoch: [161][300/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.3405 (0.4104)	Prec@1 89.062 (85.906)	Prec@5 100.000 (99.450)
EVALUATING - Epoch: [161][0/79]	Time 0.451 (0.451)	Data 0.413 (0.413)	Loss 0.6335 (0.6335)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:49	Time of Finish: 2022-03-24 02:51:21

 Epoch: 162	Training Loss 0.4084 	Training Prec@1 85.940 	Training Prec@5 99.446 	Validation Loss 0.7449 	Validation Prec@1 77.770 	Validation Prec@5 97.830 

lr: 0.09421629278094386
TRAINING - Epoch: [162][0/391]	Time 1.341 (1.341)	Data 0.452 (0.452)	Loss 0.3122 (0.3122)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [162][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.4361 (0.4022)	Prec@1 84.375 (86.255)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [162][200/391]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.5737 (0.4110)	Prec@1 79.688 (85.945)	Prec@5 98.438 (99.440)
TRAINING - Epoch: [162][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.3003 (0.4042)	Prec@1 89.062 (86.117)	Prec@5 100.000 (99.460)
EVALUATING - Epoch: [162][0/79]	Time 0.445 (0.445)	Data 0.401 (0.401)	Loss 0.6357 (0.6357)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:34

 Epoch: 163	Training Loss 0.4124 	Training Prec@1 85.852 	Training Prec@5 99.422 	Validation Loss 0.6379 	Validation Prec@1 78.770 	Validation Prec@5 98.990 

lr: 0.09414244262806495
TRAINING - Epoch: [163][0/391]	Time 1.356 (1.356)	Data 0.447 (0.447)	Loss 0.4417 (0.4417)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [163][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.3982 (0.4008)	Prec@1 85.156 (86.355)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [163][200/391]	Time 0.116 (0.122)	Data 0.000 (0.003)	Loss 0.3377 (0.4117)	Prec@1 85.156 (85.833)	Prec@5 100.000 (99.487)
TRAINING - Epoch: [163][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3443 (0.4228)	Prec@1 85.938 (85.626)	Prec@5 100.000 (99.413)
EVALUATING - Epoch: [163][0/79]	Time 0.430 (0.430)	Data 0.384 (0.384)	Loss 0.5116 (0.5116)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:54:04

 Epoch: 164	Training Loss 0.4243 	Training Prec@1 85.574 	Training Prec@5 99.386 	Validation Loss 0.6445 	Validation Prec@1 79.460 	Validation Prec@5 98.920 

lr: 0.09406815330073239
TRAINING - Epoch: [164][0/391]	Time 1.363 (1.363)	Data 0.420 (0.420)	Loss 0.4707 (0.4707)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [164][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.4758 (0.4013)	Prec@1 81.250 (85.961)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [164][200/391]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.3539 (0.4085)	Prec@1 88.281 (85.747)	Prec@5 100.000 (99.429)
TRAINING - Epoch: [164][300/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.4516 (0.4131)	Prec@1 82.031 (85.662)	Prec@5 99.219 (99.408)
EVALUATING - Epoch: [164][0/79]	Time 0.422 (0.422)	Data 0.383 (0.383)	Loss 0.5726 (0.5726)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:43:32

 Epoch: 165	Training Loss 0.4150 	Training Prec@1 85.638 	Training Prec@5 99.378 	Validation Loss 0.6220 	Validation Prec@1 80.170 	Validation Prec@5 98.420 

lr: 0.09399342553805283
TRAINING - Epoch: [165][0/391]	Time 1.326 (1.326)	Data 0.420 (0.420)	Loss 0.4762 (0.4762)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [165][100/391]	Time 0.121 (0.129)	Data 0.000 (0.005)	Loss 0.5516 (0.3985)	Prec@1 83.594 (86.239)	Prec@5 98.438 (99.505)
TRAINING - Epoch: [165][200/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.4868 (0.4100)	Prec@1 84.375 (85.996)	Prec@5 99.219 (99.394)
TRAINING - Epoch: [165][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.4357 (0.4122)	Prec@1 87.500 (85.958)	Prec@5 99.219 (99.359)
EVALUATING - Epoch: [165][0/79]	Time 0.437 (0.437)	Data 0.393 (0.393)	Loss 0.6185 (0.6185)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:49:04

 Epoch: 166	Training Loss 0.4124 	Training Prec@1 85.964 	Training Prec@5 99.372 	Validation Loss 0.6524 	Validation Prec@1 78.710 	Validation Prec@5 98.940 

lr: 0.093918260083495
TRAINING - Epoch: [166][0/391]	Time 1.284 (1.284)	Data 0.361 (0.361)	Loss 0.4101 (0.4101)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [166][100/391]	Time 0.119 (0.129)	Data 0.000 (0.004)	Loss 0.4421 (0.4030)	Prec@1 85.938 (86.293)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [166][200/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.4160 (0.4165)	Prec@1 86.719 (85.720)	Prec@5 99.219 (99.417)
TRAINING - Epoch: [166][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.4192 (0.4184)	Prec@1 80.469 (85.642)	Prec@5 99.219 (99.364)
EVALUATING - Epoch: [166][0/79]	Time 0.460 (0.460)	Data 0.418 (0.418)	Loss 0.8685 (0.8685)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:47:24

 Epoch: 167	Training Loss 0.4121 	Training Prec@1 85.854 	Training Prec@5 99.376 	Validation Loss 0.7687 	Validation Prec@1 74.990 	Validation Prec@5 98.310 

lr: 0.09384265768488219
TRAINING - Epoch: [167][0/391]	Time 1.296 (1.296)	Data 0.390 (0.390)	Loss 0.3049 (0.3049)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [167][100/391]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.4468 (0.3936)	Prec@1 87.500 (86.317)	Prec@5 99.219 (99.474)
TRAINING - Epoch: [167][200/391]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.3894 (0.4058)	Prec@1 85.156 (85.790)	Prec@5 99.219 (99.495)
TRAINING - Epoch: [167][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4512 (0.4062)	Prec@1 85.156 (85.888)	Prec@5 98.438 (99.437)
EVALUATING - Epoch: [167][0/79]	Time 0.446 (0.446)	Data 0.404 (0.404)	Loss 1.1710 (1.1710)	Prec@1 67.188 (67.188)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:26

 Epoch: 168	Training Loss 0.4110 	Training Prec@1 85.750 	Training Prec@5 99.426 	Validation Loss 1.2217 	Validation Prec@1 65.950 	Validation Prec@5 96.290 

lr: 0.0937666190943849
TRAINING - Epoch: [168][0/391]	Time 1.353 (1.353)	Data 0.454 (0.454)	Loss 0.4289 (0.4289)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [168][100/391]	Time 0.115 (0.129)	Data 0.000 (0.005)	Loss 0.4089 (0.3980)	Prec@1 84.375 (86.015)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [168][200/391]	Time 0.113 (0.124)	Data 0.000 (0.003)	Loss 0.3559 (0.3968)	Prec@1 87.500 (86.206)	Prec@5 99.219 (99.495)
TRAINING - Epoch: [168][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3096 (0.4022)	Prec@1 91.406 (86.117)	Prec@5 98.438 (99.468)
EVALUATING - Epoch: [168][0/79]	Time 0.452 (0.452)	Data 0.411 (0.411)	Loss 0.5633 (0.5633)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:50:05

 Epoch: 169	Training Loss 0.4063 	Training Prec@1 86.048 	Training Prec@5 99.398 	Validation Loss 0.5729 	Validation Prec@1 81.110 	Validation Prec@5 98.840 

lr: 0.09369014506851328
TRAINING - Epoch: [169][0/391]	Time 1.331 (1.331)	Data 0.416 (0.416)	Loss 0.4162 (0.4162)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [169][100/391]	Time 0.116 (0.130)	Data 0.000 (0.005)	Loss 0.4411 (0.3965)	Prec@1 86.719 (86.448)	Prec@5 99.219 (99.497)
TRAINING - Epoch: [169][200/391]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.4920 (0.4026)	Prec@1 85.938 (86.252)	Prec@5 99.219 (99.464)
TRAINING - Epoch: [169][300/391]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.4489 (0.4079)	Prec@1 89.062 (86.093)	Prec@5 98.438 (99.465)
EVALUATING - Epoch: [169][0/79]	Time 0.434 (0.434)	Data 0.405 (0.405)	Loss 0.6271 (0.6271)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:55:20

 Epoch: 170	Training Loss 0.4102 	Training Prec@1 85.932 	Training Prec@5 99.466 	Validation Loss 0.7152 	Validation Prec@1 77.330 	Validation Prec@5 98.220 

lr: 0.09361323636810964
TRAINING - Epoch: [170][0/391]	Time 1.621 (1.621)	Data 0.429 (0.429)	Loss 0.4552 (0.4552)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [170][100/391]	Time 0.117 (0.131)	Data 0.000 (0.005)	Loss 0.3544 (0.4253)	Prec@1 85.938 (85.574)	Prec@5 99.219 (99.373)
TRAINING - Epoch: [170][200/391]	Time 0.116 (0.124)	Data 0.000 (0.002)	Loss 0.3307 (0.4224)	Prec@1 89.844 (85.487)	Prec@5 100.000 (99.308)
TRAINING - Epoch: [170][300/391]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.4645 (0.4218)	Prec@1 83.594 (85.475)	Prec@5 100.000 (99.325)
EVALUATING - Epoch: [170][0/79]	Time 0.426 (0.426)	Data 0.379 (0.379)	Loss 0.6029 (0.6029)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 03:00:06

 Epoch: 171	Training Loss 0.4202 	Training Prec@1 85.554 	Training Prec@5 99.346 	Validation Loss 0.6241 	Validation Prec@1 79.420 	Validation Prec@5 98.600 

lr: 0.0935358937583409
TRAINING - Epoch: [171][0/391]	Time 1.314 (1.314)	Data 0.434 (0.434)	Loss 0.3221 (0.3221)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [171][100/391]	Time 0.111 (0.125)	Data 0.000 (0.005)	Loss 0.5094 (0.4106)	Prec@1 81.250 (85.667)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [171][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.4554 (0.4144)	Prec@1 84.375 (85.693)	Prec@5 100.000 (99.417)
TRAINING - Epoch: [171][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.6143 (0.4143)	Prec@1 75.000 (85.769)	Prec@5 99.219 (99.362)
EVALUATING - Epoch: [171][0/79]	Time 0.445 (0.445)	Data 0.402 (0.402)	Loss 0.6648 (0.6648)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:56

 Epoch: 172	Training Loss 0.4140 	Training Prec@1 85.832 	Training Prec@5 99.362 	Validation Loss 0.6800 	Validation Prec@1 78.510 	Validation Prec@5 98.650 

lr: 0.09345811800869096
TRAINING - Epoch: [172][0/391]	Time 1.335 (1.335)	Data 0.415 (0.415)	Loss 0.4627 (0.4627)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [172][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.3843 (0.4003)	Prec@1 85.938 (86.015)	Prec@5 98.438 (99.536)
TRAINING - Epoch: [172][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.4052 (0.4076)	Prec@1 83.594 (85.984)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [172][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.4939 (0.4117)	Prec@1 80.469 (85.857)	Prec@5 100.000 (99.426)
EVALUATING - Epoch: [172][0/79]	Time 0.445 (0.445)	Data 0.416 (0.416)	Loss 1.0455 (1.0455)	Prec@1 71.875 (71.875)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:48

 Epoch: 173	Training Loss 0.4093 	Training Prec@1 85.972 	Training Prec@5 99.428 	Validation Loss 1.0156 	Validation Prec@1 70.780 	Validation Prec@5 97.900 

lr: 0.093379909892953
TRAINING - Epoch: [173][0/391]	Time 1.318 (1.318)	Data 0.408 (0.408)	Loss 0.3822 (0.3822)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [173][100/391]	Time 0.112 (0.126)	Data 0.000 (0.004)	Loss 0.3054 (0.3922)	Prec@1 87.500 (86.317)	Prec@5 99.219 (99.520)
TRAINING - Epoch: [173][200/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.4175 (0.3954)	Prec@1 87.500 (86.256)	Prec@5 99.219 (99.475)
TRAINING - Epoch: [173][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.4881 (0.4033)	Prec@1 84.375 (86.119)	Prec@5 98.438 (99.452)
EVALUATING - Epoch: [173][0/79]	Time 0.448 (0.448)	Data 0.421 (0.421)	Loss 0.7133 (0.7133)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:37

 Epoch: 174	Training Loss 0.4065 	Training Prec@1 86.054 	Training Prec@5 99.432 	Validation Loss 0.7239 	Validation Prec@1 77.800 	Validation Prec@5 97.840 

lr: 0.09330127018922188
TRAINING - Epoch: [174][0/391]	Time 1.380 (1.380)	Data 0.445 (0.445)	Loss 0.4230 (0.4230)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [174][100/391]	Time 0.113 (0.128)	Data 0.001 (0.005)	Loss 0.3488 (0.3812)	Prec@1 86.719 (86.843)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [174][200/391]	Time 0.108 (0.121)	Data 0.000 (0.003)	Loss 0.3908 (0.3937)	Prec@1 87.500 (86.489)	Prec@5 98.438 (99.460)
TRAINING - Epoch: [174][300/391]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.5188 (0.4006)	Prec@1 82.031 (86.324)	Prec@5 99.219 (99.421)
EVALUATING - Epoch: [174][0/79]	Time 0.452 (0.452)	Data 0.412 (0.412)	Loss 0.5160 (0.5160)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:48:41

 Epoch: 175	Training Loss 0.4064 	Training Prec@1 86.150 	Training Prec@5 99.384 	Validation Loss 0.6502 	Validation Prec@1 79.410 	Validation Prec@5 98.710 

lr: 0.09322219967988632
TRAINING - Epoch: [175][0/391]	Time 1.368 (1.368)	Data 0.446 (0.446)	Loss 0.4560 (0.4560)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [175][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.5536 (0.3942)	Prec@1 81.250 (86.541)	Prec@5 99.219 (99.404)
TRAINING - Epoch: [175][200/391]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.4811 (0.4019)	Prec@1 83.594 (86.272)	Prec@5 100.000 (99.433)
TRAINING - Epoch: [175][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.4208 (0.4051)	Prec@1 87.500 (86.062)	Prec@5 99.219 (99.424)
EVALUATING - Epoch: [175][0/79]	Time 0.431 (0.431)	Data 0.390 (0.390)	Loss 0.5646 (0.5646)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:36

 Epoch: 176	Training Loss 0.4069 	Training Prec@1 86.022 	Training Prec@5 99.408 	Validation Loss 0.6556 	Validation Prec@1 78.690 	Validation Prec@5 98.830 

lr: 0.0931426991516211
TRAINING - Epoch: [176][0/391]	Time 1.361 (1.361)	Data 0.444 (0.444)	Loss 0.4263 (0.4263)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [176][100/391]	Time 0.109 (0.130)	Data 0.000 (0.005)	Loss 0.4349 (0.3909)	Prec@1 82.812 (86.417)	Prec@5 99.219 (99.312)
TRAINING - Epoch: [176][200/391]	Time 0.110 (0.122)	Data 0.000 (0.003)	Loss 0.5008 (0.4040)	Prec@1 84.375 (86.151)	Prec@5 97.656 (99.285)
TRAINING - Epoch: [176][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.4319 (0.4092)	Prec@1 85.156 (86.013)	Prec@5 100.000 (99.294)
EVALUATING - Epoch: [176][0/79]	Time 0.421 (0.421)	Data 0.387 (0.387)	Loss 0.7839 (0.7839)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:13

 Epoch: 177	Training Loss 0.4061 	Training Prec@1 86.094 	Training Prec@5 99.326 	Validation Loss 0.7409 	Validation Prec@1 78.160 	Validation Prec@5 97.790 

lr: 0.09306276939537932
TRAINING - Epoch: [177][0/391]	Time 1.352 (1.352)	Data 0.443 (0.443)	Loss 0.3807 (0.3807)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [177][100/391]	Time 0.112 (0.130)	Data 0.000 (0.005)	Loss 0.4459 (0.4013)	Prec@1 84.375 (86.278)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [177][200/391]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.4077 (0.4038)	Prec@1 85.938 (86.151)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [177][300/391]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3594 (0.4048)	Prec@1 87.500 (86.132)	Prec@5 100.000 (99.452)
EVALUATING - Epoch: [177][0/79]	Time 0.444 (0.444)	Data 0.409 (0.409)	Loss 0.6312 (0.6312)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:54:48

 Epoch: 178	Training Loss 0.4101 	Training Prec@1 85.922 	Training Prec@5 99.410 	Validation Loss 0.8170 	Validation Prec@1 76.730 	Validation Prec@5 97.840 

lr: 0.09298241120638447
TRAINING - Epoch: [178][0/391]	Time 1.337 (1.337)	Data 0.427 (0.427)	Loss 0.4090 (0.4090)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [178][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.3932 (0.3986)	Prec@1 89.062 (86.278)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [178][200/391]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.4194 (0.4005)	Prec@1 83.594 (86.194)	Prec@5 100.000 (99.475)
TRAINING - Epoch: [178][300/391]	Time 0.109 (0.120)	Data 0.000 (0.002)	Loss 0.2201 (0.4022)	Prec@1 93.750 (86.153)	Prec@5 100.000 (99.473)
EVALUATING - Epoch: [178][0/79]	Time 0.435 (0.435)	Data 0.388 (0.388)	Loss 0.7829 (0.7829)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:07

 Epoch: 179	Training Loss 0.4026 	Training Prec@1 86.168 	Training Prec@5 99.470 	Validation Loss 0.8033 	Validation Prec@1 74.200 	Validation Prec@5 97.980 

lr: 0.09290162538412251
TRAINING - Epoch: [179][0/391]	Time 1.305 (1.305)	Data 0.416 (0.416)	Loss 0.4750 (0.4750)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [179][100/391]	Time 0.106 (0.123)	Data 0.000 (0.004)	Loss 0.4110 (0.4039)	Prec@1 87.500 (86.224)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [179][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.2941 (0.4105)	Prec@1 89.844 (85.926)	Prec@5 99.219 (99.429)
TRAINING - Epoch: [179][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.4364 (0.4169)	Prec@1 85.156 (85.787)	Prec@5 99.219 (99.385)
EVALUATING - Epoch: [179][0/79]	Time 0.472 (0.472)	Data 0.435 (0.435)	Loss 0.5300 (0.5300)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:11

 Epoch: 180	Training Loss 0.4161 	Training Prec@1 85.810 	Training Prec@5 99.382 	Validation Loss 0.6677 	Validation Prec@1 78.910 	Validation Prec@5 98.670 

lr: 0.09282041273233398
TRAINING - Epoch: [180][0/391]	Time 1.616 (1.616)	Data 0.436 (0.436)	Loss 0.3310 (0.3310)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [180][100/391]	Time 0.122 (0.133)	Data 0.000 (0.005)	Loss 0.2518 (0.3926)	Prec@1 90.625 (86.556)	Prec@5 100.000 (99.397)
TRAINING - Epoch: [180][200/391]	Time 0.105 (0.121)	Data 0.000 (0.002)	Loss 0.3589 (0.4026)	Prec@1 89.844 (86.112)	Prec@5 99.219 (99.471)
TRAINING - Epoch: [180][300/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4996 (0.4073)	Prec@1 84.375 (85.938)	Prec@5 99.219 (99.429)
EVALUATING - Epoch: [180][0/79]	Time 0.433 (0.433)	Data 0.389 (0.389)	Loss 0.8776 (0.8776)	Prec@1 73.438 (73.438)	Prec@5 95.312 (95.312)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:13

 Epoch: 181	Training Loss 0.4112 	Training Prec@1 85.836 	Training Prec@5 99.406 	Validation Loss 0.8832 	Validation Prec@1 71.620 	Validation Prec@5 97.320 

lr: 0.09273877405900588
TRAINING - Epoch: [181][0/391]	Time 1.334 (1.334)	Data 0.427 (0.427)	Loss 0.3916 (0.3916)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [181][100/391]	Time 0.112 (0.128)	Data 0.000 (0.005)	Loss 0.4610 (0.3845)	Prec@1 78.906 (86.796)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [181][200/391]	Time 0.110 (0.122)	Data 0.000 (0.002)	Loss 0.3971 (0.3999)	Prec@1 86.719 (86.264)	Prec@5 99.219 (99.456)
TRAINING - Epoch: [181][300/391]	Time 0.109 (0.120)	Data 0.000 (0.002)	Loss 0.6097 (0.4072)	Prec@1 79.688 (86.057)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [181][0/79]	Time 0.443 (0.443)	Data 0.414 (0.414)	Loss 0.6523 (0.6523)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:01

 Epoch: 182	Training Loss 0.4077 	Training Prec@1 86.042 	Training Prec@5 99.450 	Validation Loss 0.7511 	Validation Prec@1 76.820 	Validation Prec@5 98.140 

lr: 0.09265671017636379
TRAINING - Epoch: [182][0/391]	Time 1.295 (1.295)	Data 0.410 (0.410)	Loss 0.4013 (0.4013)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [182][100/391]	Time 0.108 (0.125)	Data 0.000 (0.004)	Loss 0.4544 (0.3987)	Prec@1 85.156 (86.448)	Prec@5 99.219 (99.420)
TRAINING - Epoch: [182][200/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.4146 (0.4033)	Prec@1 86.719 (86.066)	Prec@5 99.219 (99.351)
TRAINING - Epoch: [182][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.4466 (0.4069)	Prec@1 82.031 (85.961)	Prec@5 99.219 (99.359)
EVALUATING - Epoch: [182][0/79]	Time 0.430 (0.430)	Data 0.382 (0.382)	Loss 0.8684 (0.8684)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:37

 Epoch: 183	Training Loss 0.4082 	Training Prec@1 85.944 	Training Prec@5 99.374 	Validation Loss 1.0164 	Validation Prec@1 71.690 	Validation Prec@5 97.870 

lr: 0.09257422190086369
TRAINING - Epoch: [183][0/391]	Time 1.327 (1.327)	Data 0.444 (0.444)	Loss 0.4093 (0.4093)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [183][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.6513 (0.3891)	Prec@1 78.906 (86.556)	Prec@5 99.219 (99.559)
TRAINING - Epoch: [183][200/391]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.2845 (0.3943)	Prec@1 90.625 (86.334)	Prec@5 100.000 (99.495)
TRAINING - Epoch: [183][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4866 (0.4030)	Prec@1 82.031 (86.015)	Prec@5 99.219 (99.452)
EVALUATING - Epoch: [183][0/79]	Time 0.457 (0.457)	Data 0.423 (0.423)	Loss 0.5502 (0.5502)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:49

 Epoch: 184	Training Loss 0.4085 	Training Prec@1 85.922 	Training Prec@5 99.438 	Validation Loss 0.7110 	Validation Prec@1 77.400 	Validation Prec@5 98.450 

lr: 0.09249131005318383
TRAINING - Epoch: [184][0/391]	Time 1.351 (1.351)	Data 0.444 (0.444)	Loss 0.4222 (0.4222)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [184][100/391]	Time 0.113 (0.129)	Data 0.000 (0.005)	Loss 0.4143 (0.4082)	Prec@1 87.500 (85.852)	Prec@5 98.438 (99.397)
TRAINING - Epoch: [184][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.3681 (0.3933)	Prec@1 85.156 (86.256)	Prec@5 98.438 (99.433)
TRAINING - Epoch: [184][300/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4385 (0.4010)	Prec@1 86.719 (86.158)	Prec@5 100.000 (99.406)
EVALUATING - Epoch: [184][0/79]	Time 0.432 (0.432)	Data 0.401 (0.401)	Loss 0.6812 (0.6812)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:48:04

 Epoch: 185	Training Loss 0.4022 	Training Prec@1 86.126 	Training Prec@5 99.404 	Validation Loss 0.6206 	Validation Prec@1 79.680 	Validation Prec@5 98.930 

lr: 0.09240797545821662
TRAINING - Epoch: [185][0/391]	Time 1.348 (1.348)	Data 0.425 (0.425)	Loss 0.3519 (0.3519)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [185][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.3230 (0.3839)	Prec@1 88.281 (86.881)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [185][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.5401 (0.3982)	Prec@1 82.812 (86.280)	Prec@5 96.875 (99.510)
TRAINING - Epoch: [185][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.4230 (0.3981)	Prec@1 86.719 (86.425)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [185][0/79]	Time 0.431 (0.431)	Data 0.378 (0.378)	Loss 0.6561 (0.6561)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:29

 Epoch: 186	Training Loss 0.3996 	Training Prec@1 86.346 	Training Prec@5 99.506 	Validation Loss 0.7286 	Validation Prec@1 77.790 	Validation Prec@5 98.330 

lr: 0.09232421894506036
TRAINING - Epoch: [186][0/391]	Time 1.331 (1.331)	Data 0.444 (0.444)	Loss 0.3267 (0.3267)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [186][100/391]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.3198 (0.3877)	Prec@1 89.844 (86.494)	Prec@5 100.000 (99.412)
TRAINING - Epoch: [186][200/391]	Time 0.114 (0.122)	Data 0.000 (0.003)	Loss 0.3095 (0.4006)	Prec@1 87.500 (86.182)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [186][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.4446 (0.4037)	Prec@1 83.594 (86.034)	Prec@5 99.219 (99.419)
EVALUATING - Epoch: [186][0/79]	Time 0.418 (0.418)	Data 0.376 (0.376)	Loss 0.4895 (0.4895)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:27

 Epoch: 187	Training Loss 0.4064 	Training Prec@1 85.994 	Training Prec@5 99.412 	Validation Loss 0.6001 	Validation Prec@1 80.250 	Validation Prec@5 98.440 

lr: 0.0922400413470111
TRAINING - Epoch: [187][0/391]	Time 1.291 (1.291)	Data 0.420 (0.420)	Loss 0.2589 (0.2589)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [187][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.5054 (0.4047)	Prec@1 80.469 (86.216)	Prec@5 99.219 (99.428)
TRAINING - Epoch: [187][200/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.2787 (0.4079)	Prec@1 89.844 (86.136)	Prec@5 100.000 (99.409)
TRAINING - Epoch: [187][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.4149 (0.4080)	Prec@1 83.594 (86.163)	Prec@5 100.000 (99.419)
EVALUATING - Epoch: [187][0/79]	Time 0.446 (0.446)	Data 0.402 (0.402)	Loss 0.7241 (0.7241)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:13

 Epoch: 188	Training Loss 0.4081 	Training Prec@1 86.120 	Training Prec@5 99.412 	Validation Loss 0.7783 	Validation Prec@1 76.770 	Validation Prec@5 97.770 

lr: 0.09215544350155419
TRAINING - Epoch: [188][0/391]	Time 1.334 (1.334)	Data 0.442 (0.442)	Loss 0.3311 (0.3311)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [188][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.5606 (0.3845)	Prec@1 82.812 (86.966)	Prec@5 96.094 (99.420)
TRAINING - Epoch: [188][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.5200 (0.3939)	Prec@1 82.031 (86.625)	Prec@5 98.438 (99.448)
TRAINING - Epoch: [188][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.4822 (0.4024)	Prec@1 82.031 (86.311)	Prec@5 100.000 (99.413)
EVALUATING - Epoch: [188][0/79]	Time 0.446 (0.446)	Data 0.408 (0.408)	Loss 1.0733 (1.0733)	Prec@1 70.312 (70.312)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:12

 Epoch: 189	Training Loss 0.4041 	Training Prec@1 86.232 	Training Prec@5 99.408 	Validation Loss 1.0008 	Validation Prec@1 72.140 	Validation Prec@5 98.460 

lr: 0.09207042625035607
TRAINING - Epoch: [189][0/391]	Time 1.376 (1.376)	Data 0.460 (0.460)	Loss 0.4189 (0.4189)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [189][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.3775 (0.3896)	Prec@1 87.500 (86.649)	Prec@5 99.219 (99.451)
TRAINING - Epoch: [189][200/391]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.3087 (0.3954)	Prec@1 89.844 (86.357)	Prec@5 100.000 (99.464)
TRAINING - Epoch: [189][300/391]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.4924 (0.3991)	Prec@1 87.500 (86.202)	Prec@5 99.219 (99.491)
EVALUATING - Epoch: [189][0/79]	Time 0.438 (0.438)	Data 0.406 (0.406)	Loss 0.8748 (0.8748)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:13

 Epoch: 190	Training Loss 0.4013 	Training Prec@1 86.112 	Training Prec@5 99.472 	Validation Loss 0.7986 	Validation Prec@1 76.730 	Validation Prec@5 97.730 

lr: 0.09198499043925586
TRAINING - Epoch: [190][0/391]	Time 1.313 (1.313)	Data 0.431 (0.431)	Loss 0.3754 (0.3754)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [190][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.4718 (0.3994)	Prec@1 81.250 (86.394)	Prec@5 98.438 (99.428)
TRAINING - Epoch: [190][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.4106 (0.3970)	Prec@1 81.250 (86.544)	Prec@5 100.000 (99.433)
TRAINING - Epoch: [190][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.5759 (0.4020)	Prec@1 81.250 (86.332)	Prec@5 97.656 (99.445)
EVALUATING - Epoch: [190][0/79]	Time 0.430 (0.430)	Data 0.387 (0.387)	Loss 0.4761 (0.4761)	Prec@1 87.500 (87.500)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:04

 Epoch: 191	Training Loss 0.4027 	Training Prec@1 86.312 	Training Prec@5 99.434 	Validation Loss 0.5824 	Validation Prec@1 81.840 	Validation Prec@5 98.650 

lr: 0.09189913691825695
TRAINING - Epoch: [191][0/391]	Time 1.300 (1.300)	Data 0.432 (0.432)	Loss 0.4431 (0.4431)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [191][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.3741 (0.3902)	Prec@1 85.938 (86.626)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [191][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4692 (0.3965)	Prec@1 85.156 (86.373)	Prec@5 99.219 (99.479)
TRAINING - Epoch: [191][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.4337 (0.3991)	Prec@1 80.469 (86.218)	Prec@5 100.000 (99.473)
EVALUATING - Epoch: [191][0/79]	Time 0.439 (0.439)	Data 0.404 (0.404)	Loss 0.6380 (0.6380)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:38

 Epoch: 192	Training Loss 0.4021 	Training Prec@1 86.166 	Training Prec@5 99.442 	Validation Loss 0.7987 	Validation Prec@1 75.860 	Validation Prec@5 98.060 

lr: 0.09181286654151855
TRAINING - Epoch: [192][0/391]	Time 1.369 (1.369)	Data 0.445 (0.445)	Loss 0.4262 (0.4262)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [192][100/391]	Time 0.109 (0.125)	Data 0.000 (0.005)	Loss 0.2721 (0.4004)	Prec@1 89.062 (86.340)	Prec@5 100.000 (99.381)
TRAINING - Epoch: [192][200/391]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.3171 (0.4089)	Prec@1 85.938 (86.120)	Prec@5 100.000 (99.363)
TRAINING - Epoch: [192][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.5904 (0.4087)	Prec@1 80.469 (86.184)	Prec@5 98.438 (99.398)
EVALUATING - Epoch: [192][0/79]	Time 0.448 (0.448)	Data 0.410 (0.410)	Loss 0.8659 (0.8659)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:01

 Epoch: 193	Training Loss 0.4115 	Training Prec@1 86.146 	Training Prec@5 99.382 	Validation Loss 0.8338 	Validation Prec@1 75.140 	Validation Prec@5 97.210 

lr: 0.09172618016734714
TRAINING - Epoch: [193][0/391]	Time 1.548 (1.548)	Data 0.376 (0.376)	Loss 0.4049 (0.4049)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [193][100/391]	Time 0.115 (0.130)	Data 0.000 (0.004)	Loss 0.4838 (0.4051)	Prec@1 84.375 (86.317)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [193][200/391]	Time 0.111 (0.123)	Data 0.000 (0.002)	Loss 0.3334 (0.4080)	Prec@1 89.062 (86.159)	Prec@5 100.000 (99.417)
TRAINING - Epoch: [193][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4079 (0.4032)	Prec@1 86.719 (86.283)	Prec@5 100.000 (99.434)
EVALUATING - Epoch: [193][0/79]	Time 0.406 (0.406)	Data 0.372 (0.372)	Loss 0.6177 (0.6177)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:33

 Epoch: 194	Training Loss 0.4054 	Training Prec@1 86.292 	Training Prec@5 99.410 	Validation Loss 0.6672 	Validation Prec@1 80.120 	Validation Prec@5 98.320 

lr: 0.09163907865818802
TRAINING - Epoch: [194][0/391]	Time 1.325 (1.325)	Data 0.434 (0.434)	Loss 0.3783 (0.3783)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [194][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.3568 (0.3895)	Prec@1 86.719 (86.556)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [194][200/391]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.4640 (0.3962)	Prec@1 85.156 (86.272)	Prec@5 100.000 (99.483)
TRAINING - Epoch: [194][300/391]	Time 0.125 (0.119)	Data 0.000 (0.002)	Loss 0.3446 (0.3954)	Prec@1 87.500 (86.280)	Prec@5 99.219 (99.452)
EVALUATING - Epoch: [194][0/79]	Time 0.436 (0.436)	Data 0.390 (0.390)	Loss 0.5467 (0.5467)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:41

 Epoch: 195	Training Loss 0.3994 	Training Prec@1 86.166 	Training Prec@5 99.416 	Validation Loss 0.6980 	Validation Prec@1 77.370 	Validation Prec@5 98.500 

lr: 0.09155156288061661
TRAINING - Epoch: [195][0/391]	Time 1.348 (1.348)	Data 0.452 (0.452)	Loss 0.3783 (0.3783)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [195][100/391]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.3950 (0.3926)	Prec@1 85.156 (86.525)	Prec@5 100.000 (99.435)
TRAINING - Epoch: [195][200/391]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.2785 (0.4013)	Prec@1 89.062 (86.245)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [195][300/391]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.3811 (0.4023)	Prec@1 85.938 (86.252)	Prec@5 100.000 (99.426)
EVALUATING - Epoch: [195][0/79]	Time 0.468 (0.468)	Data 0.426 (0.426)	Loss 0.4917 (0.4917)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:58:13

 Epoch: 196	Training Loss 0.4057 	Training Prec@1 86.194 	Training Prec@5 99.412 	Validation Loss 0.5857 	Validation Prec@1 80.540 	Validation Prec@5 98.810 

lr: 0.09146363370532998
TRAINING - Epoch: [196][0/391]	Time 1.357 (1.357)	Data 0.431 (0.431)	Loss 0.3343 (0.3343)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [196][100/391]	Time 0.111 (0.129)	Data 0.000 (0.005)	Loss 0.2763 (0.3962)	Prec@1 89.062 (86.518)	Prec@5 100.000 (99.335)
TRAINING - Epoch: [196][200/391]	Time 0.110 (0.123)	Data 0.000 (0.003)	Loss 0.3823 (0.3986)	Prec@1 84.375 (86.217)	Prec@5 99.219 (99.370)
TRAINING - Epoch: [196][300/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.4479 (0.3951)	Prec@1 85.938 (86.420)	Prec@5 99.219 (99.398)
EVALUATING - Epoch: [196][0/79]	Time 0.419 (0.419)	Data 0.378 (0.378)	Loss 0.8483 (0.8483)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:48:25

 Epoch: 197	Training Loss 0.3942 	Training Prec@1 86.486 	Training Prec@5 99.422 	Validation Loss 0.8331 	Validation Prec@1 75.150 	Validation Prec@5 97.860 

lr: 0.09137529200713805
TRAINING - Epoch: [197][0/391]	Time 1.340 (1.340)	Data 0.445 (0.445)	Loss 0.5019 (0.5019)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [197][100/391]	Time 0.114 (0.128)	Data 0.001 (0.005)	Loss 0.3638 (0.3856)	Prec@1 86.719 (87.206)	Prec@5 100.000 (99.443)
TRAINING - Epoch: [197][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.4194 (0.3939)	Prec@1 86.719 (86.758)	Prec@5 99.219 (99.452)
TRAINING - Epoch: [197][300/391]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3731 (0.3995)	Prec@1 87.500 (86.555)	Prec@5 100.000 (99.408)
EVALUATING - Epoch: [197][0/79]	Time 0.444 (0.444)	Data 0.401 (0.401)	Loss 0.5057 (0.5057)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:41

 Epoch: 198	Training Loss 0.4034 	Training Prec@1 86.404 	Training Prec@5 99.386 	Validation Loss 0.6292 	Validation Prec@1 79.730 	Validation Prec@5 98.180 

lr: 0.09128653866495498
TRAINING - Epoch: [198][0/391]	Time 1.320 (1.320)	Data 0.417 (0.417)	Loss 0.3733 (0.3733)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [198][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.4288 (0.3890)	Prec@1 85.938 (86.394)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [198][200/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.5062 (0.4026)	Prec@1 81.250 (85.914)	Prec@5 99.219 (99.444)
TRAINING - Epoch: [198][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.5280 (0.4081)	Prec@1 83.594 (85.925)	Prec@5 98.438 (99.421)
EVALUATING - Epoch: [198][0/79]	Time 0.430 (0.430)	Data 0.397 (0.397)	Loss 0.6358 (0.6358)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:41

 Epoch: 199	Training Loss 0.4072 	Training Prec@1 85.952 	Training Prec@5 99.450 	Validation Loss 0.6905 	Validation Prec@1 77.080 	Validation Prec@5 98.490 

lr: 0.09119737456179036
TRAINING - Epoch: [199][0/391]	Time 1.342 (1.342)	Data 0.441 (0.441)	Loss 0.3123 (0.3123)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [199][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.3543 (0.4000)	Prec@1 88.281 (86.402)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [199][200/391]	Time 0.116 (0.118)	Data 0.000 (0.003)	Loss 0.3366 (0.4020)	Prec@1 85.938 (86.451)	Prec@5 100.000 (99.390)
TRAINING - Epoch: [199][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3475 (0.4053)	Prec@1 89.062 (86.306)	Prec@5 100.000 (99.356)
EVALUATING - Epoch: [199][0/79]	Time 0.456 (0.456)	Data 0.417 (0.417)	Loss 0.6554 (0.6554)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:53

 Epoch: 200	Training Loss 0.4075 	Training Prec@1 86.168 	Training Prec@5 99.376 	Validation Loss 0.6785 	Validation Prec@1 78.410 	Validation Prec@5 98.890 

lr: 0.09110780058474047
TRAINING - Epoch: [200][0/391]	Time 1.334 (1.334)	Data 0.439 (0.439)	Loss 0.3823 (0.3823)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [200][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.3320 (0.3939)	Prec@1 86.719 (86.448)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [200][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.4061 (0.3894)	Prec@1 85.938 (86.544)	Prec@5 100.000 (99.479)
TRAINING - Epoch: [200][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3593 (0.3989)	Prec@1 89.844 (86.285)	Prec@5 99.219 (99.429)
EVALUATING - Epoch: [200][0/79]	Time 0.424 (0.424)	Data 0.380 (0.380)	Loss 0.9183 (0.9183)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:04

 Epoch: 201	Training Loss 0.4013 	Training Prec@1 86.222 	Training Prec@5 99.440 	Validation Loss 0.8798 	Validation Prec@1 74.850 	Validation Prec@5 98.280 

lr: 0.0910178176249794
TRAINING - Epoch: [201][0/391]	Time 1.331 (1.331)	Data 0.437 (0.437)	Loss 0.2405 (0.2405)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [201][100/391]	Time 0.111 (0.122)	Data 0.000 (0.005)	Loss 0.5074 (0.3942)	Prec@1 82.812 (86.463)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [201][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.4505 (0.3978)	Prec@1 85.938 (86.540)	Prec@5 99.219 (99.483)
TRAINING - Epoch: [201][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3129 (0.3992)	Prec@1 88.281 (86.319)	Prec@5 99.219 (99.494)
EVALUATING - Epoch: [201][0/79]	Time 0.445 (0.445)	Data 0.407 (0.407)	Loss 0.4555 (0.4555)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:55

 Epoch: 202	Training Loss 0.3984 	Training Prec@1 86.318 	Training Prec@5 99.478 	Validation Loss 0.5439 	Validation Prec@1 82.100 	Validation Prec@5 98.970 

lr: 0.09092742657775027
TRAINING - Epoch: [202][0/391]	Time 1.324 (1.324)	Data 0.429 (0.429)	Loss 0.4602 (0.4602)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [202][100/391]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.6853 (0.4040)	Prec@1 78.906 (86.239)	Prec@5 99.219 (99.404)
TRAINING - Epoch: [202][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.4762 (0.4147)	Prec@1 85.156 (85.926)	Prec@5 100.000 (99.398)
TRAINING - Epoch: [202][300/391]	Time 0.122 (0.118)	Data 0.000 (0.002)	Loss 0.4814 (0.4132)	Prec@1 84.375 (85.950)	Prec@5 100.000 (99.390)
EVALUATING - Epoch: [202][0/79]	Time 0.441 (0.441)	Data 0.404 (0.404)	Loss 0.6037 (0.6037)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:46

 Epoch: 203	Training Loss 0.4136 	Training Prec@1 85.950 	Training Prec@5 99.382 	Validation Loss 0.8353 	Validation Prec@1 75.200 	Validation Prec@5 98.530 

lr: 0.09083662834235627
TRAINING - Epoch: [203][0/391]	Time 1.400 (1.400)	Data 0.447 (0.447)	Loss 0.3853 (0.3853)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [203][100/391]	Time 0.116 (0.131)	Data 0.000 (0.005)	Loss 0.3483 (0.3928)	Prec@1 87.500 (86.618)	Prec@5 99.219 (99.358)
TRAINING - Epoch: [203][200/391]	Time 0.115 (0.125)	Data 0.000 (0.003)	Loss 0.3586 (0.4022)	Prec@1 88.281 (86.388)	Prec@5 99.219 (99.386)
TRAINING - Epoch: [203][300/391]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.3950 (0.4027)	Prec@1 88.281 (86.353)	Prec@5 99.219 (99.377)
EVALUATING - Epoch: [203][0/79]	Time 0.435 (0.435)	Data 0.387 (0.387)	Loss 0.5441 (0.5441)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:56:50

 Epoch: 204	Training Loss 0.4040 	Training Prec@1 86.278 	Training Prec@5 99.380 	Validation Loss 0.6475 	Validation Prec@1 78.690 	Validation Prec@5 98.320 

lr: 0.09074542382215167
TRAINING - Epoch: [204][0/391]	Time 1.329 (1.329)	Data 0.438 (0.438)	Loss 0.3060 (0.3060)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [204][100/391]	Time 0.117 (0.126)	Data 0.000 (0.005)	Loss 0.3727 (0.3981)	Prec@1 86.719 (86.200)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [204][200/391]	Time 0.107 (0.119)	Data 0.000 (0.003)	Loss 0.4475 (0.3986)	Prec@1 83.594 (86.384)	Prec@5 100.000 (99.444)
TRAINING - Epoch: [204][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.4720 (0.4008)	Prec@1 84.375 (86.290)	Prec@5 100.000 (99.429)
EVALUATING - Epoch: [204][0/79]	Time 0.428 (0.428)	Data 0.391 (0.391)	Loss 1.1921 (1.1921)	Prec@1 67.969 (67.969)	Prec@5 95.312 (95.312)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:31

 Epoch: 205	Training Loss 0.4016 	Training Prec@1 86.220 	Training Prec@5 99.432 	Validation Loss 0.9987 	Validation Prec@1 70.890 	Validation Prec@5 96.490 

lr: 0.09065381392453294
TRAINING - Epoch: [205][0/391]	Time 1.271 (1.271)	Data 0.351 (0.351)	Loss 0.3703 (0.3703)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [205][100/391]	Time 0.112 (0.125)	Data 0.000 (0.004)	Loss 0.3311 (0.3876)	Prec@1 88.281 (86.719)	Prec@5 99.219 (99.474)
TRAINING - Epoch: [205][200/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3428 (0.3909)	Prec@1 82.812 (86.610)	Prec@5 100.000 (99.452)
TRAINING - Epoch: [205][300/391]	Time 0.132 (0.118)	Data 0.001 (0.002)	Loss 0.6573 (0.3952)	Prec@1 77.344 (86.454)	Prec@5 100.000 (99.393)
EVALUATING - Epoch: [205][0/79]	Time 0.484 (0.484)	Data 0.443 (0.443)	Loss 0.9772 (0.9772)	Prec@1 68.750 (68.750)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:46

 Epoch: 206	Training Loss 0.4021 	Training Prec@1 86.220 	Training Prec@5 99.394 	Validation Loss 0.8799 	Validation Prec@1 74.450 	Validation Prec@5 98.240 

lr: 0.09056179956092959
TRAINING - Epoch: [206][0/391]	Time 1.400 (1.400)	Data 0.467 (0.467)	Loss 0.4440 (0.4440)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [206][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.4334 (0.3855)	Prec@1 86.719 (86.757)	Prec@5 100.000 (99.428)
TRAINING - Epoch: [206][200/391]	Time 0.114 (0.123)	Data 0.000 (0.003)	Loss 0.3544 (0.3903)	Prec@1 88.281 (86.785)	Prec@5 99.219 (99.440)
TRAINING - Epoch: [206][300/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3829 (0.3999)	Prec@1 83.594 (86.337)	Prec@5 99.219 (99.416)
EVALUATING - Epoch: [206][0/79]	Time 0.411 (0.411)	Data 0.376 (0.376)	Loss 0.5707 (0.5707)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:54:29

 Epoch: 207	Training Loss 0.4084 	Training Prec@1 86.072 	Training Prec@5 99.386 	Validation Loss 0.6013 	Validation Prec@1 80.590 	Validation Prec@5 98.610 

lr: 0.09046938164679527
TRAINING - Epoch: [207][0/391]	Time 1.364 (1.364)	Data 0.441 (0.441)	Loss 0.2100 (0.2100)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [207][100/391]	Time 0.117 (0.129)	Data 0.000 (0.005)	Loss 0.3211 (0.4092)	Prec@1 87.500 (85.953)	Prec@5 99.219 (99.412)
TRAINING - Epoch: [207][200/391]	Time 0.115 (0.122)	Data 0.001 (0.003)	Loss 0.4437 (0.4023)	Prec@1 82.031 (86.217)	Prec@5 99.219 (99.409)
TRAINING - Epoch: [207][300/391]	Time 0.119 (0.120)	Data 0.001 (0.002)	Loss 0.7178 (0.4037)	Prec@1 82.031 (86.254)	Prec@5 97.656 (99.406)
EVALUATING - Epoch: [207][0/79]	Time 0.447 (0.447)	Data 0.404 (0.404)	Loss 0.5894 (0.5894)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:24

 Epoch: 208	Training Loss 0.4070 	Training Prec@1 86.064 	Training Prec@5 99.416 	Validation Loss 0.6305 	Validation Prec@1 80.060 	Validation Prec@5 98.860 

lr: 0.09037656110159846
TRAINING - Epoch: [208][0/391]	Time 1.388 (1.388)	Data 0.430 (0.430)	Loss 0.4379 (0.4379)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [208][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.3206 (0.3855)	Prec@1 88.281 (86.928)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [208][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.6134 (0.3915)	Prec@1 79.688 (86.579)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [208][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.4220 (0.3951)	Prec@1 82.031 (86.592)	Prec@5 99.219 (99.434)
EVALUATING - Epoch: [208][0/79]	Time 0.483 (0.483)	Data 0.454 (0.454)	Loss 0.9239 (0.9239)	Prec@1 71.875 (71.875)	Prec@5 96.094 (96.094)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:35

 Epoch: 209	Training Loss 0.3969 	Training Prec@1 86.544 	Training Prec@5 99.438 	Validation Loss 0.9023 	Validation Prec@1 73.400 	Validation Prec@5 97.350 

lr: 0.09028333884881354
TRAINING - Epoch: [209][0/391]	Time 1.373 (1.373)	Data 0.435 (0.435)	Loss 0.4339 (0.4339)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [209][100/391]	Time 0.126 (0.134)	Data 0.001 (0.005)	Loss 0.3392 (0.3928)	Prec@1 86.719 (86.409)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [209][200/391]	Time 0.113 (0.124)	Data 0.000 (0.003)	Loss 0.3042 (0.3880)	Prec@1 92.969 (86.544)	Prec@5 99.219 (99.475)
TRAINING - Epoch: [209][300/391]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.3490 (0.3931)	Prec@1 85.938 (86.436)	Prec@5 99.219 (99.476)
EVALUATING - Epoch: [209][0/79]	Time 0.430 (0.430)	Data 0.389 (0.389)	Loss 0.5866 (0.5866)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 03:02:08

 Epoch: 210	Training Loss 0.3993 	Training Prec@1 86.272 	Training Prec@5 99.464 	Validation Loss 0.6848 	Validation Prec@1 78.540 	Validation Prec@5 98.550 

lr: 0.09018971581591138
TRAINING - Epoch: [210][0/391]	Time 1.379 (1.379)	Data 0.453 (0.453)	Loss 0.3559 (0.3559)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [210][100/391]	Time 0.111 (0.126)	Data 0.000 (0.005)	Loss 0.4678 (0.3923)	Prec@1 82.812 (86.572)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [210][200/391]	Time 0.109 (0.120)	Data 0.000 (0.003)	Loss 0.5110 (0.3998)	Prec@1 81.250 (86.268)	Prec@5 98.438 (99.440)
TRAINING - Epoch: [210][300/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.3507 (0.4033)	Prec@1 88.281 (86.049)	Prec@5 99.219 (99.463)
EVALUATING - Epoch: [210][0/79]	Time 0.481 (0.481)	Data 0.433 (0.433)	Loss 0.4284 (0.4284)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:49

 Epoch: 211	Training Loss 0.4033 	Training Prec@1 86.162 	Training Prec@5 99.450 	Validation Loss 0.6364 	Validation Prec@1 79.540 	Validation Prec@5 98.280 

lr: 0.09009569293435031
TRAINING - Epoch: [211][0/391]	Time 1.362 (1.362)	Data 0.423 (0.423)	Loss 0.2481 (0.2481)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [211][100/391]	Time 0.110 (0.126)	Data 0.000 (0.005)	Loss 0.3590 (0.3880)	Prec@1 88.281 (86.688)	Prec@5 98.438 (99.520)
TRAINING - Epoch: [211][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4475 (0.3965)	Prec@1 83.594 (86.365)	Prec@5 99.219 (99.460)
TRAINING - Epoch: [211][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.4379 (0.3998)	Prec@1 85.938 (86.314)	Prec@5 98.438 (99.458)
EVALUATING - Epoch: [211][0/79]	Time 0.438 (0.438)	Data 0.402 (0.402)	Loss 0.6483 (0.6483)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:49

 Epoch: 212	Training Loss 0.4011 	Training Prec@1 86.242 	Training Prec@5 99.458 	Validation Loss 0.8234 	Validation Prec@1 74.470 	Validation Prec@5 98.800 

lr: 0.0900012711395667
TRAINING - Epoch: [212][0/391]	Time 1.324 (1.324)	Data 0.444 (0.444)	Loss 0.2689 (0.2689)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [212][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.3330 (0.3887)	Prec@1 89.844 (86.688)	Prec@5 100.000 (99.489)
TRAINING - Epoch: [212][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.4306 (0.4007)	Prec@1 83.594 (86.280)	Prec@5 99.219 (99.452)
TRAINING - Epoch: [212][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3603 (0.4005)	Prec@1 87.500 (86.296)	Prec@5 100.000 (99.458)
EVALUATING - Epoch: [212][0/79]	Time 0.451 (0.451)	Data 0.409 (0.409)	Loss 1.0385 (1.0385)	Prec@1 67.969 (67.969)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:18

 Epoch: 213	Training Loss 0.4055 	Training Prec@1 86.174 	Training Prec@5 99.432 	Validation Loss 0.9430 	Validation Prec@1 72.100 	Validation Prec@5 97.880 

lr: 0.08990645137096577
TRAINING - Epoch: [213][0/391]	Time 1.309 (1.309)	Data 0.417 (0.417)	Loss 0.6047 (0.6047)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [213][100/391]	Time 0.109 (0.124)	Data 0.000 (0.004)	Loss 0.4425 (0.3890)	Prec@1 86.719 (86.873)	Prec@5 100.000 (99.319)
TRAINING - Epoch: [213][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3556 (0.3963)	Prec@1 89.062 (86.680)	Prec@5 100.000 (99.254)
TRAINING - Epoch: [213][300/391]	Time 0.120 (0.116)	Data 0.000 (0.002)	Loss 0.5081 (0.4018)	Prec@1 82.812 (86.397)	Prec@5 99.219 (99.330)
EVALUATING - Epoch: [213][0/79]	Time 0.439 (0.439)	Data 0.399 (0.399)	Loss 0.4536 (0.4536)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:02

 Epoch: 214	Training Loss 0.4033 	Training Prec@1 86.274 	Training Prec@5 99.356 	Validation Loss 0.6904 	Validation Prec@1 78.430 	Validation Prec@5 98.590 

lr: 0.08981123457191216
TRAINING - Epoch: [214][0/391]	Time 1.594 (1.594)	Data 0.448 (0.448)	Loss 0.3399 (0.3399)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [214][100/391]	Time 0.109 (0.126)	Data 0.000 (0.005)	Loss 0.6225 (0.3964)	Prec@1 79.688 (86.293)	Prec@5 97.656 (99.428)
TRAINING - Epoch: [214][200/391]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.4404 (0.4020)	Prec@1 83.594 (86.070)	Prec@5 100.000 (99.452)
TRAINING - Epoch: [214][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.4953 (0.4014)	Prec@1 87.500 (86.158)	Prec@5 98.438 (99.432)
EVALUATING - Epoch: [214][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.8225 (0.8225)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:19

 Epoch: 215	Training Loss 0.3994 	Training Prec@1 86.322 	Training Prec@5 99.402 	Validation Loss 0.7512 	Validation Prec@1 77.250 	Validation Prec@5 97.800 

lr: 0.08971562168972062
TRAINING - Epoch: [215][0/391]	Time 1.286 (1.286)	Data 0.364 (0.364)	Loss 0.5629 (0.5629)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [215][100/391]	Time 0.109 (0.127)	Data 0.000 (0.004)	Loss 0.3791 (0.3801)	Prec@1 86.719 (86.989)	Prec@5 98.438 (99.350)
TRAINING - Epoch: [215][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.5145 (0.3836)	Prec@1 78.906 (86.874)	Prec@5 98.438 (99.401)
TRAINING - Epoch: [215][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.5045 (0.3944)	Prec@1 80.469 (86.431)	Prec@5 98.438 (99.419)
EVALUATING - Epoch: [215][0/79]	Time 0.415 (0.415)	Data 0.375 (0.375)	Loss 0.7898 (0.7898)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:38

 Epoch: 216	Training Loss 0.3960 	Training Prec@1 86.442 	Training Prec@5 99.404 	Validation Loss 0.7744 	Validation Prec@1 75.070 	Validation Prec@5 98.180 

lr: 0.08961961367564647
TRAINING - Epoch: [216][0/391]	Time 1.343 (1.343)	Data 0.440 (0.440)	Loss 0.4134 (0.4134)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [216][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.3111 (0.3777)	Prec@1 88.281 (86.781)	Prec@5 100.000 (99.505)
TRAINING - Epoch: [216][200/391]	Time 0.107 (0.119)	Data 0.000 (0.003)	Loss 0.4491 (0.3940)	Prec@1 85.156 (86.384)	Prec@5 99.219 (99.456)
TRAINING - Epoch: [216][300/391]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.5262 (0.4004)	Prec@1 78.125 (86.228)	Prec@5 98.438 (99.429)
EVALUATING - Epoch: [216][0/79]	Time 0.440 (0.440)	Data 0.401 (0.401)	Loss 0.9779 (0.9779)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:02

 Epoch: 217	Training Loss 0.4054 	Training Prec@1 86.110 	Training Prec@5 99.402 	Validation Loss 0.8015 	Validation Prec@1 74.460 	Validation Prec@5 98.100 

lr: 0.08952321148487627
TRAINING - Epoch: [217][0/391]	Time 1.319 (1.319)	Data 0.418 (0.418)	Loss 0.4078 (0.4078)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [217][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.3673 (0.3848)	Prec@1 88.281 (86.997)	Prec@5 99.219 (99.389)
TRAINING - Epoch: [217][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3067 (0.4020)	Prec@1 88.281 (86.412)	Prec@5 100.000 (99.456)
TRAINING - Epoch: [217][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2558 (0.4051)	Prec@1 91.406 (86.202)	Prec@5 99.219 (99.419)
EVALUATING - Epoch: [217][0/79]	Time 0.458 (0.458)	Data 0.416 (0.416)	Loss 0.5059 (0.5059)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:31

 Epoch: 218	Training Loss 0.4104 	Training Prec@1 86.056 	Training Prec@5 99.398 	Validation Loss 0.6138 	Validation Prec@1 80.130 	Validation Prec@5 99.000 

lr: 0.08942641607651824
TRAINING - Epoch: [218][0/391]	Time 1.351 (1.351)	Data 0.442 (0.442)	Loss 0.3294 (0.3294)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [218][100/391]	Time 0.117 (0.128)	Data 0.000 (0.005)	Loss 0.4646 (0.4018)	Prec@1 85.938 (86.208)	Prec@5 98.438 (99.551)
TRAINING - Epoch: [218][200/391]	Time 0.113 (0.122)	Data 0.000 (0.003)	Loss 0.4047 (0.4058)	Prec@1 85.156 (86.167)	Prec@5 99.219 (99.483)
TRAINING - Epoch: [218][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4476 (0.4045)	Prec@1 86.719 (86.252)	Prec@5 98.438 (99.413)
EVALUATING - Epoch: [218][0/79]	Time 0.440 (0.440)	Data 0.407 (0.407)	Loss 0.5857 (0.5857)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:45:03

 Epoch: 219	Training Loss 0.4053 	Training Prec@1 86.232 	Training Prec@5 99.378 	Validation Loss 0.5717 	Validation Prec@1 81.110 	Validation Prec@5 98.930 

lr: 0.08932922841359275
TRAINING - Epoch: [219][0/391]	Time 1.337 (1.337)	Data 0.427 (0.427)	Loss 0.2712 (0.2712)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [219][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.3411 (0.3944)	Prec@1 85.938 (86.603)	Prec@5 100.000 (99.551)
TRAINING - Epoch: [219][200/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3630 (0.3963)	Prec@1 85.938 (86.532)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [219][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.5020 (0.3992)	Prec@1 81.250 (86.438)	Prec@5 99.219 (99.455)
EVALUATING - Epoch: [219][0/79]	Time 0.448 (0.448)	Data 0.389 (0.389)	Loss 0.6952 (0.6952)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:18

 Epoch: 220	Training Loss 0.3994 	Training Prec@1 86.422 	Training Prec@5 99.442 	Validation Loss 0.7269 	Validation Prec@1 76.770 	Validation Prec@5 98.090 

lr: 0.08923164946302269
TRAINING - Epoch: [220][0/391]	Time 1.325 (1.325)	Data 0.423 (0.423)	Loss 0.3862 (0.3862)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [220][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.3581 (0.4050)	Prec@1 86.719 (85.899)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [220][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3796 (0.3994)	Prec@1 85.938 (86.334)	Prec@5 99.219 (99.440)
TRAINING - Epoch: [220][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.4394 (0.3953)	Prec@1 86.719 (86.457)	Prec@5 99.219 (99.452)
EVALUATING - Epoch: [220][0/79]	Time 0.446 (0.446)	Data 0.419 (0.419)	Loss 0.5958 (0.5958)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:14

 Epoch: 221	Training Loss 0.3956 	Training Prec@1 86.396 	Training Prec@5 99.454 	Validation Loss 0.6893 	Validation Prec@1 78.330 	Validation Prec@5 98.770 

lr: 0.08913368019562386
TRAINING - Epoch: [221][0/391]	Time 1.304 (1.304)	Data 0.406 (0.406)	Loss 0.4469 (0.4469)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [221][100/391]	Time 0.112 (0.124)	Data 0.000 (0.004)	Loss 0.3479 (0.3949)	Prec@1 85.156 (86.580)	Prec@5 100.000 (99.389)
TRAINING - Epoch: [221][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3557 (0.3951)	Prec@1 85.938 (86.528)	Prec@5 99.219 (99.425)
TRAINING - Epoch: [221][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3929 (0.3944)	Prec@1 87.500 (86.472)	Prec@5 98.438 (99.463)
EVALUATING - Epoch: [221][0/79]	Time 0.450 (0.450)	Data 0.413 (0.413)	Loss 1.1166 (1.1166)	Prec@1 72.656 (72.656)	Prec@5 95.312 (95.312)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:42

 Epoch: 222	Training Loss 0.3989 	Training Prec@1 86.410 	Training Prec@5 99.452 	Validation Loss 1.0551 	Validation Prec@1 73.080 	Validation Prec@5 97.320 

lr: 0.08903532158609542
TRAINING - Epoch: [222][0/391]	Time 1.335 (1.335)	Data 0.445 (0.445)	Loss 0.3370 (0.3370)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [222][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.3650 (0.3880)	Prec@1 84.375 (86.951)	Prec@5 99.219 (99.551)
TRAINING - Epoch: [222][200/391]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.4816 (0.3988)	Prec@1 82.812 (86.451)	Prec@5 100.000 (99.425)
TRAINING - Epoch: [222][300/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.2820 (0.3932)	Prec@1 87.500 (86.651)	Prec@5 100.000 (99.442)
EVALUATING - Epoch: [222][0/79]	Time 0.432 (0.432)	Data 0.402 (0.402)	Loss 0.6172 (0.6172)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:12

 Epoch: 223	Training Loss 0.3946 	Training Prec@1 86.562 	Training Prec@5 99.458 	Validation Loss 0.7899 	Validation Prec@1 75.610 	Validation Prec@5 98.820 

lr: 0.08893657461301004
TRAINING - Epoch: [223][0/391]	Time 1.294 (1.294)	Data 0.418 (0.418)	Loss 0.4186 (0.4186)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [223][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.2787 (0.3993)	Prec@1 91.406 (86.386)	Prec@5 100.000 (99.358)
TRAINING - Epoch: [223][200/391]	Time 0.113 (0.122)	Data 0.000 (0.003)	Loss 0.5847 (0.4017)	Prec@1 82.031 (86.260)	Prec@5 99.219 (99.405)
TRAINING - Epoch: [223][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4336 (0.3969)	Prec@1 85.938 (86.462)	Prec@5 99.219 (99.419)
EVALUATING - Epoch: [223][0/79]	Time 0.406 (0.406)	Data 0.370 (0.370)	Loss 0.6317 (0.6317)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:44:46

 Epoch: 224	Training Loss 0.3991 	Training Prec@1 86.426 	Training Prec@5 99.410 	Validation Loss 0.6952 	Validation Prec@1 78.460 	Validation Prec@5 98.520 

lr: 0.08883744025880423
TRAINING - Epoch: [224][0/391]	Time 1.314 (1.314)	Data 0.418 (0.418)	Loss 0.4178 (0.4178)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [224][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.5066 (0.3867)	Prec@1 82.031 (86.649)	Prec@5 99.219 (99.528)
TRAINING - Epoch: [224][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4182 (0.3877)	Prec@1 84.375 (86.563)	Prec@5 99.219 (99.522)
TRAINING - Epoch: [224][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3505 (0.3870)	Prec@1 88.281 (86.625)	Prec@5 99.219 (99.502)
EVALUATING - Epoch: [224][0/79]	Time 0.416 (0.416)	Data 0.372 (0.372)	Loss 0.5477 (0.5477)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:58

 Epoch: 225	Training Loss 0.3901 	Training Prec@1 86.598 	Training Prec@5 99.472 	Validation Loss 0.6846 	Validation Prec@1 78.430 	Validation Prec@5 98.280 

lr: 0.08873791950976859
TRAINING - Epoch: [225][0/391]	Time 1.341 (1.341)	Data 0.445 (0.445)	Loss 0.4180 (0.4180)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [225][100/391]	Time 0.118 (0.125)	Data 0.000 (0.005)	Loss 0.3770 (0.3994)	Prec@1 89.062 (86.363)	Prec@5 96.875 (99.335)
TRAINING - Epoch: [225][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.4031 (0.3937)	Prec@1 85.938 (86.458)	Prec@5 99.219 (99.382)
TRAINING - Epoch: [225][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3605 (0.3966)	Prec@1 88.281 (86.327)	Prec@5 99.219 (99.408)
EVALUATING - Epoch: [225][0/79]	Time 0.430 (0.430)	Data 0.400 (0.400)	Loss 1.0382 (1.0382)	Prec@1 70.312 (70.312)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:07

 Epoch: 226	Training Loss 0.3984 	Training Prec@1 86.312 	Training Prec@5 99.416 	Validation Loss 0.9845 	Validation Prec@1 72.080 	Validation Prec@5 97.000 

lr: 0.08863801335603796
TRAINING - Epoch: [226][0/391]	Time 1.340 (1.340)	Data 0.445 (0.445)	Loss 0.2973 (0.2973)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [226][100/391]	Time 0.115 (0.127)	Data 0.000 (0.005)	Loss 0.3624 (0.4027)	Prec@1 83.594 (86.108)	Prec@5 100.000 (99.288)
TRAINING - Epoch: [226][200/391]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.5544 (0.3992)	Prec@1 85.156 (86.357)	Prec@5 98.438 (99.386)
TRAINING - Epoch: [226][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.5136 (0.4021)	Prec@1 82.812 (86.283)	Prec@5 100.000 (99.411)
EVALUATING - Epoch: [226][0/79]	Time 0.434 (0.434)	Data 0.398 (0.398)	Loss 1.0056 (1.0056)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:38

 Epoch: 227	Training Loss 0.4027 	Training Prec@1 86.246 	Training Prec@5 99.422 	Validation Loss 0.8755 	Validation Prec@1 76.200 	Validation Prec@5 98.400 

lr: 0.0885377227915816
TRAINING - Epoch: [227][0/391]	Time 1.330 (1.330)	Data 0.435 (0.435)	Loss 0.5169 (0.5169)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [227][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.4429 (0.3951)	Prec@1 84.375 (86.487)	Prec@5 99.219 (99.451)
TRAINING - Epoch: [227][200/391]	Time 0.112 (0.119)	Data 0.000 (0.003)	Loss 0.2900 (0.3954)	Prec@1 89.062 (86.517)	Prec@5 100.000 (99.409)
TRAINING - Epoch: [227][300/391]	Time 0.125 (0.118)	Data 0.000 (0.002)	Loss 0.4461 (0.3995)	Prec@1 84.375 (86.407)	Prec@5 99.219 (99.413)
EVALUATING - Epoch: [227][0/79]	Time 0.439 (0.439)	Data 0.399 (0.399)	Loss 0.6828 (0.6828)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:41

 Epoch: 228	Training Loss 0.4004 	Training Prec@1 86.300 	Training Prec@5 99.398 	Validation Loss 0.6393 	Validation Prec@1 78.860 	Validation Prec@5 98.830 

lr: 0.08843704881419327
TRAINING - Epoch: [228][0/391]	Time 1.364 (1.364)	Data 0.444 (0.444)	Loss 0.3047 (0.3047)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [228][100/391]	Time 0.115 (0.130)	Data 0.000 (0.005)	Loss 0.4378 (0.3820)	Prec@1 85.156 (86.703)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [228][200/391]	Time 0.122 (0.124)	Data 0.000 (0.003)	Loss 0.3179 (0.3949)	Prec@1 89.844 (86.451)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [228][300/391]	Time 0.112 (0.123)	Data 0.000 (0.002)	Loss 0.3427 (0.3986)	Prec@1 86.719 (86.324)	Prec@5 100.000 (99.439)
EVALUATING - Epoch: [228][0/79]	Time 0.447 (0.447)	Data 0.409 (0.409)	Loss 0.6513 (0.6513)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 02:59:43

 Epoch: 229	Training Loss 0.4005 	Training Prec@1 86.288 	Training Prec@5 99.428 	Validation Loss 0.6010 	Validation Prec@1 80.430 	Validation Prec@5 98.930 

lr: 0.08833599242548132
TRAINING - Epoch: [229][0/391]	Time 1.321 (1.321)	Data 0.413 (0.413)	Loss 0.4155 (0.4155)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [229][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.3888 (0.3900)	Prec@1 88.281 (86.703)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [229][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.4674 (0.3893)	Prec@1 81.250 (86.633)	Prec@5 98.438 (99.456)
TRAINING - Epoch: [229][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.4457 (0.3911)	Prec@1 84.375 (86.607)	Prec@5 100.000 (99.450)
EVALUATING - Epoch: [229][0/79]	Time 0.456 (0.456)	Data 0.407 (0.407)	Loss 0.5520 (0.5520)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:05

 Epoch: 230	Training Loss 0.3947 	Training Prec@1 86.492 	Training Prec@5 99.428 	Validation Loss 0.6031 	Validation Prec@1 80.440 	Validation Prec@5 98.930 

lr: 0.08823455463085869
TRAINING - Epoch: [230][0/391]	Time 1.334 (1.334)	Data 0.445 (0.445)	Loss 0.4111 (0.4111)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [230][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.3466 (0.3944)	Prec@1 89.062 (86.386)	Prec@5 99.219 (99.466)
TRAINING - Epoch: [230][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.4772 (0.3902)	Prec@1 80.469 (86.493)	Prec@5 100.000 (99.487)
TRAINING - Epoch: [230][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3959 (0.3883)	Prec@1 83.594 (86.664)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [230][0/79]	Time 0.427 (0.427)	Data 0.391 (0.391)	Loss 0.7204 (0.7204)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:36

 Epoch: 231	Training Loss 0.3887 	Training Prec@1 86.628 	Training Prec@5 99.430 	Validation Loss 0.7393 	Validation Prec@1 78.120 	Validation Prec@5 97.950 

lr: 0.088132736439533
TRAINING - Epoch: [231][0/391]	Time 1.327 (1.327)	Data 0.438 (0.438)	Loss 0.4710 (0.4710)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [231][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.3648 (0.3814)	Prec@1 88.281 (86.835)	Prec@5 99.219 (99.505)
TRAINING - Epoch: [231][200/391]	Time 0.111 (0.122)	Data 0.000 (0.003)	Loss 0.3717 (0.3859)	Prec@1 87.500 (86.824)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [231][300/391]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3274 (0.3889)	Prec@1 89.062 (86.734)	Prec@5 100.000 (99.437)
EVALUATING - Epoch: [231][0/79]	Time 0.444 (0.444)	Data 0.400 (0.400)	Loss 0.7707 (0.7707)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:47:33

 Epoch: 232	Training Loss 0.3932 	Training Prec@1 86.606 	Training Prec@5 99.410 	Validation Loss 0.7401 	Validation Prec@1 77.850 	Validation Prec@5 98.260 

lr: 0.0880305388644964
TRAINING - Epoch: [232][0/391]	Time 1.326 (1.326)	Data 0.414 (0.414)	Loss 0.4848 (0.4848)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [232][100/391]	Time 0.118 (0.128)	Data 0.000 (0.004)	Loss 0.5177 (0.3683)	Prec@1 81.250 (87.067)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [232][200/391]	Time 0.110 (0.122)	Data 0.000 (0.002)	Loss 0.3571 (0.3808)	Prec@1 86.719 (86.754)	Prec@5 100.000 (99.495)
TRAINING - Epoch: [232][300/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.4229 (0.3867)	Prec@1 84.375 (86.682)	Prec@5 98.438 (99.458)
EVALUATING - Epoch: [232][0/79]	Time 0.441 (0.441)	Data 0.396 (0.396)	Loss 0.4797 (0.4797)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:53

 Epoch: 233	Training Loss 0.3883 	Training Prec@1 86.640 	Training Prec@5 99.460 	Validation Loss 0.5898 	Validation Prec@1 81.630 	Validation Prec@5 99.000 

lr: 0.08792796292251555
TRAINING - Epoch: [233][0/391]	Time 1.340 (1.340)	Data 0.419 (0.419)	Loss 0.4088 (0.4088)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [233][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.5879 (0.3757)	Prec@1 85.938 (87.206)	Prec@5 98.438 (99.559)
TRAINING - Epoch: [233][200/391]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.3616 (0.3860)	Prec@1 89.062 (86.800)	Prec@5 99.219 (99.483)
TRAINING - Epoch: [233][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2764 (0.3920)	Prec@1 87.500 (86.597)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [233][0/79]	Time 0.411 (0.411)	Data 0.383 (0.383)	Loss 0.5949 (0.5949)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:45:18

 Epoch: 234	Training Loss 0.3956 	Training Prec@1 86.468 	Training Prec@5 99.452 	Validation Loss 0.6953 	Validation Prec@1 78.180 	Validation Prec@5 98.010 

lr: 0.08782500963412151
TRAINING - Epoch: [234][0/391]	Time 1.327 (1.327)	Data 0.430 (0.430)	Loss 0.3215 (0.3215)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [234][100/391]	Time 0.107 (0.126)	Data 0.000 (0.005)	Loss 0.4170 (0.3853)	Prec@1 85.156 (86.665)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [234][200/391]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.4981 (0.3933)	Prec@1 81.250 (86.594)	Prec@5 100.000 (99.448)
TRAINING - Epoch: [234][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4130 (0.3960)	Prec@1 85.156 (86.366)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [234][0/79]	Time 0.432 (0.432)	Data 0.395 (0.395)	Loss 0.7307 (0.7307)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:54

 Epoch: 235	Training Loss 0.3957 	Training Prec@1 86.410 	Training Prec@5 99.424 	Validation Loss 0.9051 	Validation Prec@1 72.230 	Validation Prec@5 98.380 

lr: 0.08772168002359956
TRAINING - Epoch: [235][0/391]	Time 1.388 (1.388)	Data 0.446 (0.446)	Loss 0.3221 (0.3221)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [235][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.4486 (0.3911)	Prec@1 83.594 (86.610)	Prec@5 99.219 (99.366)
TRAINING - Epoch: [235][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.3361 (0.3927)	Prec@1 88.281 (86.676)	Prec@5 100.000 (99.417)
TRAINING - Epoch: [235][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3317 (0.3893)	Prec@1 90.625 (86.742)	Prec@5 100.000 (99.460)
EVALUATING - Epoch: [235][0/79]	Time 0.426 (0.426)	Data 0.395 (0.395)	Loss 0.6081 (0.6081)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:03

 Epoch: 236	Training Loss 0.3923 	Training Prec@1 86.572 	Training Prec@5 99.450 	Validation Loss 0.6873 	Validation Prec@1 77.700 	Validation Prec@5 98.770 

lr: 0.08761797511897902
TRAINING - Epoch: [236][0/391]	Time 1.351 (1.351)	Data 0.443 (0.443)	Loss 0.3653 (0.3653)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [236][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.3015 (0.3822)	Prec@1 87.500 (86.897)	Prec@5 100.000 (99.482)
TRAINING - Epoch: [236][200/391]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.3837 (0.3807)	Prec@1 84.375 (86.719)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [236][300/391]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.3517 (0.3839)	Prec@1 89.062 (86.685)	Prec@5 100.000 (99.567)
EVALUATING - Epoch: [236][0/79]	Time 0.411 (0.411)	Data 0.384 (0.384)	Loss 0.7837 (0.7837)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:33

 Epoch: 237	Training Loss 0.3896 	Training Prec@1 86.522 	Training Prec@5 99.520 	Validation Loss 0.8874 	Validation Prec@1 76.410 	Validation Prec@5 98.880 

lr: 0.08751389595202301
TRAINING - Epoch: [237][0/391]	Time 1.339 (1.339)	Data 0.426 (0.426)	Loss 0.3007 (0.3007)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [237][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.5381 (0.3865)	Prec@1 84.375 (86.796)	Prec@5 98.438 (99.474)
TRAINING - Epoch: [237][200/391]	Time 0.107 (0.121)	Data 0.000 (0.002)	Loss 0.3513 (0.3964)	Prec@1 85.938 (86.521)	Prec@5 100.000 (99.444)
TRAINING - Epoch: [237][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3705 (0.3997)	Prec@1 85.938 (86.371)	Prec@5 99.219 (99.411)
EVALUATING - Epoch: [237][0/79]	Time 0.432 (0.432)	Data 0.376 (0.376)	Loss 0.5016 (0.5016)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:01

 Epoch: 238	Training Loss 0.4009 	Training Prec@1 86.282 	Training Prec@5 99.418 	Validation Loss 0.6724 	Validation Prec@1 78.860 	Validation Prec@5 98.340 

lr: 0.08740944355821822
TRAINING - Epoch: [238][0/391]	Time 1.326 (1.326)	Data 0.421 (0.421)	Loss 0.3987 (0.3987)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [238][100/391]	Time 0.121 (0.131)	Data 0.000 (0.004)	Loss 0.2443 (0.3848)	Prec@1 89.844 (86.873)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [238][200/391]	Time 0.116 (0.125)	Data 0.000 (0.002)	Loss 0.3432 (0.3825)	Prec@1 87.500 (86.890)	Prec@5 100.000 (99.506)
TRAINING - Epoch: [238][300/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3319 (0.3839)	Prec@1 89.844 (86.874)	Prec@5 99.219 (99.471)
EVALUATING - Epoch: [238][0/79]	Time 0.432 (0.432)	Data 0.400 (0.400)	Loss 0.6180 (0.6180)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 03:00:10

 Epoch: 239	Training Loss 0.3872 	Training Prec@1 86.756 	Training Prec@5 99.432 	Validation Loss 0.6366 	Validation Prec@1 80.260 	Validation Prec@5 98.810 

lr: 0.08730461897676457
TRAINING - Epoch: [239][0/391]	Time 1.345 (1.345)	Data 0.423 (0.423)	Loss 0.3722 (0.3722)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [239][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.3820 (0.3642)	Prec@1 86.719 (87.554)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [239][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.3810 (0.3735)	Prec@1 86.719 (87.104)	Prec@5 98.438 (99.436)
TRAINING - Epoch: [239][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3176 (0.3793)	Prec@1 89.062 (86.908)	Prec@5 100.000 (99.434)
EVALUATING - Epoch: [239][0/79]	Time 0.430 (0.430)	Data 0.385 (0.385)	Loss 0.7524 (0.7524)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:30

 Epoch: 240	Training Loss 0.3856 	Training Prec@1 86.696 	Training Prec@5 99.422 	Validation Loss 0.8244 	Validation Prec@1 74.000 	Validation Prec@5 97.390 

lr: 0.0871994232505649
TRAINING - Epoch: [240][0/391]	Time 1.358 (1.358)	Data 0.459 (0.459)	Loss 0.2915 (0.2915)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [240][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.4477 (0.3791)	Prec@1 85.156 (87.322)	Prec@5 98.438 (99.505)
TRAINING - Epoch: [240][200/391]	Time 0.109 (0.120)	Data 0.000 (0.003)	Loss 0.3676 (0.3919)	Prec@1 85.938 (86.707)	Prec@5 100.000 (99.429)
TRAINING - Epoch: [240][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3184 (0.3924)	Prec@1 89.062 (86.581)	Prec@5 100.000 (99.473)
EVALUATING - Epoch: [240][0/79]	Time 0.450 (0.450)	Data 0.411 (0.411)	Loss 0.7909 (0.7909)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:30

 Epoch: 241	Training Loss 0.3904 	Training Prec@1 86.612 	Training Prec@5 99.468 	Validation Loss 0.8746 	Validation Prec@1 75.500 	Validation Prec@5 97.880 

lr: 0.08709385742621453
TRAINING - Epoch: [241][0/391]	Time 1.330 (1.330)	Data 0.415 (0.415)	Loss 0.3755 (0.3755)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [241][100/391]	Time 0.110 (0.124)	Data 0.000 (0.004)	Loss 0.4366 (0.3734)	Prec@1 82.812 (87.469)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [241][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.4762 (0.3729)	Prec@1 78.125 (87.395)	Prec@5 99.219 (99.553)
TRAINING - Epoch: [241][300/391]	Time 0.122 (0.117)	Data 0.000 (0.002)	Loss 0.3481 (0.3794)	Prec@1 88.281 (87.173)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [241][0/79]	Time 0.450 (0.450)	Data 0.409 (0.409)	Loss 0.5473 (0.5473)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:42

 Epoch: 242	Training Loss 0.3776 	Training Prec@1 87.172 	Training Prec@5 99.500 	Validation Loss 0.6213 	Validation Prec@1 81.590 	Validation Prec@5 98.730 

lr: 0.08698792255399099
TRAINING - Epoch: [242][0/391]	Time 1.349 (1.349)	Data 0.410 (0.410)	Loss 0.2889 (0.2889)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [242][100/391]	Time 0.110 (0.126)	Data 0.000 (0.004)	Loss 0.3812 (0.3991)	Prec@1 84.375 (86.564)	Prec@5 100.000 (99.304)
TRAINING - Epoch: [242][200/391]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2265 (0.3910)	Prec@1 91.406 (86.859)	Prec@5 100.000 (99.401)
TRAINING - Epoch: [242][300/391]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.4021 (0.3903)	Prec@1 85.938 (86.763)	Prec@5 98.438 (99.437)
EVALUATING - Epoch: [242][0/79]	Time 0.443 (0.443)	Data 0.398 (0.398)	Loss 0.5234 (0.5234)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 02:59:31

 Epoch: 243	Training Loss 0.3902 	Training Prec@1 86.768 	Training Prec@5 99.456 	Validation Loss 0.6323 	Validation Prec@1 79.990 	Validation Prec@5 98.780 

lr: 0.0868816196878434
TRAINING - Epoch: [243][0/391]	Time 1.334 (1.334)	Data 0.441 (0.441)	Loss 0.4066 (0.4066)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [243][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.2777 (0.3609)	Prec@1 90.625 (87.693)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [243][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.3604 (0.3721)	Prec@1 87.500 (87.348)	Prec@5 100.000 (99.522)
TRAINING - Epoch: [243][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.4467 (0.3798)	Prec@1 84.375 (86.869)	Prec@5 99.219 (99.515)
EVALUATING - Epoch: [243][0/79]	Time 0.441 (0.441)	Data 0.387 (0.387)	Loss 0.8191 (0.8191)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:58

 Epoch: 244	Training Loss 0.3859 	Training Prec@1 86.744 	Training Prec@5 99.504 	Validation Loss 0.9079 	Validation Prec@1 72.860 	Validation Prec@5 97.950 

lr: 0.08677494988538205
TRAINING - Epoch: [244][0/391]	Time 1.318 (1.318)	Data 0.427 (0.427)	Loss 0.3831 (0.3831)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [244][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.4033 (0.3880)	Prec@1 85.156 (86.634)	Prec@5 100.000 (99.420)
TRAINING - Epoch: [244][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3809 (0.3799)	Prec@1 84.375 (87.065)	Prec@5 99.219 (99.499)
TRAINING - Epoch: [244][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.4537 (0.3831)	Prec@1 85.938 (86.994)	Prec@5 100.000 (99.483)
EVALUATING - Epoch: [244][0/79]	Time 0.417 (0.417)	Data 0.374 (0.374)	Loss 0.7140 (0.7140)	Prec@1 74.219 (74.219)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:44

 Epoch: 245	Training Loss 0.3862 	Training Prec@1 86.850 	Training Prec@5 99.452 	Validation Loss 0.8489 	Validation Prec@1 74.980 	Validation Prec@5 98.270 

lr: 0.08666791420786799
TRAINING - Epoch: [245][0/391]	Time 1.339 (1.339)	Data 0.419 (0.419)	Loss 0.4622 (0.4622)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [245][100/391]	Time 0.112 (0.125)	Data 0.000 (0.005)	Loss 0.2246 (0.3912)	Prec@1 94.531 (86.324)	Prec@5 98.438 (99.513)
TRAINING - Epoch: [245][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3781 (0.3925)	Prec@1 86.719 (86.365)	Prec@5 98.438 (99.514)
TRAINING - Epoch: [245][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.3701 (0.3903)	Prec@1 88.281 (86.540)	Prec@5 100.000 (99.465)
EVALUATING - Epoch: [245][0/79]	Time 0.442 (0.442)	Data 0.398 (0.398)	Loss 0.5689 (0.5689)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:32

 Epoch: 246	Training Loss 0.3912 	Training Prec@1 86.520 	Training Prec@5 99.450 	Validation Loss 0.6705 	Validation Prec@1 78.730 	Validation Prec@5 98.700 

lr: 0.08656051372020226
TRAINING - Epoch: [246][0/391]	Time 1.322 (1.322)	Data 0.425 (0.425)	Loss 0.3566 (0.3566)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [246][100/391]	Time 0.109 (0.125)	Data 0.000 (0.005)	Loss 0.3077 (0.3676)	Prec@1 89.062 (87.407)	Prec@5 99.219 (99.505)
TRAINING - Epoch: [246][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4860 (0.3734)	Prec@1 82.031 (87.267)	Prec@5 99.219 (99.495)
TRAINING - Epoch: [246][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.5153 (0.3792)	Prec@1 82.812 (87.072)	Prec@5 96.875 (99.471)
EVALUATING - Epoch: [246][0/79]	Time 0.448 (0.448)	Data 0.407 (0.407)	Loss 0.5415 (0.5415)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:05

 Epoch: 247	Training Loss 0.3827 	Training Prec@1 86.978 	Training Prec@5 99.458 	Validation Loss 0.5942 	Validation Prec@1 79.600 	Validation Prec@5 98.540 

lr: 0.08645274949091548
TRAINING - Epoch: [247][0/391]	Time 1.356 (1.356)	Data 0.455 (0.455)	Loss 0.4082 (0.4082)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [247][100/391]	Time 0.112 (0.125)	Data 0.000 (0.005)	Loss 0.3225 (0.3621)	Prec@1 90.625 (87.709)	Prec@5 99.219 (99.575)
TRAINING - Epoch: [247][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.5243 (0.3705)	Prec@1 81.250 (87.352)	Prec@5 99.219 (99.534)
TRAINING - Epoch: [247][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2904 (0.3707)	Prec@1 89.844 (87.321)	Prec@5 99.219 (99.522)
EVALUATING - Epoch: [247][0/79]	Time 0.441 (0.441)	Data 0.403 (0.403)	Loss 0.6324 (0.6324)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:42

 Epoch: 248	Training Loss 0.3766 	Training Prec@1 87.142 	Training Prec@5 99.472 	Validation Loss 0.5883 	Validation Prec@1 81.270 	Validation Prec@5 98.990 

lr: 0.08634462259215712
TRAINING - Epoch: [248][0/391]	Time 1.253 (1.253)	Data 0.391 (0.391)	Loss 0.3987 (0.3987)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [248][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.4244 (0.3767)	Prec@1 85.938 (87.121)	Prec@5 98.438 (99.482)
TRAINING - Epoch: [248][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4468 (0.3743)	Prec@1 83.594 (87.220)	Prec@5 99.219 (99.506)
TRAINING - Epoch: [248][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.4442 (0.3781)	Prec@1 86.719 (86.981)	Prec@5 100.000 (99.512)
EVALUATING - Epoch: [248][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.6366 (0.6366)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:50

 Epoch: 249	Training Loss 0.3813 	Training Prec@1 86.826 	Training Prec@5 99.462 	Validation Loss 0.6611 	Validation Prec@1 78.400 	Validation Prec@5 98.520 

lr: 0.08623613409968486
TRAINING - Epoch: [249][0/391]	Time 1.290 (1.290)	Data 0.444 (0.444)	Loss 0.2815 (0.2815)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [249][100/391]	Time 0.112 (0.128)	Data 0.000 (0.005)	Loss 0.3310 (0.3655)	Prec@1 87.500 (87.686)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [249][200/391]	Time 0.113 (0.122)	Data 0.000 (0.003)	Loss 0.4984 (0.3816)	Prec@1 85.938 (87.041)	Prec@5 100.000 (99.537)
TRAINING - Epoch: [249][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3397 (0.3837)	Prec@1 89.062 (86.911)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [249][0/79]	Time 0.446 (0.446)	Data 0.413 (0.413)	Loss 0.5883 (0.5883)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:04

 Epoch: 250	Training Loss 0.3832 	Training Prec@1 86.888 	Training Prec@5 99.526 	Validation Loss 0.6681 	Validation Prec@1 78.470 	Validation Prec@5 98.130 

lr: 0.0861272850928539
TRAINING - Epoch: [250][0/391]	Time 1.290 (1.290)	Data 0.441 (0.441)	Loss 0.4087 (0.4087)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [250][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.3400 (0.3588)	Prec@1 89.062 (87.809)	Prec@5 99.219 (99.551)
TRAINING - Epoch: [250][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.5187 (0.3687)	Prec@1 83.594 (87.527)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [250][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.4130 (0.3785)	Prec@1 87.500 (87.080)	Prec@5 100.000 (99.530)
EVALUATING - Epoch: [250][0/79]	Time 0.459 (0.459)	Data 0.425 (0.425)	Loss 0.6522 (0.6522)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:37

 Epoch: 251	Training Loss 0.3848 	Training Prec@1 86.902 	Training Prec@5 99.504 	Validation Loss 0.7999 	Validation Prec@1 75.240 	Validation Prec@5 98.760 

lr: 0.08601807665460615
TRAINING - Epoch: [251][0/391]	Time 1.306 (1.306)	Data 0.430 (0.430)	Loss 0.3617 (0.3617)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [251][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.3963 (0.3819)	Prec@1 88.281 (86.858)	Prec@5 99.219 (99.459)
TRAINING - Epoch: [251][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4616 (0.3804)	Prec@1 85.938 (86.971)	Prec@5 99.219 (99.444)
TRAINING - Epoch: [251][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.4907 (0.3808)	Prec@1 85.156 (86.947)	Prec@5 99.219 (99.463)
EVALUATING - Epoch: [251][0/79]	Time 0.436 (0.436)	Data 0.407 (0.407)	Loss 0.5905 (0.5905)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:22

 Epoch: 252	Training Loss 0.3804 	Training Prec@1 86.958 	Training Prec@5 99.472 	Validation Loss 0.6592 	Validation Prec@1 78.290 	Validation Prec@5 98.520 

lr: 0.08590850987145959
TRAINING - Epoch: [252][0/391]	Time 1.361 (1.361)	Data 0.446 (0.446)	Loss 0.4093 (0.4093)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [252][100/391]	Time 0.110 (0.126)	Data 0.000 (0.005)	Loss 0.2972 (0.3788)	Prec@1 89.062 (86.734)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [252][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.2443 (0.3782)	Prec@1 89.844 (86.870)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [252][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.4747 (0.3848)	Prec@1 84.375 (86.724)	Prec@5 99.219 (99.502)
EVALUATING - Epoch: [252][0/79]	Time 0.435 (0.435)	Data 0.398 (0.398)	Loss 0.5975 (0.5975)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:12

 Epoch: 253	Training Loss 0.3831 	Training Prec@1 86.812 	Training Prec@5 99.502 	Validation Loss 0.6579 	Validation Prec@1 78.850 	Validation Prec@5 98.580 

lr: 0.08579858583349735
TRAINING - Epoch: [253][0/391]	Time 1.308 (1.308)	Data 0.412 (0.412)	Loss 0.2747 (0.2747)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [253][100/391]	Time 0.106 (0.123)	Data 0.000 (0.004)	Loss 0.4260 (0.3625)	Prec@1 86.719 (87.477)	Prec@5 99.219 (99.544)
TRAINING - Epoch: [253][200/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.4040 (0.3858)	Prec@1 85.156 (86.769)	Prec@5 100.000 (99.429)
TRAINING - Epoch: [253][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.4553 (0.3839)	Prec@1 85.156 (86.833)	Prec@5 99.219 (99.465)
EVALUATING - Epoch: [253][0/79]	Time 0.439 (0.439)	Data 0.394 (0.394)	Loss 0.4914 (0.4914)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:19

 Epoch: 254	Training Loss 0.3824 	Training Prec@1 86.892 	Training Prec@5 99.458 	Validation Loss 0.5615 	Validation Prec@1 82.260 	Validation Prec@5 98.850 

lr: 0.08568830563435689
TRAINING - Epoch: [254][0/391]	Time 1.635 (1.635)	Data 0.431 (0.431)	Loss 0.4920 (0.4920)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [254][100/391]	Time 0.114 (0.133)	Data 0.000 (0.005)	Loss 0.4447 (0.3688)	Prec@1 85.938 (87.647)	Prec@5 98.438 (99.482)
TRAINING - Epoch: [254][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.3268 (0.3731)	Prec@1 89.062 (87.430)	Prec@5 100.000 (99.522)
TRAINING - Epoch: [254][300/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.5076 (0.3773)	Prec@1 82.031 (87.108)	Prec@5 96.875 (99.551)
EVALUATING - Epoch: [254][0/79]	Time 0.429 (0.429)	Data 0.401 (0.401)	Loss 0.7053 (0.7053)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:52:42

 Epoch: 255	Training Loss 0.3819 	Training Prec@1 86.978 	Training Prec@5 99.508 	Validation Loss 0.8101 	Validation Prec@1 76.130 	Validation Prec@5 97.630 

lr: 0.08557767037121917
TRAINING - Epoch: [255][0/391]	Time 1.672 (1.672)	Data 0.470 (0.470)	Loss 0.4318 (0.4318)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [255][100/391]	Time 0.117 (0.133)	Data 0.000 (0.005)	Loss 0.3539 (0.3825)	Prec@1 87.500 (86.812)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [255][200/391]	Time 0.121 (0.126)	Data 0.000 (0.003)	Loss 0.3413 (0.3773)	Prec@1 91.406 (87.006)	Prec@5 99.219 (99.537)
TRAINING - Epoch: [255][300/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3741 (0.3793)	Prec@1 85.938 (86.947)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [255][0/79]	Time 0.442 (0.442)	Data 0.403 (0.403)	Loss 0.7247 (0.7247)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:50	Time of Finish: 2022-03-24 02:58:51

 Epoch: 256	Training Loss 0.3800 	Training Prec@1 86.906 	Training Prec@5 99.522 	Validation Loss 0.7041 	Validation Prec@1 78.740 	Validation Prec@5 97.890 

lr: 0.08546668114479763
TRAINING - Epoch: [256][0/391]	Time 1.307 (1.307)	Data 0.400 (0.400)	Loss 0.3691 (0.3691)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [256][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.4777 (0.3725)	Prec@1 83.594 (87.167)	Prec@5 99.219 (99.489)
TRAINING - Epoch: [256][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.3843 (0.3686)	Prec@1 86.719 (87.189)	Prec@5 99.219 (99.483)
TRAINING - Epoch: [256][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.4025 (0.3730)	Prec@1 89.844 (87.054)	Prec@5 99.219 (99.468)
EVALUATING - Epoch: [256][0/79]	Time 0.442 (0.442)	Data 0.407 (0.407)	Loss 0.6191 (0.6191)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:20

 Epoch: 257	Training Loss 0.3780 	Training Prec@1 86.940 	Training Prec@5 99.464 	Validation Loss 0.6490 	Validation Prec@1 79.720 	Validation Prec@5 98.590 

lr: 0.08535533905932734
TRAINING - Epoch: [257][0/391]	Time 1.313 (1.313)	Data 0.429 (0.429)	Loss 0.3394 (0.3394)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [257][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.4065 (0.3756)	Prec@1 89.844 (87.059)	Prec@5 99.219 (99.528)
TRAINING - Epoch: [257][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.4553 (0.3721)	Prec@1 83.594 (87.278)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [257][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2781 (0.3742)	Prec@1 91.406 (87.196)	Prec@5 100.000 (99.546)
EVALUATING - Epoch: [257][0/79]	Time 0.433 (0.433)	Data 0.401 (0.401)	Loss 0.6504 (0.6504)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:57

 Epoch: 258	Training Loss 0.3758 	Training Prec@1 87.152 	Training Prec@5 99.528 	Validation Loss 0.6326 	Validation Prec@1 79.310 	Validation Prec@5 99.140 

lr: 0.08524364522255397
TRAINING - Epoch: [258][0/391]	Time 1.342 (1.342)	Data 0.431 (0.431)	Loss 0.4511 (0.4511)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [258][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.3146 (0.3810)	Prec@1 88.281 (86.904)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [258][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3751 (0.3776)	Prec@1 85.156 (87.142)	Prec@5 100.000 (99.475)
TRAINING - Epoch: [258][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3710 (0.3773)	Prec@1 83.594 (87.191)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [258][0/79]	Time 0.434 (0.434)	Data 0.388 (0.388)	Loss 0.4604 (0.4604)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:31

 Epoch: 259	Training Loss 0.3791 	Training Prec@1 87.104 	Training Prec@5 99.484 	Validation Loss 0.5703 	Validation Prec@1 81.420 	Validation Prec@5 98.880 

lr: 0.08513160074572275
TRAINING - Epoch: [259][0/391]	Time 1.326 (1.326)	Data 0.421 (0.421)	Loss 0.3502 (0.3502)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [259][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.5934 (0.3725)	Prec@1 81.250 (87.338)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [259][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.2690 (0.3810)	Prec@1 92.969 (87.057)	Prec@5 100.000 (99.390)
TRAINING - Epoch: [259][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3395 (0.3819)	Prec@1 84.375 (86.862)	Prec@5 100.000 (99.445)
EVALUATING - Epoch: [259][0/79]	Time 0.451 (0.451)	Data 0.404 (0.404)	Loss 0.5816 (0.5816)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:52

 Epoch: 260	Training Loss 0.3825 	Training Prec@1 86.878 	Training Prec@5 99.438 	Validation Loss 0.7188 	Validation Prec@1 77.200 	Validation Prec@5 98.100 

lr: 0.0850192067435675
TRAINING - Epoch: [260][0/391]	Time 1.631 (1.631)	Data 0.438 (0.438)	Loss 0.2844 (0.2844)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [260][100/391]	Time 0.118 (0.136)	Data 0.000 (0.005)	Loss 0.4571 (0.3609)	Prec@1 84.375 (87.639)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [260][200/391]	Time 0.114 (0.128)	Data 0.000 (0.003)	Loss 0.3958 (0.3741)	Prec@1 86.719 (87.201)	Prec@5 99.219 (99.549)
TRAINING - Epoch: [260][300/391]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.4161 (0.3761)	Prec@1 84.375 (87.072)	Prec@5 100.000 (99.525)
EVALUATING - Epoch: [260][0/79]	Time 0.408 (0.408)	Data 0.382 (0.382)	Loss 0.6350 (0.6350)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 03:02:27

 Epoch: 261	Training Loss 0.3786 	Training Prec@1 87.038 	Training Prec@5 99.512 	Validation Loss 0.7692 	Validation Prec@1 76.880 	Validation Prec@5 98.000 

lr: 0.08490646433429941
TRAINING - Epoch: [261][0/391]	Time 1.320 (1.320)	Data 0.426 (0.426)	Loss 0.4503 (0.4503)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [261][100/391]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.4372 (0.3819)	Prec@1 85.938 (86.804)	Prec@5 99.219 (99.420)
TRAINING - Epoch: [261][200/391]	Time 0.114 (0.122)	Data 0.000 (0.003)	Loss 0.2547 (0.3798)	Prec@1 93.750 (86.968)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [261][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2396 (0.3784)	Prec@1 88.281 (87.056)	Prec@5 100.000 (99.476)
EVALUATING - Epoch: [261][0/79]	Time 0.441 (0.441)	Data 0.404 (0.404)	Loss 0.5582 (0.5582)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:45:19

 Epoch: 262	Training Loss 0.3800 	Training Prec@1 86.996 	Training Prec@5 99.494 	Validation Loss 0.5457 	Validation Prec@1 81.830 	Validation Prec@5 98.990 

lr: 0.08479337463959602
TRAINING - Epoch: [262][0/391]	Time 1.323 (1.323)	Data 0.418 (0.418)	Loss 0.4001 (0.4001)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [262][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.4717 (0.3827)	Prec@1 84.375 (87.067)	Prec@5 100.000 (99.451)
TRAINING - Epoch: [262][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4408 (0.3788)	Prec@1 83.594 (87.170)	Prec@5 98.438 (99.448)
TRAINING - Epoch: [262][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3866 (0.3761)	Prec@1 85.938 (87.186)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [262][0/79]	Time 0.470 (0.470)	Data 0.428 (0.428)	Loss 0.7203 (0.7203)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:52

 Epoch: 263	Training Loss 0.3789 	Training Prec@1 87.068 	Training Prec@5 99.462 	Validation Loss 0.6346 	Validation Prec@1 79.290 	Validation Prec@5 98.770 

lr: 0.08467993878459
TRAINING - Epoch: [263][0/391]	Time 1.348 (1.348)	Data 0.436 (0.436)	Loss 0.4022 (0.4022)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [263][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.3382 (0.3715)	Prec@1 89.062 (87.423)	Prec@5 98.438 (99.505)
TRAINING - Epoch: [263][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.4431 (0.3786)	Prec@1 89.062 (87.037)	Prec@5 99.219 (99.522)
TRAINING - Epoch: [263][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2702 (0.3802)	Prec@1 92.188 (86.869)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [263][0/79]	Time 0.420 (0.420)	Data 0.379 (0.379)	Loss 0.7666 (0.7666)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:35

 Epoch: 264	Training Loss 0.3794 	Training Prec@1 86.862 	Training Prec@5 99.498 	Validation Loss 0.7214 	Validation Prec@1 77.120 	Validation Prec@5 98.000 

lr: 0.084566157897858
TRAINING - Epoch: [264][0/391]	Time 1.338 (1.338)	Data 0.417 (0.417)	Loss 0.4068 (0.4068)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [264][100/391]	Time 0.104 (0.117)	Data 0.000 (0.004)	Loss 0.3594 (0.3657)	Prec@1 89.062 (87.129)	Prec@5 100.000 (99.389)
TRAINING - Epoch: [264][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.5159 (0.3702)	Prec@1 84.375 (87.150)	Prec@5 99.219 (99.487)
TRAINING - Epoch: [264][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.1901 (0.3691)	Prec@1 92.188 (87.285)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [264][0/79]	Time 0.436 (0.436)	Data 0.401 (0.401)	Loss 0.5640 (0.5640)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:50:15

 Epoch: 265	Training Loss 0.3760 	Training Prec@1 87.084 	Training Prec@5 99.490 	Validation Loss 0.7180 	Validation Prec@1 79.040 	Validation Prec@5 98.220 

lr: 0.08445203311140939
TRAINING - Epoch: [265][0/391]	Time 1.306 (1.306)	Data 0.412 (0.412)	Loss 0.3082 (0.3082)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [265][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.3181 (0.3673)	Prec@1 90.625 (87.438)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [265][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.3465 (0.3753)	Prec@1 87.500 (86.882)	Prec@5 100.000 (99.487)
TRAINING - Epoch: [265][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.4191 (0.3831)	Prec@1 86.719 (86.804)	Prec@5 100.000 (99.476)
EVALUATING - Epoch: [265][0/79]	Time 0.399 (0.399)	Data 0.373 (0.373)	Loss 0.6218 (0.6218)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:06

 Epoch: 266	Training Loss 0.3797 	Training Prec@1 86.984 	Training Prec@5 99.502 	Validation Loss 0.6766 	Validation Prec@1 79.700 	Validation Prec@5 98.800 

lr: 0.08433756556067501
TRAINING - Epoch: [266][0/391]	Time 1.380 (1.380)	Data 0.454 (0.454)	Loss 0.3212 (0.3212)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [266][100/391]	Time 0.112 (0.128)	Data 0.000 (0.005)	Loss 0.3735 (0.3686)	Prec@1 83.594 (87.245)	Prec@5 100.000 (99.598)
TRAINING - Epoch: [266][200/391]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.4310 (0.3744)	Prec@1 83.594 (87.057)	Prec@5 99.219 (99.502)
TRAINING - Epoch: [266][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4968 (0.3768)	Prec@1 85.156 (86.963)	Prec@5 98.438 (99.481)
EVALUATING - Epoch: [266][0/79]	Time 0.415 (0.415)	Data 0.385 (0.385)	Loss 0.7316 (0.7316)	Prec@1 76.562 (76.562)	Prec@5 96.094 (96.094)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:54

 Epoch: 267	Training Loss 0.3819 	Training Prec@1 86.766 	Training Prec@5 99.446 	Validation Loss 0.7032 	Validation Prec@1 77.320 	Validation Prec@5 97.590 

lr: 0.08422275638449589
TRAINING - Epoch: [267][0/391]	Time 1.333 (1.333)	Data 0.418 (0.418)	Loss 0.4209 (0.4209)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [267][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.2862 (0.3436)	Prec@1 88.281 (88.235)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [267][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.4033 (0.3612)	Prec@1 86.719 (87.733)	Prec@5 97.656 (99.499)
TRAINING - Epoch: [267][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.5876 (0.3641)	Prec@1 79.688 (87.575)	Prec@5 99.219 (99.507)
EVALUATING - Epoch: [267][0/79]	Time 0.422 (0.422)	Data 0.385 (0.385)	Loss 0.5234 (0.5234)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:43

 Epoch: 268	Training Loss 0.3715 	Training Prec@1 87.344 	Training Prec@5 99.464 	Validation Loss 0.6074 	Validation Prec@1 80.940 	Validation Prec@5 98.940 

lr: 0.08410760672511186
TRAINING - Epoch: [268][0/391]	Time 1.334 (1.334)	Data 0.451 (0.451)	Loss 0.3164 (0.3164)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [268][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.3777 (0.3726)	Prec@1 83.594 (87.121)	Prec@5 100.000 (99.474)
TRAINING - Epoch: [268][200/391]	Time 0.113 (0.119)	Data 0.001 (0.003)	Loss 0.2539 (0.3749)	Prec@1 92.188 (86.971)	Prec@5 100.000 (99.456)
TRAINING - Epoch: [268][300/391]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.4069 (0.3746)	Prec@1 87.500 (87.100)	Prec@5 98.438 (99.463)
EVALUATING - Epoch: [268][0/79]	Time 0.439 (0.439)	Data 0.400 (0.400)	Loss 0.5333 (0.5333)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:50:57

 Epoch: 269	Training Loss 0.3744 	Training Prec@1 87.112 	Training Prec@5 99.486 	Validation Loss 0.6694 	Validation Prec@1 78.480 	Validation Prec@5 99.050 

lr: 0.08399211772815027
TRAINING - Epoch: [269][0/391]	Time 1.319 (1.319)	Data 0.409 (0.409)	Loss 0.3428 (0.3428)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [269][100/391]	Time 0.108 (0.127)	Data 0.000 (0.004)	Loss 0.3144 (0.3589)	Prec@1 87.500 (87.515)	Prec@5 99.219 (99.435)
TRAINING - Epoch: [269][200/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.2689 (0.3631)	Prec@1 92.188 (87.547)	Prec@5 100.000 (99.468)
TRAINING - Epoch: [269][300/391]	Time 0.118 (0.119)	Data 0.001 (0.002)	Loss 0.3090 (0.3685)	Prec@1 88.281 (87.313)	Prec@5 99.219 (99.468)
EVALUATING - Epoch: [269][0/79]	Time 0.439 (0.439)	Data 0.386 (0.386)	Loss 0.8213 (0.8213)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:22

 Epoch: 270	Training Loss 0.3732 	Training Prec@1 87.130 	Training Prec@5 99.476 	Validation Loss 0.7009 	Validation Prec@1 78.940 	Validation Prec@5 98.470 

lr: 0.08387629054261449
TRAINING - Epoch: [270][0/391]	Time 1.624 (1.624)	Data 0.437 (0.437)	Loss 0.4477 (0.4477)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [270][100/391]	Time 0.119 (0.132)	Data 0.000 (0.005)	Loss 0.4700 (0.3635)	Prec@1 85.156 (87.515)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [270][200/391]	Time 0.109 (0.123)	Data 0.000 (0.003)	Loss 0.4127 (0.3694)	Prec@1 82.031 (87.348)	Prec@5 99.219 (99.502)
TRAINING - Epoch: [270][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3974 (0.3694)	Prec@1 84.375 (87.277)	Prec@5 100.000 (99.499)
EVALUATING - Epoch: [270][0/79]	Time 0.450 (0.450)	Data 0.401 (0.401)	Loss 0.5500 (0.5500)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:07

 Epoch: 271	Training Loss 0.3704 	Training Prec@1 87.208 	Training Prec@5 99.504 	Validation Loss 0.6742 	Validation Prec@1 78.260 	Validation Prec@5 98.680 

lr: 0.08376012632087264
TRAINING - Epoch: [271][0/391]	Time 1.348 (1.348)	Data 0.423 (0.423)	Loss 0.3370 (0.3370)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [271][100/391]	Time 0.114 (0.130)	Data 0.000 (0.005)	Loss 0.4651 (0.3469)	Prec@1 80.469 (88.150)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [271][200/391]	Time 0.116 (0.124)	Data 0.000 (0.003)	Loss 0.2510 (0.3662)	Prec@1 90.625 (87.543)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [271][300/391]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.4218 (0.3650)	Prec@1 85.156 (87.555)	Prec@5 99.219 (99.541)
EVALUATING - Epoch: [271][0/79]	Time 0.442 (0.442)	Data 0.411 (0.411)	Loss 0.5196 (0.5196)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:55:41

 Epoch: 272	Training Loss 0.3684 	Training Prec@1 87.400 	Training Prec@5 99.544 	Validation Loss 0.5879 	Validation Prec@1 81.380 	Validation Prec@5 98.600 

lr: 0.0836436262186459
TRAINING - Epoch: [272][0/391]	Time 1.316 (1.316)	Data 0.418 (0.418)	Loss 0.3494 (0.3494)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [272][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.3553 (0.3570)	Prec@1 89.844 (87.570)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [272][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.2701 (0.3578)	Prec@1 92.188 (87.586)	Prec@5 100.000 (99.561)
TRAINING - Epoch: [272][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.4416 (0.3666)	Prec@1 87.500 (87.360)	Prec@5 99.219 (99.546)
EVALUATING - Epoch: [272][0/79]	Time 0.453 (0.453)	Data 0.408 (0.408)	Loss 0.9818 (0.9818)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:03

 Epoch: 273	Training Loss 0.3729 	Training Prec@1 87.180 	Training Prec@5 99.524 	Validation Loss 1.0141 	Validation Prec@1 69.450 	Validation Prec@5 97.800 

lr: 0.08352679139499726
TRAINING - Epoch: [273][0/391]	Time 1.292 (1.292)	Data 0.363 (0.363)	Loss 0.3309 (0.3309)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [273][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.5060 (0.3589)	Prec@1 85.938 (87.577)	Prec@5 99.219 (99.443)
TRAINING - Epoch: [273][200/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3333 (0.3678)	Prec@1 88.281 (87.212)	Prec@5 100.000 (99.433)
TRAINING - Epoch: [273][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2934 (0.3654)	Prec@1 92.188 (87.342)	Prec@5 100.000 (99.489)
EVALUATING - Epoch: [273][0/79]	Time 0.443 (0.443)	Data 0.405 (0.405)	Loss 0.6272 (0.6272)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:46

 Epoch: 274	Training Loss 0.3648 	Training Prec@1 87.370 	Training Prec@5 99.492 	Validation Loss 0.6926 	Validation Prec@1 77.670 	Validation Prec@5 98.660 

lr: 0.08340962301231976
TRAINING - Epoch: [274][0/391]	Time 1.363 (1.363)	Data 0.440 (0.440)	Loss 0.3429 (0.3429)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [274][100/391]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.3641 (0.3580)	Prec@1 88.281 (87.856)	Prec@5 99.219 (99.513)
TRAINING - Epoch: [274][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.4447 (0.3663)	Prec@1 83.594 (87.469)	Prec@5 100.000 (99.502)
TRAINING - Epoch: [274][300/391]	Time 0.104 (0.116)	Data 0.000 (0.002)	Loss 0.4895 (0.3664)	Prec@1 83.594 (87.451)	Prec@5 100.000 (99.507)
EVALUATING - Epoch: [274][0/79]	Time 0.417 (0.417)	Data 0.377 (0.377)	Loss 0.3987 (0.3987)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:16:25

 Epoch: 275	Training Loss 0.3692 	Training Prec@1 87.362 	Training Prec@5 99.496 	Validation Loss 0.6004 	Validation Prec@1 80.810 	Validation Prec@5 98.930 

lr: 0.08329212223632507
TRAINING - Epoch: [275][0/391]	Time 1.307 (1.307)	Data 0.422 (0.422)	Loss 0.2788 (0.2788)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [275][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.3817 (0.3557)	Prec@1 87.500 (87.918)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [275][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.3108 (0.3633)	Prec@1 89.844 (87.753)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [275][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4904 (0.3672)	Prec@1 83.594 (87.534)	Prec@5 99.219 (99.554)
EVALUATING - Epoch: [275][0/79]	Time 0.436 (0.436)	Data 0.386 (0.386)	Loss 0.8007 (0.8007)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:57

 Epoch: 276	Training Loss 0.3700 	Training Prec@1 87.394 	Training Prec@5 99.556 	Validation Loss 0.7881 	Validation Prec@1 75.960 	Validation Prec@5 98.720 

lr: 0.08317429023603186
TRAINING - Epoch: [276][0/391]	Time 1.320 (1.320)	Data 0.427 (0.427)	Loss 0.4068 (0.4068)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [276][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.3396 (0.3642)	Prec@1 86.719 (87.500)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [276][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3632 (0.3671)	Prec@1 88.281 (87.278)	Prec@5 100.000 (99.588)
TRAINING - Epoch: [276][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.2799 (0.3725)	Prec@1 92.188 (87.176)	Prec@5 99.219 (99.522)
EVALUATING - Epoch: [276][0/79]	Time 0.448 (0.448)	Data 0.407 (0.407)	Loss 0.5260 (0.5260)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:38

 Epoch: 277	Training Loss 0.3775 	Training Prec@1 86.944 	Training Prec@5 99.510 	Validation Loss 0.6572 	Validation Prec@1 80.620 	Validation Prec@5 98.430 

lr: 0.08305612818375414
TRAINING - Epoch: [277][0/391]	Time 1.291 (1.291)	Data 0.404 (0.404)	Loss 0.3017 (0.3017)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [277][100/391]	Time 0.110 (0.125)	Data 0.000 (0.004)	Loss 0.4648 (0.3609)	Prec@1 82.031 (87.508)	Prec@5 99.219 (99.629)
TRAINING - Epoch: [277][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3271 (0.3647)	Prec@1 87.500 (87.414)	Prec@5 100.000 (99.604)
TRAINING - Epoch: [277][300/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2729 (0.3699)	Prec@1 89.844 (87.243)	Prec@5 100.000 (99.577)
EVALUATING - Epoch: [277][0/79]	Time 0.425 (0.425)	Data 0.381 (0.381)	Loss 0.5485 (0.5485)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:56

 Epoch: 278	Training Loss 0.3699 	Training Prec@1 87.242 	Training Prec@5 99.556 	Validation Loss 0.6503 	Validation Prec@1 80.380 	Validation Prec@5 98.630 

lr: 0.08293763725508965
TRAINING - Epoch: [278][0/391]	Time 1.608 (1.608)	Data 0.437 (0.437)	Loss 0.4434 (0.4434)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [278][100/391]	Time 0.114 (0.131)	Data 0.000 (0.005)	Loss 0.3058 (0.3586)	Prec@1 92.188 (87.740)	Prec@5 100.000 (99.513)
TRAINING - Epoch: [278][200/391]	Time 0.113 (0.123)	Data 0.000 (0.003)	Loss 0.6580 (0.3591)	Prec@1 78.906 (87.694)	Prec@5 98.438 (99.584)
TRAINING - Epoch: [278][300/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.4638 (0.3685)	Prec@1 85.156 (87.401)	Prec@5 99.219 (99.535)
EVALUATING - Epoch: [278][0/79]	Time 0.446 (0.446)	Data 0.402 (0.402)	Loss 0.5308 (0.5308)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:49:17

 Epoch: 279	Training Loss 0.3674 	Training Prec@1 87.476 	Training Prec@5 99.532 	Validation Loss 0.6509 	Validation Prec@1 79.030 	Validation Prec@5 98.760 

lr: 0.08281881862890808
TRAINING - Epoch: [279][0/391]	Time 1.319 (1.319)	Data 0.409 (0.409)	Loss 0.2403 (0.2403)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [279][100/391]	Time 0.118 (0.126)	Data 0.000 (0.004)	Loss 0.2984 (0.3624)	Prec@1 88.281 (87.369)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [279][200/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3543 (0.3713)	Prec@1 89.062 (87.104)	Prec@5 98.438 (99.506)
TRAINING - Epoch: [279][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.5021 (0.3781)	Prec@1 84.375 (86.916)	Prec@5 100.000 (99.476)
EVALUATING - Epoch: [279][0/79]	Time 0.413 (0.413)	Data 0.383 (0.383)	Loss 0.5406 (0.5406)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:34

 Epoch: 280	Training Loss 0.3736 	Training Prec@1 87.126 	Training Prec@5 99.462 	Validation Loss 0.6075 	Validation Prec@1 80.050 	Validation Prec@5 98.890 

lr: 0.08269967348733942
TRAINING - Epoch: [280][0/391]	Time 1.636 (1.636)	Data 0.444 (0.444)	Loss 0.5472 (0.5472)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [280][100/391]	Time 0.122 (0.132)	Data 0.000 (0.005)	Loss 0.2733 (0.3638)	Prec@1 89.062 (87.291)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [280][200/391]	Time 0.115 (0.125)	Data 0.000 (0.003)	Loss 0.3366 (0.3673)	Prec@1 85.938 (87.484)	Prec@5 100.000 (99.483)
TRAINING - Epoch: [280][300/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.4845 (0.3695)	Prec@1 81.250 (87.422)	Prec@5 99.219 (99.494)
EVALUATING - Epoch: [280][0/79]	Time 0.458 (0.458)	Data 0.410 (0.410)	Loss 0.5911 (0.5911)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:53:59

 Epoch: 281	Training Loss 0.3727 	Training Prec@1 87.282 	Training Prec@5 99.504 	Validation Loss 0.6759 	Validation Prec@1 78.820 	Validation Prec@5 98.780 

lr: 0.08258020301576219
TRAINING - Epoch: [281][0/391]	Time 1.612 (1.612)	Data 0.426 (0.426)	Loss 0.3186 (0.3186)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [281][100/391]	Time 0.117 (0.132)	Data 0.000 (0.005)	Loss 0.4415 (0.3619)	Prec@1 83.594 (87.392)	Prec@5 99.219 (99.536)
TRAINING - Epoch: [281][200/391]	Time 0.112 (0.124)	Data 0.000 (0.002)	Loss 0.4501 (0.3673)	Prec@1 83.594 (87.263)	Prec@5 99.219 (99.549)
TRAINING - Epoch: [281][300/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.5889 (0.3685)	Prec@1 82.031 (87.287)	Prec@5 99.219 (99.574)
EVALUATING - Epoch: [281][0/79]	Time 0.443 (0.443)	Data 0.406 (0.406)	Loss 0.4930 (0.4930)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:50:18

 Epoch: 282	Training Loss 0.3689 	Training Prec@1 87.356 	Training Prec@5 99.538 	Validation Loss 0.6519 	Validation Prec@1 79.920 	Validation Prec@5 98.920 

lr: 0.0824604084027916
TRAINING - Epoch: [282][0/391]	Time 1.321 (1.321)	Data 0.430 (0.430)	Loss 0.2247 (0.2247)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [282][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.4506 (0.3482)	Prec@1 83.594 (87.848)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [282][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.3459 (0.3586)	Prec@1 88.281 (87.753)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [282][300/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2561 (0.3644)	Prec@1 89.844 (87.471)	Prec@5 100.000 (99.535)
EVALUATING - Epoch: [282][0/79]	Time 0.473 (0.473)	Data 0.446 (0.446)	Loss 1.0785 (1.0785)	Prec@1 67.188 (67.188)	Prec@5 95.312 (95.312)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:41

 Epoch: 283	Training Loss 0.3683 	Training Prec@1 87.384 	Training Prec@5 99.538 	Validation Loss 0.9336 	Validation Prec@1 72.610 	Validation Prec@5 97.060 

lr: 0.08234029084026775
TRAINING - Epoch: [283][0/391]	Time 1.311 (1.311)	Data 0.421 (0.421)	Loss 0.3539 (0.3539)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [283][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.3874 (0.3600)	Prec@1 85.938 (87.585)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [283][200/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.3435 (0.3684)	Prec@1 87.500 (87.275)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [283][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3567 (0.3697)	Prec@1 86.719 (87.230)	Prec@5 99.219 (99.590)
EVALUATING - Epoch: [283][0/79]	Time 0.431 (0.431)	Data 0.402 (0.402)	Loss 0.5842 (0.5842)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:11

 Epoch: 284	Training Loss 0.3719 	Training Prec@1 87.196 	Training Prec@5 99.566 	Validation Loss 0.6219 	Validation Prec@1 80.520 	Validation Prec@5 98.850 

lr: 0.0822198515232438
TRAINING - Epoch: [284][0/391]	Time 1.313 (1.313)	Data 0.414 (0.414)	Loss 0.2656 (0.2656)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [284][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.3260 (0.3459)	Prec@1 89.062 (88.150)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [284][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2311 (0.3565)	Prec@1 92.188 (87.722)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [284][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.4961 (0.3676)	Prec@1 82.031 (87.227)	Prec@5 100.000 (99.520)
EVALUATING - Epoch: [284][0/79]	Time 0.420 (0.420)	Data 0.382 (0.382)	Loss 0.5028 (0.5028)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:05

 Epoch: 285	Training Loss 0.3676 	Training Prec@1 87.238 	Training Prec@5 99.526 	Validation Loss 0.6062 	Validation Prec@1 80.640 	Validation Prec@5 99.030 

lr: 0.08209909164997405
TRAINING - Epoch: [285][0/391]	Time 1.334 (1.334)	Data 0.424 (0.424)	Loss 0.2801 (0.2801)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [285][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.3755 (0.3519)	Prec@1 85.938 (87.972)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [285][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.5099 (0.3705)	Prec@1 79.688 (87.302)	Prec@5 100.000 (99.526)
TRAINING - Epoch: [285][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.4928 (0.3662)	Prec@1 79.688 (87.474)	Prec@5 100.000 (99.525)
EVALUATING - Epoch: [285][0/79]	Time 0.427 (0.427)	Data 0.383 (0.383)	Loss 0.7483 (0.7483)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:20:01

 Epoch: 286	Training Loss 0.3710 	Training Prec@1 87.334 	Training Prec@5 99.504 	Validation Loss 0.7890 	Validation Prec@1 77.380 	Validation Prec@5 98.310 

lr: 0.08197801242190197
TRAINING - Epoch: [286][0/391]	Time 1.575 (1.575)	Data 0.419 (0.419)	Loss 0.3691 (0.3691)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [286][100/391]	Time 0.110 (0.131)	Data 0.000 (0.004)	Loss 0.3744 (0.3636)	Prec@1 88.281 (87.523)	Prec@5 99.219 (99.544)
TRAINING - Epoch: [286][200/391]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.5193 (0.3648)	Prec@1 83.594 (87.488)	Prec@5 99.219 (99.545)
TRAINING - Epoch: [286][300/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.3076 (0.3661)	Prec@1 90.625 (87.433)	Prec@5 99.219 (99.551)
EVALUATING - Epoch: [286][0/79]	Time 0.439 (0.439)	Data 0.403 (0.403)	Loss 0.6177 (0.6177)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:46:31

 Epoch: 287	Training Loss 0.3691 	Training Prec@1 87.284 	Training Prec@5 99.554 	Validation Loss 0.9429 	Validation Prec@1 72.420 	Validation Prec@5 97.860 

lr: 0.0818566150436484
TRAINING - Epoch: [287][0/391]	Time 1.307 (1.307)	Data 0.423 (0.423)	Loss 0.4230 (0.4230)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [287][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.4090 (0.3627)	Prec@1 85.156 (87.523)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [287][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.2499 (0.3623)	Prec@1 90.625 (87.655)	Prec@5 100.000 (99.596)
TRAINING - Epoch: [287][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.4115 (0.3609)	Prec@1 88.281 (87.778)	Prec@5 99.219 (99.590)
EVALUATING - Epoch: [287][0/79]	Time 0.449 (0.449)	Data 0.410 (0.410)	Loss 0.6344 (0.6344)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:15

 Epoch: 288	Training Loss 0.3657 	Training Prec@1 87.572 	Training Prec@5 99.552 	Validation Loss 0.6301 	Validation Prec@1 80.620 	Validation Prec@5 98.830 

lr: 0.08173490072299937
TRAINING - Epoch: [288][0/391]	Time 1.292 (1.292)	Data 0.427 (0.427)	Loss 0.3312 (0.3312)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [288][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.2628 (0.3441)	Prec@1 90.625 (88.304)	Prec@5 99.219 (99.606)
TRAINING - Epoch: [288][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.4677 (0.3584)	Prec@1 87.500 (87.687)	Prec@5 99.219 (99.530)
TRAINING - Epoch: [288][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.4549 (0.3637)	Prec@1 84.375 (87.536)	Prec@5 98.438 (99.473)
EVALUATING - Epoch: [288][0/79]	Time 0.440 (0.440)	Data 0.406 (0.406)	Loss 0.5279 (0.5279)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:05

 Epoch: 289	Training Loss 0.3629 	Training Prec@1 87.594 	Training Prec@5 99.520 	Validation Loss 0.6870 	Validation Prec@1 78.140 	Validation Prec@5 98.250 

lr: 0.08161287067089423
TRAINING - Epoch: [289][0/391]	Time 1.344 (1.344)	Data 0.444 (0.444)	Loss 0.5256 (0.5256)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [289][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.3241 (0.3633)	Prec@1 85.156 (87.353)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [289][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.4269 (0.3706)	Prec@1 86.719 (87.146)	Prec@5 99.219 (99.530)
TRAINING - Epoch: [289][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.3105 (0.3704)	Prec@1 85.156 (87.204)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [289][0/79]	Time 0.412 (0.412)	Data 0.384 (0.384)	Loss 0.6489 (0.6489)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:20:54

 Epoch: 290	Training Loss 0.3693 	Training Prec@1 87.244 	Training Prec@5 99.522 	Validation Loss 0.8393 	Validation Prec@1 75.280 	Validation Prec@5 98.260 

lr: 0.08149052610141352
TRAINING - Epoch: [290][0/391]	Time 1.385 (1.385)	Data 0.448 (0.448)	Loss 0.3017 (0.3017)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [290][100/391]	Time 0.119 (0.130)	Data 0.000 (0.005)	Loss 0.2421 (0.3492)	Prec@1 92.188 (88.103)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [290][200/391]	Time 0.109 (0.124)	Data 0.000 (0.003)	Loss 0.2530 (0.3608)	Prec@1 89.844 (87.500)	Prec@5 100.000 (99.534)
TRAINING - Epoch: [290][300/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3074 (0.3599)	Prec@1 89.062 (87.580)	Prec@5 99.219 (99.551)
EVALUATING - Epoch: [290][0/79]	Time 0.446 (0.446)	Data 0.402 (0.402)	Loss 0.6311 (0.6311)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:46:21

 Epoch: 291	Training Loss 0.3652 	Training Prec@1 87.402 	Training Prec@5 99.562 	Validation Loss 0.7225 	Validation Prec@1 77.470 	Validation Prec@5 98.330 

lr: 0.08136786823176698
TRAINING - Epoch: [291][0/391]	Time 1.290 (1.290)	Data 0.418 (0.418)	Loss 0.4379 (0.4379)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [291][100/391]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.2497 (0.3596)	Prec@1 92.188 (87.276)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [291][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4024 (0.3686)	Prec@1 86.719 (87.162)	Prec@5 98.438 (99.510)
TRAINING - Epoch: [291][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.5043 (0.3701)	Prec@1 83.594 (87.196)	Prec@5 99.219 (99.520)
EVALUATING - Epoch: [291][0/79]	Time 0.423 (0.423)	Data 0.391 (0.391)	Loss 0.6373 (0.6373)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:25

 Epoch: 292	Training Loss 0.3732 	Training Prec@1 87.080 	Training Prec@5 99.512 	Validation Loss 0.6864 	Validation Prec@1 76.810 	Validation Prec@5 98.950 

lr: 0.08124489828228132
TRAINING - Epoch: [292][0/391]	Time 1.297 (1.297)	Data 0.367 (0.367)	Loss 0.2604 (0.2604)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [292][100/391]	Time 0.107 (0.124)	Data 0.000 (0.004)	Loss 0.3597 (0.3665)	Prec@1 87.500 (87.222)	Prec@5 100.000 (99.520)
TRAINING - Epoch: [292][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3661 (0.3621)	Prec@1 86.719 (87.531)	Prec@5 98.438 (99.557)
TRAINING - Epoch: [292][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.5295 (0.3616)	Prec@1 82.812 (87.586)	Prec@5 99.219 (99.564)
EVALUATING - Epoch: [292][0/79]	Time 0.442 (0.442)	Data 0.413 (0.413)	Loss 0.4226 (0.4226)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:44

 Epoch: 293	Training Loss 0.3633 	Training Prec@1 87.498 	Training Prec@5 99.546 	Validation Loss 0.5826 	Validation Prec@1 80.660 	Validation Prec@5 99.200 

lr: 0.08112161747638817
TRAINING - Epoch: [293][0/391]	Time 1.317 (1.317)	Data 0.413 (0.413)	Loss 0.3682 (0.3682)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [293][100/391]	Time 0.112 (0.124)	Data 0.000 (0.004)	Loss 0.5018 (0.3565)	Prec@1 82.812 (87.817)	Prec@5 100.000 (99.505)
TRAINING - Epoch: [293][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3842 (0.3664)	Prec@1 87.500 (87.352)	Prec@5 98.438 (99.491)
TRAINING - Epoch: [293][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4120 (0.3669)	Prec@1 85.938 (87.464)	Prec@5 100.000 (99.520)
EVALUATING - Epoch: [293][0/79]	Time 0.468 (0.468)	Data 0.426 (0.426)	Loss 0.4075 (0.4075)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:28

 Epoch: 294	Training Loss 0.3661 	Training Prec@1 87.490 	Training Prec@5 99.528 	Validation Loss 0.6589 	Validation Prec@1 80.260 	Validation Prec@5 98.800 

lr: 0.0809980270406119
TRAINING - Epoch: [294][0/391]	Time 1.347 (1.347)	Data 0.445 (0.445)	Loss 0.2616 (0.2616)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [294][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.4353 (0.3667)	Prec@1 86.719 (87.608)	Prec@5 97.656 (99.489)
TRAINING - Epoch: [294][200/391]	Time 0.107 (0.118)	Data 0.000 (0.003)	Loss 0.3397 (0.3675)	Prec@1 87.500 (87.337)	Prec@5 100.000 (99.460)
TRAINING - Epoch: [294][300/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.3829 (0.3663)	Prec@1 85.938 (87.404)	Prec@5 100.000 (99.486)
EVALUATING - Epoch: [294][0/79]	Time 0.435 (0.435)	Data 0.407 (0.407)	Loss 0.4723 (0.4723)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:37

 Epoch: 295	Training Loss 0.3686 	Training Prec@1 87.346 	Training Prec@5 99.512 	Validation Loss 0.6147 	Validation Prec@1 80.140 	Validation Prec@5 99.000 

lr: 0.08087412820455733
TRAINING - Epoch: [295][0/391]	Time 1.362 (1.362)	Data 0.451 (0.451)	Loss 0.3382 (0.3382)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [295][100/391]	Time 0.110 (0.126)	Data 0.000 (0.005)	Loss 0.3315 (0.3572)	Prec@1 87.500 (87.554)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [295][200/391]	Time 0.109 (0.119)	Data 0.000 (0.003)	Loss 0.4017 (0.3555)	Prec@1 88.281 (87.694)	Prec@5 99.219 (99.596)
TRAINING - Epoch: [295][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.4964 (0.3601)	Prec@1 85.938 (87.713)	Prec@5 98.438 (99.556)
EVALUATING - Epoch: [295][0/79]	Time 0.453 (0.453)	Data 0.408 (0.408)	Loss 0.4225 (0.4225)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:38

 Epoch: 296	Training Loss 0.3635 	Training Prec@1 87.616 	Training Prec@5 99.526 	Validation Loss 0.5669 	Validation Prec@1 81.140 	Validation Prec@5 98.960 

lr: 0.08074992220089763
TRAINING - Epoch: [296][0/391]	Time 1.315 (1.315)	Data 0.427 (0.427)	Loss 0.4717 (0.4717)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [296][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.3319 (0.3561)	Prec@1 89.062 (87.639)	Prec@5 99.219 (99.505)
TRAINING - Epoch: [296][200/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.3121 (0.3512)	Prec@1 89.062 (87.850)	Prec@5 100.000 (99.580)
TRAINING - Epoch: [296][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.3002 (0.3559)	Prec@1 89.062 (87.700)	Prec@5 98.438 (99.572)
EVALUATING - Epoch: [296][0/79]	Time 0.447 (0.447)	Data 0.407 (0.407)	Loss 0.8940 (0.8940)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:20

 Epoch: 297	Training Loss 0.3572 	Training Prec@1 87.670 	Training Prec@5 99.578 	Validation Loss 0.8870 	Validation Prec@1 74.700 	Validation Prec@5 98.070 

lr: 0.08062541026536199
TRAINING - Epoch: [297][0/391]	Time 1.305 (1.305)	Data 0.416 (0.416)	Loss 0.3313 (0.3313)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [297][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.1758 (0.3713)	Prec@1 95.312 (87.013)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [297][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.4188 (0.3680)	Prec@1 85.156 (87.189)	Prec@5 99.219 (99.541)
TRAINING - Epoch: [297][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3796 (0.3644)	Prec@1 86.719 (87.318)	Prec@5 100.000 (99.559)
EVALUATING - Epoch: [297][0/79]	Time 0.423 (0.423)	Data 0.388 (0.388)	Loss 0.6377 (0.6377)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:12

 Epoch: 298	Training Loss 0.3638 	Training Prec@1 87.412 	Training Prec@5 99.542 	Validation Loss 0.7452 	Validation Prec@1 78.220 	Validation Prec@5 97.990 

lr: 0.08050059363672324
TRAINING - Epoch: [298][0/391]	Time 1.307 (1.307)	Data 0.419 (0.419)	Loss 0.4666 (0.4666)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [298][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.4581 (0.3500)	Prec@1 84.375 (88.026)	Prec@5 99.219 (99.621)
TRAINING - Epoch: [298][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3580 (0.3574)	Prec@1 87.500 (87.819)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [298][300/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.3991 (0.3548)	Prec@1 87.500 (87.874)	Prec@5 100.000 (99.572)
EVALUATING - Epoch: [298][0/79]	Time 0.433 (0.433)	Data 0.401 (0.401)	Loss 0.5871 (0.5871)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:27

 Epoch: 299	Training Loss 0.3617 	Training Prec@1 87.680 	Training Prec@5 99.552 	Validation Loss 0.6217 	Validation Prec@1 80.040 	Validation Prec@5 98.310 

lr: 0.08037547355678575
TRAINING - Epoch: [299][0/391]	Time 1.291 (1.291)	Data 0.436 (0.436)	Loss 0.4169 (0.4169)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [299][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.2823 (0.3608)	Prec@1 90.625 (87.407)	Prec@5 99.219 (99.505)
TRAINING - Epoch: [299][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.4638 (0.3591)	Prec@1 85.938 (87.613)	Prec@5 98.438 (99.522)
TRAINING - Epoch: [299][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3904 (0.3640)	Prec@1 87.500 (87.407)	Prec@5 99.219 (99.507)
EVALUATING - Epoch: [299][0/79]	Time 0.437 (0.437)	Data 0.398 (0.398)	Loss 0.5651 (0.5651)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:45

 Epoch: 300	Training Loss 0.3635 	Training Prec@1 87.418 	Training Prec@5 99.536 	Validation Loss 0.6716 	Validation Prec@1 79.180 	Validation Prec@5 98.550 

lr: 0.08025005127037278
TRAINING - Epoch: [300][0/391]	Time 1.289 (1.289)	Data 0.440 (0.440)	Loss 0.2629 (0.2629)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [300][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.4548 (0.3433)	Prec@1 84.375 (88.243)	Prec@5 98.438 (99.513)
TRAINING - Epoch: [300][200/391]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.4072 (0.3545)	Prec@1 84.375 (87.663)	Prec@5 100.000 (99.561)
TRAINING - Epoch: [300][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4607 (0.3594)	Prec@1 86.719 (87.466)	Prec@5 99.219 (99.538)
EVALUATING - Epoch: [300][0/79]	Time 0.417 (0.417)	Data 0.389 (0.389)	Loss 0.4891 (0.4891)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:39

 Epoch: 301	Training Loss 0.3611 	Training Prec@1 87.442 	Training Prec@5 99.534 	Validation Loss 0.5901 	Validation Prec@1 80.690 	Validation Prec@5 98.860 

lr: 0.08012432802531437
TRAINING - Epoch: [301][0/391]	Time 1.291 (1.291)	Data 0.443 (0.443)	Loss 0.2883 (0.2883)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [301][100/391]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.2530 (0.3439)	Prec@1 89.062 (88.390)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [301][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.2847 (0.3619)	Prec@1 89.062 (87.795)	Prec@5 99.219 (99.569)
TRAINING - Epoch: [301][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2844 (0.3611)	Prec@1 89.062 (87.804)	Prec@5 100.000 (99.564)
EVALUATING - Epoch: [301][0/79]	Time 0.430 (0.430)	Data 0.394 (0.394)	Loss 0.5306 (0.5306)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:27

 Epoch: 302	Training Loss 0.3616 	Training Prec@1 87.806 	Training Prec@5 99.566 	Validation Loss 0.6008 	Validation Prec@1 80.710 	Validation Prec@5 98.880 

lr: 0.07999830507243474
TRAINING - Epoch: [302][0/391]	Time 1.304 (1.304)	Data 0.437 (0.437)	Loss 0.2865 (0.2865)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [302][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.4728 (0.3623)	Prec@1 82.031 (87.825)	Prec@5 98.438 (99.551)
TRAINING - Epoch: [302][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3483 (0.3639)	Prec@1 88.281 (87.745)	Prec@5 99.219 (99.510)
TRAINING - Epoch: [302][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.4101 (0.3593)	Prec@1 86.719 (87.824)	Prec@5 98.438 (99.548)
EVALUATING - Epoch: [302][0/79]	Time 0.407 (0.407)	Data 0.377 (0.377)	Loss 0.6499 (0.6499)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:52

 Epoch: 303	Training Loss 0.3604 	Training Prec@1 87.720 	Training Prec@5 99.548 	Validation Loss 0.7263 	Validation Prec@1 79.030 	Validation Prec@5 98.160 

lr: 0.07987198366553998
TRAINING - Epoch: [303][0/391]	Time 1.285 (1.285)	Data 0.436 (0.436)	Loss 0.2793 (0.2793)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [303][100/391]	Time 0.107 (0.122)	Data 0.000 (0.005)	Loss 0.2912 (0.3532)	Prec@1 92.188 (87.941)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [303][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4628 (0.3572)	Prec@1 85.938 (87.823)	Prec@5 98.438 (99.584)
TRAINING - Epoch: [303][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.3201 (0.3561)	Prec@1 89.062 (87.741)	Prec@5 99.219 (99.587)
EVALUATING - Epoch: [303][0/79]	Time 0.437 (0.437)	Data 0.406 (0.406)	Loss 0.6128 (0.6128)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:20:10

 Epoch: 304	Training Loss 0.3609 	Training Prec@1 87.586 	Training Prec@5 99.570 	Validation Loss 0.6895 	Validation Prec@1 78.080 	Validation Prec@5 98.880 

lr: 0.07974536506140542
TRAINING - Epoch: [304][0/391]	Time 1.295 (1.295)	Data 0.449 (0.449)	Loss 0.3171 (0.3171)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [304][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.2651 (0.3500)	Prec@1 92.188 (87.724)	Prec@5 99.219 (99.629)
TRAINING - Epoch: [304][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.4269 (0.3599)	Prec@1 87.500 (87.492)	Prec@5 99.219 (99.592)
TRAINING - Epoch: [304][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3752 (0.3592)	Prec@1 85.156 (87.575)	Prec@5 100.000 (99.574)
EVALUATING - Epoch: [304][0/79]	Time 0.435 (0.435)	Data 0.386 (0.386)	Loss 0.4373 (0.4373)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:19

 Epoch: 305	Training Loss 0.3635 	Training Prec@1 87.440 	Training Prec@5 99.554 	Validation Loss 0.5616 	Validation Prec@1 81.840 	Validation Prec@5 98.850 

lr: 0.0796184505197633
TRAINING - Epoch: [305][0/391]	Time 1.251 (1.251)	Data 0.406 (0.406)	Loss 0.2458 (0.2458)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [305][100/391]	Time 0.105 (0.115)	Data 0.000 (0.004)	Loss 0.2817 (0.3466)	Prec@1 90.625 (88.320)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [305][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3180 (0.3567)	Prec@1 88.281 (87.924)	Prec@5 99.219 (99.561)
TRAINING - Epoch: [305][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.3281 (0.3574)	Prec@1 89.062 (87.824)	Prec@5 99.219 (99.567)
EVALUATING - Epoch: [305][0/79]	Time 0.441 (0.441)	Data 0.397 (0.397)	Loss 0.5122 (0.5122)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:44	Time of Finish: 2022-03-24 01:50:39

 Epoch: 306	Training Loss 0.3598 	Training Prec@1 87.720 	Training Prec@5 99.552 	Validation Loss 0.5969 	Validation Prec@1 80.630 	Validation Prec@5 98.570 

lr: 0.07949124130329005
TRAINING - Epoch: [306][0/391]	Time 1.300 (1.300)	Data 0.446 (0.446)	Loss 0.3992 (0.3992)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [306][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.3780 (0.3504)	Prec@1 83.594 (87.964)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [306][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.3798 (0.3602)	Prec@1 84.375 (87.784)	Prec@5 99.219 (99.491)
TRAINING - Epoch: [306][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4409 (0.3635)	Prec@1 85.938 (87.674)	Prec@5 99.219 (99.504)
EVALUATING - Epoch: [306][0/79]	Time 0.422 (0.422)	Data 0.375 (0.375)	Loss 0.5694 (0.5694)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:32

 Epoch: 307	Training Loss 0.3618 	Training Prec@1 87.746 	Training Prec@5 99.516 	Validation Loss 0.6796 	Validation Prec@1 78.620 	Validation Prec@5 98.540 

lr: 0.07936373867759396
TRAINING - Epoch: [307][0/391]	Time 1.308 (1.308)	Data 0.452 (0.452)	Loss 0.3225 (0.3225)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [307][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.2568 (0.3479)	Prec@1 90.625 (88.018)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [307][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.3660 (0.3585)	Prec@1 88.281 (87.683)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [307][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.4543 (0.3601)	Prec@1 85.156 (87.656)	Prec@5 99.219 (99.569)
EVALUATING - Epoch: [307][0/79]	Time 0.444 (0.444)	Data 0.404 (0.404)	Loss 0.6233 (0.6233)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:39

 Epoch: 308	Training Loss 0.3607 	Training Prec@1 87.650 	Training Prec@5 99.556 	Validation Loss 0.6418 	Validation Prec@1 80.150 	Validation Prec@5 98.990 

lr: 0.07923594391120234
TRAINING - Epoch: [308][0/391]	Time 1.291 (1.291)	Data 0.443 (0.443)	Loss 0.3437 (0.3437)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [308][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.4031 (0.3459)	Prec@1 87.500 (87.964)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [308][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.4059 (0.3530)	Prec@1 89.844 (87.869)	Prec@5 99.219 (99.588)
TRAINING - Epoch: [308][300/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3589 (0.3531)	Prec@1 88.281 (87.786)	Prec@5 99.219 (99.585)
EVALUATING - Epoch: [308][0/79]	Time 0.438 (0.438)	Data 0.403 (0.403)	Loss 0.5707 (0.5707)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:19

 Epoch: 309	Training Loss 0.3577 	Training Prec@1 87.672 	Training Prec@5 99.578 	Validation Loss 0.5849 	Validation Prec@1 80.640 	Validation Prec@5 98.960 

lr: 0.07910785827554905
TRAINING - Epoch: [309][0/391]	Time 1.272 (1.272)	Data 0.414 (0.414)	Loss 0.4318 (0.4318)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [309][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.4374 (0.3545)	Prec@1 84.375 (87.809)	Prec@5 100.000 (99.505)
TRAINING - Epoch: [309][200/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3929 (0.3530)	Prec@1 87.500 (87.807)	Prec@5 98.438 (99.495)
TRAINING - Epoch: [309][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.5321 (0.3512)	Prec@1 85.156 (87.923)	Prec@5 97.656 (99.522)
EVALUATING - Epoch: [309][0/79]	Time 0.446 (0.446)	Data 0.417 (0.417)	Loss 0.9524 (0.9524)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:19:52

 Epoch: 310	Training Loss 0.3547 	Training Prec@1 87.784 	Training Prec@5 99.512 	Validation Loss 0.8335 	Validation Prec@1 75.410 	Validation Prec@5 97.910 

lr: 0.07897948304496186
TRAINING - Epoch: [310][0/391]	Time 1.255 (1.255)	Data 0.421 (0.421)	Loss 0.3518 (0.3518)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [310][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.5333 (0.3368)	Prec@1 83.594 (88.390)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [310][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3850 (0.3437)	Prec@1 85.938 (88.246)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [310][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.4445 (0.3507)	Prec@1 85.156 (87.980)	Prec@5 100.000 (99.561)
EVALUATING - Epoch: [310][0/79]	Time 0.444 (0.444)	Data 0.407 (0.407)	Loss 0.5391 (0.5391)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:50:39

 Epoch: 311	Training Loss 0.3549 	Training Prec@1 87.840 	Training Prec@5 99.566 	Validation Loss 0.6179 	Validation Prec@1 80.510 	Validation Prec@5 98.480 

lr: 0.07885081949664968
TRAINING - Epoch: [311][0/391]	Time 1.284 (1.284)	Data 0.430 (0.430)	Loss 0.2880 (0.2880)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [311][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.3681 (0.3425)	Prec@1 87.500 (88.420)	Prec@5 99.219 (99.559)
TRAINING - Epoch: [311][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3918 (0.3481)	Prec@1 84.375 (88.184)	Prec@5 100.000 (99.522)
TRAINING - Epoch: [311][300/391]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.1788 (0.3520)	Prec@1 93.750 (88.001)	Prec@5 100.000 (99.541)
EVALUATING - Epoch: [311][0/79]	Time 0.452 (0.452)	Data 0.415 (0.415)	Loss 0.4971 (0.4971)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:32:04

 Epoch: 312	Training Loss 0.3541 	Training Prec@1 87.928 	Training Prec@5 99.556 	Validation Loss 0.5791 	Validation Prec@1 80.590 	Validation Prec@5 98.500 

lr: 0.07872186891068991
TRAINING - Epoch: [312][0/391]	Time 1.307 (1.307)	Data 0.452 (0.452)	Loss 0.4421 (0.4421)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [312][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.2987 (0.3526)	Prec@1 90.625 (88.096)	Prec@5 100.000 (99.528)
TRAINING - Epoch: [312][200/391]	Time 0.115 (0.117)	Data 0.000 (0.003)	Loss 0.4636 (0.3590)	Prec@1 83.594 (87.912)	Prec@5 99.219 (99.530)
TRAINING - Epoch: [312][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.5634 (0.3570)	Prec@1 82.031 (87.887)	Prec@5 99.219 (99.559)
EVALUATING - Epoch: [312][0/79]	Time 0.426 (0.426)	Data 0.389 (0.389)	Loss 0.4524 (0.4524)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:35

 Epoch: 313	Training Loss 0.3549 	Training Prec@1 87.978 	Training Prec@5 99.546 	Validation Loss 0.6209 	Validation Prec@1 80.680 	Validation Prec@5 98.740 

lr: 0.07859263257001572
TRAINING - Epoch: [313][0/391]	Time 1.302 (1.302)	Data 0.450 (0.450)	Loss 0.3650 (0.3650)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [313][100/391]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.3047 (0.3409)	Prec@1 92.188 (88.049)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [313][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.3258 (0.3453)	Prec@1 89.844 (88.056)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [313][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3520 (0.3467)	Prec@1 88.281 (88.040)	Prec@5 100.000 (99.522)
EVALUATING - Epoch: [313][0/79]	Time 0.428 (0.428)	Data 0.383 (0.383)	Loss 0.7618 (0.7618)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:01

 Epoch: 314	Training Loss 0.3522 	Training Prec@1 87.980 	Training Prec@5 99.510 	Validation Loss 0.6872 	Validation Prec@1 78.170 	Validation Prec@5 98.390 

lr: 0.07846311176040326
TRAINING - Epoch: [314][0/391]	Time 1.268 (1.268)	Data 0.434 (0.434)	Loss 0.3127 (0.3127)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [314][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.1922 (0.3483)	Prec@1 93.750 (87.771)	Prec@5 100.000 (99.497)
TRAINING - Epoch: [314][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3372 (0.3545)	Prec@1 88.281 (87.760)	Prec@5 99.219 (99.468)
TRAINING - Epoch: [314][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.4449 (0.3534)	Prec@1 82.812 (87.853)	Prec@5 98.438 (99.463)
EVALUATING - Epoch: [314][0/79]	Time 0.415 (0.415)	Data 0.385 (0.385)	Loss 0.6581 (0.6581)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:50:14

 Epoch: 315	Training Loss 0.3537 	Training Prec@1 87.872 	Training Prec@5 99.504 	Validation Loss 0.6683 	Validation Prec@1 79.850 	Validation Prec@5 98.290 

lr: 0.07833330777045881
TRAINING - Epoch: [315][0/391]	Time 1.289 (1.289)	Data 0.440 (0.440)	Loss 0.4340 (0.4340)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [315][100/391]	Time 0.117 (0.126)	Data 0.000 (0.005)	Loss 0.2135 (0.3489)	Prec@1 92.969 (88.080)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [315][200/391]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.2656 (0.3524)	Prec@1 89.844 (87.861)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [315][300/391]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3636 (0.3529)	Prec@1 89.062 (87.897)	Prec@5 99.219 (99.582)
EVALUATING - Epoch: [315][0/79]	Time 0.445 (0.445)	Data 0.410 (0.410)	Loss 0.5421 (0.5421)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:55

 Epoch: 316	Training Loss 0.3564 	Training Prec@1 87.758 	Training Prec@5 99.558 	Validation Loss 0.6887 	Validation Prec@1 78.260 	Validation Prec@5 98.830 

lr: 0.07820322189160613
TRAINING - Epoch: [316][0/391]	Time 1.284 (1.284)	Data 0.440 (0.440)	Loss 0.3961 (0.3961)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [316][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.5365 (0.3400)	Prec@1 82.031 (88.397)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [316][200/391]	Time 0.116 (0.117)	Data 0.000 (0.003)	Loss 0.3604 (0.3446)	Prec@1 89.844 (88.118)	Prec@5 99.219 (99.584)
TRAINING - Epoch: [316][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2376 (0.3439)	Prec@1 92.188 (88.133)	Prec@5 100.000 (99.572)
EVALUATING - Epoch: [316][0/79]	Time 0.439 (0.439)	Data 0.399 (0.399)	Loss 0.6192 (0.6192)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:48

 Epoch: 317	Training Loss 0.3511 	Training Prec@1 87.884 	Training Prec@5 99.576 	Validation Loss 0.6208 	Validation Prec@1 79.430 	Validation Prec@5 98.740 

lr: 0.07807285541807338
TRAINING - Epoch: [317][0/391]	Time 1.253 (1.253)	Data 0.413 (0.413)	Loss 0.2339 (0.2339)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [317][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.2494 (0.3419)	Prec@1 90.625 (88.390)	Prec@5 100.000 (99.544)
TRAINING - Epoch: [317][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.3671 (0.3548)	Prec@1 86.719 (87.830)	Prec@5 100.000 (99.541)
TRAINING - Epoch: [317][300/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.2999 (0.3527)	Prec@1 89.844 (87.944)	Prec@5 99.219 (99.567)
EVALUATING - Epoch: [317][0/79]	Time 0.423 (0.423)	Data 0.381 (0.381)	Loss 0.4585 (0.4585)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:40

 Epoch: 318	Training Loss 0.3550 	Training Prec@1 87.882 	Training Prec@5 99.578 	Validation Loss 0.5611 	Validation Prec@1 80.980 	Validation Prec@5 98.670 

lr: 0.07794220964688044
TRAINING - Epoch: [318][0/391]	Time 1.359 (1.359)	Data 0.458 (0.458)	Loss 0.2815 (0.2815)	Prec@1 91.406 (91.406)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [318][100/391]	Time 0.104 (0.117)	Data 0.000 (0.005)	Loss 0.2821 (0.3399)	Prec@1 91.406 (88.328)	Prec@5 99.219 (99.590)
TRAINING - Epoch: [318][200/391]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.3624 (0.3535)	Prec@1 87.500 (87.803)	Prec@5 100.000 (99.580)
TRAINING - Epoch: [318][300/391]	Time 0.121 (0.112)	Data 0.000 (0.002)	Loss 0.4151 (0.3514)	Prec@1 83.594 (87.944)	Prec@5 99.219 (99.569)
EVALUATING - Epoch: [318][0/79]	Time 0.430 (0.430)	Data 0.404 (0.404)	Loss 0.6469 (0.6469)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:20:25

 Epoch: 319	Training Loss 0.3529 	Training Prec@1 87.946 	Training Prec@5 99.550 	Validation Loss 0.7958 	Validation Prec@1 76.660 	Validation Prec@5 98.540 

lr: 0.0778112858778259
TRAINING - Epoch: [319][0/391]	Time 1.296 (1.296)	Data 0.441 (0.441)	Loss 0.3109 (0.3109)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [319][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.3993 (0.3273)	Prec@1 89.062 (88.854)	Prec@5 98.438 (99.598)
TRAINING - Epoch: [319][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.2410 (0.3426)	Prec@1 90.625 (88.215)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [319][300/391]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.3376 (0.3438)	Prec@1 89.062 (88.235)	Prec@5 100.000 (99.598)
EVALUATING - Epoch: [319][0/79]	Time 0.427 (0.427)	Data 0.385 (0.385)	Loss 0.4491 (0.4491)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:58

 Epoch: 320	Training Loss 0.3484 	Training Prec@1 88.036 	Training Prec@5 99.580 	Validation Loss 0.6246 	Validation Prec@1 79.970 	Validation Prec@5 98.910 

lr: 0.07768008541347418
TRAINING - Epoch: [320][0/391]	Time 1.325 (1.325)	Data 0.481 (0.481)	Loss 0.3385 (0.3385)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [320][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.3494 (0.3446)	Prec@1 87.500 (87.933)	Prec@5 99.219 (99.660)
TRAINING - Epoch: [320][200/391]	Time 0.112 (0.119)	Data 0.000 (0.003)	Loss 0.4099 (0.3469)	Prec@1 83.594 (87.861)	Prec@5 99.219 (99.619)
TRAINING - Epoch: [320][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3766 (0.3562)	Prec@1 87.500 (87.591)	Prec@5 99.219 (99.577)
EVALUATING - Epoch: [320][0/79]	Time 0.427 (0.427)	Data 0.391 (0.391)	Loss 0.7127 (0.7127)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:26

 Epoch: 321	Training Loss 0.3604 	Training Prec@1 87.550 	Training Prec@5 99.546 	Validation Loss 0.6879 	Validation Prec@1 78.560 	Validation Prec@5 98.300 

lr: 0.07754860955914257
TRAINING - Epoch: [321][0/391]	Time 1.264 (1.264)	Data 0.422 (0.422)	Loss 0.3719 (0.3719)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [321][100/391]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.3462 (0.3454)	Prec@1 86.719 (87.980)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [321][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.3283 (0.3537)	Prec@1 89.844 (87.947)	Prec@5 100.000 (99.639)
TRAINING - Epoch: [321][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.4555 (0.3560)	Prec@1 83.594 (87.863)	Prec@5 100.000 (99.616)
EVALUATING - Epoch: [321][0/79]	Time 0.495 (0.495)	Data 0.457 (0.457)	Loss 0.6044 (0.6044)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:46

 Epoch: 322	Training Loss 0.3536 	Training Prec@1 87.910 	Training Prec@5 99.606 	Validation Loss 0.6477 	Validation Prec@1 79.240 	Validation Prec@5 98.560 

lr: 0.07741685962288813
TRAINING - Epoch: [322][0/391]	Time 1.279 (1.279)	Data 0.410 (0.410)	Loss 0.4741 (0.4741)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [322][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.3370 (0.3438)	Prec@1 87.500 (88.366)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [322][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3438 (0.3464)	Prec@1 89.844 (88.371)	Prec@5 98.438 (99.580)
TRAINING - Epoch: [322][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.3542 (0.3474)	Prec@1 88.281 (88.307)	Prec@5 99.219 (99.590)
EVALUATING - Epoch: [322][0/79]	Time 0.468 (0.468)	Data 0.428 (0.428)	Loss 0.5441 (0.5441)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:58

 Epoch: 323	Training Loss 0.3494 	Training Prec@1 88.154 	Training Prec@5 99.586 	Validation Loss 0.6309 	Validation Prec@1 80.460 	Validation Prec@5 98.600 

lr: 0.07728483691549487
TRAINING - Epoch: [323][0/391]	Time 1.552 (1.552)	Data 0.418 (0.418)	Loss 0.4933 (0.4933)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [323][100/391]	Time 0.126 (0.134)	Data 0.000 (0.004)	Loss 0.4292 (0.3608)	Prec@1 87.500 (87.399)	Prec@5 97.656 (99.466)
TRAINING - Epoch: [323][200/391]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.3356 (0.3558)	Prec@1 89.844 (87.442)	Prec@5 99.219 (99.580)
TRAINING - Epoch: [323][300/391]	Time 0.115 (0.125)	Data 0.000 (0.002)	Loss 0.3611 (0.3536)	Prec@1 88.281 (87.635)	Prec@5 99.219 (99.577)
EVALUATING - Epoch: [323][0/79]	Time 0.449 (0.449)	Data 0.411 (0.411)	Loss 0.7911 (0.7911)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 03:00:22

 Epoch: 324	Training Loss 0.3531 	Training Prec@1 87.626 	Training Prec@5 99.612 	Validation Loss 0.7075 	Validation Prec@1 77.230 	Validation Prec@5 98.920 

lr: 0.07715254275046059
TRAINING - Epoch: [324][0/391]	Time 1.579 (1.579)	Data 0.451 (0.451)	Loss 0.2231 (0.2231)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [324][100/391]	Time 0.120 (0.132)	Data 0.000 (0.005)	Loss 0.4195 (0.3376)	Prec@1 82.812 (88.026)	Prec@5 98.438 (99.590)
TRAINING - Epoch: [324][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.3760 (0.3444)	Prec@1 83.594 (87.943)	Prec@5 100.000 (99.604)
TRAINING - Epoch: [324][300/391]	Time 0.107 (0.121)	Data 0.000 (0.002)	Loss 0.4027 (0.3477)	Prec@1 85.156 (87.806)	Prec@5 99.219 (99.580)
EVALUATING - Epoch: [324][0/79]	Time 0.430 (0.430)	Data 0.379 (0.379)	Loss 0.4805 (0.4805)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:42:57

 Epoch: 325	Training Loss 0.3503 	Training Prec@1 87.754 	Training Prec@5 99.560 	Validation Loss 0.6610 	Validation Prec@1 78.600 	Validation Prec@5 98.710 

lr: 0.07701997844398376
TRAINING - Epoch: [325][0/391]	Time 1.273 (1.273)	Data 0.416 (0.416)	Loss 0.3379 (0.3379)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [325][100/391]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.3341 (0.3442)	Prec@1 88.281 (88.111)	Prec@5 98.438 (99.559)
TRAINING - Epoch: [325][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.3398 (0.3480)	Prec@1 89.062 (87.963)	Prec@5 99.219 (99.600)
TRAINING - Epoch: [325][300/391]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.2711 (0.3494)	Prec@1 92.188 (88.050)	Prec@5 100.000 (99.587)
EVALUATING - Epoch: [325][0/79]	Time 0.437 (0.437)	Data 0.392 (0.392)	Loss 0.4819 (0.4819)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:15

 Epoch: 326	Training Loss 0.3528 	Training Prec@1 87.956 	Training Prec@5 99.562 	Validation Loss 0.6898 	Validation Prec@1 78.560 	Validation Prec@5 98.480 

lr: 0.07688714531495057
TRAINING - Epoch: [326][0/391]	Time 1.264 (1.264)	Data 0.413 (0.413)	Loss 0.5054 (0.5054)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [326][100/391]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.3685 (0.3542)	Prec@1 85.156 (87.840)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [326][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.5821 (0.3584)	Prec@1 83.594 (87.671)	Prec@5 100.000 (99.553)
TRAINING - Epoch: [326][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3979 (0.3522)	Prec@1 85.156 (87.884)	Prec@5 99.219 (99.603)
EVALUATING - Epoch: [326][0/79]	Time 0.411 (0.411)	Data 0.384 (0.384)	Loss 0.6185 (0.6185)	Prec@1 78.906 (78.906)	Prec@5 96.094 (96.094)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:29

 Epoch: 327	Training Loss 0.3499 	Training Prec@1 87.936 	Training Prec@5 99.606 	Validation Loss 0.5384 	Validation Prec@1 81.830 	Validation Prec@5 99.070 

lr: 0.07675404468492172
TRAINING - Epoch: [327][0/391]	Time 1.268 (1.268)	Data 0.423 (0.423)	Loss 0.4395 (0.4395)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [327][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.3586 (0.3429)	Prec@1 84.375 (88.258)	Prec@5 100.000 (99.636)
TRAINING - Epoch: [327][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.4076 (0.3454)	Prec@1 85.938 (88.165)	Prec@5 99.219 (99.584)
TRAINING - Epoch: [327][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3012 (0.3493)	Prec@1 89.844 (88.107)	Prec@5 99.219 (99.572)
EVALUATING - Epoch: [327][0/79]	Time 0.446 (0.446)	Data 0.416 (0.416)	Loss 0.6049 (0.6049)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:22:02

 Epoch: 328	Training Loss 0.3517 	Training Prec@1 87.980 	Training Prec@5 99.558 	Validation Loss 0.6526 	Validation Prec@1 79.020 	Validation Prec@5 98.980 

lr: 0.07662067787811926
TRAINING - Epoch: [328][0/391]	Time 1.270 (1.270)	Data 0.416 (0.416)	Loss 0.3626 (0.3626)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [328][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.3268 (0.3332)	Prec@1 89.844 (88.591)	Prec@5 99.219 (99.613)
TRAINING - Epoch: [328][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3701 (0.3468)	Prec@1 88.281 (88.110)	Prec@5 100.000 (99.580)
TRAINING - Epoch: [328][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2896 (0.3520)	Prec@1 88.281 (87.918)	Prec@5 100.000 (99.577)
EVALUATING - Epoch: [328][0/79]	Time 0.438 (0.438)	Data 0.408 (0.408)	Loss 0.5647 (0.5647)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:06

 Epoch: 329	Training Loss 0.3552 	Training Prec@1 87.804 	Training Prec@5 99.584 	Validation Loss 0.6781 	Validation Prec@1 78.180 	Validation Prec@5 98.840 

lr: 0.07648704622141345
TRAINING - Epoch: [329][0/391]	Time 1.267 (1.267)	Data 0.422 (0.422)	Loss 0.2553 (0.2553)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [329][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.2109 (0.3428)	Prec@1 91.406 (88.250)	Prec@5 100.000 (99.575)
TRAINING - Epoch: [329][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3064 (0.3471)	Prec@1 89.844 (88.017)	Prec@5 100.000 (99.576)
TRAINING - Epoch: [329][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3053 (0.3521)	Prec@1 88.281 (87.874)	Prec@5 100.000 (99.543)
EVALUATING - Epoch: [329][0/79]	Time 0.443 (0.443)	Data 0.411 (0.411)	Loss 0.6702 (0.6702)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:01

 Epoch: 330	Training Loss 0.3548 	Training Prec@1 87.804 	Training Prec@5 99.534 	Validation Loss 0.6816 	Validation Prec@1 79.540 	Validation Prec@5 98.700 

lr: 0.07635315104430955
TRAINING - Epoch: [330][0/391]	Time 1.291 (1.291)	Data 0.441 (0.441)	Loss 0.3708 (0.3708)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [330][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.3623 (0.3475)	Prec@1 85.938 (88.343)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [330][200/391]	Time 0.110 (0.118)	Data 0.000 (0.003)	Loss 0.3499 (0.3543)	Prec@1 87.500 (87.924)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [330][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.2830 (0.3560)	Prec@1 90.625 (87.786)	Prec@5 98.438 (99.561)
EVALUATING - Epoch: [330][0/79]	Time 0.419 (0.419)	Data 0.388 (0.388)	Loss 0.5504 (0.5504)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:01

 Epoch: 331	Training Loss 0.3541 	Training Prec@1 87.770 	Training Prec@5 99.570 	Validation Loss 0.6025 	Validation Prec@1 80.310 	Validation Prec@5 99.200 

lr: 0.07621899367893463
TRAINING - Epoch: [331][0/391]	Time 1.291 (1.291)	Data 0.440 (0.440)	Loss 0.3301 (0.3301)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [331][100/391]	Time 0.110 (0.122)	Data 0.000 (0.005)	Loss 0.3314 (0.3461)	Prec@1 84.375 (88.188)	Prec@5 100.000 (99.536)
TRAINING - Epoch: [331][200/391]	Time 0.107 (0.116)	Data 0.000 (0.003)	Loss 0.3264 (0.3421)	Prec@1 88.281 (88.242)	Prec@5 100.000 (99.576)
TRAINING - Epoch: [331][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.3995 (0.3485)	Prec@1 84.375 (88.024)	Prec@5 99.219 (99.577)
EVALUATING - Epoch: [331][0/79]	Time 0.435 (0.435)	Data 0.398 (0.398)	Loss 0.8363 (0.8363)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:26

 Epoch: 332	Training Loss 0.3507 	Training Prec@1 87.944 	Training Prec@5 99.582 	Validation Loss 0.9892 	Validation Prec@1 71.080 	Validation Prec@5 97.870 

lr: 0.0760845754600242
TRAINING - Epoch: [332][0/391]	Time 1.260 (1.260)	Data 0.413 (0.413)	Loss 0.3108 (0.3108)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [332][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.4017 (0.3308)	Prec@1 87.500 (88.513)	Prec@5 98.438 (99.636)
TRAINING - Epoch: [332][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4506 (0.3359)	Prec@1 84.375 (88.359)	Prec@5 98.438 (99.572)
TRAINING - Epoch: [332][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2924 (0.3390)	Prec@1 90.625 (88.294)	Prec@5 100.000 (99.569)
EVALUATING - Epoch: [332][0/79]	Time 0.420 (0.420)	Data 0.378 (0.378)	Loss 0.6133 (0.6133)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:09

 Epoch: 333	Training Loss 0.3451 	Training Prec@1 88.106 	Training Prec@5 99.576 	Validation Loss 0.5880 	Validation Prec@1 81.510 	Validation Prec@5 98.800 

lr: 0.07594989772490908
TRAINING - Epoch: [333][0/391]	Time 1.301 (1.301)	Data 0.471 (0.471)	Loss 0.3299 (0.3299)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [333][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.4053 (0.3517)	Prec@1 85.938 (87.902)	Prec@5 100.000 (99.459)
TRAINING - Epoch: [333][200/391]	Time 0.104 (0.110)	Data 0.000 (0.003)	Loss 0.6057 (0.3517)	Prec@1 79.688 (87.865)	Prec@5 100.000 (99.545)
TRAINING - Epoch: [333][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.4350 (0.3496)	Prec@1 85.938 (87.850)	Prec@5 98.438 (99.561)
EVALUATING - Epoch: [333][0/79]	Time 0.436 (0.436)	Data 0.393 (0.393)	Loss 0.4519 (0.4519)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:52:11

 Epoch: 334	Training Loss 0.3500 	Training Prec@1 87.912 	Training Prec@5 99.564 	Validation Loss 0.6085 	Validation Prec@1 81.460 	Validation Prec@5 98.910 

lr: 0.075814961813502
TRAINING - Epoch: [334][0/391]	Time 1.258 (1.258)	Data 0.413 (0.413)	Loss 0.2979 (0.2979)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [334][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.4757 (0.3419)	Prec@1 84.375 (88.266)	Prec@5 98.438 (99.737)
TRAINING - Epoch: [334][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.4952 (0.3366)	Prec@1 82.812 (88.398)	Prec@5 98.438 (99.666)
TRAINING - Epoch: [334][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4185 (0.3457)	Prec@1 82.031 (88.035)	Prec@5 99.219 (99.629)
EVALUATING - Epoch: [334][0/79]	Time 0.448 (0.448)	Data 0.407 (0.407)	Loss 0.6486 (0.6486)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:18

 Epoch: 335	Training Loss 0.3477 	Training Prec@1 88.000 	Training Prec@5 99.628 	Validation Loss 0.6383 	Validation Prec@1 79.470 	Validation Prec@5 98.660 

lr: 0.07567976906828429
TRAINING - Epoch: [335][0/391]	Time 1.259 (1.259)	Data 0.417 (0.417)	Loss 0.2984 (0.2984)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [335][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.3856 (0.3309)	Prec@1 85.938 (88.622)	Prec@5 98.438 (99.675)
TRAINING - Epoch: [335][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2751 (0.3404)	Prec@1 91.406 (88.223)	Prec@5 99.219 (99.631)
TRAINING - Epoch: [335][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.3886 (0.3504)	Prec@1 86.719 (87.788)	Prec@5 100.000 (99.603)
EVALUATING - Epoch: [335][0/79]	Time 0.429 (0.429)	Data 0.401 (0.401)	Loss 0.4473 (0.4473)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 01:51:45

 Epoch: 336	Training Loss 0.3495 	Training Prec@1 87.830 	Training Prec@5 99.612 	Validation Loss 0.6384 	Validation Prec@1 79.220 	Validation Prec@5 99.040 

lr: 0.07554432083429251
TRAINING - Epoch: [336][0/391]	Time 1.277 (1.277)	Data 0.424 (0.424)	Loss 0.4279 (0.4279)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [336][100/391]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.3675 (0.3458)	Prec@1 85.156 (87.949)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [336][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.2498 (0.3461)	Prec@1 90.625 (87.924)	Prec@5 100.000 (99.557)
TRAINING - Epoch: [336][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.5241 (0.3474)	Prec@1 82.812 (88.017)	Prec@5 99.219 (99.520)
EVALUATING - Epoch: [336][0/79]	Time 0.433 (0.433)	Data 0.398 (0.398)	Loss 0.4306 (0.4306)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:19

 Epoch: 337	Training Loss 0.3511 	Training Prec@1 87.918 	Training Prec@5 99.524 	Validation Loss 0.5566 	Validation Prec@1 82.040 	Validation Prec@5 98.770 

lr: 0.07540861845910511
TRAINING - Epoch: [337][0/391]	Time 1.306 (1.306)	Data 0.455 (0.455)	Loss 0.2653 (0.2653)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [337][100/391]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.3579 (0.3468)	Prec@1 87.500 (88.103)	Prec@5 99.219 (99.629)
TRAINING - Epoch: [337][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.2449 (0.3438)	Prec@1 91.406 (88.172)	Prec@5 99.219 (99.619)
TRAINING - Epoch: [337][300/391]	Time 0.119 (0.115)	Data 0.000 (0.002)	Loss 0.4275 (0.3477)	Prec@1 86.719 (88.068)	Prec@5 100.000 (99.616)
EVALUATING - Epoch: [337][0/79]	Time 0.439 (0.439)	Data 0.409 (0.409)	Loss 0.5859 (0.5859)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:20:22

 Epoch: 338	Training Loss 0.3514 	Training Prec@1 87.942 	Training Prec@5 99.582 	Validation Loss 0.6643 	Validation Prec@1 78.050 	Validation Prec@5 98.660 

lr: 0.07527266329282901
TRAINING - Epoch: [338][0/391]	Time 1.267 (1.267)	Data 0.419 (0.419)	Loss 0.2205 (0.2205)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [338][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.2686 (0.3283)	Prec@1 89.062 (88.598)	Prec@5 100.000 (99.598)
TRAINING - Epoch: [338][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3865 (0.3431)	Prec@1 85.938 (88.180)	Prec@5 100.000 (99.565)
TRAINING - Epoch: [338][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3442 (0.3471)	Prec@1 86.719 (88.011)	Prec@5 98.438 (99.572)
EVALUATING - Epoch: [338][0/79]	Time 0.443 (0.443)	Data 0.404 (0.404)	Loss 0.5940 (0.5940)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:58

 Epoch: 339	Training Loss 0.3475 	Training Prec@1 87.974 	Training Prec@5 99.570 	Validation Loss 0.6949 	Validation Prec@1 78.800 	Validation Prec@5 99.160 

lr: 0.07513645668808615
TRAINING - Epoch: [339][0/391]	Time 1.279 (1.279)	Data 0.411 (0.411)	Loss 0.2251 (0.2251)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [339][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.4258 (0.3441)	Prec@1 86.719 (88.196)	Prec@5 98.438 (99.621)
TRAINING - Epoch: [339][200/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3724 (0.3473)	Prec@1 89.062 (87.978)	Prec@5 100.000 (99.580)
TRAINING - Epoch: [339][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3838 (0.3525)	Prec@1 85.938 (87.801)	Prec@5 100.000 (99.569)
EVALUATING - Epoch: [339][0/79]	Time 0.440 (0.440)	Data 0.403 (0.403)	Loss 0.6156 (0.6156)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:40

 Epoch: 340	Training Loss 0.3504 	Training Prec@1 87.844 	Training Prec@5 99.576 	Validation Loss 0.5912 	Validation Prec@1 80.970 	Validation Prec@5 98.830 

lr: 0.07499999999999997
TRAINING - Epoch: [340][0/391]	Time 1.295 (1.295)	Data 0.450 (0.450)	Loss 0.4235 (0.4235)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [340][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.3470 (0.3369)	Prec@1 89.062 (88.289)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [340][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.4459 (0.3413)	Prec@1 85.938 (88.192)	Prec@5 98.438 (99.604)
TRAINING - Epoch: [340][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3258 (0.3428)	Prec@1 85.938 (88.074)	Prec@5 100.000 (99.567)
EVALUATING - Epoch: [340][0/79]	Time 0.443 (0.443)	Data 0.390 (0.390)	Loss 0.6124 (0.6124)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:36

 Epoch: 341	Training Loss 0.3449 	Training Prec@1 88.078 	Training Prec@5 99.558 	Validation Loss 0.6603 	Validation Prec@1 78.570 	Validation Prec@5 98.520 

lr: 0.07486329458618211
TRAINING - Epoch: [341][0/391]	Time 1.262 (1.262)	Data 0.422 (0.422)	Loss 0.4685 (0.4685)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [341][100/391]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.2900 (0.3429)	Prec@1 92.188 (88.088)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [341][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4659 (0.3425)	Prec@1 86.719 (88.223)	Prec@5 96.875 (99.611)
TRAINING - Epoch: [341][300/391]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.2178 (0.3431)	Prec@1 92.969 (88.183)	Prec@5 100.000 (99.598)
EVALUATING - Epoch: [341][0/79]	Time 0.419 (0.419)	Data 0.379 (0.379)	Loss 0.5341 (0.5341)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:11

 Epoch: 342	Training Loss 0.3470 	Training Prec@1 88.032 	Training Prec@5 99.584 	Validation Loss 0.6261 	Validation Prec@1 79.680 	Validation Prec@5 99.150 

lr: 0.0747263418067187
TRAINING - Epoch: [342][0/391]	Time 1.278 (1.278)	Data 0.419 (0.419)	Loss 0.3372 (0.3372)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [342][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.3185 (0.3447)	Prec@1 88.281 (87.910)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [342][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.3636 (0.3360)	Prec@1 86.719 (88.386)	Prec@5 100.000 (99.623)
TRAINING - Epoch: [342][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.5334 (0.3440)	Prec@1 82.031 (88.237)	Prec@5 99.219 (99.554)
EVALUATING - Epoch: [342][0/79]	Time 0.447 (0.447)	Data 0.414 (0.414)	Loss 0.5462 (0.5462)	Prec@1 80.469 (80.469)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:38

 Epoch: 343	Training Loss 0.3438 	Training Prec@1 88.168 	Training Prec@5 99.550 	Validation Loss 0.7330 	Validation Prec@1 78.110 	Validation Prec@5 98.440 

lr: 0.07458914302415698
TRAINING - Epoch: [343][0/391]	Time 1.314 (1.314)	Data 0.466 (0.466)	Loss 0.3268 (0.3268)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [343][100/391]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.3734 (0.3406)	Prec@1 89.844 (88.011)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [343][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.4427 (0.3454)	Prec@1 82.812 (87.811)	Prec@5 100.000 (99.565)
TRAINING - Epoch: [343][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3198 (0.3459)	Prec@1 89.844 (87.765)	Prec@5 99.219 (99.582)
EVALUATING - Epoch: [343][0/79]	Time 0.428 (0.428)	Data 0.380 (0.380)	Loss 0.7431 (0.7431)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:19

 Epoch: 344	Training Loss 0.3462 	Training Prec@1 87.848 	Training Prec@5 99.570 	Validation Loss 0.7148 	Validation Prec@1 79.010 	Validation Prec@5 98.840 

lr: 0.07445169960349163
TRAINING - Epoch: [344][0/391]	Time 1.261 (1.261)	Data 0.413 (0.413)	Loss 0.3478 (0.3478)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [344][100/391]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.2848 (0.3296)	Prec@1 88.281 (88.482)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [344][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3246 (0.3356)	Prec@1 90.625 (88.305)	Prec@5 99.219 (99.701)
TRAINING - Epoch: [344][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3319 (0.3427)	Prec@1 89.844 (88.100)	Prec@5 100.000 (99.644)
EVALUATING - Epoch: [344][0/79]	Time 0.452 (0.452)	Data 0.416 (0.416)	Loss 0.5938 (0.5938)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:02

 Epoch: 345	Training Loss 0.3427 	Training Prec@1 88.100 	Training Prec@5 99.628 	Validation Loss 0.5658 	Validation Prec@1 81.870 	Validation Prec@5 99.130 

lr: 0.07431401291215127
TRAINING - Epoch: [345][0/391]	Time 1.282 (1.282)	Data 0.438 (0.438)	Loss 0.3973 (0.3973)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [345][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.3925 (0.3383)	Prec@1 88.281 (88.529)	Prec@5 100.000 (99.636)
TRAINING - Epoch: [345][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2793 (0.3495)	Prec@1 92.188 (88.048)	Prec@5 99.219 (99.611)
TRAINING - Epoch: [345][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.5322 (0.3508)	Prec@1 80.469 (88.040)	Prec@5 99.219 (99.611)
EVALUATING - Epoch: [345][0/79]	Time 0.436 (0.436)	Data 0.393 (0.393)	Loss 0.6827 (0.6827)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:44	Time of Finish: 2022-03-24 01:52:23

 Epoch: 346	Training Loss 0.3507 	Training Prec@1 88.040 	Training Prec@5 99.606 	Validation Loss 0.7709 	Validation Prec@1 76.640 	Validation Prec@5 97.690 

lr: 0.07417608431998483
TRAINING - Epoch: [346][0/391]	Time 1.573 (1.573)	Data 0.418 (0.418)	Loss 0.3943 (0.3943)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [346][100/391]	Time 0.113 (0.130)	Data 0.000 (0.004)	Loss 0.4202 (0.3366)	Prec@1 88.281 (88.506)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [346][200/391]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.3484 (0.3426)	Prec@1 89.844 (88.242)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [346][300/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3328 (0.3452)	Prec@1 89.844 (88.115)	Prec@5 100.000 (99.600)
EVALUATING - Epoch: [346][0/79]	Time 0.446 (0.446)	Data 0.407 (0.407)	Loss 0.6915 (0.6915)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:45:08

 Epoch: 347	Training Loss 0.3448 	Training Prec@1 88.168 	Training Prec@5 99.600 	Validation Loss 0.6064 	Validation Prec@1 80.130 	Validation Prec@5 98.550 

lr: 0.0740379151992479
TRAINING - Epoch: [347][0/391]	Time 1.270 (1.270)	Data 0.413 (0.413)	Loss 0.2598 (0.2598)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [347][100/391]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.3309 (0.3232)	Prec@1 86.719 (88.800)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [347][200/391]	Time 0.107 (0.119)	Data 0.000 (0.002)	Loss 0.3690 (0.3280)	Prec@1 85.938 (88.689)	Prec@5 99.219 (99.658)
TRAINING - Epoch: [347][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.3437 (0.3345)	Prec@1 87.500 (88.546)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [347][0/79]	Time 0.420 (0.420)	Data 0.382 (0.382)	Loss 0.5715 (0.5715)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:01

 Epoch: 348	Training Loss 0.3387 	Training Prec@1 88.404 	Training Prec@5 99.634 	Validation Loss 0.5131 	Validation Prec@1 83.100 	Validation Prec@5 99.090 

lr: 0.07389950692458912
TRAINING - Epoch: [348][0/391]	Time 1.300 (1.300)	Data 0.442 (0.442)	Loss 0.3557 (0.3557)	Prec@1 92.188 (92.188)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [348][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.3237 (0.3326)	Prec@1 88.281 (88.405)	Prec@5 100.000 (99.582)
TRAINING - Epoch: [348][200/391]	Time 0.112 (0.117)	Data 0.000 (0.003)	Loss 0.5308 (0.3486)	Prec@1 80.469 (87.881)	Prec@5 99.219 (99.541)
TRAINING - Epoch: [348][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3519 (0.3466)	Prec@1 89.062 (88.068)	Prec@5 99.219 (99.541)
EVALUATING - Epoch: [348][0/79]	Time 0.428 (0.428)	Data 0.401 (0.401)	Loss 0.3723 (0.3723)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:14

 Epoch: 349	Training Loss 0.3479 	Training Prec@1 88.006 	Training Prec@5 99.542 	Validation Loss 0.4918 	Validation Prec@1 84.030 	Validation Prec@5 99.150 

lr: 0.07376086087303645
TRAINING - Epoch: [349][0/391]	Time 1.272 (1.272)	Data 0.415 (0.415)	Loss 0.2241 (0.2241)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [349][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.3893 (0.3324)	Prec@1 87.500 (88.714)	Prec@5 98.438 (99.598)
TRAINING - Epoch: [349][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3916 (0.3313)	Prec@1 87.500 (88.693)	Prec@5 99.219 (99.623)
TRAINING - Epoch: [349][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.3724 (0.3401)	Prec@1 86.719 (88.268)	Prec@5 99.219 (99.582)
EVALUATING - Epoch: [349][0/79]	Time 0.441 (0.441)	Data 0.408 (0.408)	Loss 0.5167 (0.5167)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:20

 Epoch: 350	Training Loss 0.3457 	Training Prec@1 88.110 	Training Prec@5 99.586 	Validation Loss 0.4771 	Validation Prec@1 84.260 	Validation Prec@5 99.120 

lr: 0.0736219784239835
TRAINING - Epoch: [350][0/391]	Time 1.281 (1.281)	Data 0.433 (0.433)	Loss 0.4203 (0.4203)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [350][100/391]	Time 0.109 (0.122)	Data 0.000 (0.005)	Loss 0.3534 (0.3497)	Prec@1 86.719 (87.809)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [350][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.4454 (0.3482)	Prec@1 85.156 (87.920)	Prec@5 100.000 (99.572)
TRAINING - Epoch: [350][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3883 (0.3473)	Prec@1 88.281 (88.042)	Prec@5 99.219 (99.559)
EVALUATING - Epoch: [350][0/79]	Time 0.444 (0.444)	Data 0.406 (0.406)	Loss 0.4999 (0.4999)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:21:08

 Epoch: 351	Training Loss 0.3448 	Training Prec@1 88.150 	Training Prec@5 99.542 	Validation Loss 0.5284 	Validation Prec@1 82.030 	Validation Prec@5 99.250 

lr: 0.07348286095917587
TRAINING - Epoch: [351][0/391]	Time 1.583 (1.583)	Data 0.443 (0.443)	Loss 0.3709 (0.3709)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [351][100/391]	Time 0.119 (0.133)	Data 0.000 (0.005)	Loss 0.3052 (0.3381)	Prec@1 89.844 (88.219)	Prec@5 99.219 (99.606)
TRAINING - Epoch: [351][200/391]	Time 0.111 (0.125)	Data 0.000 (0.003)	Loss 0.5189 (0.3430)	Prec@1 82.812 (88.130)	Prec@5 99.219 (99.576)
TRAINING - Epoch: [351][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.4553 (0.3461)	Prec@1 83.594 (88.110)	Prec@5 100.000 (99.559)
EVALUATING - Epoch: [351][0/79]	Time 0.479 (0.479)	Data 0.443 (0.443)	Loss 0.6177 (0.6177)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 02:53:58

 Epoch: 352	Training Loss 0.3465 	Training Prec@1 88.140 	Training Prec@5 99.560 	Validation Loss 0.6573 	Validation Prec@1 78.960 	Validation Prec@5 98.620 

lr: 0.07334350986269726
TRAINING - Epoch: [352][0/391]	Time 1.807 (1.807)	Data 0.444 (0.444)	Loss 0.3463 (0.3463)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [352][100/391]	Time 0.113 (0.129)	Data 0.000 (0.005)	Loss 0.4227 (0.3349)	Prec@1 85.156 (88.405)	Prec@5 99.219 (99.706)
TRAINING - Epoch: [352][200/391]	Time 0.109 (0.119)	Data 0.000 (0.003)	Loss 0.2990 (0.3343)	Prec@1 90.625 (88.514)	Prec@5 100.000 (99.689)
TRAINING - Epoch: [352][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4383 (0.3395)	Prec@1 84.375 (88.473)	Prec@5 99.219 (99.644)
EVALUATING - Epoch: [352][0/79]	Time 0.428 (0.428)	Data 0.392 (0.392)	Loss 0.5245 (0.5245)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:14

 Epoch: 353	Training Loss 0.3414 	Training Prec@1 88.386 	Training Prec@5 99.644 	Validation Loss 0.6040 	Validation Prec@1 80.530 	Validation Prec@5 98.640 

lr: 0.0732039265209558
TRAINING - Epoch: [353][0/391]	Time 1.281 (1.281)	Data 0.413 (0.413)	Loss 0.3530 (0.3530)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [353][100/391]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.2615 (0.3351)	Prec@1 89.844 (88.150)	Prec@5 99.219 (99.613)
TRAINING - Epoch: [353][200/391]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.4090 (0.3453)	Prec@1 87.500 (88.032)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [353][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3424 (0.3434)	Prec@1 87.500 (88.123)	Prec@5 99.219 (99.616)
EVALUATING - Epoch: [353][0/79]	Time 0.411 (0.411)	Data 0.384 (0.384)	Loss 0.4621 (0.4621)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:31

 Epoch: 354	Training Loss 0.3421 	Training Prec@1 88.238 	Training Prec@5 99.632 	Validation Loss 0.5286 	Validation Prec@1 82.250 	Validation Prec@5 99.150 

lr: 0.07306411232267025
TRAINING - Epoch: [354][0/391]	Time 1.260 (1.260)	Data 0.409 (0.409)	Loss 0.2871 (0.2871)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [354][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.2604 (0.3368)	Prec@1 89.844 (88.436)	Prec@5 99.219 (99.575)
TRAINING - Epoch: [354][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.4057 (0.3403)	Prec@1 87.500 (88.316)	Prec@5 98.438 (99.611)
TRAINING - Epoch: [354][300/391]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.3201 (0.3478)	Prec@1 87.500 (88.068)	Prec@5 98.438 (99.564)
EVALUATING - Epoch: [354][0/79]	Time 0.430 (0.430)	Data 0.391 (0.391)	Loss 0.5450 (0.5450)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:02

 Epoch: 355	Training Loss 0.3472 	Training Prec@1 88.064 	Training Prec@5 99.542 	Validation Loss 0.5566 	Validation Prec@1 82.000 	Validation Prec@5 99.090 

lr: 0.07292406865885614
TRAINING - Epoch: [355][0/391]	Time 1.339 (1.339)	Data 0.447 (0.447)	Loss 0.3115 (0.3115)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [355][100/391]	Time 0.114 (0.129)	Data 0.000 (0.005)	Loss 0.3227 (0.3380)	Prec@1 89.844 (88.343)	Prec@5 98.438 (99.559)
TRAINING - Epoch: [355][200/391]	Time 0.114 (0.123)	Data 0.000 (0.003)	Loss 0.4355 (0.3442)	Prec@1 87.500 (88.083)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [355][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2809 (0.3455)	Prec@1 92.969 (88.035)	Prec@5 100.000 (99.572)
EVALUATING - Epoch: [355][0/79]	Time 0.442 (0.442)	Data 0.407 (0.407)	Loss 0.5090 (0.5090)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:44:27

 Epoch: 356	Training Loss 0.3476 	Training Prec@1 87.966 	Training Prec@5 99.580 	Validation Loss 0.5279 	Validation Prec@1 82.680 	Validation Prec@5 99.090 

lr: 0.07278379692281203
TRAINING - Epoch: [356][0/391]	Time 1.292 (1.292)	Data 0.442 (0.442)	Loss 0.2597 (0.2597)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [356][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.2941 (0.3290)	Prec@1 90.625 (88.606)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [356][200/391]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.3845 (0.3296)	Prec@1 89.062 (88.608)	Prec@5 100.000 (99.658)
TRAINING - Epoch: [356][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3438 (0.3306)	Prec@1 87.500 (88.458)	Prec@5 99.219 (99.629)
EVALUATING - Epoch: [356][0/79]	Time 0.446 (0.446)	Data 0.411 (0.411)	Loss 0.5919 (0.5919)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:30

 Epoch: 357	Training Loss 0.3357 	Training Prec@1 88.322 	Training Prec@5 99.628 	Validation Loss 0.7078 	Validation Prec@1 76.450 	Validation Prec@5 98.500 

lr: 0.07264329851010548
TRAINING - Epoch: [357][0/391]	Time 1.283 (1.283)	Data 0.417 (0.417)	Loss 0.3568 (0.3568)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [357][100/391]	Time 0.114 (0.128)	Data 0.000 (0.004)	Loss 0.4198 (0.3358)	Prec@1 83.594 (88.359)	Prec@5 100.000 (99.598)
TRAINING - Epoch: [357][200/391]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3145 (0.3307)	Prec@1 86.719 (88.343)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [357][300/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.4294 (0.3347)	Prec@1 87.500 (88.255)	Prec@5 100.000 (99.611)
EVALUATING - Epoch: [357][0/79]	Time 0.447 (0.447)	Data 0.401 (0.401)	Loss 0.6195 (0.6195)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:57

 Epoch: 358	Training Loss 0.3364 	Training Prec@1 88.236 	Training Prec@5 99.604 	Validation Loss 0.6203 	Validation Prec@1 79.060 	Validation Prec@5 98.580 

lr: 0.07250257481855935
TRAINING - Epoch: [358][0/391]	Time 1.301 (1.301)	Data 0.442 (0.442)	Loss 0.3560 (0.3560)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [358][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.4469 (0.3346)	Prec@1 85.938 (88.490)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [358][200/391]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.1990 (0.3393)	Prec@1 92.969 (88.305)	Prec@5 100.000 (99.615)
TRAINING - Epoch: [358][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.4352 (0.3416)	Prec@1 85.938 (88.162)	Prec@5 99.219 (99.639)
EVALUATING - Epoch: [358][0/79]	Time 0.423 (0.423)	Data 0.380 (0.380)	Loss 0.4558 (0.4558)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:56

 Epoch: 359	Training Loss 0.3449 	Training Prec@1 88.092 	Training Prec@5 99.620 	Validation Loss 0.6076 	Validation Prec@1 79.640 	Validation Prec@5 98.650 

lr: 0.07236162724823773
TRAINING - Epoch: [359][0/391]	Time 1.333 (1.333)	Data 0.483 (0.483)	Loss 0.3617 (0.3617)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [359][100/391]	Time 0.115 (0.127)	Data 0.000 (0.005)	Loss 0.2976 (0.3355)	Prec@1 89.844 (88.374)	Prec@5 100.000 (99.598)
TRAINING - Epoch: [359][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.3394 (0.3452)	Prec@1 87.500 (88.040)	Prec@5 99.219 (99.588)
TRAINING - Epoch: [359][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2890 (0.3461)	Prec@1 90.625 (87.996)	Prec@5 100.000 (99.587)
EVALUATING - Epoch: [359][0/79]	Time 0.430 (0.430)	Data 0.390 (0.390)	Loss 0.5028 (0.5028)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:20

 Epoch: 360	Training Loss 0.3470 	Training Prec@1 87.976 	Training Prec@5 99.596 	Validation Loss 0.6111 	Validation Prec@1 80.150 	Validation Prec@5 98.850 

lr: 0.07222045720143214
TRAINING - Epoch: [360][0/391]	Time 1.270 (1.270)	Data 0.370 (0.370)	Loss 0.2711 (0.2711)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [360][100/391]	Time 0.112 (0.126)	Data 0.000 (0.004)	Loss 0.2478 (0.3186)	Prec@1 89.844 (88.838)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [360][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3038 (0.3311)	Prec@1 85.938 (88.441)	Prec@5 100.000 (99.728)
TRAINING - Epoch: [360][300/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.4082 (0.3383)	Prec@1 84.375 (88.297)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [360][0/79]	Time 0.494 (0.494)	Data 0.458 (0.458)	Loss 0.4409 (0.4409)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:51

 Epoch: 361	Training Loss 0.3353 	Training Prec@1 88.402 	Training Prec@5 99.660 	Validation Loss 0.5353 	Validation Prec@1 83.060 	Validation Prec@5 99.170 

lr: 0.0720790660826475
TRAINING - Epoch: [361][0/391]	Time 1.286 (1.286)	Data 0.439 (0.439)	Loss 0.2693 (0.2693)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [361][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.3280 (0.3373)	Prec@1 89.062 (88.235)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [361][200/391]	Time 0.112 (0.120)	Data 0.000 (0.003)	Loss 0.4872 (0.3473)	Prec@1 85.938 (87.834)	Prec@5 99.219 (99.623)
TRAINING - Epoch: [361][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2536 (0.3436)	Prec@1 92.188 (88.045)	Prec@5 100.000 (99.626)
EVALUATING - Epoch: [361][0/79]	Time 0.449 (0.449)	Data 0.410 (0.410)	Loss 0.5561 (0.5561)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:44

 Epoch: 362	Training Loss 0.3445 	Training Prec@1 88.100 	Training Prec@5 99.628 	Validation Loss 0.5901 	Validation Prec@1 81.260 	Validation Prec@5 98.580 

lr: 0.0719374552985882
TRAINING - Epoch: [362][0/391]	Time 1.296 (1.296)	Data 0.417 (0.417)	Loss 0.2802 (0.2802)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [362][100/391]	Time 0.118 (0.127)	Data 0.000 (0.004)	Loss 0.3589 (0.3434)	Prec@1 88.281 (87.918)	Prec@5 100.000 (99.567)
TRAINING - Epoch: [362][200/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2879 (0.3390)	Prec@1 89.844 (88.215)	Prec@5 99.219 (99.584)
TRAINING - Epoch: [362][300/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.4365 (0.3405)	Prec@1 83.594 (88.240)	Prec@5 100.000 (99.595)
EVALUATING - Epoch: [362][0/79]	Time 0.431 (0.431)	Data 0.395 (0.395)	Loss 0.4039 (0.4039)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:52

 Epoch: 363	Training Loss 0.3422 	Training Prec@1 88.230 	Training Prec@5 99.594 	Validation Loss 0.4593 	Validation Prec@1 84.420 	Validation Prec@5 99.280 

lr: 0.07179562625814406
TRAINING - Epoch: [363][0/391]	Time 1.263 (1.263)	Data 0.426 (0.426)	Loss 0.2652 (0.2652)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [363][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.2308 (0.3317)	Prec@1 92.969 (88.490)	Prec@5 99.219 (99.729)
TRAINING - Epoch: [363][200/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.2374 (0.3372)	Prec@1 92.969 (88.242)	Prec@5 100.000 (99.666)
TRAINING - Epoch: [363][300/391]	Time 0.114 (0.113)	Data 0.000 (0.002)	Loss 0.3081 (0.3408)	Prec@1 90.625 (88.258)	Prec@5 98.438 (99.639)
EVALUATING - Epoch: [363][0/79]	Time 0.448 (0.448)	Data 0.416 (0.416)	Loss 0.6178 (0.6178)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:16:31

 Epoch: 364	Training Loss 0.3430 	Training Prec@1 88.180 	Training Prec@5 99.634 	Validation Loss 0.6785 	Validation Prec@1 79.020 	Validation Prec@5 98.430 

lr: 0.07165358037237637
TRAINING - Epoch: [364][0/391]	Time 1.330 (1.330)	Data 0.454 (0.454)	Loss 0.3038 (0.3038)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [364][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.2117 (0.3202)	Prec@1 92.969 (88.761)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [364][200/391]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.4228 (0.3223)	Prec@1 87.500 (88.891)	Prec@5 99.219 (99.666)
TRAINING - Epoch: [364][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.4420 (0.3298)	Prec@1 86.719 (88.681)	Prec@5 99.219 (99.631)
EVALUATING - Epoch: [364][0/79]	Time 0.438 (0.438)	Data 0.406 (0.406)	Loss 0.4446 (0.4446)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:46

 Epoch: 365	Training Loss 0.3330 	Training Prec@1 88.540 	Training Prec@5 99.636 	Validation Loss 0.6253 	Validation Prec@1 80.940 	Validation Prec@5 98.980 

lr: 0.07151131905450382
TRAINING - Epoch: [365][0/391]	Time 1.555 (1.555)	Data 0.411 (0.411)	Loss 0.4227 (0.4227)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [365][100/391]	Time 0.121 (0.131)	Data 0.000 (0.004)	Loss 0.2547 (0.3349)	Prec@1 89.844 (88.475)	Prec@5 99.219 (99.691)
TRAINING - Epoch: [365][200/391]	Time 0.113 (0.123)	Data 0.000 (0.002)	Loss 0.4132 (0.3376)	Prec@1 87.500 (88.472)	Prec@5 100.000 (99.615)
TRAINING - Epoch: [365][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3670 (0.3390)	Prec@1 86.719 (88.380)	Prec@5 100.000 (99.639)
EVALUATING - Epoch: [365][0/79]	Time 0.448 (0.448)	Data 0.408 (0.408)	Loss 0.4793 (0.4793)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:45:44

 Epoch: 366	Training Loss 0.3419 	Training Prec@1 88.268 	Training Prec@5 99.636 	Validation Loss 0.7324 	Validation Prec@1 78.620 	Validation Prec@5 98.560 

lr: 0.07136884371988837
TRAINING - Epoch: [366][0/391]	Time 1.259 (1.259)	Data 0.364 (0.364)	Loss 0.2963 (0.2963)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [366][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.4462 (0.3355)	Prec@1 84.375 (88.289)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [366][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3691 (0.3376)	Prec@1 86.719 (88.312)	Prec@5 98.438 (99.635)
TRAINING - Epoch: [366][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.2636 (0.3376)	Prec@1 92.188 (88.336)	Prec@5 100.000 (99.629)
EVALUATING - Epoch: [366][0/79]	Time 0.431 (0.431)	Data 0.403 (0.403)	Loss 0.6367 (0.6367)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:23

 Epoch: 367	Training Loss 0.3391 	Training Prec@1 88.270 	Training Prec@5 99.614 	Validation Loss 0.6740 	Validation Prec@1 78.460 	Validation Prec@5 98.560 

lr: 0.07122615578602136
TRAINING - Epoch: [367][0/391]	Time 1.595 (1.595)	Data 0.455 (0.455)	Loss 0.2469 (0.2469)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [367][100/391]	Time 0.120 (0.138)	Data 0.000 (0.005)	Loss 0.2470 (0.3235)	Prec@1 92.188 (89.001)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [367][200/391]	Time 0.122 (0.129)	Data 0.000 (0.003)	Loss 0.3340 (0.3284)	Prec@1 89.844 (88.818)	Prec@5 100.000 (99.607)
TRAINING - Epoch: [367][300/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2932 (0.3363)	Prec@1 89.844 (88.577)	Prec@5 100.000 (99.585)
EVALUATING - Epoch: [367][0/79]	Time 0.455 (0.455)	Data 0.414 (0.414)	Loss 0.6869 (0.6869)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:50	Time of Finish: 2022-03-24 03:03:19

 Epoch: 368	Training Loss 0.3385 	Training Prec@1 88.414 	Training Prec@5 99.590 	Validation Loss 0.7642 	Validation Prec@1 76.030 	Validation Prec@5 97.730 

lr: 0.07108325667250916
TRAINING - Epoch: [368][0/391]	Time 1.268 (1.268)	Data 0.420 (0.420)	Loss 0.3503 (0.3503)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [368][100/391]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.2875 (0.3327)	Prec@1 89.062 (88.351)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [368][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3197 (0.3397)	Prec@1 87.500 (88.095)	Prec@5 100.000 (99.650)
TRAINING - Epoch: [368][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.4399 (0.3401)	Prec@1 85.938 (88.100)	Prec@5 99.219 (99.626)
EVALUATING - Epoch: [368][0/79]	Time 0.441 (0.441)	Data 0.414 (0.414)	Loss 0.5669 (0.5669)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:17

 Epoch: 369	Training Loss 0.3396 	Training Prec@1 88.196 	Training Prec@5 99.602 	Validation Loss 0.7267 	Validation Prec@1 77.560 	Validation Prec@5 98.560 

lr: 0.07094014780105926
TRAINING - Epoch: [369][0/391]	Time 1.298 (1.298)	Data 0.445 (0.445)	Loss 0.3384 (0.3384)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [369][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.2608 (0.3238)	Prec@1 92.188 (88.676)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [369][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.5850 (0.3322)	Prec@1 78.906 (88.522)	Prec@5 98.438 (99.600)
TRAINING - Epoch: [369][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4343 (0.3364)	Prec@1 86.719 (88.398)	Prec@5 99.219 (99.554)
EVALUATING - Epoch: [369][0/79]	Time 0.445 (0.445)	Data 0.412 (0.412)	Loss 0.5515 (0.5515)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:25

 Epoch: 370	Training Loss 0.3361 	Training Prec@1 88.342 	Training Prec@5 99.572 	Validation Loss 0.6259 	Validation Prec@1 80.080 	Validation Prec@5 98.670 

lr: 0.07079683059546601
TRAINING - Epoch: [370][0/391]	Time 1.302 (1.302)	Data 0.430 (0.430)	Loss 0.3222 (0.3222)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [370][100/391]	Time 0.111 (0.129)	Data 0.000 (0.005)	Loss 0.4218 (0.3246)	Prec@1 85.938 (89.148)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [370][200/391]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.3852 (0.3343)	Prec@1 88.281 (88.740)	Prec@5 98.438 (99.611)
TRAINING - Epoch: [370][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2863 (0.3386)	Prec@1 89.062 (88.525)	Prec@5 100.000 (99.577)
EVALUATING - Epoch: [370][0/79]	Time 0.425 (0.425)	Data 0.376 (0.376)	Loss 0.5093 (0.5093)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:44:00

 Epoch: 371	Training Loss 0.3387 	Training Prec@1 88.474 	Training Prec@5 99.586 	Validation Loss 0.5807 	Validation Prec@1 81.490 	Validation Prec@5 98.810 

lr: 0.07065330648159648
TRAINING - Epoch: [371][0/391]	Time 1.271 (1.271)	Data 0.419 (0.419)	Loss 0.4806 (0.4806)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [371][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.2787 (0.3329)	Prec@1 89.844 (88.335)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [371][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3429 (0.3338)	Prec@1 85.938 (88.410)	Prec@5 100.000 (99.639)
TRAINING - Epoch: [371][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.4185 (0.3385)	Prec@1 85.938 (88.292)	Prec@5 97.656 (99.631)
EVALUATING - Epoch: [371][0/79]	Time 0.405 (0.405)	Data 0.378 (0.378)	Loss 0.4784 (0.4784)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:51

 Epoch: 372	Training Loss 0.3410 	Training Prec@1 88.218 	Training Prec@5 99.610 	Validation Loss 0.5502 	Validation Prec@1 82.420 	Validation Prec@5 99.010 

lr: 0.07050957688737632
TRAINING - Epoch: [372][0/391]	Time 1.290 (1.290)	Data 0.447 (0.447)	Loss 0.2876 (0.2876)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [372][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.3656 (0.3331)	Prec@1 89.062 (88.645)	Prec@5 99.219 (99.582)
TRAINING - Epoch: [372][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.2682 (0.3299)	Prec@1 89.062 (88.837)	Prec@5 99.219 (99.588)
TRAINING - Epoch: [372][300/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.3002 (0.3286)	Prec@1 91.406 (88.704)	Prec@5 99.219 (99.613)
EVALUATING - Epoch: [372][0/79]	Time 0.432 (0.432)	Data 0.394 (0.394)	Loss 0.5813 (0.5813)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:44

 Epoch: 373	Training Loss 0.3328 	Training Prec@1 88.534 	Training Prec@5 99.608 	Validation Loss 0.6374 	Validation Prec@1 79.760 	Validation Prec@5 98.490 

lr: 0.07036564324277539
TRAINING - Epoch: [373][0/391]	Time 1.274 (1.274)	Data 0.422 (0.422)	Loss 0.3100 (0.3100)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [373][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.2676 (0.3220)	Prec@1 90.625 (89.163)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [373][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.3849 (0.3257)	Prec@1 88.281 (88.923)	Prec@5 99.219 (99.693)
TRAINING - Epoch: [373][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4023 (0.3270)	Prec@1 86.719 (88.795)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [373][0/79]	Time 0.432 (0.432)	Data 0.397 (0.397)	Loss 0.6008 (0.6008)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:08

 Epoch: 374	Training Loss 0.3325 	Training Prec@1 88.614 	Training Prec@5 99.640 	Validation Loss 0.6592 	Validation Prec@1 80.160 	Validation Prec@5 98.490 

lr: 0.07022150697979379
TRAINING - Epoch: [374][0/391]	Time 1.270 (1.270)	Data 0.421 (0.421)	Loss 0.3370 (0.3370)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [374][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.3803 (0.3274)	Prec@1 87.500 (88.846)	Prec@5 99.219 (99.652)
TRAINING - Epoch: [374][200/391]	Time 0.110 (0.121)	Data 0.000 (0.002)	Loss 0.3932 (0.3304)	Prec@1 84.375 (88.569)	Prec@5 99.219 (99.662)
TRAINING - Epoch: [374][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4865 (0.3307)	Prec@1 85.156 (88.554)	Prec@5 97.656 (99.639)
EVALUATING - Epoch: [374][0/79]	Time 0.408 (0.408)	Data 0.373 (0.373)	Loss 0.6645 (0.6645)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:00

 Epoch: 375	Training Loss 0.3345 	Training Prec@1 88.418 	Training Prec@5 99.654 	Validation Loss 0.7452 	Validation Prec@1 77.170 	Validation Prec@5 98.400 

lr: 0.07007716953244741
TRAINING - Epoch: [375][0/391]	Time 1.312 (1.312)	Data 0.448 (0.448)	Loss 0.2821 (0.2821)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [375][100/391]	Time 0.116 (0.129)	Data 0.000 (0.005)	Loss 0.3047 (0.3261)	Prec@1 89.062 (88.776)	Prec@5 100.000 (99.613)
TRAINING - Epoch: [375][200/391]	Time 0.112 (0.123)	Data 0.000 (0.003)	Loss 0.2804 (0.3232)	Prec@1 91.406 (88.810)	Prec@5 100.000 (99.681)
TRAINING - Epoch: [375][300/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.4265 (0.3310)	Prec@1 88.281 (88.655)	Prec@5 100.000 (99.634)
EVALUATING - Epoch: [375][0/79]	Time 0.447 (0.447)	Data 0.411 (0.411)	Loss 0.6921 (0.6921)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:47:31

 Epoch: 376	Training Loss 0.3340 	Training Prec@1 88.576 	Training Prec@5 99.648 	Validation Loss 0.6720 	Validation Prec@1 79.940 	Validation Prec@5 98.230 

lr: 0.06993263233675374
TRAINING - Epoch: [376][0/391]	Time 1.294 (1.294)	Data 0.429 (0.429)	Loss 0.3836 (0.3836)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [376][100/391]	Time 0.116 (0.131)	Data 0.000 (0.005)	Loss 0.3145 (0.3364)	Prec@1 86.719 (88.397)	Prec@5 100.000 (99.559)
TRAINING - Epoch: [376][200/391]	Time 0.125 (0.125)	Data 0.000 (0.003)	Loss 0.2656 (0.3358)	Prec@1 86.719 (88.390)	Prec@5 100.000 (99.588)
TRAINING - Epoch: [376][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.4483 (0.3372)	Prec@1 85.156 (88.388)	Prec@5 99.219 (99.564)
EVALUATING - Epoch: [376][0/79]	Time 0.449 (0.449)	Data 0.405 (0.405)	Loss 0.5943 (0.5943)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:56:19

 Epoch: 377	Training Loss 0.3386 	Training Prec@1 88.398 	Training Prec@5 99.566 	Validation Loss 0.7003 	Validation Prec@1 78.740 	Validation Prec@5 98.760 

lr: 0.06978789683071755
TRAINING - Epoch: [377][0/391]	Time 1.306 (1.306)	Data 0.420 (0.420)	Loss 0.3055 (0.3055)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [377][100/391]	Time 0.115 (0.126)	Data 0.000 (0.004)	Loss 0.2771 (0.3438)	Prec@1 89.062 (87.972)	Prec@5 99.219 (99.598)
TRAINING - Epoch: [377][200/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.4073 (0.3312)	Prec@1 88.281 (88.650)	Prec@5 97.656 (99.607)
TRAINING - Epoch: [377][300/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.3123 (0.3335)	Prec@1 87.500 (88.494)	Prec@5 100.000 (99.618)
EVALUATING - Epoch: [377][0/79]	Time 0.436 (0.436)	Data 0.406 (0.406)	Loss 0.4157 (0.4157)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:46

 Epoch: 378	Training Loss 0.3351 	Training Prec@1 88.428 	Training Prec@5 99.620 	Validation Loss 0.5973 	Validation Prec@1 81.540 	Validation Prec@5 98.770 

lr: 0.06964296445431666
TRAINING - Epoch: [378][0/391]	Time 1.339 (1.339)	Data 0.437 (0.437)	Loss 0.2698 (0.2698)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [378][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.2693 (0.3257)	Prec@1 89.844 (88.916)	Prec@5 100.000 (99.660)
TRAINING - Epoch: [378][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.3135 (0.3313)	Prec@1 89.844 (88.736)	Prec@5 99.219 (99.580)
TRAINING - Epoch: [378][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3335 (0.3295)	Prec@1 89.062 (88.795)	Prec@5 99.219 (99.567)
EVALUATING - Epoch: [378][0/79]	Time 0.445 (0.445)	Data 0.409 (0.409)	Loss 0.8492 (0.8492)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:54

 Epoch: 379	Training Loss 0.3306 	Training Prec@1 88.718 	Training Prec@5 99.580 	Validation Loss 0.7911 	Validation Prec@1 77.180 	Validation Prec@5 98.370 

lr: 0.06949783664948747
TRAINING - Epoch: [379][0/391]	Time 1.330 (1.330)	Data 0.422 (0.422)	Loss 0.3636 (0.3636)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [379][100/391]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.1891 (0.3125)	Prec@1 93.750 (89.287)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [379][200/391]	Time 0.116 (0.122)	Data 0.000 (0.003)	Loss 0.3000 (0.3297)	Prec@1 89.062 (88.752)	Prec@5 100.000 (99.592)
TRAINING - Epoch: [379][300/391]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3043 (0.3324)	Prec@1 89.062 (88.650)	Prec@5 100.000 (99.593)
EVALUATING - Epoch: [379][0/79]	Time 0.413 (0.413)	Data 0.372 (0.372)	Loss 0.4557 (0.4557)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:10

 Epoch: 380	Training Loss 0.3340 	Training Prec@1 88.576 	Training Prec@5 99.602 	Validation Loss 0.6021 	Validation Prec@1 81.220 	Validation Prec@5 98.930 

lr: 0.06935251486011082
TRAINING - Epoch: [380][0/391]	Time 1.325 (1.325)	Data 0.409 (0.409)	Loss 0.2933 (0.2933)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [380][100/391]	Time 0.117 (0.127)	Data 0.000 (0.004)	Loss 0.3378 (0.3269)	Prec@1 89.062 (88.738)	Prec@5 99.219 (99.621)
TRAINING - Epoch: [380][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3661 (0.3353)	Prec@1 88.281 (88.483)	Prec@5 100.000 (99.611)
TRAINING - Epoch: [380][300/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2740 (0.3339)	Prec@1 90.625 (88.523)	Prec@5 100.000 (99.655)
EVALUATING - Epoch: [380][0/79]	Time 0.432 (0.432)	Data 0.404 (0.404)	Loss 0.6428 (0.6428)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:51

 Epoch: 381	Training Loss 0.3346 	Training Prec@1 88.442 	Training Prec@5 99.656 	Validation Loss 0.5430 	Validation Prec@1 82.380 	Validation Prec@5 99.100 

lr: 0.0692070005319974
TRAINING - Epoch: [381][0/391]	Time 1.322 (1.322)	Data 0.446 (0.446)	Loss 0.3348 (0.3348)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [381][100/391]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.3654 (0.3320)	Prec@1 86.719 (88.482)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [381][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.4189 (0.3378)	Prec@1 89.062 (88.312)	Prec@5 99.219 (99.642)
TRAINING - Epoch: [381][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2606 (0.3324)	Prec@1 91.406 (88.543)	Prec@5 100.000 (99.624)
EVALUATING - Epoch: [381][0/79]	Time 0.444 (0.444)	Data 0.403 (0.403)	Loss 0.6585 (0.6585)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:02

 Epoch: 382	Training Loss 0.3353 	Training Prec@1 88.504 	Training Prec@5 99.632 	Validation Loss 0.7236 	Validation Prec@1 78.000 	Validation Prec@5 98.280 

lr: 0.06906129511287352
TRAINING - Epoch: [382][0/391]	Time 1.304 (1.304)	Data 0.408 (0.408)	Loss 0.2011 (0.2011)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [382][100/391]	Time 0.110 (0.125)	Data 0.000 (0.004)	Loss 0.4075 (0.3190)	Prec@1 84.375 (88.745)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [382][200/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.3423 (0.3258)	Prec@1 86.719 (88.650)	Prec@5 99.219 (99.662)
TRAINING - Epoch: [382][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.4140 (0.3262)	Prec@1 88.281 (88.684)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [382][0/79]	Time 0.447 (0.447)	Data 0.407 (0.407)	Loss 0.6762 (0.6762)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:46

 Epoch: 383	Training Loss 0.3319 	Training Prec@1 88.516 	Training Prec@5 99.624 	Validation Loss 0.6084 	Validation Prec@1 80.990 	Validation Prec@5 98.910 

lr: 0.06891540005236671
TRAINING - Epoch: [383][0/391]	Time 1.288 (1.288)	Data 0.406 (0.406)	Loss 0.3480 (0.3480)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [383][100/391]	Time 0.108 (0.124)	Data 0.000 (0.004)	Loss 0.2687 (0.3028)	Prec@1 89.062 (89.310)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [383][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4980 (0.3253)	Prec@1 82.812 (88.697)	Prec@5 99.219 (99.662)
TRAINING - Epoch: [383][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4105 (0.3342)	Prec@1 89.062 (88.460)	Prec@5 99.219 (99.655)
EVALUATING - Epoch: [383][0/79]	Time 0.418 (0.418)	Data 0.373 (0.373)	Loss 0.6767 (0.6767)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:26

 Epoch: 384	Training Loss 0.3386 	Training Prec@1 88.296 	Training Prec@5 99.642 	Validation Loss 0.6508 	Validation Prec@1 80.150 	Validation Prec@5 98.700 

lr: 0.06876931680199114
TRAINING - Epoch: [384][0/391]	Time 1.351 (1.351)	Data 0.419 (0.419)	Loss 0.3236 (0.3236)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [384][100/391]	Time 0.117 (0.124)	Data 0.000 (0.004)	Loss 0.6168 (0.3190)	Prec@1 78.125 (89.032)	Prec@5 98.438 (99.706)
TRAINING - Epoch: [384][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2422 (0.3269)	Prec@1 88.281 (88.728)	Prec@5 100.000 (99.701)
TRAINING - Epoch: [384][300/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3495 (0.3290)	Prec@1 90.625 (88.725)	Prec@5 99.219 (99.663)
EVALUATING - Epoch: [384][0/79]	Time 0.406 (0.406)	Data 0.373 (0.373)	Loss 0.6001 (0.6001)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:19

 Epoch: 385	Training Loss 0.3315 	Training Prec@1 88.632 	Training Prec@5 99.646 	Validation Loss 0.7249 	Validation Prec@1 78.940 	Validation Prec@5 98.070 

lr: 0.06862304681513338
TRAINING - Epoch: [385][0/391]	Time 1.345 (1.345)	Data 0.447 (0.447)	Loss 0.4213 (0.4213)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [385][100/391]	Time 0.119 (0.129)	Data 0.000 (0.005)	Loss 0.3754 (0.3265)	Prec@1 87.500 (88.668)	Prec@5 97.656 (99.567)
TRAINING - Epoch: [385][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.3805 (0.3299)	Prec@1 86.719 (88.503)	Prec@5 99.219 (99.565)
TRAINING - Epoch: [385][300/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.2966 (0.3294)	Prec@1 88.281 (88.538)	Prec@5 100.000 (99.598)
EVALUATING - Epoch: [385][0/79]	Time 0.430 (0.430)	Data 0.385 (0.385)	Loss 0.6998 (0.6998)	Prec@1 76.562 (76.562)	Prec@5 95.312 (95.312)
Time cost: 00:50	Time of Finish: 2022-03-24 02:53:14

 Epoch: 386	Training Loss 0.3304 	Training Prec@1 88.532 	Training Prec@5 99.602 	Validation Loss 0.6805 	Validation Prec@1 79.880 	Validation Prec@5 98.470 

lr: 0.0684765915470378
TRAINING - Epoch: [386][0/391]	Time 1.330 (1.330)	Data 0.432 (0.432)	Loss 0.3690 (0.3690)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [386][100/391]	Time 0.109 (0.126)	Data 0.000 (0.005)	Loss 0.2920 (0.3215)	Prec@1 89.062 (88.854)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [386][200/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.3745 (0.3275)	Prec@1 89.062 (88.635)	Prec@5 99.219 (99.708)
TRAINING - Epoch: [386][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2759 (0.3279)	Prec@1 89.844 (88.684)	Prec@5 100.000 (99.714)
EVALUATING - Epoch: [386][0/79]	Time 0.470 (0.470)	Data 0.431 (0.431)	Loss 0.4274 (0.4274)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:42:55

 Epoch: 387	Training Loss 0.3308 	Training Prec@1 88.536 	Training Prec@5 99.686 	Validation Loss 0.5659 	Validation Prec@1 81.970 	Validation Prec@5 99.030 

lr: 0.06832995245479213
TRAINING - Epoch: [387][0/391]	Time 1.322 (1.322)	Data 0.423 (0.423)	Loss 0.1706 (0.1706)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [387][100/391]	Time 0.117 (0.129)	Data 0.000 (0.005)	Loss 0.4061 (0.3378)	Prec@1 84.375 (88.444)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [387][200/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.4055 (0.3344)	Prec@1 85.156 (88.495)	Prec@5 98.438 (99.627)
TRAINING - Epoch: [387][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3910 (0.3306)	Prec@1 82.812 (88.629)	Prec@5 99.219 (99.629)
EVALUATING - Epoch: [387][0/79]	Time 0.449 (0.449)	Data 0.408 (0.408)	Loss 0.4677 (0.4677)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:59

 Epoch: 388	Training Loss 0.3272 	Training Prec@1 88.750 	Training Prec@5 99.622 	Validation Loss 0.6250 	Validation Prec@1 80.540 	Validation Prec@5 98.930 

lr: 0.06818313099731302
TRAINING - Epoch: [388][0/391]	Time 1.606 (1.606)	Data 0.429 (0.429)	Loss 0.2427 (0.2427)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [388][100/391]	Time 0.119 (0.132)	Data 0.000 (0.005)	Loss 0.5164 (0.3209)	Prec@1 82.812 (89.032)	Prec@5 99.219 (99.613)
TRAINING - Epoch: [388][200/391]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.4303 (0.3319)	Prec@1 84.375 (88.705)	Prec@5 99.219 (99.615)
TRAINING - Epoch: [388][300/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3866 (0.3326)	Prec@1 85.938 (88.585)	Prec@5 100.000 (99.624)
EVALUATING - Epoch: [388][0/79]	Time 0.433 (0.433)	Data 0.399 (0.399)	Loss 0.3826 (0.3826)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:52:21

 Epoch: 389	Training Loss 0.3342 	Training Prec@1 88.522 	Training Prec@5 99.606 	Validation Loss 0.5185 	Validation Prec@1 83.270 	Validation Prec@5 98.980 

lr: 0.06803612863533143
TRAINING - Epoch: [389][0/391]	Time 1.318 (1.318)	Data 0.431 (0.431)	Loss 0.2748 (0.2748)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [389][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.2206 (0.3251)	Prec@1 92.188 (88.730)	Prec@5 99.219 (99.636)
TRAINING - Epoch: [389][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3424 (0.3238)	Prec@1 89.062 (88.930)	Prec@5 98.438 (99.611)
TRAINING - Epoch: [389][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.2266 (0.3258)	Prec@1 92.188 (88.793)	Prec@5 100.000 (99.616)
EVALUATING - Epoch: [389][0/79]	Time 0.419 (0.419)	Data 0.381 (0.381)	Loss 0.4946 (0.4946)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:08

 Epoch: 390	Training Loss 0.3279 	Training Prec@1 88.670 	Training Prec@5 99.626 	Validation Loss 0.6659 	Validation Prec@1 80.300 	Validation Prec@5 98.220 

lr: 0.06788894683137817
TRAINING - Epoch: [390][0/391]	Time 1.345 (1.345)	Data 0.433 (0.433)	Loss 0.2579 (0.2579)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [390][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.2705 (0.3249)	Prec@1 89.844 (88.800)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [390][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.4659 (0.3214)	Prec@1 84.375 (88.763)	Prec@5 99.219 (99.689)
TRAINING - Epoch: [390][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3451 (0.3301)	Prec@1 86.719 (88.484)	Prec@5 99.219 (99.673)
EVALUATING - Epoch: [390][0/79]	Time 0.432 (0.432)	Data 0.394 (0.394)	Loss 0.4370 (0.4370)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:00

 Epoch: 391	Training Loss 0.3318 	Training Prec@1 88.512 	Training Prec@5 99.662 	Validation Loss 0.5203 	Validation Prec@1 82.250 	Validation Prec@5 99.010 

lr: 0.0677415870497693
TRAINING - Epoch: [391][0/391]	Time 1.307 (1.307)	Data 0.414 (0.414)	Loss 0.3073 (0.3073)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [391][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.3551 (0.3079)	Prec@1 87.500 (89.295)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [391][200/391]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3192 (0.3173)	Prec@1 86.719 (89.004)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [391][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3051 (0.3220)	Prec@1 89.062 (88.912)	Prec@5 100.000 (99.642)
EVALUATING - Epoch: [391][0/79]	Time 0.439 (0.439)	Data 0.402 (0.402)	Loss 0.5120 (0.5120)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:01

 Epoch: 392	Training Loss 0.3281 	Training Prec@1 88.726 	Training Prec@5 99.622 	Validation Loss 0.6356 	Validation Prec@1 79.750 	Validation Prec@5 98.840 

lr: 0.06759405075659161
TRAINING - Epoch: [392][0/391]	Time 1.604 (1.604)	Data 0.435 (0.435)	Loss 0.3262 (0.3262)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [392][100/391]	Time 0.121 (0.134)	Data 0.000 (0.005)	Loss 0.3154 (0.3251)	Prec@1 89.844 (88.637)	Prec@5 99.219 (99.613)
TRAINING - Epoch: [392][200/391]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.3405 (0.3247)	Prec@1 89.062 (88.685)	Prec@5 100.000 (99.619)
TRAINING - Epoch: [392][300/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2143 (0.3253)	Prec@1 91.406 (88.795)	Prec@5 100.000 (99.637)
EVALUATING - Epoch: [392][0/79]	Time 0.454 (0.454)	Data 0.412 (0.412)	Loss 0.5849 (0.5849)	Prec@1 82.812 (82.812)	Prec@5 96.875 (96.875)
Time cost: 00:50	Time of Finish: 2022-03-24 03:00:52

 Epoch: 393	Training Loss 0.3256 	Training Prec@1 88.766 	Training Prec@5 99.632 	Validation Loss 0.7108 	Validation Prec@1 78.290 	Validation Prec@5 98.150 

lr: 0.06744633941968801
TRAINING - Epoch: [393][0/391]	Time 1.361 (1.361)	Data 0.450 (0.450)	Loss 0.2983 (0.2983)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [393][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.2888 (0.3156)	Prec@1 89.844 (89.372)	Prec@5 100.000 (99.590)
TRAINING - Epoch: [393][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.3238 (0.3154)	Prec@1 89.844 (89.323)	Prec@5 98.438 (99.627)
TRAINING - Epoch: [393][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2700 (0.3192)	Prec@1 92.969 (89.187)	Prec@5 100.000 (99.600)
EVALUATING - Epoch: [393][0/79]	Time 0.427 (0.427)	Data 0.394 (0.394)	Loss 0.4249 (0.4249)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:10

 Epoch: 394	Training Loss 0.3221 	Training Prec@1 89.028 	Training Prec@5 99.590 	Validation Loss 0.5391 	Validation Prec@1 82.460 	Validation Prec@5 99.000 

lr: 0.0672984545086429
TRAINING - Epoch: [394][0/391]	Time 1.325 (1.325)	Data 0.413 (0.413)	Loss 0.2677 (0.2677)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [394][100/391]	Time 0.116 (0.125)	Data 0.000 (0.004)	Loss 0.4105 (0.3122)	Prec@1 84.375 (89.148)	Prec@5 98.438 (99.691)
TRAINING - Epoch: [394][200/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3467 (0.3193)	Prec@1 86.719 (88.923)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [394][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3543 (0.3225)	Prec@1 90.625 (88.811)	Prec@5 100.000 (99.618)
EVALUATING - Epoch: [394][0/79]	Time 0.469 (0.469)	Data 0.433 (0.433)	Loss 0.5214 (0.5214)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:17

 Epoch: 395	Training Loss 0.3241 	Training Prec@1 88.778 	Training Prec@5 99.626 	Validation Loss 0.5986 	Validation Prec@1 81.070 	Validation Prec@5 98.680 

lr: 0.06715039749476759
TRAINING - Epoch: [395][0/391]	Time 1.340 (1.340)	Data 0.421 (0.421)	Loss 0.3536 (0.3536)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [395][100/391]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.3059 (0.3137)	Prec@1 87.500 (89.256)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [395][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3040 (0.3202)	Prec@1 91.406 (89.016)	Prec@5 100.000 (99.670)
TRAINING - Epoch: [395][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3108 (0.3216)	Prec@1 89.844 (88.933)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [395][0/79]	Time 0.442 (0.442)	Data 0.409 (0.409)	Loss 0.5299 (0.5299)	Prec@1 85.156 (85.156)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:57

 Epoch: 396	Training Loss 0.3297 	Training Prec@1 88.652 	Training Prec@5 99.650 	Validation Loss 0.6209 	Validation Prec@1 80.880 	Validation Prec@5 98.230 

lr: 0.06700216985108566
TRAINING - Epoch: [396][0/391]	Time 1.322 (1.322)	Data 0.422 (0.422)	Loss 0.3106 (0.3106)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [396][100/391]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.2400 (0.3112)	Prec@1 92.188 (88.916)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [396][200/391]	Time 0.109 (0.120)	Data 0.000 (0.002)	Loss 0.3128 (0.3198)	Prec@1 87.500 (88.864)	Prec@5 99.219 (99.600)
TRAINING - Epoch: [396][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.3279 (0.3236)	Prec@1 89.844 (88.813)	Prec@5 100.000 (99.613)
EVALUATING - Epoch: [396][0/79]	Time 0.447 (0.447)	Data 0.408 (0.408)	Loss 0.5449 (0.5449)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:53

 Epoch: 397	Training Loss 0.3251 	Training Prec@1 88.772 	Training Prec@5 99.610 	Validation Loss 0.5925 	Validation Prec@1 81.840 	Validation Prec@5 99.020 

lr: 0.06685377305231824
TRAINING - Epoch: [397][0/391]	Time 1.392 (1.392)	Data 0.450 (0.450)	Loss 0.3635 (0.3635)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [397][100/391]	Time 0.115 (0.128)	Data 0.000 (0.005)	Loss 0.2994 (0.3112)	Prec@1 88.281 (89.387)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [397][200/391]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.3842 (0.3220)	Prec@1 85.938 (88.985)	Prec@5 100.000 (99.584)
TRAINING - Epoch: [397][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2792 (0.3249)	Prec@1 89.844 (88.896)	Prec@5 99.219 (99.590)
EVALUATING - Epoch: [397][0/79]	Time 0.473 (0.473)	Data 0.435 (0.435)	Loss 0.5061 (0.5061)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:16

 Epoch: 398	Training Loss 0.3280 	Training Prec@1 88.816 	Training Prec@5 99.596 	Validation Loss 0.5631 	Validation Prec@1 81.760 	Validation Prec@5 98.780 

lr: 0.06670520857486947
TRAINING - Epoch: [398][0/391]	Time 1.300 (1.300)	Data 0.430 (0.430)	Loss 0.3607 (0.3607)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [398][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.2561 (0.3130)	Prec@1 92.188 (89.325)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [398][200/391]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.3532 (0.3184)	Prec@1 89.062 (89.129)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [398][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3134 (0.3224)	Prec@1 89.062 (88.959)	Prec@5 100.000 (99.605)
EVALUATING - Epoch: [398][0/79]	Time 0.416 (0.416)	Data 0.391 (0.391)	Loss 0.4648 (0.4648)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:46:04

 Epoch: 399	Training Loss 0.3217 	Training Prec@1 88.982 	Training Prec@5 99.620 	Validation Loss 0.5239 	Validation Prec@1 83.760 	Validation Prec@5 99.190 

lr: 0.06655647789681164
TRAINING - Epoch: [399][0/391]	Time 1.339 (1.339)	Data 0.451 (0.451)	Loss 0.3180 (0.3180)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [399][100/391]	Time 0.115 (0.128)	Data 0.000 (0.005)	Loss 0.3804 (0.3108)	Prec@1 86.719 (89.310)	Prec@5 98.438 (99.575)
TRAINING - Epoch: [399][200/391]	Time 0.112 (0.120)	Data 0.000 (0.003)	Loss 0.3794 (0.3215)	Prec@1 85.938 (88.926)	Prec@5 99.219 (99.604)
TRAINING - Epoch: [399][300/391]	Time 0.106 (0.117)	Data 0.000 (0.002)	Loss 0.4368 (0.3201)	Prec@1 82.812 (88.933)	Prec@5 99.219 (99.600)
EVALUATING - Epoch: [399][0/79]	Time 0.433 (0.433)	Data 0.400 (0.400)	Loss 0.6120 (0.6120)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:31

 Epoch: 400	Training Loss 0.3220 	Training Prec@1 88.888 	Training Prec@5 99.604 	Validation Loss 0.5891 	Validation Prec@1 81.010 	Validation Prec@5 98.950 

lr: 0.06640758249787064
TRAINING - Epoch: [400][0/391]	Time 1.298 (1.298)	Data 0.423 (0.423)	Loss 0.2279 (0.2279)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [400][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.2334 (0.2954)	Prec@1 94.531 (89.612)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [400][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.3060 (0.3080)	Prec@1 87.500 (89.307)	Prec@5 100.000 (99.639)
TRAINING - Epoch: [400][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2174 (0.3133)	Prec@1 94.531 (89.216)	Prec@5 100.000 (99.644)
EVALUATING - Epoch: [400][0/79]	Time 0.439 (0.439)	Data 0.397 (0.397)	Loss 0.5766 (0.5766)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:20

 Epoch: 401	Training Loss 0.3133 	Training Prec@1 89.218 	Training Prec@5 99.646 	Validation Loss 0.6246 	Validation Prec@1 80.110 	Validation Prec@5 98.810 

lr: 0.06625852385941117
TRAINING - Epoch: [401][0/391]	Time 1.285 (1.285)	Data 0.410 (0.410)	Loss 0.2801 (0.2801)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [401][100/391]	Time 0.118 (0.128)	Data 0.000 (0.004)	Loss 0.2632 (0.3094)	Prec@1 91.406 (89.140)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [401][200/391]	Time 0.107 (0.121)	Data 0.000 (0.002)	Loss 0.3462 (0.3225)	Prec@1 87.500 (88.705)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [401][300/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3798 (0.3222)	Prec@1 89.062 (88.790)	Prec@5 100.000 (99.647)
EVALUATING - Epoch: [401][0/79]	Time 0.438 (0.438)	Data 0.400 (0.400)	Loss 0.5276 (0.5276)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:04

 Epoch: 402	Training Loss 0.3263 	Training Prec@1 88.662 	Training Prec@5 99.618 	Validation Loss 0.6250 	Validation Prec@1 80.660 	Validation Prec@5 98.820 

lr: 0.06610930346442195
TRAINING - Epoch: [402][0/391]	Time 1.364 (1.364)	Data 0.439 (0.439)	Loss 0.1805 (0.1805)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [402][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.2704 (0.3023)	Prec@1 89.062 (89.805)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [402][200/391]	Time 0.111 (0.120)	Data 0.000 (0.003)	Loss 0.4595 (0.3106)	Prec@1 86.719 (89.502)	Prec@5 98.438 (99.642)
TRAINING - Epoch: [402][300/391]	Time 0.109 (0.120)	Data 0.000 (0.002)	Loss 0.2495 (0.3150)	Prec@1 89.844 (89.213)	Prec@5 99.219 (99.631)
EVALUATING - Epoch: [402][0/79]	Time 0.419 (0.419)	Data 0.382 (0.382)	Loss 0.5542 (0.5542)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:15

 Epoch: 403	Training Loss 0.3174 	Training Prec@1 89.130 	Training Prec@5 99.626 	Validation Loss 0.6441 	Validation Prec@1 80.220 	Validation Prec@5 99.110 

lr: 0.06595992279750108
TRAINING - Epoch: [403][0/391]	Time 1.321 (1.321)	Data 0.421 (0.421)	Loss 0.2304 (0.2304)	Prec@1 95.312 (95.312)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [403][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.2329 (0.3130)	Prec@1 92.188 (89.325)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [403][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3303 (0.3175)	Prec@1 89.844 (89.272)	Prec@5 100.000 (99.689)
TRAINING - Epoch: [403][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.3106 (0.3246)	Prec@1 90.625 (88.990)	Prec@5 100.000 (99.647)
EVALUATING - Epoch: [403][0/79]	Time 0.442 (0.442)	Data 0.404 (0.404)	Loss 0.4714 (0.4714)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:44

 Epoch: 404	Training Loss 0.3204 	Training Prec@1 89.190 	Training Prec@5 99.658 	Validation Loss 0.7027 	Validation Prec@1 79.630 	Validation Prec@5 98.750 

lr: 0.06581038334484117
TRAINING - Epoch: [404][0/391]	Time 1.601 (1.601)	Data 0.418 (0.418)	Loss 0.2890 (0.2890)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [404][100/391]	Time 0.120 (0.133)	Data 0.000 (0.004)	Loss 0.3607 (0.3140)	Prec@1 86.719 (89.016)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [404][200/391]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.4186 (0.3137)	Prec@1 86.719 (88.996)	Prec@5 99.219 (99.689)
TRAINING - Epoch: [404][300/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3192 (0.3178)	Prec@1 89.062 (88.951)	Prec@5 100.000 (99.686)
EVALUATING - Epoch: [404][0/79]	Time 0.426 (0.426)	Data 0.391 (0.391)	Loss 0.4995 (0.4995)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:56:13

 Epoch: 405	Training Loss 0.3194 	Training Prec@1 88.930 	Training Prec@5 99.688 	Validation Loss 0.5864 	Validation Prec@1 81.110 	Validation Prec@5 98.890 

lr: 0.06566068659421465
TRAINING - Epoch: [405][0/391]	Time 1.266 (1.266)	Data 0.372 (0.372)	Loss 0.3457 (0.3457)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [405][100/391]	Time 0.108 (0.125)	Data 0.000 (0.004)	Loss 0.4995 (0.3103)	Prec@1 85.156 (89.782)	Prec@5 99.219 (99.675)
TRAINING - Epoch: [405][200/391]	Time 0.130 (0.118)	Data 0.000 (0.002)	Loss 0.4113 (0.3153)	Prec@1 87.500 (89.237)	Prec@5 100.000 (99.685)
TRAINING - Epoch: [405][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.3500 (0.3158)	Prec@1 85.938 (89.234)	Prec@5 99.219 (99.694)
EVALUATING - Epoch: [405][0/79]	Time 0.434 (0.434)	Data 0.389 (0.389)	Loss 0.6302 (0.6302)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:22

 Epoch: 406	Training Loss 0.3184 	Training Prec@1 89.104 	Training Prec@5 99.682 	Validation Loss 0.6428 	Validation Prec@1 80.560 	Validation Prec@5 98.840 

lr: 0.06551083403495882
TRAINING - Epoch: [406][0/391]	Time 1.334 (1.334)	Data 0.415 (0.415)	Loss 0.3144 (0.3144)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [406][100/391]	Time 0.115 (0.126)	Data 0.000 (0.004)	Loss 0.3140 (0.3066)	Prec@1 87.500 (89.488)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [406][200/391]	Time 0.109 (0.120)	Data 0.000 (0.002)	Loss 0.3957 (0.3176)	Prec@1 89.062 (89.086)	Prec@5 99.219 (99.677)
TRAINING - Epoch: [406][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3692 (0.3211)	Prec@1 88.281 (88.956)	Prec@5 100.000 (99.660)
EVALUATING - Epoch: [406][0/79]	Time 0.440 (0.440)	Data 0.391 (0.391)	Loss 0.7409 (0.7409)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:30

 Epoch: 407	Training Loss 0.3213 	Training Prec@1 88.974 	Training Prec@5 99.656 	Validation Loss 0.8159 	Validation Prec@1 76.510 	Validation Prec@5 98.240 

lr: 0.06536082715796122
TRAINING - Epoch: [407][0/391]	Time 1.588 (1.588)	Data 0.382 (0.382)	Loss 0.2929 (0.2929)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [407][100/391]	Time 0.111 (0.131)	Data 0.000 (0.004)	Loss 0.3174 (0.3048)	Prec@1 90.625 (89.179)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [407][200/391]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.2727 (0.3166)	Prec@1 93.750 (88.860)	Prec@5 100.000 (99.642)
TRAINING - Epoch: [407][300/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3116 (0.3182)	Prec@1 88.281 (88.870)	Prec@5 100.000 (99.642)
EVALUATING - Epoch: [407][0/79]	Time 0.451 (0.451)	Data 0.417 (0.417)	Loss 0.8506 (0.8506)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:50	Time of Finish: 2022-03-24 02:52:01

 Epoch: 408	Training Loss 0.3224 	Training Prec@1 88.726 	Training Prec@5 99.624 	Validation Loss 0.7893 	Validation Prec@1 76.720 	Validation Prec@5 97.770 

lr: 0.06521066745564463
TRAINING - Epoch: [408][0/391]	Time 1.299 (1.299)	Data 0.415 (0.415)	Loss 0.2690 (0.2690)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [408][100/391]	Time 0.112 (0.127)	Data 0.000 (0.004)	Loss 0.3710 (0.3249)	Prec@1 85.938 (88.869)	Prec@5 100.000 (99.606)
TRAINING - Epoch: [408][200/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.2232 (0.3149)	Prec@1 92.969 (89.164)	Prec@5 100.000 (99.635)
TRAINING - Epoch: [408][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3310 (0.3155)	Prec@1 88.281 (89.151)	Prec@5 100.000 (99.652)
EVALUATING - Epoch: [408][0/79]	Time 0.431 (0.431)	Data 0.396 (0.396)	Loss 0.5029 (0.5029)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:57

 Epoch: 409	Training Loss 0.3180 	Training Prec@1 89.140 	Training Prec@5 99.652 	Validation Loss 0.6101 	Validation Prec@1 81.300 	Validation Prec@5 98.790 

lr: 0.06506035642195238
TRAINING - Epoch: [409][0/391]	Time 1.337 (1.337)	Data 0.413 (0.413)	Loss 0.3448 (0.3448)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [409][100/391]	Time 0.108 (0.124)	Data 0.000 (0.004)	Loss 0.4019 (0.3152)	Prec@1 89.062 (88.970)	Prec@5 99.219 (99.636)
TRAINING - Epoch: [409][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.4205 (0.3152)	Prec@1 84.375 (89.113)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [409][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.4043 (0.3167)	Prec@1 85.938 (89.016)	Prec@5 100.000 (99.639)
EVALUATING - Epoch: [409][0/79]	Time 0.425 (0.425)	Data 0.394 (0.394)	Loss 0.4680 (0.4680)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:58

 Epoch: 410	Training Loss 0.3176 	Training Prec@1 88.994 	Training Prec@5 99.646 	Validation Loss 0.5145 	Validation Prec@1 83.110 	Validation Prec@5 99.050 

lr: 0.06490989555233326
TRAINING - Epoch: [410][0/391]	Time 1.358 (1.358)	Data 0.442 (0.442)	Loss 0.2752 (0.2752)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [410][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.3945 (0.2976)	Prec@1 84.375 (89.728)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [410][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.2154 (0.3070)	Prec@1 91.406 (89.428)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [410][300/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.4229 (0.3140)	Prec@1 84.375 (89.151)	Prec@5 100.000 (99.665)
EVALUATING - Epoch: [410][0/79]	Time 0.441 (0.441)	Data 0.410 (0.410)	Loss 0.3260 (0.3260)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:59

 Epoch: 411	Training Loss 0.3134 	Training Prec@1 89.176 	Training Prec@5 99.672 	Validation Loss 0.4867 	Validation Prec@1 83.700 	Validation Prec@5 99.360 

lr: 0.06475928634372692
TRAINING - Epoch: [411][0/391]	Time 1.363 (1.363)	Data 0.433 (0.433)	Loss 0.2579 (0.2579)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [411][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.2759 (0.3030)	Prec@1 89.844 (89.720)	Prec@5 100.000 (99.621)
TRAINING - Epoch: [411][200/391]	Time 0.110 (0.120)	Data 0.000 (0.003)	Loss 0.4076 (0.3110)	Prec@1 85.156 (89.319)	Prec@5 99.219 (99.607)
TRAINING - Epoch: [411][300/391]	Time 0.107 (0.119)	Data 0.000 (0.002)	Loss 0.2387 (0.3148)	Prec@1 92.188 (89.151)	Prec@5 100.000 (99.629)
EVALUATING - Epoch: [411][0/79]	Time 0.457 (0.457)	Data 0.419 (0.419)	Loss 0.6215 (0.6215)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:48	Time of Finish: 2022-03-24 02:41:29

 Epoch: 412	Training Loss 0.3171 	Training Prec@1 89.108 	Training Prec@5 99.658 	Validation Loss 0.6158 	Validation Prec@1 80.070 	Validation Prec@5 99.030 

lr: 0.06460853029454876
TRAINING - Epoch: [412][0/391]	Time 1.307 (1.307)	Data 0.417 (0.417)	Loss 0.4399 (0.4399)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [412][100/391]	Time 0.118 (0.131)	Data 0.000 (0.005)	Loss 0.5021 (0.3033)	Prec@1 83.594 (89.194)	Prec@5 99.219 (99.621)
TRAINING - Epoch: [412][200/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2246 (0.3094)	Prec@1 94.531 (89.129)	Prec@5 100.000 (99.654)
TRAINING - Epoch: [412][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.3376 (0.3066)	Prec@1 87.500 (89.234)	Prec@5 99.219 (99.678)
EVALUATING - Epoch: [412][0/79]	Time 0.432 (0.432)	Data 0.385 (0.385)	Loss 0.6109 (0.6109)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Time cost: 00:50	Time of Finish: 2022-03-24 02:53:49

 Epoch: 413	Training Loss 0.3095 	Training Prec@1 89.186 	Training Prec@5 99.684 	Validation Loss 0.6635 	Validation Prec@1 79.020 	Validation Prec@5 98.540 

lr: 0.06445762890467514
TRAINING - Epoch: [413][0/391]	Time 1.361 (1.361)	Data 0.434 (0.434)	Loss 0.4148 (0.4148)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [413][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.3195 (0.3138)	Prec@1 88.281 (89.333)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [413][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.2976 (0.3179)	Prec@1 88.281 (89.097)	Prec@5 100.000 (99.627)
TRAINING - Epoch: [413][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4396 (0.3168)	Prec@1 86.719 (89.208)	Prec@5 96.875 (99.626)
EVALUATING - Epoch: [413][0/79]	Time 0.471 (0.471)	Data 0.427 (0.427)	Loss 0.6227 (0.6227)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:43:46

 Epoch: 414	Training Loss 0.3158 	Training Prec@1 89.150 	Training Prec@5 99.640 	Validation Loss 0.5945 	Validation Prec@1 80.910 	Validation Prec@5 99.250 

lr: 0.06430658367542841
TRAINING - Epoch: [414][0/391]	Time 1.339 (1.339)	Data 0.421 (0.421)	Loss 0.2611 (0.2611)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [414][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.3098 (0.3031)	Prec@1 88.281 (89.635)	Prec@5 100.000 (99.652)
TRAINING - Epoch: [414][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2982 (0.3122)	Prec@1 89.062 (89.311)	Prec@5 100.000 (99.646)
TRAINING - Epoch: [414][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2431 (0.3117)	Prec@1 92.188 (89.322)	Prec@5 99.219 (99.647)
EVALUATING - Epoch: [414][0/79]	Time 0.437 (0.437)	Data 0.400 (0.400)	Loss 0.5190 (0.5190)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:54

 Epoch: 415	Training Loss 0.3152 	Training Prec@1 89.196 	Training Prec@5 99.652 	Validation Loss 0.6351 	Validation Prec@1 80.640 	Validation Prec@5 98.140 

lr: 0.06415539610956196
TRAINING - Epoch: [415][0/391]	Time 1.331 (1.331)	Data 0.418 (0.418)	Loss 0.4378 (0.4378)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [415][100/391]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.2329 (0.2902)	Prec@1 92.188 (90.145)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [415][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3724 (0.3087)	Prec@1 89.062 (89.471)	Prec@5 98.438 (99.712)
TRAINING - Epoch: [415][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3135 (0.3135)	Prec@1 85.156 (89.229)	Prec@5 99.219 (99.712)
EVALUATING - Epoch: [415][0/79]	Time 0.489 (0.489)	Data 0.447 (0.447)	Loss 0.4630 (0.4630)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:29

 Epoch: 416	Training Loss 0.3133 	Training Prec@1 89.232 	Training Prec@5 99.700 	Validation Loss 0.5861 	Validation Prec@1 81.210 	Validation Prec@5 98.910 

lr: 0.06400406771124534
TRAINING - Epoch: [416][0/391]	Time 1.329 (1.329)	Data 0.421 (0.421)	Loss 0.2776 (0.2776)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [416][100/391]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.3955 (0.3059)	Prec@1 86.719 (89.256)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [416][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.4384 (0.3053)	Prec@1 82.031 (89.342)	Prec@5 100.000 (99.654)
TRAINING - Epoch: [416][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2543 (0.3124)	Prec@1 89.844 (89.216)	Prec@5 100.000 (99.655)
EVALUATING - Epoch: [416][0/79]	Time 0.443 (0.443)	Data 0.407 (0.407)	Loss 0.4278 (0.4278)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:50

 Epoch: 417	Training Loss 0.3132 	Training Prec@1 89.242 	Training Prec@5 99.650 	Validation Loss 0.5077 	Validation Prec@1 83.510 	Validation Prec@5 99.180 

lr: 0.06385259998604915
TRAINING - Epoch: [417][0/391]	Time 1.322 (1.322)	Data 0.419 (0.419)	Loss 0.3051 (0.3051)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [417][100/391]	Time 0.106 (0.124)	Data 0.000 (0.004)	Loss 0.3072 (0.3027)	Prec@1 89.062 (89.395)	Prec@5 99.219 (99.683)
TRAINING - Epoch: [417][200/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.4119 (0.3113)	Prec@1 86.719 (89.129)	Prec@5 100.000 (99.685)
TRAINING - Epoch: [417][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4378 (0.3130)	Prec@1 85.156 (89.125)	Prec@5 99.219 (99.673)
EVALUATING - Epoch: [417][0/79]	Time 0.435 (0.435)	Data 0.399 (0.399)	Loss 0.5076 (0.5076)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:35

 Epoch: 418	Training Loss 0.3135 	Training Prec@1 89.146 	Training Prec@5 99.672 	Validation Loss 0.6542 	Validation Prec@1 80.780 	Validation Prec@5 98.660 

lr: 0.06370099444093029
TRAINING - Epoch: [418][0/391]	Time 1.310 (1.310)	Data 0.411 (0.411)	Loss 0.3113 (0.3113)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [418][100/391]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.3370 (0.3061)	Prec@1 89.062 (89.604)	Prec@5 99.219 (99.675)
TRAINING - Epoch: [418][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2307 (0.3076)	Prec@1 93.750 (89.459)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [418][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3231 (0.3103)	Prec@1 89.844 (89.252)	Prec@5 100.000 (99.676)
EVALUATING - Epoch: [418][0/79]	Time 0.444 (0.444)	Data 0.406 (0.406)	Loss 0.8202 (0.8202)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:58

 Epoch: 419	Training Loss 0.3147 	Training Prec@1 89.052 	Training Prec@5 99.674 	Validation Loss 0.8106 	Validation Prec@1 75.090 	Validation Prec@5 98.300 

lr: 0.06354925258421673
TRAINING - Epoch: [419][0/391]	Time 1.342 (1.342)	Data 0.416 (0.416)	Loss 0.2727 (0.2727)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [419][100/391]	Time 0.115 (0.129)	Data 0.000 (0.004)	Loss 0.3158 (0.2941)	Prec@1 90.625 (89.913)	Prec@5 99.219 (99.698)
TRAINING - Epoch: [419][200/391]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.1993 (0.3049)	Prec@1 92.969 (89.475)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [419][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.2458 (0.3065)	Prec@1 90.625 (89.421)	Prec@5 100.000 (99.650)
EVALUATING - Epoch: [419][0/79]	Time 0.431 (0.431)	Data 0.383 (0.383)	Loss 0.5344 (0.5344)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:44:13

 Epoch: 420	Training Loss 0.3093 	Training Prec@1 89.246 	Training Prec@5 99.664 	Validation Loss 0.5689 	Validation Prec@1 81.710 	Validation Prec@5 98.820 

lr: 0.06339737592559265
TRAINING - Epoch: [420][0/391]	Time 1.320 (1.320)	Data 0.427 (0.427)	Loss 0.2691 (0.2691)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [420][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.2976 (0.2999)	Prec@1 92.188 (89.705)	Prec@5 98.438 (99.691)
TRAINING - Epoch: [420][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.2309 (0.3133)	Prec@1 90.625 (89.253)	Prec@5 99.219 (99.600)
TRAINING - Epoch: [420][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3060 (0.3152)	Prec@1 89.062 (89.197)	Prec@5 98.438 (99.616)
EVALUATING - Epoch: [420][0/79]	Time 0.413 (0.413)	Data 0.383 (0.383)	Loss 0.4370 (0.4370)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:23

 Epoch: 421	Training Loss 0.3160 	Training Prec@1 89.180 	Training Prec@5 99.630 	Validation Loss 0.4877 	Validation Prec@1 84.010 	Validation Prec@5 99.240 

lr: 0.06324536597608338
TRAINING - Epoch: [421][0/391]	Time 1.302 (1.302)	Data 0.414 (0.414)	Loss 0.4150 (0.4150)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [421][100/391]	Time 0.112 (0.126)	Data 0.000 (0.004)	Loss 0.3401 (0.3004)	Prec@1 88.281 (89.627)	Prec@5 100.000 (99.737)
TRAINING - Epoch: [421][200/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.4943 (0.3091)	Prec@1 85.156 (89.354)	Prec@5 98.438 (99.670)
TRAINING - Epoch: [421][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.3255 (0.3119)	Prec@1 88.281 (89.252)	Prec@5 100.000 (99.663)
EVALUATING - Epoch: [421][0/79]	Time 0.430 (0.430)	Data 0.389 (0.389)	Loss 0.5847 (0.5847)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:24

 Epoch: 422	Training Loss 0.3138 	Training Prec@1 89.192 	Training Prec@5 99.662 	Validation Loss 0.5483 	Validation Prec@1 81.890 	Validation Prec@5 99.160 

lr: 0.06309322424804033
TRAINING - Epoch: [422][0/391]	Time 1.311 (1.311)	Data 0.409 (0.409)	Loss 0.1347 (0.1347)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [422][100/391]	Time 0.109 (0.125)	Data 0.000 (0.004)	Loss 0.1807 (0.3113)	Prec@1 92.188 (89.209)	Prec@5 100.000 (99.745)
TRAINING - Epoch: [422][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3457 (0.3104)	Prec@1 89.062 (89.249)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [422][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3395 (0.3132)	Prec@1 91.406 (89.192)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [422][0/79]	Time 0.416 (0.416)	Data 0.385 (0.385)	Loss 0.7210 (0.7210)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:00

 Epoch: 423	Training Loss 0.3191 	Training Prec@1 88.996 	Training Prec@5 99.656 	Validation Loss 0.6996 	Validation Prec@1 78.940 	Validation Prec@5 98.360 

lr: 0.06294095225512601
TRAINING - Epoch: [423][0/391]	Time 1.323 (1.323)	Data 0.424 (0.424)	Loss 0.3253 (0.3253)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [423][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.3725 (0.3008)	Prec@1 86.719 (89.534)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [423][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2737 (0.3045)	Prec@1 90.625 (89.572)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [423][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.4243 (0.3078)	Prec@1 87.500 (89.444)	Prec@5 98.438 (99.655)
EVALUATING - Epoch: [423][0/79]	Time 0.445 (0.445)	Data 0.412 (0.412)	Loss 0.5936 (0.5936)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:21

 Epoch: 424	Training Loss 0.3099 	Training Prec@1 89.344 	Training Prec@5 99.668 	Validation Loss 0.5363 	Validation Prec@1 83.360 	Validation Prec@5 99.110 

lr: 0.06278855151229897
TRAINING - Epoch: [424][0/391]	Time 1.387 (1.387)	Data 0.461 (0.461)	Loss 0.3265 (0.3265)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [424][100/391]	Time 0.112 (0.126)	Data 0.000 (0.005)	Loss 0.3041 (0.3069)	Prec@1 91.406 (89.565)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [424][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.3764 (0.3119)	Prec@1 83.594 (89.346)	Prec@5 100.000 (99.677)
TRAINING - Epoch: [424][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4057 (0.3114)	Prec@1 85.938 (89.351)	Prec@5 100.000 (99.660)
EVALUATING - Epoch: [424][0/79]	Time 0.431 (0.431)	Data 0.393 (0.393)	Loss 0.6485 (0.6485)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:36

 Epoch: 425	Training Loss 0.3146 	Training Prec@1 89.210 	Training Prec@5 99.670 	Validation Loss 0.6273 	Validation Prec@1 81.440 	Validation Prec@5 98.830 

lr: 0.06263602353579864
TRAINING - Epoch: [425][0/391]	Time 1.338 (1.338)	Data 0.438 (0.438)	Loss 0.2830 (0.2830)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [425][100/391]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.2126 (0.2950)	Prec@1 91.406 (89.681)	Prec@5 100.000 (99.667)
TRAINING - Epoch: [425][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.4083 (0.3091)	Prec@1 87.500 (89.249)	Prec@5 99.219 (99.666)
TRAINING - Epoch: [425][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2769 (0.3112)	Prec@1 92.188 (89.210)	Prec@5 100.000 (99.670)
EVALUATING - Epoch: [425][0/79]	Time 0.435 (0.435)	Data 0.402 (0.402)	Loss 0.7548 (0.7548)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:51

 Epoch: 426	Training Loss 0.3107 	Training Prec@1 89.270 	Training Prec@5 99.684 	Validation Loss 0.6610 	Validation Prec@1 80.150 	Validation Prec@5 99.220 

lr: 0.062483369843130306
TRAINING - Epoch: [426][0/391]	Time 1.314 (1.314)	Data 0.421 (0.421)	Loss 0.2423 (0.2423)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [426][100/391]	Time 0.119 (0.128)	Data 0.000 (0.005)	Loss 0.3973 (0.3049)	Prec@1 86.719 (89.310)	Prec@5 99.219 (99.675)
TRAINING - Epoch: [426][200/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.3902 (0.3089)	Prec@1 85.938 (89.241)	Prec@5 100.000 (99.681)
TRAINING - Epoch: [426][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2581 (0.3134)	Prec@1 91.406 (89.161)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [426][0/79]	Time 0.413 (0.413)	Data 0.384 (0.384)	Loss 0.5769 (0.5769)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:28

 Epoch: 427	Training Loss 0.3126 	Training Prec@1 89.164 	Training Prec@5 99.698 	Validation Loss 0.5759 	Validation Prec@1 81.300 	Validation Prec@5 99.210 

lr: 0.062330591953050074
TRAINING - Epoch: [427][0/391]	Time 1.352 (1.352)	Data 0.464 (0.464)	Loss 0.4740 (0.4740)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [427][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.2492 (0.3061)	Prec@1 92.969 (89.534)	Prec@5 98.438 (99.706)
TRAINING - Epoch: [427][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.3802 (0.3092)	Prec@1 86.719 (89.307)	Prec@5 99.219 (99.685)
TRAINING - Epoch: [427][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3369 (0.3071)	Prec@1 89.844 (89.415)	Prec@5 100.000 (99.676)
EVALUATING - Epoch: [427][0/79]	Time 0.445 (0.445)	Data 0.407 (0.407)	Loss 0.5060 (0.5060)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:02

 Epoch: 428	Training Loss 0.3079 	Training Prec@1 89.382 	Training Prec@5 99.674 	Validation Loss 0.5417 	Validation Prec@1 82.700 	Validation Prec@5 98.910 

lr: 0.06217769138554957
TRAINING - Epoch: [428][0/391]	Time 1.318 (1.318)	Data 0.418 (0.418)	Loss 0.2346 (0.2346)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [428][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.3735 (0.3023)	Prec@1 88.281 (89.403)	Prec@5 98.438 (99.691)
TRAINING - Epoch: [428][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3201 (0.3054)	Prec@1 85.156 (89.253)	Prec@5 99.219 (99.654)
TRAINING - Epoch: [428][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2499 (0.3101)	Prec@1 89.844 (89.195)	Prec@5 100.000 (99.660)
EVALUATING - Epoch: [428][0/79]	Time 0.472 (0.472)	Data 0.426 (0.426)	Loss 0.5121 (0.5121)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:47

 Epoch: 429	Training Loss 0.3104 	Training Prec@1 89.204 	Training Prec@5 99.650 	Validation Loss 0.6451 	Validation Prec@1 79.270 	Validation Prec@5 98.810 

lr: 0.06202466966184109
TRAINING - Epoch: [429][0/391]	Time 1.391 (1.391)	Data 0.443 (0.443)	Loss 0.4127 (0.4127)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [429][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.3221 (0.3061)	Prec@1 86.719 (89.302)	Prec@5 100.000 (99.629)
TRAINING - Epoch: [429][200/391]	Time 0.111 (0.119)	Data 0.000 (0.003)	Loss 0.2414 (0.3061)	Prec@1 91.406 (89.370)	Prec@5 100.000 (99.693)
TRAINING - Epoch: [429][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.2806 (0.3063)	Prec@1 89.844 (89.400)	Prec@5 99.219 (99.689)
EVALUATING - Epoch: [429][0/79]	Time 0.414 (0.414)	Data 0.377 (0.377)	Loss 0.6813 (0.6813)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:28

 Epoch: 430	Training Loss 0.3090 	Training Prec@1 89.294 	Training Prec@5 99.674 	Validation Loss 0.7080 	Validation Prec@1 77.410 	Validation Prec@5 97.990 

lr: 0.06187152830434217
TRAINING - Epoch: [430][0/391]	Time 1.356 (1.356)	Data 0.465 (0.465)	Loss 0.2499 (0.2499)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [430][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.3837 (0.2928)	Prec@1 86.719 (89.797)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [430][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.2374 (0.2976)	Prec@1 92.969 (89.782)	Prec@5 99.219 (99.681)
TRAINING - Epoch: [430][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.3247 (0.3058)	Prec@1 87.500 (89.488)	Prec@5 99.219 (99.665)
EVALUATING - Epoch: [430][0/79]	Time 0.443 (0.443)	Data 0.411 (0.411)	Loss 0.5271 (0.5271)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:05

 Epoch: 431	Training Loss 0.3068 	Training Prec@1 89.436 	Training Prec@5 99.630 	Validation Loss 0.5160 	Validation Prec@1 83.310 	Validation Prec@5 99.170 

lr: 0.06171826883666071
TRAINING - Epoch: [431][0/391]	Time 1.310 (1.310)	Data 0.443 (0.443)	Loss 0.1854 (0.1854)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [431][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.2799 (0.3022)	Prec@1 90.625 (89.735)	Prec@5 99.219 (99.667)
TRAINING - Epoch: [431][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.3943 (0.3042)	Prec@1 85.938 (89.560)	Prec@5 99.219 (99.681)
TRAINING - Epoch: [431][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2492 (0.3073)	Prec@1 92.188 (89.488)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [431][0/79]	Time 0.442 (0.442)	Data 0.397 (0.397)	Loss 0.5798 (0.5798)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:59

 Epoch: 432	Training Loss 0.3075 	Training Prec@1 89.410 	Training Prec@5 99.662 	Validation Loss 0.6260 	Validation Prec@1 81.250 	Validation Prec@5 98.890 

lr: 0.061564892783579635
TRAINING - Epoch: [432][0/391]	Time 1.642 (1.642)	Data 0.445 (0.445)	Loss 0.3149 (0.3149)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [432][100/391]	Time 0.126 (0.136)	Data 0.000 (0.005)	Loss 0.3021 (0.2923)	Prec@1 89.062 (89.952)	Prec@5 99.219 (99.745)
TRAINING - Epoch: [432][200/391]	Time 0.121 (0.128)	Data 0.000 (0.003)	Loss 0.3272 (0.2970)	Prec@1 86.719 (89.824)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [432][300/391]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3380 (0.3050)	Prec@1 89.844 (89.582)	Prec@5 100.000 (99.670)
EVALUATING - Epoch: [432][0/79]	Time 0.458 (0.458)	Data 0.419 (0.419)	Loss 0.5649 (0.5649)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 02:57:21

 Epoch: 433	Training Loss 0.3112 	Training Prec@1 89.442 	Training Prec@5 99.660 	Validation Loss 0.6341 	Validation Prec@1 81.980 	Validation Prec@5 98.840 

lr: 0.06141140167104176
TRAINING - Epoch: [433][0/391]	Time 1.316 (1.316)	Data 0.397 (0.397)	Loss 0.3305 (0.3305)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [433][100/391]	Time 0.114 (0.125)	Data 0.000 (0.004)	Loss 0.3589 (0.3051)	Prec@1 88.281 (89.380)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [433][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.2794 (0.3051)	Prec@1 90.625 (89.342)	Prec@5 99.219 (99.693)
TRAINING - Epoch: [433][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3006 (0.3075)	Prec@1 89.844 (89.319)	Prec@5 100.000 (99.686)
EVALUATING - Epoch: [433][0/79]	Time 0.451 (0.451)	Data 0.400 (0.400)	Loss 0.4252 (0.4252)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:53

 Epoch: 434	Training Loss 0.3106 	Training Prec@1 89.188 	Training Prec@5 99.660 	Validation Loss 0.4931 	Validation Prec@1 83.850 	Validation Prec@5 99.160 

lr: 0.06125779702613468
TRAINING - Epoch: [434][0/391]	Time 1.255 (1.255)	Data 0.377 (0.377)	Loss 0.2862 (0.2862)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [434][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.2467 (0.2914)	Prec@1 91.406 (90.130)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [434][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2035 (0.2964)	Prec@1 96.094 (90.050)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [434][300/391]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.2892 (0.2990)	Prec@1 92.188 (89.888)	Prec@5 100.000 (99.691)
EVALUATING - Epoch: [434][0/79]	Time 0.446 (0.446)	Data 0.396 (0.396)	Loss 0.4170 (0.4170)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 01:58:59

 Epoch: 435	Training Loss 0.3025 	Training Prec@1 89.678 	Training Prec@5 99.666 	Validation Loss 0.5106 	Validation Prec@1 83.740 	Validation Prec@5 99.190 

lr: 0.06110408037707548
TRAINING - Epoch: [435][0/391]	Time 1.339 (1.339)	Data 0.431 (0.431)	Loss 0.2004 (0.2004)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [435][100/391]	Time 0.109 (0.126)	Data 0.000 (0.005)	Loss 0.2877 (0.2881)	Prec@1 89.844 (90.091)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [435][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.3326 (0.2937)	Prec@1 85.156 (90.003)	Prec@5 99.219 (99.759)
TRAINING - Epoch: [435][300/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.3217 (0.3002)	Prec@1 89.062 (89.774)	Prec@5 100.000 (99.712)
EVALUATING - Epoch: [435][0/79]	Time 0.434 (0.434)	Data 0.400 (0.400)	Loss 0.5054 (0.5054)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:42

 Epoch: 436	Training Loss 0.3031 	Training Prec@1 89.714 	Training Prec@5 99.694 	Validation Loss 0.5676 	Validation Prec@1 81.930 	Validation Prec@5 99.130 

lr: 0.06095025325319563
TRAINING - Epoch: [436][0/391]	Time 1.273 (1.273)	Data 0.413 (0.413)	Loss 0.3740 (0.3740)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [436][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.2419 (0.2879)	Prec@1 92.188 (90.362)	Prec@5 100.000 (99.644)
TRAINING - Epoch: [436][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.2405 (0.3016)	Prec@1 90.625 (89.735)	Prec@5 100.000 (99.631)
TRAINING - Epoch: [436][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3285 (0.3038)	Prec@1 88.281 (89.659)	Prec@5 100.000 (99.621)
EVALUATING - Epoch: [436][0/79]	Time 0.481 (0.481)	Data 0.435 (0.435)	Loss 0.5696 (0.5696)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:19

 Epoch: 437	Training Loss 0.3055 	Training Prec@1 89.574 	Training Prec@5 99.628 	Validation Loss 0.6169 	Validation Prec@1 81.270 	Validation Prec@5 98.570 

lr: 0.06079631718492566
TRAINING - Epoch: [437][0/391]	Time 1.306 (1.306)	Data 0.451 (0.451)	Loss 0.4850 (0.4850)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [437][100/391]	Time 0.112 (0.126)	Data 0.000 (0.005)	Loss 0.3035 (0.2808)	Prec@1 89.062 (89.968)	Prec@5 98.438 (99.776)
TRAINING - Epoch: [437][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.2363 (0.2850)	Prec@1 89.844 (89.937)	Prec@5 99.219 (99.767)
TRAINING - Epoch: [437][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.2365 (0.2921)	Prec@1 91.406 (89.841)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [437][0/79]	Time 0.427 (0.427)	Data 0.387 (0.387)	Loss 0.5050 (0.5050)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:36

 Epoch: 438	Training Loss 0.2947 	Training Prec@1 89.760 	Training Prec@5 99.724 	Validation Loss 0.5346 	Validation Prec@1 83.310 	Validation Prec@5 99.240 

lr: 0.060642273703780045
TRAINING - Epoch: [438][0/391]	Time 1.354 (1.354)	Data 0.446 (0.446)	Loss 0.1723 (0.1723)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [438][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.3101 (0.2857)	Prec@1 89.062 (90.153)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [438][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.2409 (0.2972)	Prec@1 91.406 (89.883)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [438][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3157 (0.3018)	Prec@1 90.625 (89.652)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [438][0/79]	Time 0.435 (0.435)	Data 0.402 (0.402)	Loss 0.4122 (0.4122)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:38

 Epoch: 439	Training Loss 0.2998 	Training Prec@1 89.690 	Training Prec@5 99.718 	Validation Loss 0.5594 	Validation Prec@1 82.590 	Validation Prec@5 99.200 

lr: 0.06048812434234185
TRAINING - Epoch: [439][0/391]	Time 1.344 (1.344)	Data 0.428 (0.428)	Loss 0.3521 (0.3521)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [439][100/391]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.2789 (0.2833)	Prec@1 90.625 (90.439)	Prec@5 99.219 (99.652)
TRAINING - Epoch: [439][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2798 (0.2959)	Prec@1 89.844 (89.914)	Prec@5 100.000 (99.674)
TRAINING - Epoch: [439][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.3076 (0.2976)	Prec@1 88.281 (89.932)	Prec@5 98.438 (99.678)
EVALUATING - Epoch: [439][0/79]	Time 0.447 (0.447)	Data 0.413 (0.413)	Loss 0.5359 (0.5359)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:20

 Epoch: 440	Training Loss 0.2994 	Training Prec@1 89.806 	Training Prec@5 99.688 	Validation Loss 0.5139 	Validation Prec@1 83.750 	Validation Prec@5 99.240 

lr: 0.060333870634247624
TRAINING - Epoch: [440][0/391]	Time 1.342 (1.342)	Data 0.437 (0.437)	Loss 0.1474 (0.1474)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [440][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.3679 (0.2973)	Prec@1 88.281 (89.898)	Prec@5 99.219 (99.698)
TRAINING - Epoch: [440][200/391]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.2757 (0.2993)	Prec@1 91.406 (89.688)	Prec@5 100.000 (99.689)
TRAINING - Epoch: [440][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.3456 (0.3033)	Prec@1 88.281 (89.499)	Prec@5 99.219 (99.678)
EVALUATING - Epoch: [440][0/79]	Time 0.439 (0.439)	Data 0.402 (0.402)	Loss 0.4233 (0.4233)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:42

 Epoch: 441	Training Loss 0.3032 	Training Prec@1 89.530 	Training Prec@5 99.678 	Validation Loss 0.4802 	Validation Prec@1 84.110 	Validation Prec@5 99.250 

lr: 0.060179514114172
TRAINING - Epoch: [441][0/391]	Time 1.328 (1.328)	Data 0.426 (0.426)	Loss 0.2196 (0.2196)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [441][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.2648 (0.2897)	Prec@1 89.844 (89.975)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [441][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.2661 (0.3010)	Prec@1 91.406 (89.583)	Prec@5 100.000 (99.662)
TRAINING - Epoch: [441][300/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2778 (0.3041)	Prec@1 92.188 (89.426)	Prec@5 99.219 (99.652)
EVALUATING - Epoch: [441][0/79]	Time 0.434 (0.434)	Data 0.396 (0.396)	Loss 0.5796 (0.5796)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:14

 Epoch: 442	Training Loss 0.3039 	Training Prec@1 89.404 	Training Prec@5 99.662 	Validation Loss 0.6731 	Validation Prec@1 79.250 	Validation Prec@5 98.630 

lr: 0.060025056317812533
TRAINING - Epoch: [442][0/391]	Time 1.319 (1.319)	Data 0.416 (0.416)	Loss 0.2832 (0.2832)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [442][100/391]	Time 0.108 (0.124)	Data 0.000 (0.004)	Loss 0.1674 (0.2919)	Prec@1 96.875 (89.728)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [442][200/391]	Time 0.108 (0.119)	Data 0.000 (0.002)	Loss 0.3211 (0.2980)	Prec@1 89.062 (89.544)	Prec@5 100.000 (99.712)
TRAINING - Epoch: [442][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.2001 (0.2993)	Prec@1 94.531 (89.517)	Prec@5 99.219 (99.720)
EVALUATING - Epoch: [442][0/79]	Time 0.447 (0.447)	Data 0.411 (0.411)	Loss 0.6332 (0.6332)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:18

 Epoch: 443	Training Loss 0.2986 	Training Prec@1 89.544 	Training Prec@5 99.716 	Validation Loss 0.6826 	Validation Prec@1 79.330 	Validation Prec@5 98.630 

lr: 0.05987049878187433
TRAINING - Epoch: [443][0/391]	Time 1.308 (1.308)	Data 0.409 (0.409)	Loss 0.2324 (0.2324)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [443][100/391]	Time 0.104 (0.122)	Data 0.000 (0.004)	Loss 0.3459 (0.2910)	Prec@1 89.844 (89.882)	Prec@5 99.219 (99.776)
TRAINING - Epoch: [443][200/391]	Time 0.104 (0.113)	Data 0.000 (0.002)	Loss 0.2488 (0.3004)	Prec@1 91.406 (89.591)	Prec@5 100.000 (99.743)
TRAINING - Epoch: [443][300/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2942 (0.3001)	Prec@1 90.625 (89.605)	Prec@5 100.000 (99.727)
EVALUATING - Epoch: [443][0/79]	Time 0.416 (0.416)	Data 0.384 (0.384)	Loss 0.5885 (0.5885)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:45	Time of Finish: 2022-03-24 02:04:51

 Epoch: 444	Training Loss 0.3031 	Training Prec@1 89.490 	Training Prec@5 99.708 	Validation Loss 0.6439 	Validation Prec@1 80.270 	Validation Prec@5 98.530 

lr: 0.059715843044054855
TRAINING - Epoch: [444][0/391]	Time 1.309 (1.309)	Data 0.451 (0.451)	Loss 0.2648 (0.2648)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [444][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.3096 (0.2909)	Prec@1 90.625 (90.169)	Prec@5 99.219 (99.660)
TRAINING - Epoch: [444][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.2991 (0.2938)	Prec@1 89.844 (90.050)	Prec@5 100.000 (99.681)
TRAINING - Epoch: [444][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2995 (0.2949)	Prec@1 89.844 (89.937)	Prec@5 100.000 (99.681)
EVALUATING - Epoch: [444][0/79]	Time 0.421 (0.421)	Data 0.382 (0.382)	Loss 0.4811 (0.4811)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:43

 Epoch: 445	Training Loss 0.2995 	Training Prec@1 89.802 	Training Prec@5 99.682 	Validation Loss 0.5493 	Validation Prec@1 82.780 	Validation Prec@5 99.140 

lr: 0.059561090643028586
TRAINING - Epoch: [445][0/391]	Time 1.282 (1.282)	Data 0.424 (0.424)	Loss 0.2336 (0.2336)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [445][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.2952 (0.3037)	Prec@1 89.062 (89.395)	Prec@5 99.219 (99.752)
TRAINING - Epoch: [445][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.4519 (0.2953)	Prec@1 83.594 (89.712)	Prec@5 99.219 (99.724)
TRAINING - Epoch: [445][300/391]	Time 0.106 (0.115)	Data 0.000 (0.002)	Loss 0.3152 (0.2993)	Prec@1 90.625 (89.602)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [445][0/79]	Time 0.434 (0.434)	Data 0.402 (0.402)	Loss 0.3689 (0.3689)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:51

 Epoch: 446	Training Loss 0.3051 	Training Prec@1 89.488 	Training Prec@5 99.694 	Validation Loss 0.5230 	Validation Prec@1 83.800 	Validation Prec@5 99.160 

lr: 0.05940624311843165
TRAINING - Epoch: [446][0/391]	Time 1.259 (1.259)	Data 0.411 (0.411)	Loss 0.3233 (0.3233)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [446][100/391]	Time 0.108 (0.125)	Data 0.000 (0.004)	Loss 0.3046 (0.3008)	Prec@1 90.625 (89.844)	Prec@5 100.000 (99.745)
TRAINING - Epoch: [446][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.1976 (0.3000)	Prec@1 94.531 (89.999)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [446][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.4580 (0.3063)	Prec@1 85.938 (89.709)	Prec@5 98.438 (99.691)
EVALUATING - Epoch: [446][0/79]	Time 0.439 (0.439)	Data 0.405 (0.405)	Loss 0.4522 (0.4522)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:22

 Epoch: 447	Training Loss 0.3017 	Training Prec@1 89.748 	Training Prec@5 99.706 	Validation Loss 0.5820 	Validation Prec@1 82.370 	Validation Prec@5 99.010 

lr: 0.05925130201084667
TRAINING - Epoch: [447][0/391]	Time 1.266 (1.266)	Data 0.434 (0.434)	Loss 0.2751 (0.2751)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [447][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.2658 (0.2957)	Prec@1 91.406 (89.828)	Prec@5 100.000 (99.714)
TRAINING - Epoch: [447][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2391 (0.2989)	Prec@1 92.969 (89.747)	Prec@5 99.219 (99.658)
TRAINING - Epoch: [447][300/391]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.3432 (0.3008)	Prec@1 87.500 (89.602)	Prec@5 100.000 (99.663)
EVALUATING - Epoch: [447][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.7586 (0.7586)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:45	Time of Finish: 2022-03-24 02:06:20

 Epoch: 448	Training Loss 0.3000 	Training Prec@1 89.690 	Training Prec@5 99.672 	Validation Loss 0.7248 	Validation Prec@1 78.410 	Validation Prec@5 98.460 

lr: 0.05909626886178718
TRAINING - Epoch: [448][0/391]	Time 1.273 (1.273)	Data 0.437 (0.437)	Loss 0.2693 (0.2693)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [448][100/391]	Time 0.109 (0.116)	Data 0.000 (0.005)	Loss 0.3559 (0.2990)	Prec@1 87.500 (89.805)	Prec@5 99.219 (99.737)
TRAINING - Epoch: [448][200/391]	Time 0.104 (0.112)	Data 0.000 (0.002)	Loss 0.2091 (0.2990)	Prec@1 92.188 (89.552)	Prec@5 100.000 (99.716)
TRAINING - Epoch: [448][300/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2015 (0.2987)	Prec@1 94.531 (89.683)	Prec@5 100.000 (99.704)
EVALUATING - Epoch: [448][0/79]	Time 0.432 (0.432)	Data 0.398 (0.398)	Loss 0.5400 (0.5400)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:02:50

 Epoch: 449	Training Loss 0.3028 	Training Prec@1 89.494 	Training Prec@5 99.694 	Validation Loss 0.5786 	Validation Prec@1 81.650 	Validation Prec@5 98.760 

lr: 0.05894114521368256
TRAINING - Epoch: [449][0/391]	Time 1.244 (1.244)	Data 0.399 (0.399)	Loss 0.3278 (0.3278)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [449][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.2893 (0.2869)	Prec@1 88.281 (90.231)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [449][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2721 (0.2956)	Prec@1 89.062 (89.731)	Prec@5 100.000 (99.778)
TRAINING - Epoch: [449][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3839 (0.3000)	Prec@1 89.844 (89.537)	Prec@5 99.219 (99.740)
EVALUATING - Epoch: [449][0/79]	Time 0.451 (0.451)	Data 0.405 (0.405)	Loss 0.6269 (0.6269)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:21:54

 Epoch: 450	Training Loss 0.3004 	Training Prec@1 89.586 	Training Prec@5 99.748 	Validation Loss 0.6381 	Validation Prec@1 79.680 	Validation Prec@5 99.230 

lr: 0.05878593260986253
TRAINING - Epoch: [450][0/391]	Time 1.270 (1.270)	Data 0.412 (0.412)	Loss 0.2548 (0.2548)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [450][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.5394 (0.2974)	Prec@1 84.375 (89.735)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [450][200/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3439 (0.2954)	Prec@1 86.719 (89.758)	Prec@5 100.000 (99.743)
TRAINING - Epoch: [450][300/391]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.1848 (0.2972)	Prec@1 93.750 (89.615)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [450][0/79]	Time 0.444 (0.444)	Data 0.406 (0.406)	Loss 0.4895 (0.4895)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:19:56

 Epoch: 451	Training Loss 0.3039 	Training Prec@1 89.508 	Training Prec@5 99.716 	Validation Loss 0.6359 	Validation Prec@1 80.450 	Validation Prec@5 98.830 

lr: 0.058630632594541814
TRAINING - Epoch: [451][0/391]	Time 1.312 (1.312)	Data 0.446 (0.446)	Loss 0.2639 (0.2639)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [451][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.2579 (0.2923)	Prec@1 90.625 (89.720)	Prec@5 100.000 (99.691)
TRAINING - Epoch: [451][200/391]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.3509 (0.2961)	Prec@1 89.844 (89.708)	Prec@5 100.000 (99.670)
TRAINING - Epoch: [451][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3522 (0.2973)	Prec@1 91.406 (89.623)	Prec@5 97.656 (99.668)
EVALUATING - Epoch: [451][0/79]	Time 0.417 (0.417)	Data 0.385 (0.385)	Loss 0.4797 (0.4797)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:42

 Epoch: 452	Training Loss 0.3018 	Training Prec@1 89.468 	Training Prec@5 99.658 	Validation Loss 0.5340 	Validation Prec@1 83.120 	Validation Prec@5 98.800 

lr: 0.058475246712804796
TRAINING - Epoch: [452][0/391]	Time 1.316 (1.316)	Data 0.451 (0.451)	Loss 0.3037 (0.3037)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [452][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.3378 (0.2676)	Prec@1 88.281 (90.811)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [452][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.2843 (0.2812)	Prec@1 88.281 (90.365)	Prec@5 100.000 (99.740)
TRAINING - Epoch: [452][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.2664 (0.2877)	Prec@1 89.062 (90.121)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [452][0/79]	Time 0.445 (0.445)	Data 0.410 (0.410)	Loss 0.5774 (0.5774)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:09

 Epoch: 453	Training Loss 0.2931 	Training Prec@1 89.918 	Training Prec@5 99.694 	Validation Loss 0.6839 	Validation Prec@1 78.780 	Validation Prec@5 98.970 

lr: 0.058319776510590206
TRAINING - Epoch: [453][0/391]	Time 1.278 (1.278)	Data 0.427 (0.427)	Loss 0.3743 (0.3743)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [453][100/391]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.2210 (0.2923)	Prec@1 93.750 (89.952)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [453][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.2585 (0.2923)	Prec@1 91.406 (89.941)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [453][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3442 (0.2938)	Prec@1 89.844 (89.859)	Prec@5 100.000 (99.704)
EVALUATING - Epoch: [453][0/79]	Time 0.413 (0.413)	Data 0.381 (0.381)	Loss 0.5476 (0.5476)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:00

 Epoch: 454	Training Loss 0.2981 	Training Prec@1 89.732 	Training Prec@5 99.682 	Validation Loss 0.5529 	Validation Prec@1 82.460 	Validation Prec@5 99.070 

lr: 0.05816422353467559
TRAINING - Epoch: [454][0/391]	Time 1.336 (1.336)	Data 0.488 (0.488)	Loss 0.2359 (0.2359)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [454][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.2593 (0.2842)	Prec@1 91.406 (90.022)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [454][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.1677 (0.2819)	Prec@1 93.750 (90.069)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [454][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2776 (0.2836)	Prec@1 90.625 (90.116)	Prec@5 100.000 (99.709)
EVALUATING - Epoch: [454][0/79]	Time 0.438 (0.438)	Data 0.400 (0.400)	Loss 0.3779 (0.3779)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:44

 Epoch: 455	Training Loss 0.2865 	Training Prec@1 89.966 	Training Prec@5 99.702 	Validation Loss 0.5643 	Validation Prec@1 82.530 	Validation Prec@5 99.150 

lr: 0.058008589332662105
TRAINING - Epoch: [455][0/391]	Time 1.310 (1.310)	Data 0.421 (0.421)	Loss 0.3657 (0.3657)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [455][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.2741 (0.2849)	Prec@1 92.188 (90.053)	Prec@5 100.000 (99.675)
TRAINING - Epoch: [455][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2577 (0.2901)	Prec@1 90.625 (89.859)	Prec@5 99.219 (99.712)
TRAINING - Epoch: [455][300/391]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.3620 (0.2898)	Prec@1 88.281 (89.890)	Prec@5 99.219 (99.740)
EVALUATING - Epoch: [455][0/79]	Time 0.426 (0.426)	Data 0.394 (0.394)	Loss 0.4722 (0.4722)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:37

 Epoch: 456	Training Loss 0.2926 	Training Prec@1 89.844 	Training Prec@5 99.738 	Validation Loss 0.5329 	Validation Prec@1 83.620 	Validation Prec@5 99.090 

lr: 0.057852875452958925
TRAINING - Epoch: [456][0/391]	Time 1.304 (1.304)	Data 0.453 (0.453)	Loss 0.3757 (0.3757)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [456][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.1183 (0.2793)	Prec@1 96.094 (90.277)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [456][200/391]	Time 0.113 (0.117)	Data 0.000 (0.003)	Loss 0.2851 (0.2911)	Prec@1 89.062 (89.879)	Prec@5 100.000 (99.685)
TRAINING - Epoch: [456][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3203 (0.2915)	Prec@1 90.625 (89.877)	Prec@5 99.219 (99.709)
EVALUATING - Epoch: [456][0/79]	Time 0.451 (0.451)	Data 0.414 (0.414)	Loss 0.4758 (0.4758)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:36

 Epoch: 457	Training Loss 0.2950 	Training Prec@1 89.822 	Training Prec@5 99.696 	Validation Loss 0.5605 	Validation Prec@1 81.650 	Validation Prec@5 99.060 

lr: 0.057697083444768024
TRAINING - Epoch: [457][0/391]	Time 1.271 (1.271)	Data 0.412 (0.412)	Loss 0.3102 (0.3102)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [457][100/391]	Time 0.117 (0.130)	Data 0.000 (0.005)	Loss 0.4531 (0.2978)	Prec@1 88.281 (89.991)	Prec@5 98.438 (99.698)
TRAINING - Epoch: [457][200/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2152 (0.2956)	Prec@1 92.969 (89.844)	Prec@5 100.000 (99.708)
TRAINING - Epoch: [457][300/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2521 (0.3000)	Prec@1 89.844 (89.600)	Prec@5 100.000 (99.704)
EVALUATING - Epoch: [457][0/79]	Time 0.446 (0.446)	Data 0.404 (0.404)	Loss 0.5561 (0.5561)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:45:19

 Epoch: 458	Training Loss 0.3005 	Training Prec@1 89.608 	Training Prec@5 99.712 	Validation Loss 0.5305 	Validation Prec@1 83.600 	Validation Prec@5 99.240 

lr: 0.05754121485806867
TRAINING - Epoch: [458][0/391]	Time 1.271 (1.271)	Data 0.431 (0.431)	Loss 0.3187 (0.3187)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [458][100/391]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 0.3259 (0.3005)	Prec@1 90.625 (89.418)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [458][200/391]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.2672 (0.2981)	Prec@1 89.062 (89.735)	Prec@5 100.000 (99.724)
TRAINING - Epoch: [458][300/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4521 (0.3046)	Prec@1 84.375 (89.517)	Prec@5 100.000 (99.746)
EVALUATING - Epoch: [458][0/79]	Time 0.455 (0.455)	Data 0.410 (0.410)	Loss 0.8388 (0.8388)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:43

 Epoch: 459	Training Loss 0.3034 	Training Prec@1 89.526 	Training Prec@5 99.718 	Validation Loss 0.6356 	Validation Prec@1 81.520 	Validation Prec@5 98.640 

lr: 0.05738527124360196
TRAINING - Epoch: [459][0/391]	Time 1.261 (1.261)	Data 0.405 (0.405)	Loss 0.2230 (0.2230)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [459][100/391]	Time 0.113 (0.125)	Data 0.000 (0.004)	Loss 0.2585 (0.2933)	Prec@1 89.062 (90.130)	Prec@5 100.000 (99.714)
TRAINING - Epoch: [459][200/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.5094 (0.2916)	Prec@1 82.031 (89.972)	Prec@5 99.219 (99.708)
TRAINING - Epoch: [459][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1991 (0.2920)	Prec@1 92.188 (89.966)	Prec@5 100.000 (99.730)
EVALUATING - Epoch: [459][0/79]	Time 0.452 (0.452)	Data 0.422 (0.422)	Loss 0.3534 (0.3534)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:42

 Epoch: 460	Training Loss 0.2980 	Training Prec@1 89.768 	Training Prec@5 99.706 	Validation Loss 0.5031 	Validation Prec@1 83.370 	Validation Prec@5 99.260 

lr: 0.05722925415285552
TRAINING - Epoch: [460][0/391]	Time 1.267 (1.267)	Data 0.414 (0.414)	Loss 0.3006 (0.3006)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [460][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.4234 (0.2748)	Prec@1 86.719 (90.401)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [460][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.2456 (0.2890)	Prec@1 91.406 (89.890)	Prec@5 99.219 (99.782)
TRAINING - Epoch: [460][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.2001 (0.2962)	Prec@1 92.969 (89.735)	Prec@5 100.000 (99.753)
EVALUATING - Epoch: [460][0/79]	Time 0.432 (0.432)	Data 0.401 (0.401)	Loss 0.4816 (0.4816)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:21:38

 Epoch: 461	Training Loss 0.2940 	Training Prec@1 89.820 	Training Prec@5 99.770 	Validation Loss 0.4995 	Validation Prec@1 84.210 	Validation Prec@5 99.190 

lr: 0.057073165138047895
TRAINING - Epoch: [461][0/391]	Time 1.266 (1.266)	Data 0.407 (0.407)	Loss 0.3251 (0.3251)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [461][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.2880 (0.2880)	Prec@1 90.625 (90.254)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [461][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1926 (0.2879)	Prec@1 93.750 (90.232)	Prec@5 100.000 (99.705)
TRAINING - Epoch: [461][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.2612 (0.2925)	Prec@1 91.406 (90.020)	Prec@5 98.438 (99.712)
EVALUATING - Epoch: [461][0/79]	Time 0.439 (0.439)	Data 0.405 (0.405)	Loss 0.4605 (0.4605)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:23:08

 Epoch: 462	Training Loss 0.2933 	Training Prec@1 89.978 	Training Prec@5 99.732 	Validation Loss 0.5844 	Validation Prec@1 81.830 	Validation Prec@5 99.090 

lr: 0.05691700575211332
TRAINING - Epoch: [462][0/391]	Time 1.261 (1.261)	Data 0.403 (0.403)	Loss 0.2426 (0.2426)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [462][100/391]	Time 0.107 (0.121)	Data 0.000 (0.004)	Loss 0.3167 (0.2966)	Prec@1 89.062 (89.975)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [462][200/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2537 (0.2934)	Prec@1 91.406 (90.061)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [462][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.4459 (0.2970)	Prec@1 84.375 (89.870)	Prec@5 99.219 (99.751)
EVALUATING - Epoch: [462][0/79]	Time 0.453 (0.453)	Data 0.414 (0.414)	Loss 0.3830 (0.3830)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:01

 Epoch: 463	Training Loss 0.2994 	Training Prec@1 89.764 	Training Prec@5 99.724 	Validation Loss 0.5369 	Validation Prec@1 82.570 	Validation Prec@5 98.960 

lr: 0.05676077754868607
TRAINING - Epoch: [463][0/391]	Time 1.222 (1.222)	Data 0.375 (0.375)	Loss 0.4035 (0.4035)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [463][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.2418 (0.2865)	Prec@1 89.062 (90.029)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [463][200/391]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2065 (0.2847)	Prec@1 91.406 (90.104)	Prec@5 99.219 (99.778)
TRAINING - Epoch: [463][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3301 (0.2893)	Prec@1 86.719 (89.927)	Prec@5 100.000 (99.740)
EVALUATING - Epoch: [463][0/79]	Time 0.428 (0.428)	Data 0.391 (0.391)	Loss 0.5452 (0.5452)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:28

 Epoch: 464	Training Loss 0.2925 	Training Prec@1 89.774 	Training Prec@5 99.724 	Validation Loss 0.5795 	Validation Prec@1 82.940 	Validation Prec@5 98.910 

lr: 0.05660448208208511
TRAINING - Epoch: [464][0/391]	Time 1.268 (1.268)	Data 0.417 (0.417)	Loss 0.2512 (0.2512)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [464][100/391]	Time 0.108 (0.121)	Data 0.000 (0.004)	Loss 0.2922 (0.2867)	Prec@1 87.500 (90.107)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [464][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4177 (0.2955)	Prec@1 86.719 (89.809)	Prec@5 99.219 (99.693)
TRAINING - Epoch: [464][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.2736 (0.2941)	Prec@1 90.625 (89.922)	Prec@5 100.000 (99.722)
EVALUATING - Epoch: [464][0/79]	Time 0.444 (0.444)	Data 0.401 (0.401)	Loss 0.4178 (0.4178)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:20:06

 Epoch: 465	Training Loss 0.2941 	Training Prec@1 89.884 	Training Prec@5 99.710 	Validation Loss 0.5315 	Validation Prec@1 82.930 	Validation Prec@5 98.880 

lr: 0.05644812090729861
TRAINING - Epoch: [465][0/391]	Time 1.283 (1.283)	Data 0.439 (0.439)	Loss 0.2364 (0.2364)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [465][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.4157 (0.2801)	Prec@1 87.500 (90.153)	Prec@5 100.000 (99.706)
TRAINING - Epoch: [465][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.3133 (0.2862)	Prec@1 88.281 (89.995)	Prec@5 99.219 (99.712)
TRAINING - Epoch: [465][300/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3078 (0.2873)	Prec@1 90.625 (90.085)	Prec@5 99.219 (99.694)
EVALUATING - Epoch: [465][0/79]	Time 0.437 (0.437)	Data 0.406 (0.406)	Loss 0.4463 (0.4463)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:59

 Epoch: 466	Training Loss 0.2876 	Training Prec@1 90.022 	Training Prec@5 99.690 	Validation Loss 0.4834 	Validation Prec@1 84.700 	Validation Prec@5 98.920 

lr: 0.05629169557996847
TRAINING - Epoch: [466][0/391]	Time 1.265 (1.265)	Data 0.412 (0.412)	Loss 0.2977 (0.2977)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [466][100/391]	Time 0.112 (0.128)	Data 0.000 (0.004)	Loss 0.4060 (0.2752)	Prec@1 88.281 (90.532)	Prec@5 97.656 (99.737)
TRAINING - Epoch: [466][200/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3283 (0.2830)	Prec@1 87.500 (90.174)	Prec@5 100.000 (99.705)
TRAINING - Epoch: [466][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2204 (0.2898)	Prec@1 90.625 (90.007)	Prec@5 100.000 (99.673)
EVALUATING - Epoch: [466][0/79]	Time 0.479 (0.479)	Data 0.436 (0.436)	Loss 0.3929 (0.3929)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:40:22

 Epoch: 467	Training Loss 0.2939 	Training Prec@1 89.922 	Training Prec@5 99.664 	Validation Loss 0.4861 	Validation Prec@1 84.600 	Validation Prec@5 99.160 

lr: 0.056135207656374864
TRAINING - Epoch: [467][0/391]	Time 1.297 (1.297)	Data 0.441 (0.441)	Loss 0.2624 (0.2624)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [467][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.4067 (0.2776)	Prec@1 83.594 (90.053)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [467][200/391]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.3269 (0.2821)	Prec@1 89.062 (90.096)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [467][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2499 (0.2877)	Prec@1 92.969 (89.989)	Prec@5 100.000 (99.751)
EVALUATING - Epoch: [467][0/79]	Time 0.448 (0.448)	Data 0.410 (0.410)	Loss 0.5517 (0.5517)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:23

 Epoch: 468	Training Loss 0.2894 	Training Prec@1 89.926 	Training Prec@5 99.740 	Validation Loss 0.5840 	Validation Prec@1 80.480 	Validation Prec@5 99.010 

lr: 0.055978658693420724
TRAINING - Epoch: [468][0/391]	Time 1.257 (1.257)	Data 0.384 (0.384)	Loss 0.3141 (0.3141)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [468][100/391]	Time 0.112 (0.125)	Data 0.000 (0.004)	Loss 0.1825 (0.2822)	Prec@1 92.188 (89.983)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [468][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3582 (0.2848)	Prec@1 89.062 (90.007)	Prec@5 99.219 (99.728)
TRAINING - Epoch: [468][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.4063 (0.2886)	Prec@1 87.500 (89.932)	Prec@5 100.000 (99.730)
EVALUATING - Epoch: [468][0/79]	Time 0.451 (0.451)	Data 0.406 (0.406)	Loss 0.5809 (0.5809)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:36

 Epoch: 469	Training Loss 0.2891 	Training Prec@1 89.968 	Training Prec@5 99.736 	Validation Loss 0.5404 	Validation Prec@1 82.350 	Validation Prec@5 99.400 

lr: 0.055822050248616265
TRAINING - Epoch: [469][0/391]	Time 1.292 (1.292)	Data 0.431 (0.431)	Loss 0.3578 (0.3578)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [469][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.2942 (0.2820)	Prec@1 87.500 (90.153)	Prec@5 100.000 (99.752)
TRAINING - Epoch: [469][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.1870 (0.2782)	Prec@1 93.750 (90.236)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [469][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1775 (0.2861)	Prec@1 94.531 (89.945)	Prec@5 100.000 (99.735)
EVALUATING - Epoch: [469][0/79]	Time 0.427 (0.427)	Data 0.393 (0.393)	Loss 0.4773 (0.4773)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:35

 Epoch: 470	Training Loss 0.2882 	Training Prec@1 89.904 	Training Prec@5 99.744 	Validation Loss 0.5543 	Validation Prec@1 82.550 	Validation Prec@5 99.090 

lr: 0.05566538388006347
TRAINING - Epoch: [470][0/391]	Time 1.308 (1.308)	Data 0.454 (0.454)	Loss 0.3102 (0.3102)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [470][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.2721 (0.2664)	Prec@1 87.500 (90.602)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [470][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.2756 (0.2700)	Prec@1 90.625 (90.586)	Prec@5 100.000 (99.767)
TRAINING - Epoch: [470][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.2339 (0.2783)	Prec@1 90.625 (90.316)	Prec@5 100.000 (99.753)
EVALUATING - Epoch: [470][0/79]	Time 0.408 (0.408)	Data 0.382 (0.382)	Loss 0.5343 (0.5343)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:53

 Epoch: 471	Training Loss 0.2836 	Training Prec@1 90.156 	Training Prec@5 99.740 	Validation Loss 0.5618 	Validation Prec@1 81.640 	Validation Prec@5 99.030 

lr: 0.05550866114644066
TRAINING - Epoch: [471][0/391]	Time 1.288 (1.288)	Data 0.413 (0.413)	Loss 0.3371 (0.3371)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [471][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.3958 (0.2807)	Prec@1 85.938 (90.602)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [471][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2231 (0.2792)	Prec@1 93.750 (90.497)	Prec@5 100.000 (99.712)
TRAINING - Epoch: [471][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.3880 (0.2816)	Prec@1 85.156 (90.298)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [471][0/79]	Time 0.445 (0.445)	Data 0.402 (0.402)	Loss 0.6570 (0.6570)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:44	Time of Finish: 2022-03-24 02:00:15

 Epoch: 472	Training Loss 0.2836 	Training Prec@1 90.208 	Training Prec@5 99.718 	Validation Loss 0.7686 	Validation Prec@1 78.260 	Validation Prec@5 98.070 

lr: 0.05535188360698685
TRAINING - Epoch: [472][0/391]	Time 1.258 (1.258)	Data 0.411 (0.411)	Loss 0.2481 (0.2481)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [472][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.3145 (0.2918)	Prec@1 89.062 (89.743)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [472][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2496 (0.2869)	Prec@1 89.844 (89.933)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [472][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.3310 (0.2895)	Prec@1 88.281 (89.898)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [472][0/79]	Time 0.442 (0.442)	Data 0.403 (0.403)	Loss 0.5259 (0.5259)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:27

 Epoch: 473	Training Loss 0.2886 	Training Prec@1 89.890 	Training Prec@5 99.764 	Validation Loss 0.5436 	Validation Prec@1 82.830 	Validation Prec@5 99.190 

lr: 0.05519505282148642
TRAINING - Epoch: [473][0/391]	Time 1.240 (1.240)	Data 0.371 (0.371)	Loss 0.2724 (0.2724)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [473][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.3174 (0.2782)	Prec@1 89.844 (90.447)	Prec@5 100.000 (99.683)
TRAINING - Epoch: [473][200/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3075 (0.2737)	Prec@1 89.844 (90.656)	Prec@5 100.000 (99.705)
TRAINING - Epoch: [473][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2501 (0.2799)	Prec@1 88.281 (90.368)	Prec@5 100.000 (99.689)
EVALUATING - Epoch: [473][0/79]	Time 0.416 (0.416)	Data 0.382 (0.382)	Loss 0.4711 (0.4711)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:07

 Epoch: 474	Training Loss 0.2840 	Training Prec@1 90.198 	Training Prec@5 99.690 	Validation Loss 0.5564 	Validation Prec@1 83.450 	Validation Prec@5 99.180 

lr: 0.0550381703502534
TRAINING - Epoch: [474][0/391]	Time 1.265 (1.265)	Data 0.367 (0.367)	Loss 0.1522 (0.1522)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [474][100/391]	Time 0.107 (0.121)	Data 0.000 (0.004)	Loss 0.1877 (0.2690)	Prec@1 94.531 (90.818)	Prec@5 99.219 (99.737)
TRAINING - Epoch: [474][200/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.3210 (0.2779)	Prec@1 89.062 (90.563)	Prec@5 100.000 (99.724)
TRAINING - Epoch: [474][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.3673 (0.2809)	Prec@1 85.938 (90.399)	Prec@5 99.219 (99.681)
EVALUATING - Epoch: [474][0/79]	Time 0.422 (0.422)	Data 0.395 (0.395)	Loss 0.4703 (0.4703)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:18:42

 Epoch: 475	Training Loss 0.2816 	Training Prec@1 90.360 	Training Prec@5 99.678 	Validation Loss 0.5721 	Validation Prec@1 81.150 	Validation Prec@5 99.120 

lr: 0.054881237754116116
TRAINING - Epoch: [475][0/391]	Time 1.236 (1.236)	Data 0.373 (0.373)	Loss 0.3042 (0.3042)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [475][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.2218 (0.2736)	Prec@1 92.969 (90.726)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [475][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.2816 (0.2775)	Prec@1 89.844 (90.516)	Prec@5 100.000 (99.751)
TRAINING - Epoch: [475][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2069 (0.2792)	Prec@1 90.625 (90.404)	Prec@5 100.000 (99.759)
EVALUATING - Epoch: [475][0/79]	Time 0.429 (0.429)	Data 0.391 (0.391)	Loss 0.4017 (0.4017)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:39

 Epoch: 476	Training Loss 0.2790 	Training Prec@1 90.384 	Training Prec@5 99.748 	Validation Loss 0.4716 	Validation Prec@1 85.140 	Validation Prec@5 99.420 

lr: 0.054724256594401555
TRAINING - Epoch: [476][0/391]	Time 1.311 (1.311)	Data 0.448 (0.448)	Loss 0.2300 (0.2300)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [476][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.3964 (0.2653)	Prec@1 83.594 (90.849)	Prec@5 99.219 (99.799)
TRAINING - Epoch: [476][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.2198 (0.2710)	Prec@1 94.531 (90.652)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [476][300/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2451 (0.2766)	Prec@1 92.188 (90.454)	Prec@5 100.000 (99.740)
EVALUATING - Epoch: [476][0/79]	Time 0.442 (0.442)	Data 0.409 (0.409)	Loss 0.5602 (0.5602)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 477	Training Loss 0.2807 	Training Prec@1 90.350 	Training Prec@5 99.722 	Validation Loss 0.5144 	Validation Prec@1 83.850 	Validation Prec@5 99.170 

lr: 0.05456722843291987
TRAINING - Epoch: [477][0/391]	Time 1.238 (1.238)	Data 0.374 (0.374)	Loss 0.3123 (0.3123)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [477][100/391]	Time 0.112 (0.124)	Data 0.000 (0.004)	Loss 0.3033 (0.2702)	Prec@1 91.406 (90.687)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [477][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3798 (0.2724)	Prec@1 85.938 (90.532)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [477][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3094 (0.2771)	Prec@1 89.062 (90.363)	Prec@5 100.000 (99.800)
EVALUATING - Epoch: [477][0/79]	Time 0.460 (0.460)	Data 0.416 (0.416)	Loss 0.3891 (0.3891)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:53

 Epoch: 478	Training Loss 0.2840 	Training Prec@1 90.150 	Training Prec@5 99.754 	Validation Loss 0.5628 	Validation Prec@1 81.830 	Validation Prec@5 98.920 

lr: 0.05441015483194882
TRAINING - Epoch: [478][0/391]	Time 1.310 (1.310)	Data 0.443 (0.443)	Loss 0.2347 (0.2347)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [478][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.1966 (0.2700)	Prec@1 92.969 (90.826)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [478][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.2362 (0.2720)	Prec@1 91.406 (90.722)	Prec@5 100.000 (99.767)
TRAINING - Epoch: [478][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.2710 (0.2795)	Prec@1 90.625 (90.433)	Prec@5 99.219 (99.751)
EVALUATING - Epoch: [478][0/79]	Time 0.452 (0.452)	Data 0.414 (0.414)	Loss 0.6144 (0.6144)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:30

 Epoch: 479	Training Loss 0.2800 	Training Prec@1 90.354 	Training Prec@5 99.744 	Validation Loss 0.5363 	Validation Prec@1 83.120 	Validation Prec@5 99.080 

lr: 0.05425303735421826
TRAINING - Epoch: [479][0/391]	Time 1.307 (1.307)	Data 0.452 (0.452)	Loss 0.4249 (0.4249)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [479][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.2506 (0.2696)	Prec@1 90.625 (90.509)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [479][200/391]	Time 0.122 (0.121)	Data 0.000 (0.003)	Loss 0.4247 (0.2753)	Prec@1 87.500 (90.326)	Prec@5 99.219 (99.736)
TRAINING - Epoch: [479][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2435 (0.2789)	Prec@1 92.188 (90.241)	Prec@5 100.000 (99.748)
EVALUATING - Epoch: [479][0/79]	Time 0.419 (0.419)	Data 0.381 (0.381)	Loss 0.5645 (0.5645)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:42:16

 Epoch: 480	Training Loss 0.2827 	Training Prec@1 90.136 	Training Prec@5 99.744 	Validation Loss 0.6160 	Validation Prec@1 80.820 	Validation Prec@5 98.750 

lr: 0.054095877562894606
TRAINING - Epoch: [480][0/391]	Time 1.275 (1.275)	Data 0.418 (0.418)	Loss 0.2378 (0.2378)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [480][100/391]	Time 0.113 (0.125)	Data 0.000 (0.004)	Loss 0.2767 (0.2806)	Prec@1 92.969 (90.231)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [480][200/391]	Time 0.107 (0.119)	Data 0.000 (0.002)	Loss 0.2553 (0.2820)	Prec@1 88.281 (90.221)	Prec@5 100.000 (99.724)
TRAINING - Epoch: [480][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.3030 (0.2854)	Prec@1 88.281 (90.137)	Prec@5 99.219 (99.709)
EVALUATING - Epoch: [480][0/79]	Time 0.430 (0.430)	Data 0.382 (0.382)	Loss 0.5112 (0.5112)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:53

 Epoch: 481	Training Loss 0.2854 	Training Prec@1 90.122 	Training Prec@5 99.708 	Validation Loss 0.6308 	Validation Prec@1 81.630 	Validation Prec@5 98.600 

lr: 0.0539386770215652
TRAINING - Epoch: [481][0/391]	Time 1.291 (1.291)	Data 0.435 (0.435)	Loss 0.1057 (0.1057)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [481][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.3638 (0.2756)	Prec@1 88.281 (90.540)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [481][200/391]	Time 0.118 (0.118)	Data 0.000 (0.003)	Loss 0.2309 (0.2744)	Prec@1 91.406 (90.567)	Prec@5 100.000 (99.747)
TRAINING - Epoch: [481][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.2587 (0.2794)	Prec@1 90.625 (90.371)	Prec@5 100.000 (99.753)
EVALUATING - Epoch: [481][0/79]	Time 0.427 (0.427)	Data 0.374 (0.374)	Loss 0.5818 (0.5818)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:43

 Epoch: 482	Training Loss 0.2835 	Training Prec@1 90.254 	Training Prec@5 99.734 	Validation Loss 0.5794 	Validation Prec@1 81.160 	Validation Prec@5 99.000 

lr: 0.05378143729422283
TRAINING - Epoch: [482][0/391]	Time 1.287 (1.287)	Data 0.431 (0.431)	Loss 0.2628 (0.2628)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [482][100/391]	Time 0.113 (0.122)	Data 0.000 (0.005)	Loss 0.4252 (0.2782)	Prec@1 86.719 (90.408)	Prec@5 99.219 (99.838)
TRAINING - Epoch: [482][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2636 (0.2828)	Prec@1 90.625 (90.392)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [482][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.3108 (0.2757)	Prec@1 88.281 (90.648)	Prec@5 99.219 (99.779)
EVALUATING - Epoch: [482][0/79]	Time 0.428 (0.428)	Data 0.388 (0.388)	Loss 0.7513 (0.7513)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:03

 Epoch: 483	Training Loss 0.2814 	Training Prec@1 90.378 	Training Prec@5 99.762 	Validation Loss 0.6490 	Validation Prec@1 80.600 	Validation Prec@5 98.680 

lr: 0.05362415994525012
TRAINING - Epoch: [483][0/391]	Time 1.283 (1.283)	Data 0.415 (0.415)	Loss 0.1973 (0.1973)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [483][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.3589 (0.2694)	Prec@1 87.500 (90.563)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [483][200/391]	Time 0.107 (0.120)	Data 0.000 (0.002)	Loss 0.2958 (0.2803)	Prec@1 91.406 (90.337)	Prec@5 100.000 (99.732)
TRAINING - Epoch: [483][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.3251 (0.2830)	Prec@1 88.281 (90.202)	Prec@5 100.000 (99.727)
EVALUATING - Epoch: [483][0/79]	Time 0.443 (0.443)	Data 0.398 (0.398)	Loss 0.5482 (0.5482)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:35

 Epoch: 484	Training Loss 0.2838 	Training Prec@1 90.162 	Training Prec@5 99.720 	Validation Loss 0.5176 	Validation Prec@1 83.250 	Validation Prec@5 99.250 

lr: 0.053466846539404075
TRAINING - Epoch: [484][0/391]	Time 1.278 (1.278)	Data 0.416 (0.416)	Loss 0.1794 (0.1794)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [484][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.3550 (0.2759)	Prec@1 87.500 (90.648)	Prec@5 99.219 (99.644)
TRAINING - Epoch: [484][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3476 (0.2751)	Prec@1 88.281 (90.551)	Prec@5 100.000 (99.693)
TRAINING - Epoch: [484][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2850 (0.2778)	Prec@1 84.375 (90.487)	Prec@5 100.000 (99.717)
EVALUATING - Epoch: [484][0/79]	Time 0.441 (0.441)	Data 0.406 (0.406)	Loss 0.4405 (0.4405)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:06

 Epoch: 485	Training Loss 0.2813 	Training Prec@1 90.314 	Training Prec@5 99.716 	Validation Loss 0.5222 	Validation Prec@1 82.880 	Validation Prec@5 99.230 

lr: 0.05330949864180032
TRAINING - Epoch: [485][0/391]	Time 1.299 (1.299)	Data 0.441 (0.441)	Loss 0.2342 (0.2342)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [485][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.1942 (0.2696)	Prec@1 92.969 (90.648)	Prec@5 100.000 (99.722)
TRAINING - Epoch: [485][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.2172 (0.2724)	Prec@1 91.406 (90.450)	Prec@5 100.000 (99.740)
TRAINING - Epoch: [485][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3403 (0.2761)	Prec@1 86.719 (90.412)	Prec@5 99.219 (99.751)
EVALUATING - Epoch: [485][0/79]	Time 0.444 (0.444)	Data 0.412 (0.412)	Loss 0.4289 (0.4289)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:00

 Epoch: 486	Training Loss 0.2773 	Training Prec@1 90.382 	Training Prec@5 99.756 	Validation Loss 0.4981 	Validation Prec@1 83.750 	Validation Prec@5 99.170 

lr: 0.05315211781789773
TRAINING - Epoch: [486][0/391]	Time 1.300 (1.300)	Data 0.445 (0.445)	Loss 0.2382 (0.2382)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [486][100/391]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.1945 (0.2731)	Prec@1 96.094 (90.633)	Prec@5 100.000 (99.714)
TRAINING - Epoch: [486][200/391]	Time 0.111 (0.116)	Data 0.000 (0.003)	Loss 0.3363 (0.2832)	Prec@1 87.500 (90.279)	Prec@5 100.000 (99.720)
TRAINING - Epoch: [486][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.2138 (0.2822)	Prec@1 90.625 (90.243)	Prec@5 100.000 (99.725)
EVALUATING - Epoch: [486][0/79]	Time 0.412 (0.412)	Data 0.385 (0.385)	Loss 0.5762 (0.5762)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:47

 Epoch: 487	Training Loss 0.2843 	Training Prec@1 90.154 	Training Prec@5 99.732 	Validation Loss 0.6369 	Validation Prec@1 80.510 	Validation Prec@5 98.790 

lr: 0.0529947056334827
TRAINING - Epoch: [487][0/391]	Time 1.249 (1.249)	Data 0.346 (0.346)	Loss 0.2793 (0.2793)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [487][100/391]	Time 0.118 (0.130)	Data 0.000 (0.004)	Loss 0.2209 (0.2708)	Prec@1 92.969 (90.610)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [487][200/391]	Time 0.110 (0.121)	Data 0.000 (0.002)	Loss 0.2482 (0.2716)	Prec@1 89.062 (90.644)	Prec@5 100.000 (99.759)
TRAINING - Epoch: [487][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.4256 (0.2763)	Prec@1 85.938 (90.397)	Prec@5 99.219 (99.753)
EVALUATING - Epoch: [487][0/79]	Time 0.475 (0.475)	Data 0.432 (0.432)	Loss 0.4281 (0.4281)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:40

 Epoch: 488	Training Loss 0.2785 	Training Prec@1 90.274 	Training Prec@5 99.760 	Validation Loss 0.4735 	Validation Prec@1 84.480 	Validation Prec@5 99.380 

lr: 0.052837263654653695
TRAINING - Epoch: [488][0/391]	Time 1.294 (1.294)	Data 0.417 (0.417)	Loss 0.2771 (0.2771)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [488][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.2803 (0.2723)	Prec@1 90.625 (90.594)	Prec@5 99.219 (99.706)
TRAINING - Epoch: [488][200/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.3408 (0.2794)	Prec@1 85.156 (90.403)	Prec@5 100.000 (99.728)
TRAINING - Epoch: [488][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1846 (0.2782)	Prec@1 93.750 (90.363)	Prec@5 99.219 (99.756)
EVALUATING - Epoch: [488][0/79]	Time 0.461 (0.461)	Data 0.422 (0.422)	Loss 0.4994 (0.4994)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:15

 Epoch: 489	Training Loss 0.2785 	Training Prec@1 90.376 	Training Prec@5 99.752 	Validation Loss 0.5386 	Validation Prec@1 83.010 	Validation Prec@5 99.160 

lr: 0.052679793447805524
TRAINING - Epoch: [489][0/391]	Time 1.253 (1.253)	Data 0.364 (0.364)	Loss 0.2538 (0.2538)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [489][100/391]	Time 0.116 (0.129)	Data 0.000 (0.004)	Loss 0.2759 (0.2688)	Prec@1 91.406 (90.439)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [489][200/391]	Time 0.109 (0.122)	Data 0.000 (0.002)	Loss 0.2772 (0.2729)	Prec@1 89.062 (90.353)	Prec@5 99.219 (99.759)
TRAINING - Epoch: [489][300/391]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3256 (0.2730)	Prec@1 89.062 (90.365)	Prec@5 100.000 (99.764)
EVALUATING - Epoch: [489][0/79]	Time 0.422 (0.422)	Data 0.384 (0.384)	Loss 0.4586 (0.4586)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:54

 Epoch: 490	Training Loss 0.2758 	Training Prec@1 90.334 	Training Prec@5 99.750 	Validation Loss 0.4714 	Validation Prec@1 84.750 	Validation Prec@5 99.200 

lr: 0.052522296579613915
TRAINING - Epoch: [490][0/391]	Time 1.302 (1.302)	Data 0.452 (0.452)	Loss 0.1669 (0.1669)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [490][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.1972 (0.2513)	Prec@1 91.406 (91.221)	Prec@5 99.219 (99.791)
TRAINING - Epoch: [490][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.2072 (0.2665)	Prec@1 92.188 (90.924)	Prec@5 99.219 (99.755)
TRAINING - Epoch: [490][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3056 (0.2722)	Prec@1 91.406 (90.583)	Prec@5 100.000 (99.753)
EVALUATING - Epoch: [490][0/79]	Time 0.430 (0.430)	Data 0.396 (0.396)	Loss 0.5341 (0.5341)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:11

 Epoch: 491	Training Loss 0.2743 	Training Prec@1 90.548 	Training Prec@5 99.756 	Validation Loss 0.6534 	Validation Prec@1 79.900 	Validation Prec@5 98.810 

lr: 0.05236477461701983
TRAINING - Epoch: [491][0/391]	Time 1.285 (1.285)	Data 0.438 (0.438)	Loss 0.2004 (0.2004)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [491][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.3194 (0.2615)	Prec@1 88.281 (90.903)	Prec@5 99.219 (99.760)
TRAINING - Epoch: [491][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.2507 (0.2670)	Prec@1 92.188 (90.792)	Prec@5 100.000 (99.728)
TRAINING - Epoch: [491][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2381 (0.2713)	Prec@1 90.625 (90.547)	Prec@5 98.438 (99.714)
EVALUATING - Epoch: [491][0/79]	Time 0.440 (0.440)	Data 0.407 (0.407)	Loss 0.5339 (0.5339)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:45

 Epoch: 492	Training Loss 0.2750 	Training Prec@1 90.434 	Training Prec@5 99.720 	Validation Loss 0.5440 	Validation Prec@1 84.010 	Validation Prec@5 98.990 

lr: 0.05220722912721384
TRAINING - Epoch: [492][0/391]	Time 1.581 (1.581)	Data 0.449 (0.449)	Loss 0.3235 (0.3235)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [492][100/391]	Time 0.112 (0.131)	Data 0.000 (0.005)	Loss 0.1758 (0.2670)	Prec@1 94.531 (90.911)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [492][200/391]	Time 0.107 (0.122)	Data 0.000 (0.003)	Loss 0.3149 (0.2760)	Prec@1 87.500 (90.660)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [492][300/391]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2749 (0.2779)	Prec@1 89.844 (90.581)	Prec@5 99.219 (99.779)
EVALUATING - Epoch: [492][0/79]	Time 0.430 (0.430)	Data 0.394 (0.394)	Loss 0.4213 (0.4213)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:37

 Epoch: 493	Training Loss 0.2787 	Training Prec@1 90.520 	Training Prec@5 99.768 	Validation Loss 0.6772 	Validation Prec@1 80.020 	Validation Prec@5 99.240 

lr: 0.05204966167762067
TRAINING - Epoch: [493][0/391]	Time 1.260 (1.260)	Data 0.344 (0.344)	Loss 0.2729 (0.2729)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [493][100/391]	Time 0.121 (0.131)	Data 0.001 (0.004)	Loss 0.3437 (0.2526)	Prec@1 89.844 (91.368)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [493][200/391]	Time 0.121 (0.126)	Data 0.001 (0.002)	Loss 0.2014 (0.2603)	Prec@1 94.531 (90.986)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [493][300/391]	Time 0.115 (0.124)	Data 0.001 (0.002)	Loss 0.3230 (0.2662)	Prec@1 87.500 (90.778)	Prec@5 99.219 (99.779)
EVALUATING - Epoch: [493][0/79]	Time 0.393 (0.393)	Data 0.355 (0.355)	Loss 0.4626 (0.4626)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
Time cost: 00:50	Time of Finish: 2022-03-24 02:53:24

 Epoch: 494	Training Loss 0.2673 	Training Prec@1 90.788 	Training Prec@5 99.780 	Validation Loss 0.5148 	Validation Prec@1 84.450 	Validation Prec@5 99.290 

lr: 0.0518920738358835
TRAINING - Epoch: [494][0/391]	Time 1.271 (1.271)	Data 0.382 (0.382)	Loss 0.2288 (0.2288)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [494][100/391]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.2725 (0.2778)	Prec@1 89.844 (90.107)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [494][200/391]	Time 0.119 (0.124)	Data 0.001 (0.002)	Loss 0.1772 (0.2745)	Prec@1 93.750 (90.209)	Prec@5 100.000 (99.747)
TRAINING - Epoch: [494][300/391]	Time 0.123 (0.124)	Data 0.001 (0.002)	Loss 0.3079 (0.2774)	Prec@1 89.062 (90.207)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [494][0/79]	Time 0.351 (0.351)	Data 0.319 (0.319)	Loss 0.4687 (0.4687)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:56:49

 Epoch: 495	Training Loss 0.2763 	Training Prec@1 90.306 	Training Prec@5 99.754 	Validation Loss 0.5596 	Validation Prec@1 82.760 	Validation Prec@5 99.360 

lr: 0.05173446716984834
TRAINING - Epoch: [495][0/391]	Time 1.255 (1.255)	Data 0.365 (0.365)	Loss 0.3145 (0.3145)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [495][100/391]	Time 0.126 (0.137)	Data 0.001 (0.004)	Loss 0.3697 (0.2767)	Prec@1 88.281 (90.695)	Prec@5 98.438 (99.706)
TRAINING - Epoch: [495][200/391]	Time 0.125 (0.131)	Data 0.001 (0.002)	Loss 0.2887 (0.2699)	Prec@1 89.062 (90.850)	Prec@5 100.000 (99.755)
TRAINING - Epoch: [495][300/391]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.3005 (0.2710)	Prec@1 89.062 (90.687)	Prec@5 100.000 (99.777)
EVALUATING - Epoch: [495][0/79]	Time 0.377 (0.377)	Data 0.338 (0.338)	Loss 0.4170 (0.4170)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:52	Time of Finish: 2022-03-24 03:09:07

 Epoch: 496	Training Loss 0.2758 	Training Prec@1 90.540 	Training Prec@5 99.756 	Validation Loss 0.5586 	Validation Prec@1 83.080 	Validation Prec@5 99.060 

lr: 0.05157684324754854
TRAINING - Epoch: [496][0/391]	Time 1.251 (1.251)	Data 0.346 (0.346)	Loss 0.2156 (0.2156)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [496][100/391]	Time 0.109 (0.126)	Data 0.000 (0.004)	Loss 0.1721 (0.2679)	Prec@1 95.312 (90.834)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [496][200/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.1591 (0.2683)	Prec@1 93.750 (90.691)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [496][300/391]	Time 0.118 (0.118)	Data 0.000 (0.001)	Loss 0.2213 (0.2656)	Prec@1 92.188 (90.833)	Prec@5 100.000 (99.769)
EVALUATING - Epoch: [496][0/79]	Time 0.458 (0.458)	Data 0.416 (0.416)	Loss 0.4014 (0.4014)	Prec@1 88.281 (88.281)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:35

 Epoch: 497	Training Loss 0.2695 	Training Prec@1 90.710 	Training Prec@5 99.756 	Validation Loss 0.5290 	Validation Prec@1 83.840 	Validation Prec@5 98.860 

lr: 0.051419203637189145
TRAINING - Epoch: [497][0/391]	Time 1.284 (1.284)	Data 0.431 (0.431)	Loss 0.2377 (0.2377)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [497][100/391]	Time 0.118 (0.132)	Data 0.000 (0.005)	Loss 0.3210 (0.2658)	Prec@1 87.500 (90.834)	Prec@5 100.000 (99.698)
TRAINING - Epoch: [497][200/391]	Time 0.116 (0.124)	Data 0.000 (0.003)	Loss 0.1901 (0.2662)	Prec@1 91.406 (90.769)	Prec@5 100.000 (99.736)
TRAINING - Epoch: [497][300/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3220 (0.2693)	Prec@1 89.844 (90.622)	Prec@5 100.000 (99.743)
EVALUATING - Epoch: [497][0/79]	Time 0.476 (0.476)	Data 0.447 (0.447)	Loss 0.4990 (0.4990)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:44:18

 Epoch: 498	Training Loss 0.2675 	Training Prec@1 90.732 	Training Prec@5 99.732 	Validation Loss 0.5176 	Validation Prec@1 83.420 	Validation Prec@5 99.240 

lr: 0.0512615499071312
TRAINING - Epoch: [498][0/391]	Time 1.283 (1.283)	Data 0.420 (0.420)	Loss 0.3293 (0.3293)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [498][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.2625 (0.2629)	Prec@1 92.188 (90.795)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [498][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.4988 (0.2655)	Prec@1 84.375 (90.808)	Prec@5 99.219 (99.720)
TRAINING - Epoch: [498][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.1914 (0.2684)	Prec@1 92.188 (90.783)	Prec@5 100.000 (99.720)
EVALUATING - Epoch: [498][0/79]	Time 0.426 (0.426)	Data 0.383 (0.383)	Loss 0.3599 (0.3599)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:25

 Epoch: 499	Training Loss 0.2681 	Training Prec@1 90.848 	Training Prec@5 99.736 	Validation Loss 0.4879 	Validation Prec@1 84.210 	Validation Prec@5 99.170 

lr: 0.05110388362587631
TRAINING - Epoch: [499][0/391]	Time 1.250 (1.250)	Data 0.355 (0.355)	Loss 0.4306 (0.4306)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [499][100/391]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.2308 (0.2595)	Prec@1 89.844 (90.656)	Prec@5 100.000 (99.768)
TRAINING - Epoch: [499][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3002 (0.2658)	Prec@1 92.969 (90.749)	Prec@5 100.000 (99.740)
TRAINING - Epoch: [499][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.3147 (0.2690)	Prec@1 89.844 (90.687)	Prec@5 99.219 (99.756)
EVALUATING - Epoch: [499][0/79]	Time 0.441 (0.441)	Data 0.403 (0.403)	Loss 0.5354 (0.5354)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:46	Time of Finish: 2022-03-24 02:21:49

 Epoch: 500	Training Loss 0.2673 	Training Prec@1 90.696 	Training Prec@5 99.752 	Validation Loss 0.5396 	Validation Prec@1 83.020 	Validation Prec@5 99.090 

lr: 0.05094620636205093
TRAINING - Epoch: [500][0/391]	Time 1.305 (1.305)	Data 0.444 (0.444)	Loss 0.3027 (0.3027)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [500][100/391]	Time 0.112 (0.128)	Data 0.000 (0.005)	Loss 0.2039 (0.2500)	Prec@1 93.750 (91.306)	Prec@5 99.219 (99.791)
TRAINING - Epoch: [500][200/391]	Time 0.115 (0.122)	Data 0.000 (0.003)	Loss 0.2414 (0.2618)	Prec@1 93.750 (90.955)	Prec@5 99.219 (99.763)
TRAINING - Epoch: [500][300/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.3768 (0.2642)	Prec@1 88.281 (90.853)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [500][0/79]	Time 0.417 (0.417)	Data 0.384 (0.384)	Loss 0.4460 (0.4460)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:47

 Epoch: 501	Training Loss 0.2639 	Training Prec@1 90.778 	Training Prec@5 99.778 	Validation Loss 0.4534 	Validation Prec@1 85.540 	Validation Prec@5 99.390 

lr: 0.05078851968439075
TRAINING - Epoch: [501][0/391]	Time 1.272 (1.272)	Data 0.421 (0.421)	Loss 0.1931 (0.1931)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [501][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.2620 (0.2668)	Prec@1 88.281 (90.679)	Prec@5 99.219 (99.768)
TRAINING - Epoch: [501][200/391]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3364 (0.2718)	Prec@1 86.719 (90.505)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [501][300/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.2890 (0.2710)	Prec@1 92.969 (90.545)	Prec@5 100.000 (99.764)
EVALUATING - Epoch: [501][0/79]	Time 0.416 (0.416)	Data 0.383 (0.383)	Loss 0.5210 (0.5210)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:41:44

 Epoch: 502	Training Loss 0.2703 	Training Prec@1 90.594 	Training Prec@5 99.764 	Validation Loss 0.5130 	Validation Prec@1 83.940 	Validation Prec@5 99.370 

lr: 0.05063082516172517
TRAINING - Epoch: [502][0/391]	Time 1.278 (1.278)	Data 0.417 (0.417)	Loss 0.1660 (0.1660)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [502][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.2482 (0.2654)	Prec@1 91.406 (90.803)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [502][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3375 (0.2662)	Prec@1 84.375 (90.699)	Prec@5 100.000 (99.771)
TRAINING - Epoch: [502][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3839 (0.2687)	Prec@1 89.844 (90.685)	Prec@5 99.219 (99.756)
EVALUATING - Epoch: [502][0/79]	Time 0.451 (0.451)	Data 0.405 (0.405)	Loss 0.5747 (0.5747)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:34

 Epoch: 503	Training Loss 0.2716 	Training Prec@1 90.602 	Training Prec@5 99.756 	Validation Loss 0.6736 	Validation Prec@1 79.720 	Validation Prec@5 98.750 

lr: 0.050473124362961565
TRAINING - Epoch: [503][0/391]	Time 1.258 (1.258)	Data 0.363 (0.363)	Loss 0.3521 (0.3521)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [503][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.4180 (0.2541)	Prec@1 84.375 (91.368)	Prec@5 99.219 (99.776)
TRAINING - Epoch: [503][200/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2218 (0.2590)	Prec@1 91.406 (91.196)	Prec@5 100.000 (99.782)
TRAINING - Epoch: [503][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2637 (0.2642)	Prec@1 92.969 (91.032)	Prec@5 99.219 (99.769)
EVALUATING - Epoch: [503][0/79]	Time 0.437 (0.437)	Data 0.403 (0.403)	Loss 0.4472 (0.4472)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:28

 Epoch: 504	Training Loss 0.2672 	Training Prec@1 90.906 	Training Prec@5 99.770 	Validation Loss 0.5443 	Validation Prec@1 82.690 	Validation Prec@5 98.840 

lr: 0.05031541885706985
TRAINING - Epoch: [504][0/391]	Time 1.308 (1.308)	Data 0.456 (0.456)	Loss 0.1358 (0.1358)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [504][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.2966 (0.2524)	Prec@1 92.188 (91.058)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [504][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.2711 (0.2630)	Prec@1 90.625 (90.920)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [504][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3234 (0.2637)	Prec@1 89.844 (90.898)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [504][0/79]	Time 0.459 (0.459)	Data 0.405 (0.405)	Loss 0.4821 (0.4821)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:07

 Epoch: 505	Training Loss 0.2631 	Training Prec@1 90.862 	Training Prec@5 99.772 	Validation Loss 0.4643 	Validation Prec@1 84.690 	Validation Prec@5 99.330 

lr: 0.050157710213066684
TRAINING - Epoch: [505][0/391]	Time 1.276 (1.276)	Data 0.418 (0.418)	Loss 0.2099 (0.2099)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [505][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.2336 (0.2684)	Prec@1 93.750 (90.424)	Prec@5 98.438 (99.760)
TRAINING - Epoch: [505][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.2559 (0.2715)	Prec@1 92.969 (90.652)	Prec@5 100.000 (99.755)
TRAINING - Epoch: [505][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.3698 (0.2705)	Prec@1 89.062 (90.667)	Prec@5 100.000 (99.769)
EVALUATING - Epoch: [505][0/79]	Time 0.441 (0.441)	Data 0.407 (0.407)	Loss 0.4536 (0.4536)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:57

 Epoch: 506	Training Loss 0.2703 	Training Prec@1 90.696 	Training Prec@5 99.782 	Validation Loss 0.4481 	Validation Prec@1 85.450 	Validation Prec@5 99.240 

lr: 0.04999999999999999
TRAINING - Epoch: [506][0/391]	Time 1.365 (1.365)	Data 0.458 (0.458)	Loss 0.3173 (0.3173)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [506][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.3951 (0.2478)	Prec@1 87.500 (91.143)	Prec@5 99.219 (99.807)
TRAINING - Epoch: [506][200/391]	Time 0.119 (0.119)	Data 0.000 (0.003)	Loss 0.2352 (0.2514)	Prec@1 89.844 (90.913)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [506][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2580 (0.2570)	Prec@1 88.281 (90.752)	Prec@5 100.000 (99.800)
EVALUATING - Epoch: [506][0/79]	Time 0.439 (0.439)	Data 0.405 (0.405)	Loss 0.4619 (0.4619)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:17

 Epoch: 507	Training Loss 0.2574 	Training Prec@1 90.836 	Training Prec@5 99.792 	Validation Loss 0.5405 	Validation Prec@1 83.170 	Validation Prec@5 98.610 

lr: 0.0498422897869333
TRAINING - Epoch: [507][0/391]	Time 1.218 (1.218)	Data 0.375 (0.375)	Loss 0.1947 (0.1947)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [507][100/391]	Time 0.107 (0.121)	Data 0.000 (0.004)	Loss 0.1741 (0.2463)	Prec@1 93.750 (91.159)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [507][200/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3318 (0.2579)	Prec@1 86.719 (90.862)	Prec@5 100.000 (99.829)
TRAINING - Epoch: [507][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.4497 (0.2629)	Prec@1 86.719 (90.783)	Prec@5 99.219 (99.816)
EVALUATING - Epoch: [507][0/79]	Time 0.441 (0.441)	Data 0.415 (0.415)	Loss 0.4015 (0.4015)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:43

 Epoch: 508	Training Loss 0.2640 	Training Prec@1 90.722 	Training Prec@5 99.808 	Validation Loss 0.5043 	Validation Prec@1 84.400 	Validation Prec@5 99.280 

lr: 0.04968458114293013
TRAINING - Epoch: [508][0/391]	Time 1.255 (1.255)	Data 0.360 (0.360)	Loss 0.2963 (0.2963)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [508][100/391]	Time 0.112 (0.127)	Data 0.000 (0.004)	Loss 0.3537 (0.2451)	Prec@1 85.938 (91.290)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [508][200/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2909 (0.2539)	Prec@1 88.281 (91.037)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [508][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3250 (0.2565)	Prec@1 88.281 (90.983)	Prec@5 100.000 (99.842)
EVALUATING - Epoch: [508][0/79]	Time 0.447 (0.447)	Data 0.403 (0.403)	Loss 0.5737 (0.5737)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:15

 Epoch: 509	Training Loss 0.2599 	Training Prec@1 90.928 	Training Prec@5 99.824 	Validation Loss 0.5464 	Validation Prec@1 82.030 	Validation Prec@5 99.190 

lr: 0.049526875637038406
TRAINING - Epoch: [509][0/391]	Time 1.269 (1.269)	Data 0.406 (0.406)	Loss 0.3800 (0.3800)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [509][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.2492 (0.2599)	Prec@1 92.969 (90.965)	Prec@5 100.000 (99.729)
TRAINING - Epoch: [509][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2036 (0.2579)	Prec@1 92.188 (90.986)	Prec@5 100.000 (99.755)
TRAINING - Epoch: [509][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3238 (0.2627)	Prec@1 87.500 (90.796)	Prec@5 100.000 (99.759)
EVALUATING - Epoch: [509][0/79]	Time 0.422 (0.422)	Data 0.389 (0.389)	Loss 0.4476 (0.4476)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:04

 Epoch: 510	Training Loss 0.2636 	Training Prec@1 90.784 	Training Prec@5 99.746 	Validation Loss 0.5120 	Validation Prec@1 84.330 	Validation Prec@5 99.170 

lr: 0.049369174838274806
TRAINING - Epoch: [510][0/391]	Time 1.352 (1.352)	Data 0.490 (0.490)	Loss 0.1679 (0.1679)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [510][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.2402 (0.2454)	Prec@1 91.406 (91.399)	Prec@5 99.219 (99.807)
TRAINING - Epoch: [510][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.3675 (0.2536)	Prec@1 89.844 (91.103)	Prec@5 99.219 (99.813)
TRAINING - Epoch: [510][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.2849 (0.2627)	Prec@1 89.844 (90.796)	Prec@5 97.656 (99.772)
EVALUATING - Epoch: [510][0/79]	Time 0.434 (0.434)	Data 0.392 (0.392)	Loss 0.4878 (0.4878)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:37

 Epoch: 511	Training Loss 0.2606 	Training Prec@1 90.864 	Training Prec@5 99.782 	Validation Loss 0.5254 	Validation Prec@1 84.250 	Validation Prec@5 98.930 

lr: 0.049211480315609214
TRAINING - Epoch: [511][0/391]	Time 1.308 (1.308)	Data 0.455 (0.455)	Loss 0.1949 (0.1949)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [511][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.1983 (0.2469)	Prec@1 92.969 (91.484)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [511][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.1950 (0.2459)	Prec@1 92.188 (91.344)	Prec@5 100.000 (99.848)
TRAINING - Epoch: [511][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3019 (0.2558)	Prec@1 91.406 (91.126)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [511][0/79]	Time 0.420 (0.420)	Data 0.379 (0.379)	Loss 0.5090 (0.5090)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:29

 Epoch: 512	Training Loss 0.2592 	Training Prec@1 91.004 	Training Prec@5 99.798 	Validation Loss 0.4384 	Validation Prec@1 85.480 	Validation Prec@5 99.420 

lr: 0.04905379363794904
TRAINING - Epoch: [512][0/391]	Time 1.289 (1.289)	Data 0.439 (0.439)	Loss 0.1744 (0.1744)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [512][100/391]	Time 0.110 (0.128)	Data 0.000 (0.005)	Loss 0.1938 (0.2550)	Prec@1 92.188 (91.066)	Prec@5 99.219 (99.799)
TRAINING - Epoch: [512][200/391]	Time 0.111 (0.122)	Data 0.000 (0.003)	Loss 0.2660 (0.2567)	Prec@1 88.281 (91.088)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [512][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.1978 (0.2591)	Prec@1 92.188 (91.103)	Prec@5 100.000 (99.777)
EVALUATING - Epoch: [512][0/79]	Time 0.474 (0.474)	Data 0.435 (0.435)	Loss 0.4784 (0.4784)	Prec@1 84.375 (84.375)	Prec@5 97.656 (97.656)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:26

 Epoch: 513	Training Loss 0.2643 	Training Prec@1 90.890 	Training Prec@5 99.754 	Validation Loss 0.4828 	Validation Prec@1 84.810 	Validation Prec@5 99.200 

lr: 0.04889611637412365
TRAINING - Epoch: [513][0/391]	Time 1.290 (1.290)	Data 0.432 (0.432)	Loss 0.3234 (0.3234)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [513][100/391]	Time 0.112 (0.127)	Data 0.000 (0.005)	Loss 0.1862 (0.2520)	Prec@1 91.406 (91.066)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [513][200/391]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.2589 (0.2544)	Prec@1 92.188 (91.138)	Prec@5 100.000 (99.810)
TRAINING - Epoch: [513][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2216 (0.2571)	Prec@1 92.969 (90.988)	Prec@5 100.000 (99.787)
EVALUATING - Epoch: [513][0/79]	Time 0.418 (0.418)	Data 0.381 (0.381)	Loss 0.6399 (0.6399)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:52

 Epoch: 514	Training Loss 0.2599 	Training Prec@1 90.916 	Training Prec@5 99.786 	Validation Loss 0.6708 	Validation Prec@1 80.950 	Validation Prec@5 98.260 

lr: 0.048738450092868764
TRAINING - Epoch: [514][0/391]	Time 1.311 (1.311)	Data 0.453 (0.453)	Loss 0.2505 (0.2505)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [514][100/391]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.1497 (0.2549)	Prec@1 95.312 (90.718)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [514][200/391]	Time 0.123 (0.122)	Data 0.000 (0.003)	Loss 0.2455 (0.2605)	Prec@1 92.969 (90.668)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [514][300/391]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2057 (0.2614)	Prec@1 92.188 (90.682)	Prec@5 100.000 (99.842)
EVALUATING - Epoch: [514][0/79]	Time 0.447 (0.447)	Data 0.410 (0.410)	Loss 0.4327 (0.4327)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:22

 Epoch: 515	Training Loss 0.2607 	Training Prec@1 90.830 	Training Prec@5 99.810 	Validation Loss 0.5099 	Validation Prec@1 83.920 	Validation Prec@5 99.300 

lr: 0.048580796362810846
TRAINING - Epoch: [515][0/391]	Time 1.255 (1.255)	Data 0.419 (0.419)	Loss 0.3217 (0.3217)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [515][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.3239 (0.2478)	Prec@1 85.938 (91.344)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [515][200/391]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.4556 (0.2496)	Prec@1 83.594 (91.321)	Prec@5 99.219 (99.841)
TRAINING - Epoch: [515][300/391]	Time 0.114 (0.113)	Data 0.000 (0.002)	Loss 0.3919 (0.2523)	Prec@1 88.281 (91.222)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [515][0/79]	Time 0.446 (0.446)	Data 0.409 (0.409)	Loss 0.3251 (0.3251)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:11

 Epoch: 516	Training Loss 0.2576 	Training Prec@1 91.056 	Training Prec@5 99.830 	Validation Loss 0.4501 	Validation Prec@1 85.360 	Validation Prec@5 99.380 

lr: 0.04842315675245142
TRAINING - Epoch: [516][0/391]	Time 1.299 (1.299)	Data 0.446 (0.446)	Loss 0.2541 (0.2541)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [516][100/391]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.2493 (0.2510)	Prec@1 93.750 (91.337)	Prec@5 100.000 (99.776)
TRAINING - Epoch: [516][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.3153 (0.2653)	Prec@1 89.844 (90.847)	Prec@5 99.219 (99.747)
TRAINING - Epoch: [516][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2298 (0.2643)	Prec@1 91.406 (90.918)	Prec@5 100.000 (99.743)
EVALUATING - Epoch: [516][0/79]	Time 0.452 (0.452)	Data 0.409 (0.409)	Loss 0.5883 (0.5883)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:55

 Epoch: 517	Training Loss 0.2609 	Training Prec@1 91.050 	Training Prec@5 99.746 	Validation Loss 0.5920 	Validation Prec@1 82.310 	Validation Prec@5 99.100 

lr: 0.04826553283015165
TRAINING - Epoch: [517][0/391]	Time 1.320 (1.320)	Data 0.456 (0.456)	Loss 0.2233 (0.2233)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [517][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.2829 (0.2513)	Prec@1 89.062 (91.399)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [517][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1533 (0.2555)	Prec@1 95.312 (91.142)	Prec@5 100.000 (99.790)
TRAINING - Epoch: [517][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2393 (0.2518)	Prec@1 89.844 (91.225)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [517][0/79]	Time 0.443 (0.443)	Data 0.404 (0.404)	Loss 0.5891 (0.5891)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:30

 Epoch: 518	Training Loss 0.2520 	Training Prec@1 91.276 	Training Prec@5 99.804 	Validation Loss 0.4815 	Validation Prec@1 85.100 	Validation Prec@5 99.030 

lr: 0.04810792616411649
TRAINING - Epoch: [518][0/391]	Time 1.275 (1.275)	Data 0.426 (0.426)	Loss 0.2105 (0.2105)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [518][100/391]	Time 0.112 (0.125)	Data 0.000 (0.005)	Loss 0.2905 (0.2397)	Prec@1 86.719 (91.677)	Prec@5 99.219 (99.830)
TRAINING - Epoch: [518][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.2429 (0.2473)	Prec@1 92.188 (91.352)	Prec@5 100.000 (99.790)
TRAINING - Epoch: [518][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2500 (0.2501)	Prec@1 90.625 (91.266)	Prec@5 99.219 (99.798)
EVALUATING - Epoch: [518][0/79]	Time 0.437 (0.437)	Data 0.408 (0.408)	Loss 0.4746 (0.4746)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:56

 Epoch: 519	Training Loss 0.2547 	Training Prec@1 91.052 	Training Prec@5 99.800 	Validation Loss 0.6057 	Validation Prec@1 82.850 	Validation Prec@5 99.120 

lr: 0.047950338322379306
TRAINING - Epoch: [519][0/391]	Time 1.279 (1.279)	Data 0.412 (0.412)	Loss 0.2400 (0.2400)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [519][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.2339 (0.2524)	Prec@1 92.188 (91.368)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [519][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.2982 (0.2522)	Prec@1 88.281 (91.305)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [519][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2905 (0.2547)	Prec@1 89.844 (91.240)	Prec@5 100.000 (99.782)
EVALUATING - Epoch: [519][0/79]	Time 0.436 (0.436)	Data 0.402 (0.402)	Loss 0.4489 (0.4489)	Prec@1 88.281 (88.281)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:31

 Epoch: 520	Training Loss 0.2573 	Training Prec@1 91.136 	Training Prec@5 99.782 	Validation Loss 0.4925 	Validation Prec@1 84.060 	Validation Prec@5 99.000 

lr: 0.04779277087278615
TRAINING - Epoch: [520][0/391]	Time 1.289 (1.289)	Data 0.439 (0.439)	Loss 0.2609 (0.2609)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [520][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.1787 (0.2543)	Prec@1 92.188 (91.213)	Prec@5 100.000 (99.783)
TRAINING - Epoch: [520][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.2297 (0.2558)	Prec@1 91.406 (91.064)	Prec@5 100.000 (99.794)
TRAINING - Epoch: [520][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.1411 (0.2511)	Prec@1 95.312 (91.251)	Prec@5 100.000 (99.808)
EVALUATING - Epoch: [520][0/79]	Time 0.407 (0.407)	Data 0.375 (0.375)	Loss 0.3767 (0.3767)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:34

 Epoch: 521	Training Loss 0.2541 	Training Prec@1 91.224 	Training Prec@5 99.802 	Validation Loss 0.5196 	Validation Prec@1 84.180 	Validation Prec@5 99.340 

lr: 0.047635225382980165
TRAINING - Epoch: [521][0/391]	Time 1.265 (1.265)	Data 0.411 (0.411)	Loss 0.2997 (0.2997)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [521][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.1912 (0.2519)	Prec@1 92.969 (91.391)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [521][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3432 (0.2503)	Prec@1 88.281 (91.457)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [521][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.2501 (0.2548)	Prec@1 91.406 (91.305)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [521][0/79]	Time 0.426 (0.426)	Data 0.392 (0.392)	Loss 0.4338 (0.4338)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:02

 Epoch: 522	Training Loss 0.2563 	Training Prec@1 91.222 	Training Prec@5 99.768 	Validation Loss 0.5495 	Validation Prec@1 83.070 	Validation Prec@5 98.980 

lr: 0.04747770342038608
TRAINING - Epoch: [522][0/391]	Time 1.272 (1.272)	Data 0.417 (0.417)	Loss 0.2406 (0.2406)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [522][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.2605 (0.2400)	Prec@1 89.844 (91.607)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [522][200/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2375 (0.2512)	Prec@1 90.625 (91.208)	Prec@5 100.000 (99.802)
TRAINING - Epoch: [522][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2091 (0.2533)	Prec@1 91.406 (91.157)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [522][0/79]	Time 0.426 (0.426)	Data 0.384 (0.384)	Loss 0.5989 (0.5989)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:16

 Epoch: 523	Training Loss 0.2537 	Training Prec@1 91.078 	Training Prec@5 99.816 	Validation Loss 0.5421 	Validation Prec@1 83.690 	Validation Prec@5 99.180 

lr: 0.04732020655219447
TRAINING - Epoch: [523][0/391]	Time 1.268 (1.268)	Data 0.417 (0.417)	Loss 0.2339 (0.2339)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [523][100/391]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.1406 (0.2561)	Prec@1 94.531 (91.151)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [523][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.2431 (0.2464)	Prec@1 91.406 (91.531)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [523][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.3239 (0.2513)	Prec@1 89.844 (91.339)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [523][0/79]	Time 0.443 (0.443)	Data 0.400 (0.400)	Loss 0.4836 (0.4836)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:21:58

 Epoch: 524	Training Loss 0.2518 	Training Prec@1 91.296 	Training Prec@5 99.814 	Validation Loss 0.5928 	Validation Prec@1 82.010 	Validation Prec@5 98.920 

lr: 0.04716273634534631
TRAINING - Epoch: [524][0/391]	Time 1.571 (1.571)	Data 0.419 (0.419)	Loss 0.2527 (0.2527)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [524][100/391]	Time 0.112 (0.130)	Data 0.000 (0.004)	Loss 0.2202 (0.2404)	Prec@1 90.625 (91.747)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [524][200/391]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.2192 (0.2401)	Prec@1 92.969 (91.682)	Prec@5 100.000 (99.802)
TRAINING - Epoch: [524][300/391]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1465 (0.2458)	Prec@1 95.312 (91.461)	Prec@5 100.000 (99.805)
EVALUATING - Epoch: [524][0/79]	Time 0.448 (0.448)	Data 0.412 (0.412)	Loss 0.4485 (0.4485)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:48:23

 Epoch: 525	Training Loss 0.2486 	Training Prec@1 91.396 	Training Prec@5 99.792 	Validation Loss 0.4710 	Validation Prec@1 84.660 	Validation Prec@5 99.210 

lr: 0.0470052943665173
TRAINING - Epoch: [525][0/391]	Time 1.303 (1.303)	Data 0.450 (0.450)	Loss 0.1726 (0.1726)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [525][100/391]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.2740 (0.2533)	Prec@1 90.625 (91.190)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [525][200/391]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.3224 (0.2599)	Prec@1 89.062 (91.060)	Prec@5 100.000 (99.798)
TRAINING - Epoch: [525][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2368 (0.2582)	Prec@1 91.406 (91.126)	Prec@5 100.000 (99.785)
EVALUATING - Epoch: [525][0/79]	Time 0.486 (0.486)	Data 0.451 (0.451)	Loss 0.3957 (0.3957)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:39:30

 Epoch: 526	Training Loss 0.2571 	Training Prec@1 91.158 	Training Prec@5 99.786 	Validation Loss 0.4732 	Validation Prec@1 84.720 	Validation Prec@5 99.020 

lr: 0.04684788218210228
TRAINING - Epoch: [526][0/391]	Time 1.310 (1.310)	Data 0.446 (0.446)	Loss 0.2687 (0.2687)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [526][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.1368 (0.2409)	Prec@1 93.750 (91.569)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [526][200/391]	Time 0.109 (0.119)	Data 0.000 (0.003)	Loss 0.2704 (0.2442)	Prec@1 92.188 (91.476)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [526][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1418 (0.2488)	Prec@1 96.875 (91.409)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [526][0/79]	Time 0.439 (0.439)	Data 0.401 (0.401)	Loss 0.5319 (0.5319)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:39

 Epoch: 527	Training Loss 0.2529 	Training Prec@1 91.256 	Training Prec@5 99.810 	Validation Loss 0.4598 	Validation Prec@1 85.080 	Validation Prec@5 99.340 

lr: 0.046690501358199674
TRAINING - Epoch: [527][0/391]	Time 1.272 (1.272)	Data 0.417 (0.417)	Loss 0.1873 (0.1873)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [527][100/391]	Time 0.111 (0.122)	Data 0.000 (0.004)	Loss 0.2230 (0.2375)	Prec@1 89.062 (91.569)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [527][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.2243 (0.2373)	Prec@1 92.969 (91.593)	Prec@5 99.219 (99.821)
TRAINING - Epoch: [527][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2834 (0.2488)	Prec@1 92.969 (91.287)	Prec@5 99.219 (99.805)
EVALUATING - Epoch: [527][0/79]	Time 0.433 (0.433)	Data 0.400 (0.400)	Loss 0.4647 (0.4647)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:22

 Epoch: 528	Training Loss 0.2502 	Training Prec@1 91.286 	Training Prec@5 99.802 	Validation Loss 0.5294 	Validation Prec@1 83.180 	Validation Prec@5 99.180 

lr: 0.04653315346059594
TRAINING - Epoch: [528][0/391]	Time 1.268 (1.268)	Data 0.414 (0.414)	Loss 0.2591 (0.2591)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [528][100/391]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.1593 (0.2385)	Prec@1 94.531 (91.252)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [528][200/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3785 (0.2438)	Prec@1 88.281 (91.313)	Prec@5 97.656 (99.817)
TRAINING - Epoch: [528][300/391]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.2150 (0.2486)	Prec@1 93.750 (91.230)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [528][0/79]	Time 0.406 (0.406)	Data 0.380 (0.380)	Loss 0.4185 (0.4185)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:27

 Epoch: 529	Training Loss 0.2536 	Training Prec@1 91.092 	Training Prec@5 99.800 	Validation Loss 0.5303 	Validation Prec@1 83.320 	Validation Prec@5 99.220 

lr: 0.04637584005474987
TRAINING - Epoch: [529][0/391]	Time 1.310 (1.310)	Data 0.431 (0.431)	Loss 0.2762 (0.2762)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [529][100/391]	Time 0.115 (0.125)	Data 0.000 (0.005)	Loss 0.2335 (0.2333)	Prec@1 91.406 (91.723)	Prec@5 99.219 (99.814)
TRAINING - Epoch: [529][200/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2643 (0.2455)	Prec@1 88.281 (91.484)	Prec@5 99.219 (99.759)
TRAINING - Epoch: [529][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3882 (0.2441)	Prec@1 86.719 (91.471)	Prec@5 100.000 (99.782)
EVALUATING - Epoch: [529][0/79]	Time 0.434 (0.434)	Data 0.389 (0.389)	Loss 0.7907 (0.7907)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:51

 Epoch: 530	Training Loss 0.2459 	Training Prec@1 91.414 	Training Prec@5 99.772 	Validation Loss 0.6912 	Validation Prec@1 79.920 	Validation Prec@5 98.630 

lr: 0.04621856270577719
TRAINING - Epoch: [530][0/391]	Time 1.290 (1.290)	Data 0.415 (0.415)	Loss 0.2642 (0.2642)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [530][100/391]	Time 0.110 (0.125)	Data 0.000 (0.004)	Loss 0.2133 (0.2435)	Prec@1 90.625 (91.723)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [530][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2442 (0.2455)	Prec@1 89.062 (91.535)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [530][300/391]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.2764 (0.2499)	Prec@1 89.062 (91.305)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [530][0/79]	Time 0.416 (0.416)	Data 0.379 (0.379)	Loss 0.6135 (0.6135)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:21

 Epoch: 531	Training Loss 0.2519 	Training Prec@1 91.226 	Training Prec@5 99.818 	Validation Loss 0.6217 	Validation Prec@1 81.720 	Validation Prec@5 98.530 

lr: 0.04606132297843481
TRAINING - Epoch: [531][0/391]	Time 1.279 (1.279)	Data 0.448 (0.448)	Loss 0.2518 (0.2518)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [531][100/391]	Time 0.104 (0.115)	Data 0.000 (0.005)	Loss 0.2976 (0.2401)	Prec@1 89.844 (91.739)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [531][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2107 (0.2430)	Prec@1 92.969 (91.535)	Prec@5 100.000 (99.821)
TRAINING - Epoch: [531][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.2029 (0.2423)	Prec@1 92.188 (91.513)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [531][0/79]	Time 0.424 (0.424)	Data 0.395 (0.395)	Loss 0.4691 (0.4691)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:44	Time of Finish: 2022-03-24 02:02:56

 Epoch: 532	Training Loss 0.2462 	Training Prec@1 91.380 	Training Prec@5 99.798 	Validation Loss 0.5209 	Validation Prec@1 84.140 	Validation Prec@5 99.170 

lr: 0.045904122437105385
TRAINING - Epoch: [532][0/391]	Time 1.273 (1.273)	Data 0.421 (0.421)	Loss 0.2130 (0.2130)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [532][100/391]	Time 0.110 (0.126)	Data 0.001 (0.005)	Loss 0.2220 (0.2415)	Prec@1 90.625 (91.414)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [532][200/391]	Time 0.108 (0.119)	Data 0.000 (0.002)	Loss 0.1832 (0.2401)	Prec@1 95.312 (91.550)	Prec@5 100.000 (99.817)
TRAINING - Epoch: [532][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1871 (0.2441)	Prec@1 93.750 (91.435)	Prec@5 100.000 (99.816)
EVALUATING - Epoch: [532][0/79]	Time 0.449 (0.449)	Data 0.407 (0.407)	Loss 0.4889 (0.4889)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 533	Training Loss 0.2472 	Training Prec@1 91.318 	Training Prec@5 99.804 	Validation Loss 0.5533 	Validation Prec@1 83.140 	Validation Prec@5 99.050 

lr: 0.045746962645781736
TRAINING - Epoch: [533][0/391]	Time 1.316 (1.316)	Data 0.425 (0.425)	Loss 0.3274 (0.3274)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [533][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.1780 (0.2441)	Prec@1 93.750 (91.522)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [533][200/391]	Time 0.111 (0.121)	Data 0.000 (0.003)	Loss 0.1746 (0.2436)	Prec@1 95.312 (91.523)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [533][300/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.2962 (0.2433)	Prec@1 89.062 (91.552)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [533][0/79]	Time 0.459 (0.459)	Data 0.427 (0.427)	Loss 0.3420 (0.3420)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:27

 Epoch: 534	Training Loss 0.2430 	Training Prec@1 91.534 	Training Prec@5 99.814 	Validation Loss 0.4524 	Validation Prec@1 85.380 	Validation Prec@5 99.340 

lr: 0.04558984516805119
TRAINING - Epoch: [534][0/391]	Time 1.292 (1.292)	Data 0.444 (0.444)	Loss 0.1691 (0.1691)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [534][100/391]	Time 0.111 (0.122)	Data 0.000 (0.005)	Loss 0.2753 (0.2354)	Prec@1 90.625 (91.770)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [534][200/391]	Time 0.112 (0.117)	Data 0.000 (0.003)	Loss 0.2227 (0.2357)	Prec@1 92.969 (91.647)	Prec@5 100.000 (99.817)
TRAINING - Epoch: [534][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.2032 (0.2411)	Prec@1 92.969 (91.461)	Prec@5 100.000 (99.811)
EVALUATING - Epoch: [534][0/79]	Time 0.441 (0.441)	Data 0.406 (0.406)	Loss 0.4924 (0.4924)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:53

 Epoch: 535	Training Loss 0.2447 	Training Prec@1 91.348 	Training Prec@5 99.810 	Validation Loss 0.5342 	Validation Prec@1 83.900 	Validation Prec@5 99.070 

lr: 0.04543277156708015
TRAINING - Epoch: [535][0/391]	Time 1.288 (1.288)	Data 0.433 (0.433)	Loss 0.2407 (0.2407)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [535][100/391]	Time 0.111 (0.122)	Data 0.000 (0.005)	Loss 0.1865 (0.2364)	Prec@1 92.188 (91.863)	Prec@5 99.219 (99.861)
TRAINING - Epoch: [535][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.4060 (0.2432)	Prec@1 85.156 (91.546)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [535][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.2409 (0.2481)	Prec@1 92.188 (91.474)	Prec@5 100.000 (99.836)
EVALUATING - Epoch: [535][0/79]	Time 0.435 (0.435)	Data 0.390 (0.390)	Loss 0.4606 (0.4606)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:09

 Epoch: 536	Training Loss 0.2513 	Training Prec@1 91.324 	Training Prec@5 99.828 	Validation Loss 0.5018 	Validation Prec@1 85.350 	Validation Prec@5 99.200 

lr: 0.04527574340559845
TRAINING - Epoch: [536][0/391]	Time 1.281 (1.281)	Data 0.432 (0.432)	Loss 0.2813 (0.2813)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [536][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.3386 (0.2363)	Prec@1 87.500 (91.708)	Prec@5 100.000 (99.791)
TRAINING - Epoch: [536][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3249 (0.2435)	Prec@1 88.281 (91.418)	Prec@5 100.000 (99.813)
TRAINING - Epoch: [536][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.1431 (0.2421)	Prec@1 93.750 (91.484)	Prec@5 100.000 (99.813)
EVALUATING - Epoch: [536][0/79]	Time 0.489 (0.489)	Data 0.452 (0.452)	Loss 0.3372 (0.3372)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:07

 Epoch: 537	Training Loss 0.2448 	Training Prec@1 91.352 	Training Prec@5 99.828 	Validation Loss 0.4341 	Validation Prec@1 85.700 	Validation Prec@5 99.240 

lr: 0.04511876224588388
TRAINING - Epoch: [537][0/391]	Time 1.275 (1.275)	Data 0.424 (0.424)	Loss 0.1836 (0.1836)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [537][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.2601 (0.2377)	Prec@1 92.969 (91.925)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [537][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.3148 (0.2386)	Prec@1 89.844 (91.709)	Prec@5 99.219 (99.806)
TRAINING - Epoch: [537][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3019 (0.2406)	Prec@1 89.844 (91.666)	Prec@5 100.000 (99.774)
EVALUATING - Epoch: [537][0/79]	Time 0.453 (0.453)	Data 0.416 (0.416)	Loss 0.5337 (0.5337)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:41

 Epoch: 538	Training Loss 0.2410 	Training Prec@1 91.542 	Training Prec@5 99.778 	Validation Loss 0.6034 	Validation Prec@1 81.920 	Validation Prec@5 99.080 

lr: 0.0449618296497466
TRAINING - Epoch: [538][0/391]	Time 1.296 (1.296)	Data 0.435 (0.435)	Loss 0.1693 (0.1693)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [538][100/391]	Time 0.117 (0.128)	Data 0.000 (0.005)	Loss 0.1690 (0.2389)	Prec@1 92.969 (91.731)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [538][200/391]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.1637 (0.2407)	Prec@1 95.312 (91.527)	Prec@5 100.000 (99.810)
TRAINING - Epoch: [538][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1915 (0.2440)	Prec@1 91.406 (91.430)	Prec@5 100.000 (99.805)
EVALUATING - Epoch: [538][0/79]	Time 0.440 (0.440)	Data 0.401 (0.401)	Loss 0.3722 (0.3722)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:41:16

 Epoch: 539	Training Loss 0.2453 	Training Prec@1 91.392 	Training Prec@5 99.814 	Validation Loss 0.5075 	Validation Prec@1 84.150 	Validation Prec@5 99.230 

lr: 0.04480494717851359
TRAINING - Epoch: [539][0/391]	Time 1.304 (1.304)	Data 0.417 (0.417)	Loss 0.2315 (0.2315)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [539][100/391]	Time 0.116 (0.128)	Data 0.000 (0.004)	Loss 0.2510 (0.2357)	Prec@1 92.188 (92.141)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [539][200/391]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1815 (0.2372)	Prec@1 94.531 (91.873)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [539][300/391]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2047 (0.2381)	Prec@1 92.188 (91.783)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [539][0/79]	Time 0.411 (0.411)	Data 0.383 (0.383)	Loss 0.5164 (0.5164)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:49	Time of Finish: 2022-03-24 02:43:32

 Epoch: 540	Training Loss 0.2399 	Training Prec@1 91.760 	Training Prec@5 99.822 	Validation Loss 0.5653 	Validation Prec@1 81.860 	Validation Prec@5 98.890 

lr: 0.04464811639301314
TRAINING - Epoch: [540][0/391]	Time 1.307 (1.307)	Data 0.440 (0.440)	Loss 0.2153 (0.2153)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [540][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.2208 (0.2257)	Prec@1 92.188 (92.095)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [540][200/391]	Time 0.112 (0.122)	Data 0.000 (0.003)	Loss 0.1695 (0.2316)	Prec@1 93.750 (91.989)	Prec@5 100.000 (99.825)
TRAINING - Epoch: [540][300/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.3343 (0.2395)	Prec@1 86.719 (91.718)	Prec@5 99.219 (99.834)
EVALUATING - Epoch: [540][0/79]	Time 0.427 (0.427)	Data 0.393 (0.393)	Loss 0.2901 (0.2901)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:38:05

 Epoch: 541	Training Loss 0.2386 	Training Prec@1 91.732 	Training Prec@5 99.838 	Validation Loss 0.4384 	Validation Prec@1 85.840 	Validation Prec@5 99.440 

lr: 0.044491338853559353
TRAINING - Epoch: [541][0/391]	Time 1.291 (1.291)	Data 0.435 (0.435)	Loss 0.2674 (0.2674)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [541][100/391]	Time 0.117 (0.126)	Data 0.000 (0.005)	Loss 0.2176 (0.2378)	Prec@1 91.406 (91.662)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [541][200/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2989 (0.2345)	Prec@1 85.938 (91.795)	Prec@5 99.219 (99.817)
TRAINING - Epoch: [541][300/391]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1582 (0.2402)	Prec@1 96.094 (91.648)	Prec@5 100.000 (99.787)
EVALUATING - Epoch: [541][0/79]	Time 0.453 (0.453)	Data 0.413 (0.413)	Loss 0.5154 (0.5154)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:33

 Epoch: 542	Training Loss 0.2410 	Training Prec@1 91.610 	Training Prec@5 99.800 	Validation Loss 0.5505 	Validation Prec@1 83.450 	Validation Prec@5 99.140 

lr: 0.04433461611993652
TRAINING - Epoch: [542][0/391]	Time 1.312 (1.312)	Data 0.442 (0.442)	Loss 0.2314 (0.2314)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [542][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.3180 (0.2429)	Prec@1 89.844 (91.275)	Prec@5 100.000 (99.760)
TRAINING - Epoch: [542][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.2242 (0.2381)	Prec@1 89.844 (91.639)	Prec@5 100.000 (99.775)
TRAINING - Epoch: [542][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.2315 (0.2386)	Prec@1 91.406 (91.642)	Prec@5 100.000 (99.798)
EVALUATING - Epoch: [542][0/79]	Time 0.430 (0.430)	Data 0.393 (0.393)	Loss 0.4209 (0.4209)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:57

 Epoch: 543	Training Loss 0.2431 	Training Prec@1 91.528 	Training Prec@5 99.784 	Validation Loss 0.4761 	Validation Prec@1 84.950 	Validation Prec@5 99.340 

lr: 0.044177949751383734
TRAINING - Epoch: [543][0/391]	Time 1.284 (1.284)	Data 0.377 (0.377)	Loss 0.2621 (0.2621)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [543][100/391]	Time 0.112 (0.130)	Data 0.000 (0.004)	Loss 0.2765 (0.2330)	Prec@1 89.844 (91.963)	Prec@5 99.219 (99.853)
TRAINING - Epoch: [543][200/391]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.2173 (0.2356)	Prec@1 92.188 (91.978)	Prec@5 100.000 (99.806)
TRAINING - Epoch: [543][300/391]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1458 (0.2372)	Prec@1 96.094 (91.868)	Prec@5 100.000 (99.824)
EVALUATING - Epoch: [543][0/79]	Time 0.450 (0.450)	Data 0.414 (0.414)	Loss 0.4353 (0.4353)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:44:52

 Epoch: 544	Training Loss 0.2376 	Training Prec@1 91.838 	Training Prec@5 99.824 	Validation Loss 0.4365 	Validation Prec@1 85.780 	Validation Prec@5 99.510 

lr: 0.044021341306579274
TRAINING - Epoch: [544][0/391]	Time 1.274 (1.274)	Data 0.411 (0.411)	Loss 0.3181 (0.3181)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [544][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.2056 (0.2221)	Prec@1 89.844 (92.342)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [544][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.2414 (0.2276)	Prec@1 89.844 (92.036)	Prec@5 100.000 (99.848)
TRAINING - Epoch: [544][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.1509 (0.2286)	Prec@1 95.312 (92.050)	Prec@5 100.000 (99.847)
EVALUATING - Epoch: [544][0/79]	Time 0.435 (0.435)	Data 0.409 (0.409)	Loss 0.3527 (0.3527)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:53

 Epoch: 545	Training Loss 0.2347 	Training Prec@1 91.822 	Training Prec@5 99.838 	Validation Loss 0.4698 	Validation Prec@1 84.800 	Validation Prec@5 99.400 

lr: 0.04386479234362513
TRAINING - Epoch: [545][0/391]	Time 1.310 (1.310)	Data 0.422 (0.422)	Loss 0.1757 (0.1757)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [545][100/391]	Time 0.112 (0.122)	Data 0.000 (0.005)	Loss 0.1838 (0.2276)	Prec@1 96.094 (92.218)	Prec@5 100.000 (99.822)
TRAINING - Epoch: [545][200/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.1529 (0.2302)	Prec@1 95.312 (92.048)	Prec@5 99.219 (99.821)
TRAINING - Epoch: [545][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.2798 (0.2329)	Prec@1 91.406 (92.011)	Prec@5 100.000 (99.808)
EVALUATING - Epoch: [545][0/79]	Time 0.438 (0.438)	Data 0.410 (0.410)	Loss 0.4840 (0.4840)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:30

 Epoch: 546	Training Loss 0.2362 	Training Prec@1 91.898 	Training Prec@5 99.804 	Validation Loss 0.4976 	Validation Prec@1 84.530 	Validation Prec@5 99.310 

lr: 0.043708304420031534
TRAINING - Epoch: [546][0/391]	Time 1.264 (1.264)	Data 0.409 (0.409)	Loss 0.1377 (0.1377)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [546][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.3027 (0.2340)	Prec@1 88.281 (91.584)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [546][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2293 (0.2341)	Prec@1 92.188 (91.655)	Prec@5 100.000 (99.864)
TRAINING - Epoch: [546][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.3801 (0.2402)	Prec@1 88.281 (91.489)	Prec@5 99.219 (99.842)
EVALUATING - Epoch: [546][0/79]	Time 0.430 (0.430)	Data 0.397 (0.397)	Loss 0.3569 (0.3569)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:15

 Epoch: 547	Training Loss 0.2394 	Training Prec@1 91.504 	Training Prec@5 99.858 	Validation Loss 0.5122 	Validation Prec@1 85.110 	Validation Prec@5 99.140 

lr: 0.0435518790927014
TRAINING - Epoch: [547][0/391]	Time 1.282 (1.282)	Data 0.417 (0.417)	Loss 0.2785 (0.2785)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [547][100/391]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.2138 (0.2332)	Prec@1 91.406 (91.994)	Prec@5 100.000 (99.799)
TRAINING - Epoch: [547][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.2364 (0.2329)	Prec@1 94.531 (91.947)	Prec@5 99.219 (99.817)
TRAINING - Epoch: [547][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2983 (0.2379)	Prec@1 91.406 (91.736)	Prec@5 99.219 (99.800)
EVALUATING - Epoch: [547][0/79]	Time 0.450 (0.450)	Data 0.408 (0.408)	Loss 0.5613 (0.5613)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:12

 Epoch: 548	Training Loss 0.2398 	Training Prec@1 91.620 	Training Prec@5 99.812 	Validation Loss 0.5706 	Validation Prec@1 82.700 	Validation Prec@5 99.160 

lr: 0.043395517917914905
TRAINING - Epoch: [548][0/391]	Time 1.273 (1.273)	Data 0.409 (0.409)	Loss 0.2467 (0.2467)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [548][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.1685 (0.2250)	Prec@1 96.094 (92.017)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [548][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1497 (0.2301)	Prec@1 92.969 (91.904)	Prec@5 100.000 (99.860)
TRAINING - Epoch: [548][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.1497 (0.2384)	Prec@1 94.531 (91.606)	Prec@5 100.000 (99.836)
EVALUATING - Epoch: [548][0/79]	Time 0.407 (0.407)	Data 0.370 (0.370)	Loss 0.4309 (0.4309)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:33

 Epoch: 549	Training Loss 0.2379 	Training Prec@1 91.686 	Training Prec@5 99.838 	Validation Loss 0.4514 	Validation Prec@1 85.630 	Validation Prec@5 99.320 

lr: 0.04323922245131393
TRAINING - Epoch: [549][0/391]	Time 1.274 (1.274)	Data 0.421 (0.421)	Loss 0.2540 (0.2540)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [549][100/391]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.2251 (0.2362)	Prec@1 93.750 (91.808)	Prec@5 100.000 (99.853)
TRAINING - Epoch: [549][200/391]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.2320 (0.2342)	Prec@1 90.625 (91.896)	Prec@5 99.219 (99.825)
TRAINING - Epoch: [549][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1835 (0.2321)	Prec@1 93.750 (91.933)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [549][0/79]	Time 0.418 (0.418)	Data 0.375 (0.375)	Loss 0.4160 (0.4160)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:16

 Epoch: 550	Training Loss 0.2368 	Training Prec@1 91.766 	Training Prec@5 99.800 	Validation Loss 0.4993 	Validation Prec@1 85.090 	Validation Prec@5 99.200 

lr: 0.043082994247886676
TRAINING - Epoch: [550][0/391]	Time 1.290 (1.290)	Data 0.440 (0.440)	Loss 0.1605 (0.1605)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [550][100/391]	Time 0.112 (0.122)	Data 0.000 (0.005)	Loss 0.1650 (0.2119)	Prec@1 94.531 (92.698)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [550][200/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3239 (0.2224)	Prec@1 89.844 (92.285)	Prec@5 100.000 (99.883)
TRAINING - Epoch: [550][300/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.2774 (0.2309)	Prec@1 87.500 (91.956)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [550][0/79]	Time 0.498 (0.498)	Data 0.448 (0.448)	Loss 0.3941 (0.3941)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:44

 Epoch: 551	Training Loss 0.2349 	Training Prec@1 91.880 	Training Prec@5 99.868 	Validation Loss 0.5034 	Validation Prec@1 84.260 	Validation Prec@5 99.250 

lr: 0.0429268348619521
TRAINING - Epoch: [551][0/391]	Time 1.270 (1.270)	Data 0.413 (0.413)	Loss 0.1867 (0.1867)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [551][100/391]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.2709 (0.2340)	Prec@1 91.406 (91.839)	Prec@5 100.000 (99.814)
TRAINING - Epoch: [551][200/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.1853 (0.2291)	Prec@1 92.969 (92.075)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [551][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3269 (0.2324)	Prec@1 89.062 (91.993)	Prec@5 98.438 (99.831)
EVALUATING - Epoch: [551][0/79]	Time 0.435 (0.435)	Data 0.389 (0.389)	Loss 0.4824 (0.4824)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:56

 Epoch: 552	Training Loss 0.2315 	Training Prec@1 92.040 	Training Prec@5 99.838 	Validation Loss 0.4823 	Validation Prec@1 84.560 	Validation Prec@5 99.380 

lr: 0.04277074584714448
TRAINING - Epoch: [552][0/391]	Time 1.271 (1.271)	Data 0.360 (0.360)	Loss 0.2604 (0.2604)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [552][100/391]	Time 0.112 (0.129)	Data 0.000 (0.004)	Loss 0.1411 (0.2264)	Prec@1 94.531 (92.242)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [552][200/391]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2296 (0.2237)	Prec@1 92.969 (92.324)	Prec@5 100.000 (99.864)
TRAINING - Epoch: [552][300/391]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2077 (0.2280)	Prec@1 91.406 (92.058)	Prec@5 100.000 (99.852)
EVALUATING - Epoch: [552][0/79]	Time 0.457 (0.457)	Data 0.411 (0.411)	Loss 0.3786 (0.3786)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:42:13

 Epoch: 553	Training Loss 0.2307 	Training Prec@1 91.964 	Training Prec@5 99.836 	Validation Loss 0.4072 	Validation Prec@1 86.720 	Validation Prec@5 99.620 

lr: 0.04261472875639802
TRAINING - Epoch: [553][0/391]	Time 1.292 (1.292)	Data 0.418 (0.418)	Loss 0.2734 (0.2734)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [553][100/391]	Time 0.112 (0.128)	Data 0.000 (0.004)	Loss 0.1074 (0.2169)	Prec@1 96.875 (92.365)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [553][200/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.1677 (0.2223)	Prec@1 95.312 (92.238)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [553][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2527 (0.2242)	Prec@1 92.188 (92.175)	Prec@5 99.219 (99.836)
EVALUATING - Epoch: [553][0/79]	Time 0.475 (0.475)	Data 0.434 (0.434)	Loss 0.5540 (0.5540)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:39:23

 Epoch: 554	Training Loss 0.2275 	Training Prec@1 92.040 	Training Prec@5 99.822 	Validation Loss 0.4710 	Validation Prec@1 85.390 	Validation Prec@5 99.230 

lr: 0.04245878514193132
TRAINING - Epoch: [554][0/391]	Time 1.280 (1.280)	Data 0.425 (0.425)	Loss 0.1717 (0.1717)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [554][100/391]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.2165 (0.2304)	Prec@1 92.188 (91.692)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [554][200/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1065 (0.2264)	Prec@1 96.094 (91.974)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [554][300/391]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2779 (0.2262)	Prec@1 92.188 (92.034)	Prec@5 100.000 (99.847)
EVALUATING - Epoch: [554][0/79]	Time 0.466 (0.466)	Data 0.422 (0.422)	Loss 0.4678 (0.4678)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:06

 Epoch: 555	Training Loss 0.2301 	Training Prec@1 91.878 	Training Prec@5 99.838 	Validation Loss 0.5595 	Validation Prec@1 83.660 	Validation Prec@5 99.150 

lr: 0.04230291655523196
TRAINING - Epoch: [555][0/391]	Time 1.277 (1.277)	Data 0.425 (0.425)	Loss 0.2430 (0.2430)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [555][100/391]	Time 0.112 (0.127)	Data 0.000 (0.005)	Loss 0.2149 (0.2181)	Prec@1 94.531 (92.597)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [555][200/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3036 (0.2223)	Prec@1 91.406 (92.409)	Prec@5 99.219 (99.810)
TRAINING - Epoch: [555][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1764 (0.2251)	Prec@1 92.969 (92.297)	Prec@5 100.000 (99.824)
EVALUATING - Epoch: [555][0/79]	Time 0.425 (0.425)	Data 0.378 (0.378)	Loss 0.4744 (0.4744)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:06

 Epoch: 556	Training Loss 0.2246 	Training Prec@1 92.260 	Training Prec@5 99.812 	Validation Loss 0.4628 	Validation Prec@1 85.840 	Validation Prec@5 99.340 

lr: 0.042147124547041066
TRAINING - Epoch: [556][0/391]	Time 1.308 (1.308)	Data 0.436 (0.436)	Loss 0.1691 (0.1691)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [556][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.1758 (0.2193)	Prec@1 93.750 (92.203)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [556][200/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.1294 (0.2254)	Prec@1 94.531 (91.958)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [556][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.2686 (0.2300)	Prec@1 91.406 (91.855)	Prec@5 98.438 (99.868)
EVALUATING - Epoch: [556][0/79]	Time 0.426 (0.426)	Data 0.392 (0.392)	Loss 0.4665 (0.4665)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:26

 Epoch: 557	Training Loss 0.2313 	Training Prec@1 91.818 	Training Prec@5 99.866 	Validation Loss 0.4496 	Validation Prec@1 85.790 	Validation Prec@5 99.290 

lr: 0.0419914106673379
TRAINING - Epoch: [557][0/391]	Time 1.291 (1.291)	Data 0.431 (0.431)	Loss 0.2042 (0.2042)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [557][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.2993 (0.2257)	Prec@1 89.062 (92.141)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [557][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.2763 (0.2293)	Prec@1 93.750 (92.051)	Prec@5 100.000 (99.837)
TRAINING - Epoch: [557][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.3047 (0.2344)	Prec@1 89.844 (91.931)	Prec@5 99.219 (99.813)
EVALUATING - Epoch: [557][0/79]	Time 0.450 (0.450)	Data 0.408 (0.408)	Loss 0.4195 (0.4195)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:52

 Epoch: 558	Training Loss 0.2355 	Training Prec@1 91.868 	Training Prec@5 99.810 	Validation Loss 0.4387 	Validation Prec@1 86.540 	Validation Prec@5 99.340 

lr: 0.04183577646532439
TRAINING - Epoch: [558][0/391]	Time 1.262 (1.262)	Data 0.364 (0.364)	Loss 0.0979 (0.0979)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [558][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.1659 (0.2126)	Prec@1 93.750 (92.621)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [558][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2748 (0.2192)	Prec@1 87.500 (92.409)	Prec@5 100.000 (99.868)
TRAINING - Epoch: [558][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1545 (0.2264)	Prec@1 95.312 (92.159)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [558][0/79]	Time 0.455 (0.455)	Data 0.420 (0.420)	Loss 0.4205 (0.4205)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:24:28

 Epoch: 559	Training Loss 0.2292 	Training Prec@1 91.990 	Training Prec@5 99.850 	Validation Loss 0.4954 	Validation Prec@1 84.870 	Validation Prec@5 99.270 

lr: 0.04168022348940979
TRAINING - Epoch: [559][0/391]	Time 1.279 (1.279)	Data 0.414 (0.414)	Loss 0.1227 (0.1227)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [559][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.2470 (0.2244)	Prec@1 89.062 (92.071)	Prec@5 100.000 (99.830)
TRAINING - Epoch: [559][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.1946 (0.2151)	Prec@1 92.969 (92.514)	Prec@5 100.000 (99.868)
TRAINING - Epoch: [559][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.1773 (0.2227)	Prec@1 94.531 (92.304)	Prec@5 100.000 (99.875)
EVALUATING - Epoch: [559][0/79]	Time 0.430 (0.430)	Data 0.399 (0.399)	Loss 0.4389 (0.4389)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:11

 Epoch: 560	Training Loss 0.2265 	Training Prec@1 92.204 	Training Prec@5 99.860 	Validation Loss 0.4320 	Validation Prec@1 86.720 	Validation Prec@5 99.340 

lr: 0.041524753287195175
TRAINING - Epoch: [560][0/391]	Time 1.588 (1.588)	Data 0.442 (0.442)	Loss 0.1634 (0.1634)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [560][100/391]	Time 0.114 (0.131)	Data 0.000 (0.005)	Loss 0.3499 (0.2092)	Prec@1 88.281 (92.683)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [560][200/391]	Time 0.115 (0.123)	Data 0.000 (0.003)	Loss 0.2201 (0.2204)	Prec@1 89.844 (92.382)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [560][300/391]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2179 (0.2211)	Prec@1 90.625 (92.315)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [560][0/79]	Time 0.405 (0.405)	Data 0.377 (0.377)	Loss 0.4278 (0.4278)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:40:16

 Epoch: 561	Training Loss 0.2261 	Training Prec@1 92.078 	Training Prec@5 99.872 	Validation Loss 0.5193 	Validation Prec@1 84.590 	Validation Prec@5 99.150 

lr: 0.04136936740545819
TRAINING - Epoch: [561][0/391]	Time 1.281 (1.281)	Data 0.426 (0.426)	Loss 0.2100 (0.2100)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [561][100/391]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.1722 (0.2235)	Prec@1 95.312 (92.211)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [561][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1776 (0.2216)	Prec@1 94.531 (92.312)	Prec@5 99.219 (99.825)
TRAINING - Epoch: [561][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.2396 (0.2233)	Prec@1 91.406 (92.273)	Prec@5 99.219 (99.826)
EVALUATING - Epoch: [561][0/79]	Time 0.429 (0.429)	Data 0.401 (0.401)	Loss 0.4027 (0.4027)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:46

 Epoch: 562	Training Loss 0.2277 	Training Prec@1 92.166 	Training Prec@5 99.806 	Validation Loss 0.4505 	Validation Prec@1 86.470 	Validation Prec@5 99.380 

lr: 0.041214067390137464
TRAINING - Epoch: [562][0/391]	Time 1.263 (1.263)	Data 0.412 (0.412)	Loss 0.2487 (0.2487)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [562][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.1905 (0.2333)	Prec@1 92.969 (91.770)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [562][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2188 (0.2276)	Prec@1 93.750 (92.013)	Prec@5 100.000 (99.852)
TRAINING - Epoch: [562][300/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.1553 (0.2288)	Prec@1 94.531 (92.001)	Prec@5 99.219 (99.857)
EVALUATING - Epoch: [562][0/79]	Time 0.432 (0.432)	Data 0.402 (0.402)	Loss 0.4442 (0.4442)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:09

 Epoch: 563	Training Loss 0.2289 	Training Prec@1 91.980 	Training Prec@5 99.870 	Validation Loss 0.5014 	Validation Prec@1 84.790 	Validation Prec@5 99.330 

lr: 0.04105885478631741
TRAINING - Epoch: [563][0/391]	Time 1.272 (1.272)	Data 0.403 (0.403)	Loss 0.1575 (0.1575)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [563][100/391]	Time 0.110 (0.124)	Data 0.000 (0.004)	Loss 0.2295 (0.2205)	Prec@1 92.188 (92.458)	Prec@5 100.000 (99.838)
TRAINING - Epoch: [563][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2700 (0.2257)	Prec@1 89.844 (92.195)	Prec@5 100.000 (99.833)
TRAINING - Epoch: [563][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1672 (0.2244)	Prec@1 94.531 (92.252)	Prec@5 100.000 (99.847)
EVALUATING - Epoch: [563][0/79]	Time 0.446 (0.446)	Data 0.405 (0.405)	Loss 0.3131 (0.3131)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:31

 Epoch: 564	Training Loss 0.2224 	Training Prec@1 92.312 	Training Prec@5 99.850 	Validation Loss 0.4519 	Validation Prec@1 86.040 	Validation Prec@5 99.070 

lr: 0.040903731138212815
TRAINING - Epoch: [564][0/391]	Time 1.293 (1.293)	Data 0.444 (0.444)	Loss 0.2189 (0.2189)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [564][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.1114 (0.2141)	Prec@1 96.094 (92.605)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [564][200/391]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.2437 (0.2192)	Prec@1 88.281 (92.440)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [564][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2921 (0.2243)	Prec@1 89.844 (92.309)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [564][0/79]	Time 0.419 (0.419)	Data 0.384 (0.384)	Loss 0.7003 (0.7003)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:36

 Epoch: 565	Training Loss 0.2270 	Training Prec@1 92.154 	Training Prec@5 99.818 	Validation Loss 0.5401 	Validation Prec@1 83.220 	Validation Prec@5 99.010 

lr: 0.04074869798915332
TRAINING - Epoch: [565][0/391]	Time 1.267 (1.267)	Data 0.414 (0.414)	Loss 0.1531 (0.1531)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [565][100/391]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.1449 (0.2347)	Prec@1 95.312 (91.785)	Prec@5 100.000 (99.807)
TRAINING - Epoch: [565][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1936 (0.2251)	Prec@1 92.188 (92.188)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [565][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2043 (0.2239)	Prec@1 92.188 (92.198)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [565][0/79]	Time 0.443 (0.443)	Data 0.396 (0.396)	Loss 0.3474 (0.3474)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:26

 Epoch: 566	Training Loss 0.2254 	Training Prec@1 92.142 	Training Prec@5 99.848 	Validation Loss 0.4822 	Validation Prec@1 85.480 	Validation Prec@5 99.150 

lr: 0.04059375688156833
TRAINING - Epoch: [566][0/391]	Time 1.275 (1.275)	Data 0.438 (0.438)	Loss 0.1601 (0.1601)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [566][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.2253 (0.2193)	Prec@1 90.625 (92.458)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [566][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3263 (0.2175)	Prec@1 85.938 (92.588)	Prec@5 100.000 (99.841)
TRAINING - Epoch: [566][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.2800 (0.2192)	Prec@1 89.844 (92.535)	Prec@5 100.000 (99.844)
EVALUATING - Epoch: [566][0/79]	Time 0.440 (0.440)	Data 0.386 (0.386)	Loss 0.4329 (0.4329)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:05:39

 Epoch: 567	Training Loss 0.2202 	Training Prec@1 92.508 	Training Prec@5 99.844 	Validation Loss 0.4883 	Validation Prec@1 84.700 	Validation Prec@5 99.170 

lr: 0.0404389093569714
TRAINING - Epoch: [567][0/391]	Time 1.312 (1.312)	Data 0.438 (0.438)	Loss 0.3125 (0.3125)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [567][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.2585 (0.2152)	Prec@1 92.969 (92.659)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [567][200/391]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.1702 (0.2172)	Prec@1 93.750 (92.545)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [567][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2579 (0.2170)	Prec@1 89.062 (92.499)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [567][0/79]	Time 0.430 (0.430)	Data 0.397 (0.397)	Loss 0.5211 (0.5211)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:09

 Epoch: 568	Training Loss 0.2199 	Training Prec@1 92.394 	Training Prec@5 99.864 	Validation Loss 0.5981 	Validation Prec@1 82.830 	Validation Prec@5 98.760 

lr: 0.040284156955945116
TRAINING - Epoch: [568][0/391]	Time 1.256 (1.256)	Data 0.415 (0.415)	Loss 0.2471 (0.2471)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [568][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.2524 (0.2086)	Prec@1 90.625 (92.613)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [568][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.2735 (0.2180)	Prec@1 86.719 (92.324)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [568][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.1481 (0.2199)	Prec@1 96.094 (92.208)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [568][0/79]	Time 0.436 (0.436)	Data 0.398 (0.398)	Loss 0.3577 (0.3577)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:56

 Epoch: 569	Training Loss 0.2183 	Training Prec@1 92.312 	Training Prec@5 99.850 	Validation Loss 0.4309 	Validation Prec@1 86.830 	Validation Prec@5 99.300 

lr: 0.04012950121812565
TRAINING - Epoch: [569][0/391]	Time 1.292 (1.292)	Data 0.441 (0.441)	Loss 0.2184 (0.2184)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [569][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.2213 (0.2155)	Prec@1 89.844 (92.551)	Prec@5 100.000 (99.845)
TRAINING - Epoch: [569][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1711 (0.2190)	Prec@1 93.750 (92.296)	Prec@5 100.000 (99.856)
TRAINING - Epoch: [569][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.1545 (0.2168)	Prec@1 95.312 (92.395)	Prec@5 100.000 (99.862)
EVALUATING - Epoch: [569][0/79]	Time 0.456 (0.456)	Data 0.413 (0.413)	Loss 0.3720 (0.3720)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:32

 Epoch: 570	Training Loss 0.2165 	Training Prec@1 92.412 	Training Prec@5 99.860 	Validation Loss 0.4438 	Validation Prec@1 85.690 	Validation Prec@5 99.270 

lr: 0.03997494368218745
TRAINING - Epoch: [570][0/391]	Time 1.291 (1.291)	Data 0.422 (0.422)	Loss 0.1645 (0.1645)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [570][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.3268 (0.2162)	Prec@1 89.062 (92.365)	Prec@5 99.219 (99.822)
TRAINING - Epoch: [570][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1255 (0.2143)	Prec@1 95.312 (92.401)	Prec@5 100.000 (99.790)
TRAINING - Epoch: [570][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1886 (0.2123)	Prec@1 91.406 (92.551)	Prec@5 100.000 (99.821)
EVALUATING - Epoch: [570][0/79]	Time 0.420 (0.420)	Data 0.375 (0.375)	Loss 0.3615 (0.3615)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:21:15

 Epoch: 571	Training Loss 0.2143 	Training Prec@1 92.476 	Training Prec@5 99.840 	Validation Loss 0.4721 	Validation Prec@1 85.010 	Validation Prec@5 99.440 

lr: 0.03982048588582796
TRAINING - Epoch: [571][0/391]	Time 1.292 (1.292)	Data 0.444 (0.444)	Loss 0.1640 (0.1640)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [571][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.1859 (0.2084)	Prec@1 93.750 (92.891)	Prec@5 100.000 (99.861)
TRAINING - Epoch: [571][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.2511 (0.2092)	Prec@1 89.844 (92.642)	Prec@5 100.000 (99.883)
TRAINING - Epoch: [571][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3371 (0.2124)	Prec@1 89.062 (92.491)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [571][0/79]	Time 0.434 (0.434)	Data 0.408 (0.408)	Loss 0.4909 (0.4909)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:31

 Epoch: 572	Training Loss 0.2146 	Training Prec@1 92.476 	Training Prec@5 99.876 	Validation Loss 0.4497 	Validation Prec@1 86.060 	Validation Prec@5 99.410 

lr: 0.03966612936575235
TRAINING - Epoch: [572][0/391]	Time 1.566 (1.566)	Data 0.439 (0.439)	Loss 0.1374 (0.1374)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [572][100/391]	Time 0.121 (0.132)	Data 0.000 (0.005)	Loss 0.2462 (0.1959)	Prec@1 92.969 (93.108)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [572][200/391]	Time 0.115 (0.124)	Data 0.000 (0.003)	Loss 0.2835 (0.2072)	Prec@1 89.062 (92.767)	Prec@5 100.000 (99.883)
TRAINING - Epoch: [572][300/391]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.2514 (0.2099)	Prec@1 91.406 (92.655)	Prec@5 99.219 (99.873)
EVALUATING - Epoch: [572][0/79]	Time 0.407 (0.407)	Data 0.372 (0.372)	Loss 0.3287 (0.3287)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:38:52

 Epoch: 573	Training Loss 0.2145 	Training Prec@1 92.508 	Training Prec@5 99.852 	Validation Loss 0.4443 	Validation Prec@1 85.970 	Validation Prec@5 99.330 

lr: 0.03951187565765811
TRAINING - Epoch: [573][0/391]	Time 1.286 (1.286)	Data 0.438 (0.438)	Loss 0.1914 (0.1914)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [573][100/391]	Time 0.110 (0.122)	Data 0.000 (0.005)	Loss 0.3141 (0.2046)	Prec@1 89.844 (92.729)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [573][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1260 (0.2015)	Prec@1 95.312 (92.887)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [573][300/391]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.1931 (0.2055)	Prec@1 93.750 (92.792)	Prec@5 100.000 (99.881)
EVALUATING - Epoch: [573][0/79]	Time 0.434 (0.434)	Data 0.398 (0.398)	Loss 0.5916 (0.5916)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:53

 Epoch: 574	Training Loss 0.2061 	Training Prec@1 92.760 	Training Prec@5 99.886 	Validation Loss 0.5561 	Validation Prec@1 84.430 	Validation Prec@5 99.080 

lr: 0.03935772629621993
TRAINING - Epoch: [574][0/391]	Time 1.293 (1.293)	Data 0.431 (0.431)	Loss 0.1627 (0.1627)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [574][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.2392 (0.2084)	Prec@1 90.625 (92.613)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [574][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.1773 (0.2054)	Prec@1 93.750 (92.615)	Prec@5 99.219 (99.876)
TRAINING - Epoch: [574][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2223 (0.2092)	Prec@1 92.969 (92.494)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [574][0/79]	Time 0.444 (0.444)	Data 0.403 (0.403)	Loss 0.3502 (0.3502)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:11

 Epoch: 575	Training Loss 0.2131 	Training Prec@1 92.382 	Training Prec@5 99.874 	Validation Loss 0.4904 	Validation Prec@1 84.790 	Validation Prec@5 99.250 

lr: 0.0392036828150743
TRAINING - Epoch: [575][0/391]	Time 1.282 (1.282)	Data 0.422 (0.422)	Loss 0.1734 (0.1734)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [575][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.3110 (0.2047)	Prec@1 90.625 (92.613)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [575][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.1636 (0.2103)	Prec@1 93.750 (92.518)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [575][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2499 (0.2101)	Prec@1 91.406 (92.515)	Prec@5 100.000 (99.881)
EVALUATING - Epoch: [575][0/79]	Time 0.430 (0.430)	Data 0.400 (0.400)	Loss 0.3316 (0.3316)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:12

 Epoch: 576	Training Loss 0.2091 	Training Prec@1 92.588 	Training Prec@5 99.890 	Validation Loss 0.4722 	Validation Prec@1 85.840 	Validation Prec@5 99.350 

lr: 0.03904974674680433
TRAINING - Epoch: [576][0/391]	Time 1.300 (1.300)	Data 0.437 (0.437)	Loss 0.1726 (0.1726)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [576][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.2094 (0.1966)	Prec@1 92.969 (93.147)	Prec@5 99.219 (99.884)
TRAINING - Epoch: [576][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.1124 (0.2064)	Prec@1 95.312 (92.817)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [576][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2417 (0.2084)	Prec@1 89.844 (92.766)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [576][0/79]	Time 0.441 (0.441)	Data 0.409 (0.409)	Loss 0.4282 (0.4282)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:15

 Epoch: 577	Training Loss 0.2101 	Training Prec@1 92.650 	Training Prec@5 99.878 	Validation Loss 0.4828 	Validation Prec@1 85.440 	Validation Prec@5 99.150 

lr: 0.03889591962292449
TRAINING - Epoch: [577][0/391]	Time 1.315 (1.315)	Data 0.453 (0.453)	Loss 0.1400 (0.1400)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [577][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.2113 (0.2113)	Prec@1 92.969 (92.559)	Prec@5 99.219 (99.930)
TRAINING - Epoch: [577][200/391]	Time 0.111 (0.117)	Data 0.000 (0.003)	Loss 0.2438 (0.2141)	Prec@1 91.406 (92.537)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [577][300/391]	Time 0.104 (0.113)	Data 0.000 (0.002)	Loss 0.2776 (0.2168)	Prec@1 88.281 (92.434)	Prec@5 100.000 (99.896)
EVALUATING - Epoch: [577][0/79]	Time 0.438 (0.438)	Data 0.405 (0.405)	Loss 0.4600 (0.4600)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:45	Time of Finish: 2022-03-24 02:17:02

 Epoch: 578	Training Loss 0.2125 	Training Prec@1 92.604 	Training Prec@5 99.892 	Validation Loss 0.4754 	Validation Prec@1 85.490 	Validation Prec@5 99.240 

lr: 0.03874220297386528
TRAINING - Epoch: [578][0/391]	Time 1.274 (1.274)	Data 0.417 (0.417)	Loss 0.2269 (0.2269)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [578][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.2355 (0.1990)	Prec@1 91.406 (92.837)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [578][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2300 (0.2008)	Prec@1 91.406 (92.918)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [578][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2508 (0.2046)	Prec@1 91.406 (92.844)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [578][0/79]	Time 0.445 (0.445)	Data 0.417 (0.417)	Loss 0.4500 (0.4500)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:30

 Epoch: 579	Training Loss 0.2093 	Training Prec@1 92.688 	Training Prec@5 99.888 	Validation Loss 0.5408 	Validation Prec@1 83.060 	Validation Prec@5 99.280 

lr: 0.03858859832895821
TRAINING - Epoch: [579][0/391]	Time 1.307 (1.307)	Data 0.449 (0.449)	Loss 0.2860 (0.2860)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [579][100/391]	Time 0.111 (0.124)	Data 0.001 (0.005)	Loss 0.1126 (0.2010)	Prec@1 94.531 (93.108)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [579][200/391]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.2785 (0.2038)	Prec@1 87.500 (93.015)	Prec@5 100.000 (99.872)
TRAINING - Epoch: [579][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.1953 (0.2069)	Prec@1 94.531 (92.849)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [579][0/79]	Time 0.422 (0.422)	Data 0.384 (0.384)	Loss 0.4460 (0.4460)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:24

 Epoch: 580	Training Loss 0.2110 	Training Prec@1 92.734 	Training Prec@5 99.852 	Validation Loss 0.5565 	Validation Prec@1 84.330 	Validation Prec@5 99.330 

lr: 0.038435107216420336
TRAINING - Epoch: [580][0/391]	Time 1.298 (1.298)	Data 0.440 (0.440)	Loss 0.1804 (0.1804)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [580][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.2205 (0.1871)	Prec@1 93.750 (93.711)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [580][200/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.1920 (0.1939)	Prec@1 93.750 (93.365)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [580][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.2936 (0.1990)	Prec@1 88.281 (93.156)	Prec@5 99.219 (99.888)
EVALUATING - Epoch: [580][0/79]	Time 0.432 (0.432)	Data 0.403 (0.403)	Loss 0.4115 (0.4115)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:08

 Epoch: 581	Training Loss 0.2027 	Training Prec@1 93.056 	Training Prec@5 99.894 	Validation Loss 0.4783 	Validation Prec@1 85.310 	Validation Prec@5 99.430 

lr: 0.03828173116333925
TRAINING - Epoch: [581][0/391]	Time 1.271 (1.271)	Data 0.403 (0.403)	Loss 0.2545 (0.2545)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [581][100/391]	Time 0.121 (0.126)	Data 0.000 (0.004)	Loss 0.2420 (0.1937)	Prec@1 92.969 (93.270)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [581][200/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2514 (0.2006)	Prec@1 92.969 (92.895)	Prec@5 100.000 (99.880)
TRAINING - Epoch: [581][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.2025 (0.2006)	Prec@1 92.969 (93.008)	Prec@5 100.000 (99.878)
EVALUATING - Epoch: [581][0/79]	Time 0.432 (0.432)	Data 0.397 (0.397)	Loss 0.5227 (0.5227)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:06

 Epoch: 582	Training Loss 0.2010 	Training Prec@1 92.968 	Training Prec@5 99.866 	Validation Loss 0.4800 	Validation Prec@1 85.600 	Validation Prec@5 99.310 

lr: 0.03812847169565779
TRAINING - Epoch: [582][0/391]	Time 1.274 (1.274)	Data 0.415 (0.415)	Loss 0.1607 (0.1607)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [582][100/391]	Time 0.114 (0.127)	Data 0.000 (0.004)	Loss 0.3359 (0.2112)	Prec@1 88.281 (92.559)	Prec@5 97.656 (99.845)
TRAINING - Epoch: [582][200/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.1399 (0.2043)	Prec@1 95.312 (92.965)	Prec@5 100.000 (99.864)
TRAINING - Epoch: [582][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2145 (0.2032)	Prec@1 89.844 (92.940)	Prec@5 100.000 (99.855)
EVALUATING - Epoch: [582][0/79]	Time 0.462 (0.462)	Data 0.429 (0.429)	Loss 0.4574 (0.4574)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:54

 Epoch: 583	Training Loss 0.2040 	Training Prec@1 92.912 	Training Prec@5 99.850 	Validation Loss 0.6041 	Validation Prec@1 82.300 	Validation Prec@5 99.150 

lr: 0.03797533033815889
TRAINING - Epoch: [583][0/391]	Time 1.290 (1.290)	Data 0.433 (0.433)	Loss 0.2194 (0.2194)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [583][100/391]	Time 0.115 (0.128)	Data 0.000 (0.005)	Loss 0.1902 (0.1866)	Prec@1 92.969 (93.479)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [583][200/391]	Time 0.120 (0.123)	Data 0.000 (0.003)	Loss 0.2717 (0.1900)	Prec@1 90.625 (93.295)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [583][300/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2442 (0.2005)	Prec@1 89.844 (92.925)	Prec@5 100.000 (99.904)
EVALUATING - Epoch: [583][0/79]	Time 0.437 (0.437)	Data 0.404 (0.404)	Loss 0.3827 (0.3827)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:43:39

 Epoch: 584	Training Loss 0.2017 	Training Prec@1 92.920 	Training Prec@5 99.900 	Validation Loss 0.4546 	Validation Prec@1 85.410 	Validation Prec@5 99.410 

lr: 0.03782230861445038
TRAINING - Epoch: [584][0/391]	Time 1.293 (1.293)	Data 0.430 (0.430)	Loss 0.2261 (0.2261)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [584][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.2963 (0.2040)	Prec@1 88.281 (92.768)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [584][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1040 (0.2031)	Prec@1 96.094 (92.743)	Prec@5 100.000 (99.887)
TRAINING - Epoch: [584][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.1290 (0.2044)	Prec@1 95.312 (92.818)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [584][0/79]	Time 0.446 (0.446)	Data 0.401 (0.401)	Loss 0.2681 (0.2681)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:50

 Epoch: 585	Training Loss 0.2024 	Training Prec@1 92.920 	Training Prec@5 99.886 	Validation Loss 0.4321 	Validation Prec@1 86.760 	Validation Prec@5 99.540 

lr: 0.0376694080469499
TRAINING - Epoch: [585][0/391]	Time 1.276 (1.276)	Data 0.413 (0.413)	Loss 0.3288 (0.3288)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [585][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.1762 (0.2062)	Prec@1 92.188 (92.891)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [585][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.2105 (0.2039)	Prec@1 92.969 (92.953)	Prec@5 100.000 (99.880)
TRAINING - Epoch: [585][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2958 (0.1989)	Prec@1 89.062 (93.060)	Prec@5 99.219 (99.886)
EVALUATING - Epoch: [585][0/79]	Time 0.448 (0.448)	Data 0.412 (0.412)	Loss 0.3685 (0.3685)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:03

 Epoch: 586	Training Loss 0.1998 	Training Prec@1 93.010 	Training Prec@5 99.886 	Validation Loss 0.4322 	Validation Prec@1 86.740 	Validation Prec@5 99.420 

lr: 0.03751663015686964
TRAINING - Epoch: [586][0/391]	Time 1.274 (1.274)	Data 0.419 (0.419)	Loss 0.1480 (0.1480)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [586][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.1265 (0.1937)	Prec@1 96.094 (93.162)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [586][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2163 (0.2008)	Prec@1 93.750 (93.008)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [586][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2777 (0.1988)	Prec@1 90.625 (93.052)	Prec@5 100.000 (99.920)
EVALUATING - Epoch: [586][0/79]	Time 0.416 (0.416)	Data 0.377 (0.377)	Loss 0.4863 (0.4863)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:26

 Epoch: 587	Training Loss 0.2017 	Training Prec@1 92.984 	Training Prec@5 99.894 	Validation Loss 0.5006 	Validation Prec@1 84.940 	Validation Prec@5 99.170 

lr: 0.03736397646420132
TRAINING - Epoch: [587][0/391]	Time 1.274 (1.274)	Data 0.418 (0.418)	Loss 0.1467 (0.1467)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [587][100/391]	Time 0.109 (0.124)	Data 0.000 (0.004)	Loss 0.1525 (0.2060)	Prec@1 95.312 (92.760)	Prec@5 100.000 (99.869)
TRAINING - Epoch: [587][200/391]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.2438 (0.2021)	Prec@1 94.531 (92.934)	Prec@5 98.438 (99.895)
TRAINING - Epoch: [587][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.2451 (0.2003)	Prec@1 90.625 (92.974)	Prec@5 100.000 (99.904)
EVALUATING - Epoch: [587][0/79]	Time 0.452 (0.452)	Data 0.415 (0.415)	Loss 0.3706 (0.3706)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:04

 Epoch: 588	Training Loss 0.1997 	Training Prec@1 93.028 	Training Prec@5 99.894 	Validation Loss 0.4596 	Validation Prec@1 85.980 	Validation Prec@5 99.380 

lr: 0.03721144848770099
TRAINING - Epoch: [588][0/391]	Time 1.574 (1.574)	Data 0.417 (0.417)	Loss 0.1439 (0.1439)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [588][100/391]	Time 0.119 (0.135)	Data 0.000 (0.004)	Loss 0.2575 (0.2058)	Prec@1 92.969 (92.853)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [588][200/391]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.1845 (0.2019)	Prec@1 95.312 (93.004)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [588][300/391]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.3737 (0.2037)	Prec@1 88.281 (92.891)	Prec@5 100.000 (99.891)
EVALUATING - Epoch: [588][0/79]	Time 0.449 (0.449)	Data 0.402 (0.402)	Loss 0.3565 (0.3565)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:47:24

 Epoch: 589	Training Loss 0.2056 	Training Prec@1 92.832 	Training Prec@5 99.890 	Validation Loss 0.4670 	Validation Prec@1 85.060 	Validation Prec@5 99.240 

lr: 0.03705904774487394
TRAINING - Epoch: [589][0/391]	Time 1.282 (1.282)	Data 0.428 (0.428)	Loss 0.2160 (0.2160)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [589][100/391]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.3059 (0.2022)	Prec@1 90.625 (92.969)	Prec@5 99.219 (99.892)
TRAINING - Epoch: [589][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1800 (0.1971)	Prec@1 92.969 (93.097)	Prec@5 100.000 (99.903)
TRAINING - Epoch: [589][300/391]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.2089 (0.1996)	Prec@1 90.625 (92.979)	Prec@5 100.000 (99.886)
EVALUATING - Epoch: [589][0/79]	Time 0.421 (0.421)	Data 0.389 (0.389)	Loss 0.4130 (0.4130)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:53

 Epoch: 590	Training Loss 0.2037 	Training Prec@1 92.836 	Training Prec@5 99.882 	Validation Loss 0.4748 	Validation Prec@1 85.540 	Validation Prec@5 99.460 

lr: 0.03690677575195966
TRAINING - Epoch: [590][0/391]	Time 1.292 (1.292)	Data 0.446 (0.446)	Loss 0.1942 (0.1942)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [590][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.1942 (0.2022)	Prec@1 92.188 (93.000)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [590][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.2390 (0.1954)	Prec@1 92.969 (93.163)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [590][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.1708 (0.1962)	Prec@1 92.969 (93.075)	Prec@5 100.000 (99.896)
EVALUATING - Epoch: [590][0/79]	Time 0.447 (0.447)	Data 0.405 (0.405)	Loss 0.3451 (0.3451)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:25

 Epoch: 591	Training Loss 0.1957 	Training Prec@1 93.100 	Training Prec@5 99.896 	Validation Loss 0.4415 	Validation Prec@1 86.080 	Validation Prec@5 99.430 

lr: 0.0367546340239166
TRAINING - Epoch: [591][0/391]	Time 1.282 (1.282)	Data 0.432 (0.432)	Loss 0.1971 (0.1971)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [591][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.0777 (0.1858)	Prec@1 97.656 (93.410)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [591][200/391]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.1429 (0.1927)	Prec@1 94.531 (93.159)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [591][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1476 (0.1942)	Prec@1 95.312 (93.156)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [591][0/79]	Time 0.436 (0.436)	Data 0.401 (0.401)	Loss 0.5905 (0.5905)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:26

 Epoch: 592	Training Loss 0.1965 	Training Prec@1 93.054 	Training Prec@5 99.898 	Validation Loss 0.4072 	Validation Prec@1 86.850 	Validation Prec@5 99.520 

lr: 0.03660262407440733
TRAINING - Epoch: [592][0/391]	Time 1.268 (1.268)	Data 0.376 (0.376)	Loss 0.1391 (0.1391)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [592][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.1642 (0.1881)	Prec@1 93.750 (93.479)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [592][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.2516 (0.1904)	Prec@1 93.750 (93.287)	Prec@5 99.219 (99.926)
TRAINING - Epoch: [592][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.1933 (0.1947)	Prec@1 92.969 (93.161)	Prec@5 100.000 (99.912)
EVALUATING - Epoch: [592][0/79]	Time 0.449 (0.449)	Data 0.412 (0.412)	Loss 0.3352 (0.3352)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:37

 Epoch: 593	Training Loss 0.1938 	Training Prec@1 93.184 	Training Prec@5 99.900 	Validation Loss 0.4634 	Validation Prec@1 85.390 	Validation Prec@5 99.370 

lr: 0.03645074741578323
TRAINING - Epoch: [593][0/391]	Time 1.297 (1.297)	Data 0.441 (0.441)	Loss 0.0666 (0.0666)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [593][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.2108 (0.1836)	Prec@1 92.188 (93.835)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [593][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.1993 (0.1793)	Prec@1 92.969 (93.894)	Prec@5 100.000 (99.887)
TRAINING - Epoch: [593][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2815 (0.1870)	Prec@1 90.625 (93.574)	Prec@5 99.219 (99.888)
EVALUATING - Epoch: [593][0/79]	Time 0.417 (0.417)	Data 0.378 (0.378)	Loss 0.3878 (0.3878)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:44

 Epoch: 594	Training Loss 0.1867 	Training Prec@1 93.570 	Training Prec@5 99.888 	Validation Loss 0.4597 	Validation Prec@1 85.690 	Validation Prec@5 99.410 

lr: 0.036299005559069675
TRAINING - Epoch: [594][0/391]	Time 1.217 (1.217)	Data 0.364 (0.364)	Loss 0.1968 (0.1968)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [594][100/391]	Time 0.118 (0.128)	Data 0.000 (0.004)	Loss 0.1467 (0.1749)	Prec@1 96.094 (93.773)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [594][200/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.1533 (0.1880)	Prec@1 95.312 (93.381)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [594][300/391]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2799 (0.1926)	Prec@1 89.844 (93.200)	Prec@5 100.000 (99.909)
EVALUATING - Epoch: [594][0/79]	Time 0.436 (0.436)	Data 0.393 (0.393)	Loss 0.3780 (0.3780)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:42:05

 Epoch: 595	Training Loss 0.1922 	Training Prec@1 93.230 	Training Prec@5 99.908 	Validation Loss 0.4821 	Validation Prec@1 85.370 	Validation Prec@5 99.400 

lr: 0.03614740001395081
TRAINING - Epoch: [595][0/391]	Time 1.281 (1.281)	Data 0.380 (0.380)	Loss 0.0723 (0.0723)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [595][100/391]	Time 0.109 (0.127)	Data 0.000 (0.004)	Loss 0.2024 (0.1850)	Prec@1 90.625 (93.363)	Prec@5 100.000 (99.876)
TRAINING - Epoch: [595][200/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1097 (0.1886)	Prec@1 95.312 (93.151)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [595][300/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1706 (0.1905)	Prec@1 92.969 (93.158)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [595][0/79]	Time 0.411 (0.411)	Data 0.385 (0.385)	Loss 0.3652 (0.3652)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:22

 Epoch: 596	Training Loss 0.1891 	Training Prec@1 93.218 	Training Prec@5 99.894 	Validation Loss 0.4573 	Validation Prec@1 86.280 	Validation Prec@5 99.340 

lr: 0.03599593228875463
TRAINING - Epoch: [596][0/391]	Time 1.267 (1.267)	Data 0.405 (0.405)	Loss 0.2208 (0.2208)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [596][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.1435 (0.1857)	Prec@1 96.094 (93.549)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [596][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1501 (0.1861)	Prec@1 94.531 (93.556)	Prec@5 100.000 (99.891)
TRAINING - Epoch: [596][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2350 (0.1875)	Prec@1 89.062 (93.470)	Prec@5 100.000 (99.883)
EVALUATING - Epoch: [596][0/79]	Time 0.441 (0.441)	Data 0.402 (0.402)	Loss 0.3768 (0.3768)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:14

 Epoch: 597	Training Loss 0.1882 	Training Prec@1 93.438 	Training Prec@5 99.882 	Validation Loss 0.3941 	Validation Prec@1 87.830 	Validation Prec@5 99.530 

lr: 0.03584460389043799
TRAINING - Epoch: [597][0/391]	Time 1.296 (1.296)	Data 0.447 (0.447)	Loss 0.1915 (0.1915)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [597][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.1680 (0.1831)	Prec@1 93.750 (93.464)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [597][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.1914 (0.1839)	Prec@1 92.188 (93.478)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [597][300/391]	Time 0.110 (0.115)	Data 0.001 (0.002)	Loss 0.2086 (0.1854)	Prec@1 92.969 (93.493)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [597][0/79]	Time 0.457 (0.457)	Data 0.414 (0.414)	Loss 0.4583 (0.4583)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:43

 Epoch: 598	Training Loss 0.1888 	Training Prec@1 93.376 	Training Prec@5 99.900 	Validation Loss 0.5603 	Validation Prec@1 83.840 	Validation Prec@5 99.310 

lr: 0.03569341632457155
TRAINING - Epoch: [598][0/391]	Time 1.585 (1.585)	Data 0.431 (0.431)	Loss 0.2050 (0.2050)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [598][100/391]	Time 0.111 (0.131)	Data 0.000 (0.005)	Loss 0.1657 (0.1921)	Prec@1 92.969 (93.162)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [598][200/391]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.2242 (0.1865)	Prec@1 91.406 (93.392)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [598][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.1583 (0.1875)	Prec@1 96.094 (93.337)	Prec@5 99.219 (99.920)
EVALUATING - Epoch: [598][0/79]	Time 0.421 (0.421)	Data 0.386 (0.386)	Loss 0.4379 (0.4379)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:39:19

 Epoch: 599	Training Loss 0.1892 	Training Prec@1 93.336 	Training Prec@5 99.918 	Validation Loss 0.4165 	Validation Prec@1 86.740 	Validation Prec@5 99.540 

lr: 0.03554237109532482
TRAINING - Epoch: [599][0/391]	Time 1.306 (1.306)	Data 0.450 (0.450)	Loss 0.2139 (0.2139)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [599][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.2373 (0.1817)	Prec@1 91.406 (93.688)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [599][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.1544 (0.1764)	Prec@1 93.750 (93.843)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [599][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1857 (0.1832)	Prec@1 92.969 (93.592)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [599][0/79]	Time 0.402 (0.402)	Data 0.376 (0.376)	Loss 0.4108 (0.4108)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:38

 Epoch: 600	Training Loss 0.1855 	Training Prec@1 93.500 	Training Prec@5 99.912 	Validation Loss 0.4959 	Validation Prec@1 85.320 	Validation Prec@5 99.280 

lr: 0.03539146970545121
TRAINING - Epoch: [600][0/391]	Time 1.299 (1.299)	Data 0.412 (0.412)	Loss 0.2173 (0.2173)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [600][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.1416 (0.1756)	Prec@1 96.094 (93.634)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [600][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2120 (0.1820)	Prec@1 92.969 (93.517)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [600][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1843 (0.1863)	Prec@1 94.531 (93.428)	Prec@5 99.219 (99.914)
EVALUATING - Epoch: [600][0/79]	Time 0.469 (0.469)	Data 0.430 (0.430)	Loss 0.4493 (0.4493)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:55

 Epoch: 601	Training Loss 0.1883 	Training Prec@1 93.394 	Training Prec@5 99.918 	Validation Loss 0.4627 	Validation Prec@1 86.310 	Validation Prec@5 99.140 

lr: 0.035240713656273064
TRAINING - Epoch: [601][0/391]	Time 1.311 (1.311)	Data 0.439 (0.439)	Loss 0.2223 (0.2223)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [601][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.2502 (0.1845)	Prec@1 92.969 (93.572)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [601][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.1619 (0.1868)	Prec@1 92.969 (93.482)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [601][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.2069 (0.1874)	Prec@1 92.969 (93.529)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [601][0/79]	Time 0.421 (0.421)	Data 0.372 (0.372)	Loss 0.3620 (0.3620)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:27

 Epoch: 602	Training Loss 0.1869 	Training Prec@1 93.534 	Training Prec@5 99.912 	Validation Loss 0.4271 	Validation Prec@1 86.760 	Validation Prec@5 99.490 

lr: 0.03509010444766671
TRAINING - Epoch: [602][0/391]	Time 1.267 (1.267)	Data 0.425 (0.425)	Loss 0.2029 (0.2029)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [602][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.1922 (0.1871)	Prec@1 95.312 (93.410)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [602][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1794 (0.1833)	Prec@1 90.625 (93.560)	Prec@5 100.000 (99.914)
TRAINING - Epoch: [602][300/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.1069 (0.1824)	Prec@1 96.875 (93.540)	Prec@5 100.000 (99.901)
EVALUATING - Epoch: [602][0/79]	Time 0.439 (0.439)	Data 0.402 (0.402)	Loss 0.3980 (0.3980)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:08

 Epoch: 603	Training Loss 0.1842 	Training Prec@1 93.530 	Training Prec@5 99.888 	Validation Loss 0.4770 	Validation Prec@1 86.000 	Validation Prec@5 99.450 

lr: 0.034939643578047616
TRAINING - Epoch: [603][0/391]	Time 1.313 (1.313)	Data 0.459 (0.459)	Loss 0.1599 (0.1599)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [603][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.1755 (0.1749)	Prec@1 92.969 (93.912)	Prec@5 100.000 (99.892)
TRAINING - Epoch: [603][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.1525 (0.1822)	Prec@1 95.312 (93.610)	Prec@5 99.219 (99.914)
TRAINING - Epoch: [603][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.2777 (0.1825)	Prec@1 92.188 (93.592)	Prec@5 100.000 (99.917)
EVALUATING - Epoch: [603][0/79]	Time 0.431 (0.431)	Data 0.389 (0.389)	Loss 0.3274 (0.3274)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:38:31

 Epoch: 604	Training Loss 0.1862 	Training Prec@1 93.478 	Training Prec@5 99.914 	Validation Loss 0.4562 	Validation Prec@1 86.080 	Validation Prec@5 99.450 

lr: 0.034789332544355324
TRAINING - Epoch: [604][0/391]	Time 1.279 (1.279)	Data 0.410 (0.410)	Loss 0.1991 (0.1991)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [604][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.1124 (0.1707)	Prec@1 96.094 (94.075)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [604][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2208 (0.1807)	Prec@1 92.188 (93.801)	Prec@5 100.000 (99.914)
TRAINING - Epoch: [604][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.2219 (0.1842)	Prec@1 92.969 (93.542)	Prec@5 99.219 (99.907)
EVALUATING - Epoch: [604][0/79]	Time 0.428 (0.428)	Data 0.399 (0.399)	Loss 0.3846 (0.3846)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:14

 Epoch: 605	Training Loss 0.1855 	Training Prec@1 93.460 	Training Prec@5 99.900 	Validation Loss 0.4331 	Validation Prec@1 86.570 	Validation Prec@5 99.560 

lr: 0.034639172842038754
TRAINING - Epoch: [605][0/391]	Time 1.269 (1.269)	Data 0.416 (0.416)	Loss 0.1836 (0.1836)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [605][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.1866 (0.1791)	Prec@1 94.531 (93.998)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [605][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2083 (0.1734)	Prec@1 93.750 (94.139)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [605][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.2075 (0.1779)	Prec@1 92.188 (93.888)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [605][0/79]	Time 0.422 (0.422)	Data 0.387 (0.387)	Loss 0.3981 (0.3981)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:16

 Epoch: 606	Training Loss 0.1793 	Training Prec@1 93.800 	Training Prec@5 99.908 	Validation Loss 0.4137 	Validation Prec@1 86.690 	Validation Prec@5 99.490 

lr: 0.034489165965041146
TRAINING - Epoch: [606][0/391]	Time 1.555 (1.555)	Data 0.412 (0.412)	Loss 0.1992 (0.1992)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [606][100/391]	Time 0.127 (0.135)	Data 0.000 (0.004)	Loss 0.2046 (0.1667)	Prec@1 94.531 (94.276)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [606][200/391]	Time 0.117 (0.126)	Data 0.000 (0.002)	Loss 0.2381 (0.1736)	Prec@1 91.406 (93.952)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [606][300/391]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.0897 (0.1781)	Prec@1 98.438 (93.859)	Prec@5 100.000 (99.901)
EVALUATING - Epoch: [606][0/79]	Time 0.439 (0.439)	Data 0.394 (0.394)	Loss 0.3959 (0.3959)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:39:03

 Epoch: 607	Training Loss 0.1790 	Training Prec@1 93.804 	Training Prec@5 99.896 	Validation Loss 0.4388 	Validation Prec@1 87.030 	Validation Prec@5 99.420 

lr: 0.03433931340578532
TRAINING - Epoch: [607][0/391]	Time 1.297 (1.297)	Data 0.446 (0.446)	Loss 0.1760 (0.1760)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [607][100/391]	Time 0.113 (0.124)	Data 0.000 (0.005)	Loss 0.1056 (0.1701)	Prec@1 97.656 (94.098)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [607][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.1733 (0.1777)	Prec@1 95.312 (93.894)	Prec@5 100.000 (99.899)
TRAINING - Epoch: [607][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.1764 (0.1806)	Prec@1 94.531 (93.747)	Prec@5 99.219 (99.901)
EVALUATING - Epoch: [607][0/79]	Time 0.455 (0.455)	Data 0.412 (0.412)	Loss 0.3833 (0.3833)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:37

 Epoch: 608	Training Loss 0.1808 	Training Prec@1 93.754 	Training Prec@5 99.904 	Validation Loss 0.4232 	Validation Prec@1 86.360 	Validation Prec@5 99.530 

lr: 0.0341896166551588
TRAINING - Epoch: [608][0/391]	Time 1.262 (1.262)	Data 0.420 (0.420)	Loss 0.1345 (0.1345)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [608][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.1137 (0.1687)	Prec@1 96.094 (94.114)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [608][200/391]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.1286 (0.1771)	Prec@1 92.969 (93.832)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [608][300/391]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.2027 (0.1809)	Prec@1 92.969 (93.612)	Prec@5 100.000 (99.904)
EVALUATING - Epoch: [608][0/79]	Time 0.468 (0.468)	Data 0.430 (0.430)	Loss 0.4421 (0.4421)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:45	Time of Finish: 2022-03-24 02:17:59

 Epoch: 609	Training Loss 0.1834 	Training Prec@1 93.558 	Training Prec@5 99.906 	Validation Loss 0.4807 	Validation Prec@1 85.640 	Validation Prec@5 99.500 

lr: 0.034040077202498895
TRAINING - Epoch: [609][0/391]	Time 1.298 (1.298)	Data 0.422 (0.422)	Loss 0.2047 (0.2047)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [609][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.1490 (0.1730)	Prec@1 93.750 (93.804)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [609][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1788 (0.1775)	Prec@1 94.531 (93.746)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [609][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1649 (0.1783)	Prec@1 97.656 (93.753)	Prec@5 99.219 (99.907)
EVALUATING - Epoch: [609][0/79]	Time 0.436 (0.436)	Data 0.400 (0.400)	Loss 0.4081 (0.4081)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:00

 Epoch: 610	Training Loss 0.1781 	Training Prec@1 93.728 	Training Prec@5 99.918 	Validation Loss 0.4276 	Validation Prec@1 86.970 	Validation Prec@5 99.460 

lr: 0.03389069653557804
TRAINING - Epoch: [610][0/391]	Time 1.293 (1.293)	Data 0.438 (0.438)	Loss 0.1564 (0.1564)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [610][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.1527 (0.1817)	Prec@1 93.750 (93.502)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [610][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.2098 (0.1745)	Prec@1 93.750 (93.773)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [610][300/391]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1635 (0.1770)	Prec@1 94.531 (93.719)	Prec@5 99.219 (99.912)
EVALUATING - Epoch: [610][0/79]	Time 0.425 (0.425)	Data 0.385 (0.385)	Loss 0.3823 (0.3823)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:41

 Epoch: 611	Training Loss 0.1787 	Training Prec@1 93.672 	Training Prec@5 99.910 	Validation Loss 0.4397 	Validation Prec@1 86.560 	Validation Prec@5 99.390 

lr: 0.03374147614058881
TRAINING - Epoch: [611][0/391]	Time 1.270 (1.270)	Data 0.371 (0.371)	Loss 0.1889 (0.1889)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [611][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.1970 (0.1816)	Prec@1 92.969 (93.580)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [611][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.1115 (0.1757)	Prec@1 96.875 (93.785)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [611][300/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.1570 (0.1775)	Prec@1 94.531 (93.768)	Prec@5 100.000 (99.912)
EVALUATING - Epoch: [611][0/79]	Time 0.416 (0.416)	Data 0.382 (0.382)	Loss 0.4222 (0.4222)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:34

 Epoch: 612	Training Loss 0.1794 	Training Prec@1 93.700 	Training Prec@5 99.914 	Validation Loss 0.5091 	Validation Prec@1 85.340 	Validation Prec@5 99.490 

lr: 0.033592417502129324
TRAINING - Epoch: [612][0/391]	Time 1.319 (1.319)	Data 0.454 (0.454)	Loss 0.2963 (0.2963)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [612][100/391]	Time 0.116 (0.128)	Data 0.000 (0.005)	Loss 0.0751 (0.1740)	Prec@1 96.875 (93.912)	Prec@5 100.000 (99.915)
TRAINING - Epoch: [612][200/391]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.1276 (0.1731)	Prec@1 94.531 (93.944)	Prec@5 100.000 (99.914)
TRAINING - Epoch: [612][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2307 (0.1753)	Prec@1 92.969 (93.901)	Prec@5 100.000 (99.914)
EVALUATING - Epoch: [612][0/79]	Time 0.438 (0.438)	Data 0.386 (0.386)	Loss 0.4408 (0.4408)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:37:04

 Epoch: 613	Training Loss 0.1745 	Training Prec@1 93.896 	Training Prec@5 99.924 	Validation Loss 0.5045 	Validation Prec@1 85.010 	Validation Prec@5 99.360 

lr: 0.03344352210318833
TRAINING - Epoch: [613][0/391]	Time 1.308 (1.308)	Data 0.457 (0.457)	Loss 0.1517 (0.1517)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [613][100/391]	Time 0.115 (0.125)	Data 0.000 (0.005)	Loss 0.1414 (0.1648)	Prec@1 96.875 (94.245)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [613][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.1605 (0.1660)	Prec@1 92.188 (94.248)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [613][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2041 (0.1696)	Prec@1 93.750 (94.080)	Prec@5 99.219 (99.917)
EVALUATING - Epoch: [613][0/79]	Time 0.431 (0.431)	Data 0.400 (0.400)	Loss 0.4064 (0.4064)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:48

 Epoch: 614	Training Loss 0.1710 	Training Prec@1 94.024 	Training Prec@5 99.906 	Validation Loss 0.4243 	Validation Prec@1 87.530 	Validation Prec@5 99.460 

lr: 0.03329479142513051
TRAINING - Epoch: [614][0/391]	Time 1.271 (1.271)	Data 0.419 (0.419)	Loss 0.2460 (0.2460)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [614][100/391]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.1902 (0.1571)	Prec@1 92.969 (94.415)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [614][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2178 (0.1662)	Prec@1 92.188 (94.100)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [614][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.1271 (0.1706)	Prec@1 96.094 (93.994)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [614][0/79]	Time 0.431 (0.431)	Data 0.403 (0.403)	Loss 0.3929 (0.3929)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:24

 Epoch: 615	Training Loss 0.1702 	Training Prec@1 94.022 	Training Prec@5 99.924 	Validation Loss 0.4953 	Validation Prec@1 85.810 	Validation Prec@5 99.430 

lr: 0.03314622694768171
TRAINING - Epoch: [615][0/391]	Time 1.206 (1.206)	Data 0.361 (0.361)	Loss 0.2116 (0.2116)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [615][100/391]	Time 0.110 (0.122)	Data 0.000 (0.004)	Loss 0.1998 (0.1701)	Prec@1 93.750 (94.121)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [615][200/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0785 (0.1753)	Prec@1 97.656 (93.832)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [615][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.1200 (0.1750)	Prec@1 95.312 (93.849)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [615][0/79]	Time 0.448 (0.448)	Data 0.416 (0.416)	Loss 0.4567 (0.4567)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:11

 Epoch: 616	Training Loss 0.1767 	Training Prec@1 93.786 	Training Prec@5 99.934 	Validation Loss 0.5034 	Validation Prec@1 84.430 	Validation Prec@5 99.390 

lr: 0.03299783014891432
TRAINING - Epoch: [616][0/391]	Time 1.306 (1.306)	Data 0.445 (0.445)	Loss 0.0889 (0.0889)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [616][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.1916 (0.1667)	Prec@1 91.406 (94.206)	Prec@5 100.000 (99.884)
TRAINING - Epoch: [616][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.0753 (0.1692)	Prec@1 97.656 (94.174)	Prec@5 100.000 (99.911)
TRAINING - Epoch: [616][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1286 (0.1676)	Prec@1 94.531 (94.196)	Prec@5 100.000 (99.922)
EVALUATING - Epoch: [616][0/79]	Time 0.424 (0.424)	Data 0.385 (0.385)	Loss 0.3271 (0.3271)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:11

 Epoch: 617	Training Loss 0.1699 	Training Prec@1 94.148 	Training Prec@5 99.930 	Validation Loss 0.5186 	Validation Prec@1 84.680 	Validation Prec@5 99.330 

lr: 0.03284960250523236
TRAINING - Epoch: [617][0/391]	Time 1.265 (1.265)	Data 0.411 (0.411)	Loss 0.1528 (0.1528)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [617][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.1037 (0.1594)	Prec@1 96.875 (94.299)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [617][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.1546 (0.1681)	Prec@1 93.750 (94.096)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [617][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1088 (0.1677)	Prec@1 96.875 (94.072)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [617][0/79]	Time 0.402 (0.402)	Data 0.375 (0.375)	Loss 0.4443 (0.4443)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:50

 Epoch: 618	Training Loss 0.1731 	Training Prec@1 93.928 	Training Prec@5 99.940 	Validation Loss 0.4800 	Validation Prec@1 85.520 	Validation Prec@5 99.290 

lr: 0.03270154549135706
TRAINING - Epoch: [618][0/391]	Time 1.256 (1.256)	Data 0.360 (0.360)	Loss 0.0784 (0.0784)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [618][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.1199 (0.1722)	Prec@1 95.312 (93.812)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [618][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0925 (0.1709)	Prec@1 97.656 (93.902)	Prec@5 100.000 (99.926)
TRAINING - Epoch: [618][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.2153 (0.1732)	Prec@1 92.969 (93.817)	Prec@5 100.000 (99.920)
EVALUATING - Epoch: [618][0/79]	Time 0.453 (0.453)	Data 0.417 (0.417)	Loss 0.2464 (0.2464)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:07

 Epoch: 619	Training Loss 0.1723 	Training Prec@1 93.880 	Training Prec@5 99.922 	Validation Loss 0.4200 	Validation Prec@1 87.030 	Validation Prec@5 99.310 

lr: 0.03255366058031195
TRAINING - Epoch: [619][0/391]	Time 1.573 (1.573)	Data 0.451 (0.451)	Loss 0.1368 (0.1368)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [619][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.1312 (0.1546)	Prec@1 95.312 (94.508)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [619][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0933 (0.1610)	Prec@1 96.875 (94.236)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [619][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.2743 (0.1615)	Prec@1 88.281 (94.277)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [619][0/79]	Time 0.449 (0.449)	Data 0.406 (0.406)	Loss 0.3109 (0.3109)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:55

 Epoch: 620	Training Loss 0.1626 	Training Prec@1 94.256 	Training Prec@5 99.944 	Validation Loss 0.4394 	Validation Prec@1 86.560 	Validation Prec@5 99.430 

lr: 0.03240594924340833
TRAINING - Epoch: [620][0/391]	Time 1.282 (1.282)	Data 0.421 (0.421)	Loss 0.1196 (0.1196)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [620][100/391]	Time 0.111 (0.126)	Data 0.000 (0.004)	Loss 0.1456 (0.1489)	Prec@1 93.750 (94.833)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [620][200/391]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2206 (0.1591)	Prec@1 91.406 (94.465)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [620][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.2463 (0.1618)	Prec@1 91.406 (94.388)	Prec@5 100.000 (99.927)
EVALUATING - Epoch: [620][0/79]	Time 0.443 (0.443)	Data 0.401 (0.401)	Loss 0.3465 (0.3465)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:25

 Epoch: 621	Training Loss 0.1646 	Training Prec@1 94.314 	Training Prec@5 99.922 	Validation Loss 0.4034 	Validation Prec@1 87.620 	Validation Prec@5 99.550 

lr: 0.03225841295023066
TRAINING - Epoch: [621][0/391]	Time 1.359 (1.359)	Data 0.459 (0.459)	Loss 0.2581 (0.2581)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [621][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.0992 (0.1617)	Prec@1 97.656 (94.624)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [621][200/391]	Time 0.112 (0.119)	Data 0.000 (0.003)	Loss 0.1507 (0.1598)	Prec@1 95.312 (94.566)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [621][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1555 (0.1616)	Prec@1 95.312 (94.464)	Prec@5 100.000 (99.948)
EVALUATING - Epoch: [621][0/79]	Time 0.437 (0.437)	Data 0.403 (0.403)	Loss 0.3794 (0.3794)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:56

 Epoch: 622	Training Loss 0.1630 	Training Prec@1 94.378 	Training Prec@5 99.936 	Validation Loss 0.4262 	Validation Prec@1 87.580 	Validation Prec@5 99.490 

lr: 0.03211105316862179
TRAINING - Epoch: [622][0/391]	Time 1.257 (1.257)	Data 0.414 (0.414)	Loss 0.1159 (0.1159)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [622][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.0968 (0.1569)	Prec@1 95.312 (94.407)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [622][200/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.1651 (0.1588)	Prec@1 95.312 (94.387)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [622][300/391]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.1886 (0.1635)	Prec@1 93.750 (94.334)	Prec@5 100.000 (99.925)
EVALUATING - Epoch: [622][0/79]	Time 0.446 (0.446)	Data 0.391 (0.391)	Loss 0.3455 (0.3455)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:01

 Epoch: 623	Training Loss 0.1672 	Training Prec@1 94.214 	Training Prec@5 99.922 	Validation Loss 0.4307 	Validation Prec@1 87.140 	Validation Prec@5 99.650 

lr: 0.031963871364668536
TRAINING - Epoch: [623][0/391]	Time 1.256 (1.256)	Data 0.409 (0.409)	Loss 0.2091 (0.2091)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [623][100/391]	Time 0.111 (0.125)	Data 0.000 (0.004)	Loss 0.1602 (0.1597)	Prec@1 93.750 (94.407)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [623][200/391]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1377 (0.1638)	Prec@1 94.531 (94.298)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [623][300/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2520 (0.1643)	Prec@1 89.844 (94.269)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [623][0/79]	Time 0.429 (0.429)	Data 0.394 (0.394)	Loss 0.3446 (0.3446)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:03

 Epoch: 624	Training Loss 0.1640 	Training Prec@1 94.298 	Training Prec@5 99.932 	Validation Loss 0.4506 	Validation Prec@1 86.180 	Validation Prec@5 99.530 

lr: 0.03181686900268693
TRAINING - Epoch: [624][0/391]	Time 1.310 (1.310)	Data 0.433 (0.433)	Loss 0.1669 (0.1669)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [624][100/391]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.1393 (0.1574)	Prec@1 94.531 (94.500)	Prec@5 100.000 (99.907)
TRAINING - Epoch: [624][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.2033 (0.1631)	Prec@1 92.188 (94.236)	Prec@5 100.000 (99.918)
TRAINING - Epoch: [624][300/391]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1854 (0.1634)	Prec@1 92.188 (94.196)	Prec@5 100.000 (99.925)
EVALUATING - Epoch: [624][0/79]	Time 0.436 (0.436)	Data 0.393 (0.393)	Loss 0.3762 (0.3762)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:36:45

 Epoch: 625	Training Loss 0.1635 	Training Prec@1 94.138 	Training Prec@5 99.932 	Validation Loss 0.4039 	Validation Prec@1 87.650 	Validation Prec@5 99.480 

lr: 0.031670047545207816
TRAINING - Epoch: [625][0/391]	Time 1.274 (1.274)	Data 0.366 (0.366)	Loss 0.1629 (0.1629)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [625][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.1117 (0.1476)	Prec@1 96.094 (94.732)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [625][200/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.2134 (0.1503)	Prec@1 92.969 (94.694)	Prec@5 99.219 (99.938)
TRAINING - Epoch: [625][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.1507 (0.1544)	Prec@1 91.406 (94.510)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [625][0/79]	Time 0.426 (0.426)	Data 0.394 (0.394)	Loss 0.3546 (0.3546)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:28

 Epoch: 626	Training Loss 0.1592 	Training Prec@1 94.378 	Training Prec@5 99.934 	Validation Loss 0.4884 	Validation Prec@1 85.190 	Validation Prec@5 99.370 

lr: 0.03152340845296216
TRAINING - Epoch: [626][0/391]	Time 1.237 (1.237)	Data 0.367 (0.367)	Loss 0.1544 (0.1544)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [626][100/391]	Time 0.108 (0.115)	Data 0.000 (0.004)	Loss 0.1317 (0.1526)	Prec@1 94.531 (94.593)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [626][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1653 (0.1554)	Prec@1 93.750 (94.558)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [626][300/391]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.1283 (0.1591)	Prec@1 96.094 (94.461)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [626][0/79]	Time 0.438 (0.438)	Data 0.407 (0.407)	Loss 0.3215 (0.3215)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:09:42

 Epoch: 627	Training Loss 0.1587 	Training Prec@1 94.516 	Training Prec@5 99.928 	Validation Loss 0.4766 	Validation Prec@1 86.020 	Validation Prec@5 99.510 

lr: 0.03137695318486655
TRAINING - Epoch: [627][0/391]	Time 1.268 (1.268)	Data 0.412 (0.412)	Loss 0.1885 (0.1885)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [627][100/391]	Time 0.112 (0.125)	Data 0.000 (0.004)	Loss 0.1162 (0.1458)	Prec@1 96.875 (95.003)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [627][200/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1700 (0.1490)	Prec@1 94.531 (94.838)	Prec@5 100.000 (99.949)
TRAINING - Epoch: [627][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1466 (0.1578)	Prec@1 92.969 (94.492)	Prec@5 100.000 (99.938)
EVALUATING - Epoch: [627][0/79]	Time 0.433 (0.433)	Data 0.383 (0.383)	Loss 0.3947 (0.3947)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:13

 Epoch: 628	Training Loss 0.1600 	Training Prec@1 94.388 	Training Prec@5 99.930 	Validation Loss 0.4425 	Validation Prec@1 87.380 	Validation Prec@5 99.490 

lr: 0.03123068319800879
TRAINING - Epoch: [628][0/391]	Time 1.286 (1.286)	Data 0.430 (0.430)	Loss 0.0969 (0.0969)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [628][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.2318 (0.1417)	Prec@1 90.625 (94.964)	Prec@5 100.000 (99.923)
TRAINING - Epoch: [628][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1325 (0.1496)	Prec@1 95.312 (94.741)	Prec@5 100.000 (99.922)
TRAINING - Epoch: [628][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.1605 (0.1562)	Prec@1 96.094 (94.487)	Prec@5 100.000 (99.935)
EVALUATING - Epoch: [628][0/79]	Time 0.450 (0.450)	Data 0.415 (0.415)	Loss 0.4127 (0.4127)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:50

 Epoch: 629	Training Loss 0.1591 	Training Prec@1 94.404 	Training Prec@5 99.932 	Validation Loss 0.4147 	Validation Prec@1 87.500 	Validation Prec@5 99.550 

lr: 0.031084599947633226
TRAINING - Epoch: [629][0/391]	Time 1.290 (1.290)	Data 0.433 (0.433)	Loss 0.1345 (0.1345)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [629][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.1442 (0.1538)	Prec@1 96.094 (94.562)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [629][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2513 (0.1541)	Prec@1 89.844 (94.547)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [629][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.1532 (0.1534)	Prec@1 92.188 (94.627)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [629][0/79]	Time 0.410 (0.410)	Data 0.377 (0.377)	Loss 0.5566 (0.5566)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:44	Time of Finish: 2022-03-24 02:09:08

 Epoch: 630	Training Loss 0.1531 	Training Prec@1 94.638 	Training Prec@5 99.958 	Validation Loss 0.4285 	Validation Prec@1 86.930 	Validation Prec@5 99.420 

lr: 0.030938704887126408
TRAINING - Epoch: [630][0/391]	Time 1.301 (1.301)	Data 0.416 (0.416)	Loss 0.1236 (0.1236)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [630][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.1570 (0.1459)	Prec@1 94.531 (94.825)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [630][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2417 (0.1488)	Prec@1 91.406 (94.768)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [630][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.1790 (0.1505)	Prec@1 94.531 (94.677)	Prec@5 100.000 (99.933)
EVALUATING - Epoch: [630][0/79]	Time 0.437 (0.437)	Data 0.399 (0.399)	Loss 0.2839 (0.2839)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:40

 Epoch: 631	Training Loss 0.1529 	Training Prec@1 94.570 	Training Prec@5 99.936 	Validation Loss 0.4151 	Validation Prec@1 87.380 	Validation Prec@5 99.520 

lr: 0.03079299946800255
TRAINING - Epoch: [631][0/391]	Time 1.270 (1.270)	Data 0.363 (0.363)	Loss 0.0559 (0.0559)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [631][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.2217 (0.1603)	Prec@1 89.062 (94.415)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [631][200/391]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1250 (0.1554)	Prec@1 96.094 (94.555)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [631][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1800 (0.1586)	Prec@1 92.188 (94.388)	Prec@5 99.219 (99.945)
EVALUATING - Epoch: [631][0/79]	Time 0.443 (0.443)	Data 0.396 (0.396)	Loss 0.3243 (0.3243)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:39:31

 Epoch: 632	Training Loss 0.1602 	Training Prec@1 94.302 	Training Prec@5 99.938 	Validation Loss 0.4448 	Validation Prec@1 86.530 	Validation Prec@5 99.520 

lr: 0.03064748513988914
TRAINING - Epoch: [632][0/391]	Time 1.236 (1.236)	Data 0.359 (0.359)	Loss 0.2069 (0.2069)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [632][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.1314 (0.1558)	Prec@1 95.312 (94.369)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [632][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1702 (0.1553)	Prec@1 94.531 (94.477)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [632][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1816 (0.1526)	Prec@1 95.312 (94.529)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [632][0/79]	Time 0.463 (0.463)	Data 0.436 (0.436)	Loss 0.3318 (0.3318)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:48

 Epoch: 633	Training Loss 0.1516 	Training Prec@1 94.576 	Training Prec@5 99.948 	Validation Loss 0.4337 	Validation Prec@1 87.730 	Validation Prec@5 99.520 

lr: 0.03050216335051247
TRAINING - Epoch: [633][0/391]	Time 1.225 (1.225)	Data 0.373 (0.373)	Loss 0.1854 (0.1854)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [633][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.2628 (0.1482)	Prec@1 90.625 (94.756)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [633][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.0927 (0.1447)	Prec@1 96.875 (94.970)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [633][300/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.1858 (0.1462)	Prec@1 93.750 (94.926)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [633][0/79]	Time 0.441 (0.441)	Data 0.403 (0.403)	Loss 0.3923 (0.3923)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:56

 Epoch: 634	Training Loss 0.1479 	Training Prec@1 94.824 	Training Prec@5 99.954 	Validation Loss 0.4518 	Validation Prec@1 87.450 	Validation Prec@5 99.350 

lr: 0.030357035545683312
TRAINING - Epoch: [634][0/391]	Time 1.293 (1.293)	Data 0.453 (0.453)	Loss 0.1229 (0.1229)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [634][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.2085 (0.1514)	Prec@1 93.750 (94.624)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [634][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1450 (0.1493)	Prec@1 95.312 (94.710)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [634][300/391]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.1503 (0.1519)	Prec@1 93.750 (94.565)	Prec@5 100.000 (99.945)
EVALUATING - Epoch: [634][0/79]	Time 0.471 (0.471)	Data 0.435 (0.435)	Loss 0.2655 (0.2655)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:09:39

 Epoch: 635	Training Loss 0.1532 	Training Prec@1 94.568 	Training Prec@5 99.940 	Validation Loss 0.3969 	Validation Prec@1 87.760 	Validation Prec@5 99.460 

lr: 0.030212103169282394
TRAINING - Epoch: [635][0/391]	Time 1.282 (1.282)	Data 0.419 (0.419)	Loss 0.1834 (0.1834)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [635][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.1106 (0.1437)	Prec@1 96.094 (94.995)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [635][200/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.1516 (0.1486)	Prec@1 95.312 (94.799)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [635][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1105 (0.1505)	Prec@1 95.312 (94.752)	Prec@5 100.000 (99.943)
EVALUATING - Epoch: [635][0/79]	Time 0.432 (0.432)	Data 0.383 (0.383)	Loss 0.3455 (0.3455)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:07

 Epoch: 636	Training Loss 0.1502 	Training Prec@1 94.740 	Training Prec@5 99.952 	Validation Loss 0.4143 	Validation Prec@1 87.690 	Validation Prec@5 99.570 

lr: 0.03006736766324622
TRAINING - Epoch: [636][0/391]	Time 1.286 (1.286)	Data 0.434 (0.434)	Loss 0.2390 (0.2390)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [636][100/391]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.1648 (0.1501)	Prec@1 92.188 (94.485)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [636][200/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.1201 (0.1508)	Prec@1 95.312 (94.531)	Prec@5 99.219 (99.961)
TRAINING - Epoch: [636][300/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.0825 (0.1494)	Prec@1 98.438 (94.666)	Prec@5 100.000 (99.945)
EVALUATING - Epoch: [636][0/79]	Time 0.441 (0.441)	Data 0.396 (0.396)	Loss 0.3579 (0.3579)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:52

 Epoch: 637	Training Loss 0.1511 	Training Prec@1 94.602 	Training Prec@5 99.952 	Validation Loss 0.3971 	Validation Prec@1 88.160 	Validation Prec@5 99.490 

lr: 0.029922830467552536
TRAINING - Epoch: [637][0/391]	Time 1.286 (1.286)	Data 0.437 (0.437)	Loss 0.0742 (0.0742)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [637][100/391]	Time 0.103 (0.116)	Data 0.000 (0.005)	Loss 0.0419 (0.1390)	Prec@1 100.000 (95.189)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [637][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1069 (0.1425)	Prec@1 96.875 (94.970)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [637][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.1354 (0.1441)	Prec@1 94.531 (94.908)	Prec@5 100.000 (99.933)
EVALUATING - Epoch: [637][0/79]	Time 0.436 (0.436)	Data 0.406 (0.406)	Loss 0.3668 (0.3668)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:09:16

 Epoch: 638	Training Loss 0.1460 	Training Prec@1 94.838 	Training Prec@5 99.928 	Validation Loss 0.4258 	Validation Prec@1 87.370 	Validation Prec@5 99.390 

lr: 0.02977849302020614
TRAINING - Epoch: [638][0/391]	Time 1.219 (1.219)	Data 0.372 (0.372)	Loss 0.1811 (0.1811)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [638][100/391]	Time 0.108 (0.121)	Data 0.000 (0.004)	Loss 0.0681 (0.1514)	Prec@1 96.875 (94.578)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [638][200/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.1411 (0.1513)	Prec@1 95.312 (94.660)	Prec@5 99.219 (99.953)
TRAINING - Epoch: [638][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.1805 (0.1463)	Prec@1 94.531 (94.845)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [638][0/79]	Time 0.437 (0.437)	Data 0.403 (0.403)	Loss 0.2958 (0.2958)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:25:05

 Epoch: 639	Training Loss 0.1470 	Training Prec@1 94.796 	Training Prec@5 99.954 	Validation Loss 0.3985 	Validation Prec@1 87.820 	Validation Prec@5 99.480 

lr: 0.029634356757224558
TRAINING - Epoch: [639][0/391]	Time 1.273 (1.273)	Data 0.356 (0.356)	Loss 0.1715 (0.1715)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [639][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.0985 (0.1468)	Prec@1 96.094 (94.988)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [639][200/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.1151 (0.1459)	Prec@1 94.531 (94.885)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [639][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.2002 (0.1461)	Prec@1 92.188 (94.848)	Prec@5 100.000 (99.940)
EVALUATING - Epoch: [639][0/79]	Time 0.433 (0.433)	Data 0.397 (0.397)	Loss 0.2938 (0.2938)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:03

 Epoch: 640	Training Loss 0.1457 	Training Prec@1 94.862 	Training Prec@5 99.942 	Validation Loss 0.3771 	Validation Prec@1 88.660 	Validation Prec@5 99.570 

lr: 0.02949042311262364
TRAINING - Epoch: [640][0/391]	Time 1.294 (1.294)	Data 0.442 (0.442)	Loss 0.0920 (0.0920)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [640][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.1405 (0.1315)	Prec@1 93.750 (95.312)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [640][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.1454 (0.1364)	Prec@1 96.094 (95.281)	Prec@5 99.219 (99.946)
TRAINING - Epoch: [640][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.1146 (0.1397)	Prec@1 95.312 (95.105)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [640][0/79]	Time 0.427 (0.427)	Data 0.396 (0.396)	Loss 0.3633 (0.3633)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:40

 Epoch: 641	Training Loss 0.1415 	Training Prec@1 95.092 	Training Prec@5 99.950 	Validation Loss 0.4263 	Validation Prec@1 87.850 	Validation Prec@5 99.470 

lr: 0.029346693518403452
TRAINING - Epoch: [641][0/391]	Time 1.242 (1.242)	Data 0.343 (0.343)	Loss 0.1477 (0.1477)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [641][100/391]	Time 0.121 (0.127)	Data 0.004 (0.004)	Loss 0.1638 (0.1406)	Prec@1 94.531 (94.872)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [641][200/391]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.1630 (0.1389)	Prec@1 92.969 (94.912)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [641][300/391]	Time 0.115 (0.118)	Data 0.000 (0.001)	Loss 0.0751 (0.1381)	Prec@1 97.656 (94.985)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [641][0/79]	Time 0.439 (0.439)	Data 0.394 (0.394)	Loss 0.3814 (0.3814)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:48

 Epoch: 642	Training Loss 0.1405 	Training Prec@1 94.942 	Training Prec@5 99.950 	Validation Loss 0.4431 	Validation Prec@1 87.130 	Validation Prec@5 99.400 

lr: 0.02920316940453393
TRAINING - Epoch: [642][0/391]	Time 1.328 (1.328)	Data 0.439 (0.439)	Loss 0.1386 (0.1386)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [642][100/391]	Time 0.110 (0.126)	Data 0.000 (0.005)	Loss 0.1258 (0.1360)	Prec@1 94.531 (95.204)	Prec@5 100.000 (99.930)
TRAINING - Epoch: [642][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.2636 (0.1383)	Prec@1 89.062 (95.149)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [642][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.2091 (0.1385)	Prec@1 91.406 (95.076)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [642][0/79]	Time 0.440 (0.440)	Data 0.408 (0.408)	Loss 0.4232 (0.4232)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:20

 Epoch: 643	Training Loss 0.1398 	Training Prec@1 95.020 	Training Prec@5 99.950 	Validation Loss 0.5115 	Validation Prec@1 85.290 	Validation Prec@5 99.360 

lr: 0.02905985219894069
TRAINING - Epoch: [643][0/391]	Time 1.297 (1.297)	Data 0.442 (0.442)	Loss 0.1089 (0.1089)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [643][100/391]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.1593 (0.1372)	Prec@1 94.531 (95.204)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [643][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.2437 (0.1399)	Prec@1 93.750 (95.223)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [643][300/391]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.2470 (0.1419)	Prec@1 92.188 (95.058)	Prec@5 99.219 (99.956)
EVALUATING - Epoch: [643][0/79]	Time 0.418 (0.418)	Data 0.386 (0.386)	Loss 0.4159 (0.4159)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:52

 Epoch: 644	Training Loss 0.1426 	Training Prec@1 94.956 	Training Prec@5 99.950 	Validation Loss 0.5225 	Validation Prec@1 85.180 	Validation Prec@5 99.250 

lr: 0.028916743327490797
TRAINING - Epoch: [644][0/391]	Time 1.295 (1.295)	Data 0.438 (0.438)	Loss 0.1128 (0.1128)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [644][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.1386 (0.1418)	Prec@1 95.312 (94.933)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [644][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.0775 (0.1384)	Prec@1 97.656 (94.947)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [644][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.1408 (0.1405)	Prec@1 94.531 (94.892)	Prec@5 100.000 (99.945)
EVALUATING - Epoch: [644][0/79]	Time 0.412 (0.412)	Data 0.384 (0.384)	Loss 0.3695 (0.3695)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:12

 Epoch: 645	Training Loss 0.1419 	Training Prec@1 94.886 	Training Prec@5 99.950 	Validation Loss 0.4396 	Validation Prec@1 86.900 	Validation Prec@5 99.400 

lr: 0.02877384421397861
TRAINING - Epoch: [645][0/391]	Time 1.287 (1.287)	Data 0.418 (0.418)	Loss 0.1717 (0.1717)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [645][100/391]	Time 0.116 (0.127)	Data 0.000 (0.004)	Loss 0.1301 (0.1375)	Prec@1 93.750 (95.204)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [645][200/391]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.1049 (0.1389)	Prec@1 96.094 (95.075)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [645][300/391]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.0655 (0.1358)	Prec@1 99.219 (95.211)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [645][0/79]	Time 0.422 (0.422)	Data 0.386 (0.386)	Loss 0.3528 (0.3528)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:10

 Epoch: 646	Training Loss 0.1383 	Training Prec@1 95.136 	Training Prec@5 99.962 	Validation Loss 0.4263 	Validation Prec@1 87.280 	Validation Prec@5 99.530 

lr: 0.02863115628011157
TRAINING - Epoch: [646][0/391]	Time 1.286 (1.286)	Data 0.431 (0.431)	Loss 0.0404 (0.0404)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [646][100/391]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.1184 (0.1409)	Prec@1 95.312 (94.964)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [646][200/391]	Time 0.120 (0.123)	Data 0.000 (0.003)	Loss 0.1642 (0.1415)	Prec@1 92.188 (94.866)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [646][300/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1243 (0.1428)	Prec@1 94.531 (94.895)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [646][0/79]	Time 0.439 (0.439)	Data 0.403 (0.403)	Loss 0.3606 (0.3606)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:47

 Epoch: 647	Training Loss 0.1428 	Training Prec@1 94.948 	Training Prec@5 99.956 	Validation Loss 0.3954 	Validation Prec@1 88.220 	Validation Prec@5 99.570 

lr: 0.02848868094549614
TRAINING - Epoch: [647][0/391]	Time 1.311 (1.311)	Data 0.425 (0.425)	Loss 0.1320 (0.1320)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [647][100/391]	Time 0.119 (0.131)	Data 0.000 (0.005)	Loss 0.1064 (0.1298)	Prec@1 96.875 (95.289)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [647][200/391]	Time 0.121 (0.125)	Data 0.001 (0.003)	Loss 0.1241 (0.1379)	Prec@1 96.094 (95.138)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [647][300/391]	Time 0.109 (0.121)	Data 0.000 (0.002)	Loss 0.0552 (0.1343)	Prec@1 98.438 (95.242)	Prec@5 100.000 (99.964)
EVALUATING - Epoch: [647][0/79]	Time 0.446 (0.446)	Data 0.405 (0.405)	Loss 0.4567 (0.4567)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:31

 Epoch: 648	Training Loss 0.1356 	Training Prec@1 95.180 	Training Prec@5 99.968 	Validation Loss 0.4608 	Validation Prec@1 86.790 	Validation Prec@5 99.450 

lr: 0.028346419627623565
TRAINING - Epoch: [648][0/391]	Time 1.311 (1.311)	Data 0.424 (0.424)	Loss 0.0852 (0.0852)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [648][100/391]	Time 0.112 (0.129)	Data 0.000 (0.005)	Loss 0.1100 (0.1299)	Prec@1 95.312 (95.297)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [648][200/391]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.1230 (0.1332)	Prec@1 95.312 (95.095)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [648][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2008 (0.1354)	Prec@1 93.750 (95.053)	Prec@5 99.219 (99.956)
EVALUATING - Epoch: [648][0/79]	Time 0.423 (0.423)	Data 0.386 (0.386)	Loss 0.5037 (0.5037)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:40:43

 Epoch: 649	Training Loss 0.1364 	Training Prec@1 95.054 	Training Prec@5 99.962 	Validation Loss 0.5018 	Validation Prec@1 86.530 	Validation Prec@5 99.490 

lr: 0.02820437374185586
TRAINING - Epoch: [649][0/391]	Time 1.241 (1.241)	Data 0.358 (0.358)	Loss 0.1015 (0.1015)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [649][100/391]	Time 0.110 (0.126)	Data 0.000 (0.004)	Loss 0.1620 (0.1330)	Prec@1 96.875 (95.374)	Prec@5 100.000 (99.946)
TRAINING - Epoch: [649][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.1593 (0.1347)	Prec@1 95.312 (95.278)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [649][300/391]	Time 0.117 (0.117)	Data 0.001 (0.002)	Loss 0.2366 (0.1370)	Prec@1 91.406 (95.141)	Prec@5 99.219 (99.951)
EVALUATING - Epoch: [649][0/79]	Time 0.467 (0.467)	Data 0.439 (0.439)	Loss 0.2969 (0.2969)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:09

 Epoch: 650	Training Loss 0.1389 	Training Prec@1 95.062 	Training Prec@5 99.956 	Validation Loss 0.4047 	Validation Prec@1 88.210 	Validation Prec@5 99.590 

lr: 0.02806254470141173
TRAINING - Epoch: [650][0/391]	Time 1.264 (1.264)	Data 0.409 (0.409)	Loss 0.1481 (0.1481)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [650][100/391]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.1288 (0.1258)	Prec@1 96.094 (95.506)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [650][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0862 (0.1275)	Prec@1 96.094 (95.429)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [650][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.1221 (0.1302)	Prec@1 95.312 (95.284)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [650][0/79]	Time 0.414 (0.414)	Data 0.382 (0.382)	Loss 0.3295 (0.3295)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:50

 Epoch: 651	Training Loss 0.1320 	Training Prec@1 95.220 	Training Prec@5 99.962 	Validation Loss 0.4228 	Validation Prec@1 87.430 	Validation Prec@5 99.500 

lr: 0.027920933917352432
TRAINING - Epoch: [651][0/391]	Time 1.269 (1.269)	Data 0.418 (0.418)	Loss 0.0707 (0.0707)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [651][100/391]	Time 0.115 (0.126)	Data 0.000 (0.005)	Loss 0.1653 (0.1371)	Prec@1 93.750 (95.119)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [651][200/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2056 (0.1341)	Prec@1 92.969 (95.165)	Prec@5 100.000 (99.942)
TRAINING - Epoch: [651][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1169 (0.1368)	Prec@1 95.312 (95.074)	Prec@5 99.219 (99.943)
EVALUATING - Epoch: [651][0/79]	Time 0.434 (0.434)	Data 0.383 (0.383)	Loss 0.4825 (0.4825)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:42

 Epoch: 652	Training Loss 0.1388 	Training Prec@1 95.036 	Training Prec@5 99.946 	Validation Loss 0.4318 	Validation Prec@1 87.700 	Validation Prec@5 99.510 

lr: 0.027779542798567793
TRAINING - Epoch: [652][0/391]	Time 1.560 (1.560)	Data 0.403 (0.403)	Loss 0.1798 (0.1798)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [652][100/391]	Time 0.115 (0.136)	Data 0.000 (0.004)	Loss 0.1013 (0.1280)	Prec@1 96.094 (95.483)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [652][200/391]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.0550 (0.1299)	Prec@1 97.656 (95.519)	Prec@5 100.000 (99.965)
TRAINING - Epoch: [652][300/391]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.1964 (0.1323)	Prec@1 94.531 (95.377)	Prec@5 99.219 (99.961)
EVALUATING - Epoch: [652][0/79]	Time 0.443 (0.443)	Data 0.404 (0.404)	Loss 0.4370 (0.4370)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:41:06

 Epoch: 653	Training Loss 0.1341 	Training Prec@1 95.266 	Training Prec@5 99.950 	Validation Loss 0.4536 	Validation Prec@1 86.760 	Validation Prec@5 99.510 

lr: 0.02763837275176221
TRAINING - Epoch: [653][0/391]	Time 1.560 (1.560)	Data 0.427 (0.427)	Loss 0.1745 (0.1745)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [653][100/391]	Time 0.119 (0.130)	Data 0.000 (0.005)	Loss 0.0719 (0.1272)	Prec@1 98.438 (95.452)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [653][200/391]	Time 0.112 (0.123)	Data 0.000 (0.002)	Loss 0.1007 (0.1289)	Prec@1 96.094 (95.406)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [653][300/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.1215 (0.1294)	Prec@1 94.531 (95.419)	Prec@5 100.000 (99.964)
EVALUATING - Epoch: [653][0/79]	Time 0.447 (0.447)	Data 0.410 (0.410)	Loss 0.3745 (0.3745)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:39:22

 Epoch: 654	Training Loss 0.1295 	Training Prec@1 95.390 	Training Prec@5 99.962 	Validation Loss 0.4570 	Validation Prec@1 86.960 	Validation Prec@5 99.510 

lr: 0.027497425181440598
TRAINING - Epoch: [654][0/391]	Time 1.284 (1.284)	Data 0.437 (0.437)	Loss 0.1148 (0.1148)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [654][100/391]	Time 0.110 (0.122)	Data 0.000 (0.005)	Loss 0.1609 (0.1233)	Prec@1 93.750 (95.668)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [654][200/391]	Time 0.120 (0.116)	Data 0.000 (0.002)	Loss 0.1557 (0.1239)	Prec@1 94.531 (95.701)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [654][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.0666 (0.1267)	Prec@1 97.656 (95.510)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [654][0/79]	Time 0.432 (0.432)	Data 0.394 (0.394)	Loss 0.3319 (0.3319)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:23:31

 Epoch: 655	Training Loss 0.1273 	Training Prec@1 95.490 	Training Prec@5 99.968 	Validation Loss 0.4279 	Validation Prec@1 87.790 	Validation Prec@5 99.440 

lr: 0.027356701489894455
TRAINING - Epoch: [655][0/391]	Time 1.283 (1.283)	Data 0.428 (0.428)	Loss 0.1017 (0.1017)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [655][100/391]	Time 0.112 (0.122)	Data 0.000 (0.005)	Loss 0.0746 (0.1246)	Prec@1 96.875 (95.637)	Prec@5 100.000 (99.938)
TRAINING - Epoch: [655][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1168 (0.1238)	Prec@1 95.312 (95.643)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [655][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1250 (0.1252)	Prec@1 96.094 (95.580)	Prec@5 100.000 (99.951)
EVALUATING - Epoch: [655][0/79]	Time 0.421 (0.421)	Data 0.392 (0.392)	Loss 0.4424 (0.4424)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:38

 Epoch: 656	Training Loss 0.1251 	Training Prec@1 95.570 	Training Prec@5 99.956 	Validation Loss 0.4924 	Validation Prec@1 85.460 	Validation Prec@5 99.520 

lr: 0.02721620307718792
TRAINING - Epoch: [656][0/391]	Time 1.263 (1.263)	Data 0.405 (0.405)	Loss 0.1061 (0.1061)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [656][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.0852 (0.1241)	Prec@1 96.875 (95.529)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [656][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.1586 (0.1315)	Prec@1 94.531 (95.351)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [656][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0921 (0.1306)	Prec@1 96.875 (95.388)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [656][0/79]	Time 0.436 (0.436)	Data 0.404 (0.404)	Loss 0.4516 (0.4516)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:13

 Epoch: 657	Training Loss 0.1301 	Training Prec@1 95.436 	Training Prec@5 99.976 	Validation Loss 0.4255 	Validation Prec@1 88.050 	Validation Prec@5 99.520 

lr: 0.0270759313411438
TRAINING - Epoch: [657][0/391]	Time 1.271 (1.271)	Data 0.415 (0.415)	Loss 0.1909 (0.1909)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [657][100/391]	Time 0.112 (0.124)	Data 0.000 (0.004)	Loss 0.1505 (0.1235)	Prec@1 93.750 (95.684)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [657][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1150 (0.1232)	Prec@1 95.312 (95.553)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [657][300/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1613 (0.1242)	Prec@1 94.531 (95.541)	Prec@5 100.000 (99.964)
EVALUATING - Epoch: [657][0/79]	Time 0.431 (0.431)	Data 0.403 (0.403)	Loss 0.3867 (0.3867)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:50

 Epoch: 658	Training Loss 0.1260 	Training Prec@1 95.518 	Training Prec@5 99.956 	Validation Loss 0.3905 	Validation Prec@1 88.740 	Validation Prec@5 99.620 

lr: 0.026935887677329712
TRAINING - Epoch: [658][0/391]	Time 1.332 (1.332)	Data 0.481 (0.481)	Loss 0.1198 (0.1198)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [658][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.1001 (0.1168)	Prec@1 96.094 (95.908)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [658][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.1138 (0.1231)	Prec@1 95.312 (95.752)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [658][300/391]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1194 (0.1219)	Prec@1 94.531 (95.743)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [658][0/79]	Time 0.415 (0.415)	Data 0.389 (0.389)	Loss 0.2836 (0.2836)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:51

 Epoch: 659	Training Loss 0.1230 	Training Prec@1 95.696 	Training Prec@5 99.964 	Validation Loss 0.4165 	Validation Prec@1 88.070 	Validation Prec@5 99.540 

lr: 0.026796073479044162
TRAINING - Epoch: [659][0/391]	Time 1.212 (1.212)	Data 0.343 (0.343)	Loss 0.2249 (0.2249)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [659][100/391]	Time 0.113 (0.127)	Data 0.000 (0.004)	Loss 0.0928 (0.1198)	Prec@1 97.656 (95.823)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [659][200/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1334 (0.1222)	Prec@1 96.094 (95.651)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [659][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.0975 (0.1233)	Prec@1 95.312 (95.653)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [659][0/79]	Time 0.433 (0.433)	Data 0.386 (0.386)	Loss 0.2833 (0.2833)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:45

 Epoch: 660	Training Loss 0.1245 	Training Prec@1 95.608 	Training Prec@5 99.978 	Validation Loss 0.4821 	Validation Prec@1 86.810 	Validation Prec@5 99.480 

lr: 0.026656490137302702
TRAINING - Epoch: [660][0/391]	Time 1.268 (1.268)	Data 0.352 (0.352)	Loss 0.0955 (0.0955)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [660][100/391]	Time 0.116 (0.127)	Data 0.000 (0.004)	Loss 0.1127 (0.1187)	Prec@1 95.312 (95.668)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [660][200/391]	Time 0.111 (0.121)	Data 0.000 (0.002)	Loss 0.1611 (0.1227)	Prec@1 93.750 (95.639)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [660][300/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.1104 (0.1234)	Prec@1 94.531 (95.564)	Prec@5 99.219 (99.979)
EVALUATING - Epoch: [660][0/79]	Time 0.420 (0.420)	Data 0.383 (0.383)	Loss 0.4124 (0.4124)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:21

 Epoch: 661	Training Loss 0.1229 	Training Prec@1 95.584 	Training Prec@5 99.974 	Validation Loss 0.4536 	Validation Prec@1 87.250 	Validation Prec@5 99.360 

lr: 0.02651713904082407
TRAINING - Epoch: [661][0/391]	Time 1.244 (1.244)	Data 0.369 (0.369)	Loss 0.0813 (0.0813)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [661][100/391]	Time 0.110 (0.124)	Data 0.000 (0.004)	Loss 0.0915 (0.1218)	Prec@1 96.094 (95.599)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [661][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.1268 (0.1201)	Prec@1 94.531 (95.655)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [661][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1770 (0.1201)	Prec@1 92.969 (95.655)	Prec@5 100.000 (99.971)
EVALUATING - Epoch: [661][0/79]	Time 0.439 (0.439)	Data 0.411 (0.411)	Loss 0.4200 (0.4200)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:04

 Epoch: 662	Training Loss 0.1224 	Training Prec@1 95.612 	Training Prec@5 99.962 	Validation Loss 0.4420 	Validation Prec@1 87.490 	Validation Prec@5 99.420 

lr: 0.026378021576016434
TRAINING - Epoch: [662][0/391]	Time 1.313 (1.313)	Data 0.465 (0.465)	Loss 0.0693 (0.0693)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [662][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.0937 (0.1257)	Prec@1 95.312 (95.529)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [662][200/391]	Time 0.118 (0.118)	Data 0.000 (0.003)	Loss 0.1065 (0.1210)	Prec@1 96.094 (95.763)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [662][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.1991 (0.1221)	Prec@1 91.406 (95.707)	Prec@5 99.219 (99.977)
EVALUATING - Epoch: [662][0/79]	Time 0.443 (0.443)	Data 0.409 (0.409)	Loss 0.3168 (0.3168)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:17

 Epoch: 663	Training Loss 0.1229 	Training Prec@1 95.680 	Training Prec@5 99.974 	Validation Loss 0.4134 	Validation Prec@1 88.050 	Validation Prec@5 99.540 

lr: 0.026239139126963507
TRAINING - Epoch: [663][0/391]	Time 1.585 (1.585)	Data 0.450 (0.450)	Loss 0.0582 (0.0582)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [663][100/391]	Time 0.120 (0.135)	Data 0.000 (0.005)	Loss 0.1166 (0.1200)	Prec@1 96.094 (95.730)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [663][200/391]	Time 0.123 (0.128)	Data 0.000 (0.003)	Loss 0.0823 (0.1204)	Prec@1 97.656 (95.713)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [663][300/391]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.1241 (0.1193)	Prec@1 95.312 (95.743)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [663][0/79]	Time 0.417 (0.417)	Data 0.379 (0.379)	Loss 0.2704 (0.2704)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:47:42

 Epoch: 664	Training Loss 0.1202 	Training Prec@1 95.726 	Training Prec@5 99.976 	Validation Loss 0.4078 	Validation Prec@1 88.120 	Validation Prec@5 99.440 

lr: 0.026100493075410857
TRAINING - Epoch: [664][0/391]	Time 1.285 (1.285)	Data 0.439 (0.439)	Loss 0.0945 (0.0945)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [664][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.0575 (0.1145)	Prec@1 96.875 (95.962)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [664][200/391]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.1568 (0.1149)	Prec@1 96.094 (95.857)	Prec@5 99.219 (99.965)
TRAINING - Epoch: [664][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.1641 (0.1165)	Prec@1 95.312 (95.787)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [664][0/79]	Time 0.448 (0.448)	Data 0.418 (0.418)	Loss 0.3444 (0.3444)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:03

 Epoch: 665	Training Loss 0.1183 	Training Prec@1 95.734 	Training Prec@5 99.968 	Validation Loss 0.4459 	Validation Prec@1 87.550 	Validation Prec@5 99.400 

lr: 0.02596208480075205
TRAINING - Epoch: [665][0/391]	Time 1.274 (1.274)	Data 0.419 (0.419)	Loss 0.1568 (0.1568)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [665][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.1883 (0.1214)	Prec@1 90.625 (95.908)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [665][200/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0799 (0.1209)	Prec@1 98.438 (95.876)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [665][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.2060 (0.1207)	Prec@1 92.188 (95.824)	Prec@5 100.000 (99.966)
EVALUATING - Epoch: [665][0/79]	Time 0.436 (0.436)	Data 0.401 (0.401)	Loss 0.3842 (0.3842)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:55

 Epoch: 666	Training Loss 0.1216 	Training Prec@1 95.758 	Training Prec@5 99.968 	Validation Loss 0.4646 	Validation Prec@1 87.200 	Validation Prec@5 99.420 

lr: 0.025823915680015127
TRAINING - Epoch: [666][0/391]	Time 1.337 (1.337)	Data 0.482 (0.482)	Loss 0.0969 (0.0969)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [666][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.1311 (0.1177)	Prec@1 95.312 (95.823)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [666][200/391]	Time 0.109 (0.116)	Data 0.000 (0.003)	Loss 0.1126 (0.1218)	Prec@1 95.312 (95.647)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [666][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.1069 (0.1201)	Prec@1 95.312 (95.660)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [666][0/79]	Time 0.442 (0.442)	Data 0.404 (0.404)	Loss 0.2242 (0.2242)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:53

 Epoch: 667	Training Loss 0.1183 	Training Prec@1 95.720 	Training Prec@5 99.974 	Validation Loss 0.3903 	Validation Prec@1 88.520 	Validation Prec@5 99.520 

lr: 0.025685987087848684
TRAINING - Epoch: [667][0/391]	Time 1.264 (1.264)	Data 0.406 (0.406)	Loss 0.1326 (0.1326)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [667][100/391]	Time 0.118 (0.126)	Data 0.000 (0.004)	Loss 0.0816 (0.1133)	Prec@1 97.656 (96.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [667][200/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.1399 (0.1153)	Prec@1 95.312 (96.020)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [667][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0763 (0.1157)	Prec@1 97.656 (96.000)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [667][0/79]	Time 0.441 (0.441)	Data 0.408 (0.408)	Loss 0.3662 (0.3662)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:29

 Epoch: 668	Training Loss 0.1146 	Training Prec@1 96.026 	Training Prec@5 99.980 	Validation Loss 0.3976 	Validation Prec@1 88.470 	Validation Prec@5 99.600 

lr: 0.025548300396508326
TRAINING - Epoch: [668][0/391]	Time 1.587 (1.587)	Data 0.442 (0.442)	Loss 0.0834 (0.0834)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [668][100/391]	Time 0.121 (0.136)	Data 0.000 (0.005)	Loss 0.0726 (0.1096)	Prec@1 97.656 (96.040)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [668][200/391]	Time 0.117 (0.126)	Data 0.000 (0.003)	Loss 0.0936 (0.1124)	Prec@1 96.094 (95.977)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [668][300/391]	Time 0.107 (0.122)	Data 0.000 (0.002)	Loss 0.1430 (0.1139)	Prec@1 96.094 (95.961)	Prec@5 99.219 (99.971)
EVALUATING - Epoch: [668][0/79]	Time 0.438 (0.438)	Data 0.403 (0.403)	Loss 0.2939 (0.2939)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:12

 Epoch: 669	Training Loss 0.1129 	Training Prec@1 96.022 	Training Prec@5 99.974 	Validation Loss 0.3991 	Validation Prec@1 88.290 	Validation Prec@5 99.590 

lr: 0.025410856975842982
TRAINING - Epoch: [669][0/391]	Time 1.271 (1.271)	Data 0.424 (0.424)	Loss 0.1632 (0.1632)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [669][100/391]	Time 0.108 (0.122)	Data 0.000 (0.005)	Loss 0.0825 (0.1097)	Prec@1 96.875 (96.009)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [669][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.1434 (0.1091)	Prec@1 94.531 (96.051)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [669][300/391]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.1364 (0.1102)	Prec@1 92.188 (96.018)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [669][0/79]	Time 0.425 (0.425)	Data 0.384 (0.384)	Loss 0.4667 (0.4667)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:08

 Epoch: 670	Training Loss 0.1128 	Training Prec@1 95.950 	Training Prec@5 99.966 	Validation Loss 0.4334 	Validation Prec@1 87.650 	Validation Prec@5 99.480 

lr: 0.025273658193281257
TRAINING - Epoch: [670][0/391]	Time 1.308 (1.308)	Data 0.456 (0.456)	Loss 0.1035 (0.1035)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [670][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.1003 (0.1168)	Prec@1 96.094 (95.908)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [670][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.0908 (0.1142)	Prec@1 97.656 (96.004)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [670][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0824 (0.1145)	Prec@1 97.656 (95.969)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [670][0/79]	Time 0.460 (0.460)	Data 0.419 (0.419)	Loss 0.4080 (0.4080)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:25:57

 Epoch: 671	Training Loss 0.1152 	Training Prec@1 95.946 	Training Prec@5 99.968 	Validation Loss 0.3930 	Validation Prec@1 88.520 	Validation Prec@5 99.500 

lr: 0.025136705413817864
TRAINING - Epoch: [671][0/391]	Time 1.280 (1.280)	Data 0.427 (0.427)	Loss 0.1486 (0.1486)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [671][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.1066 (0.1230)	Prec@1 95.312 (95.630)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [671][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0536 (0.1191)	Prec@1 97.656 (95.767)	Prec@5 100.000 (99.957)
TRAINING - Epoch: [671][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.1085 (0.1182)	Prec@1 96.094 (95.816)	Prec@5 100.000 (99.961)
EVALUATING - Epoch: [671][0/79]	Time 0.432 (0.432)	Data 0.385 (0.385)	Loss 0.4208 (0.4208)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:13

 Epoch: 672	Training Loss 0.1176 	Training Prec@1 95.846 	Training Prec@5 99.964 	Validation Loss 0.3926 	Validation Prec@1 88.840 	Validation Prec@5 99.700 

lr: 0.02499999999999998
TRAINING - Epoch: [672][0/391]	Time 1.300 (1.300)	Data 0.446 (0.446)	Loss 0.0679 (0.0679)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [672][100/391]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.0894 (0.1099)	Prec@1 96.875 (95.815)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [672][200/391]	Time 0.108 (0.116)	Data 0.000 (0.003)	Loss 0.0969 (0.1121)	Prec@1 96.875 (95.868)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [672][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0955 (0.1116)	Prec@1 96.875 (95.873)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [672][0/79]	Time 0.438 (0.438)	Data 0.406 (0.406)	Loss 0.2814 (0.2814)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:25:26

 Epoch: 673	Training Loss 0.1115 	Training Prec@1 95.872 	Training Prec@5 99.982 	Validation Loss 0.4269 	Validation Prec@1 87.980 	Validation Prec@5 99.530 

lr: 0.02486354331191382
TRAINING - Epoch: [673][0/391]	Time 1.274 (1.274)	Data 0.407 (0.407)	Loss 0.1087 (0.1087)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [673][100/391]	Time 0.120 (0.130)	Data 0.000 (0.004)	Loss 0.1852 (0.1108)	Prec@1 92.188 (96.078)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [673][200/391]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.0995 (0.1114)	Prec@1 97.656 (96.020)	Prec@5 99.219 (99.957)
TRAINING - Epoch: [673][300/391]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.0925 (0.1149)	Prec@1 94.531 (95.951)	Prec@5 100.000 (99.958)
EVALUATING - Epoch: [673][0/79]	Time 0.433 (0.433)	Data 0.397 (0.397)	Loss 0.3762 (0.3762)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:50	Time of Finish: 2022-03-24 02:43:04

 Epoch: 674	Training Loss 0.1153 	Training Prec@1 95.956 	Training Prec@5 99.968 	Validation Loss 0.4154 	Validation Prec@1 88.570 	Validation Prec@5 99.650 

lr: 0.024727336707170963
TRAINING - Epoch: [674][0/391]	Time 1.265 (1.265)	Data 0.414 (0.414)	Loss 0.0940 (0.0940)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [674][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.0780 (0.1045)	Prec@1 96.094 (96.256)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [674][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0827 (0.1101)	Prec@1 97.656 (96.094)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [674][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.1427 (0.1115)	Prec@1 95.312 (96.070)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [674][0/79]	Time 0.427 (0.427)	Data 0.396 (0.396)	Loss 0.2086 (0.2086)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:19

 Epoch: 675	Training Loss 0.1118 	Training Prec@1 96.056 	Training Prec@5 99.978 	Validation Loss 0.4150 	Validation Prec@1 88.460 	Validation Prec@5 99.550 

lr: 0.024591381540894866
TRAINING - Epoch: [675][0/391]	Time 1.295 (1.295)	Data 0.445 (0.445)	Loss 0.0934 (0.0934)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [675][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.1945 (0.1191)	Prec@1 94.531 (95.808)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [675][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.0588 (0.1105)	Prec@1 99.219 (96.094)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [675][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0448 (0.1109)	Prec@1 98.438 (96.050)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [675][0/79]	Time 0.437 (0.437)	Data 0.403 (0.403)	Loss 0.3511 (0.3511)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:10

 Epoch: 676	Training Loss 0.1107 	Training Prec@1 96.074 	Training Prec@5 99.980 	Validation Loss 0.4217 	Validation Prec@1 87.840 	Validation Prec@5 99.560 

lr: 0.024455679165707463
TRAINING - Epoch: [676][0/391]	Time 1.272 (1.272)	Data 0.404 (0.404)	Loss 0.1395 (0.1395)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [676][100/391]	Time 0.111 (0.127)	Data 0.000 (0.004)	Loss 0.0406 (0.0899)	Prec@1 98.438 (96.705)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [676][200/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1308 (0.0967)	Prec@1 96.094 (96.510)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [676][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.1047 (0.1005)	Prec@1 95.312 (96.408)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [676][0/79]	Time 0.430 (0.430)	Data 0.401 (0.401)	Loss 0.3276 (0.3276)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:30

 Epoch: 677	Training Loss 0.1039 	Training Prec@1 96.312 	Training Prec@5 99.988 	Validation Loss 0.4462 	Validation Prec@1 87.680 	Validation Prec@5 99.490 

lr: 0.02432023093171569
TRAINING - Epoch: [677][0/391]	Time 1.275 (1.275)	Data 0.417 (0.417)	Loss 0.1445 (0.1445)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [677][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.0988 (0.1011)	Prec@1 96.094 (96.349)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [677][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.0633 (0.1040)	Prec@1 97.656 (96.230)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [677][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.1719 (0.1051)	Prec@1 94.531 (96.185)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [677][0/79]	Time 0.413 (0.413)	Data 0.386 (0.386)	Loss 0.3693 (0.3693)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:46

 Epoch: 678	Training Loss 0.1066 	Training Prec@1 96.156 	Training Prec@5 99.990 	Validation Loss 0.4240 	Validation Prec@1 88.400 	Validation Prec@5 99.600 

lr: 0.024185038186497965
TRAINING - Epoch: [678][0/391]	Time 1.293 (1.293)	Data 0.437 (0.437)	Loss 0.0782 (0.0782)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [678][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.0901 (0.1042)	Prec@1 96.875 (96.349)	Prec@5 99.219 (99.961)
TRAINING - Epoch: [678][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.0998 (0.1080)	Prec@1 95.312 (96.179)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [678][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1918 (0.1082)	Prec@1 92.969 (96.177)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [678][0/79]	Time 0.416 (0.416)	Data 0.373 (0.373)	Loss 0.6340 (0.6340)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:59

 Epoch: 679	Training Loss 0.1111 	Training Prec@1 96.092 	Training Prec@5 99.970 	Validation Loss 0.4769 	Validation Prec@1 87.070 	Validation Prec@5 99.470 

lr: 0.0240501022750909
TRAINING - Epoch: [679][0/391]	Time 1.288 (1.288)	Data 0.419 (0.419)	Loss 0.0806 (0.0806)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [679][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.1837 (0.1028)	Prec@1 95.312 (96.411)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [679][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1218 (0.1053)	Prec@1 96.094 (96.292)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [679][300/391]	Time 0.121 (0.116)	Data 0.000 (0.002)	Loss 0.1487 (0.1072)	Prec@1 95.312 (96.205)	Prec@5 99.219 (99.961)
EVALUATING - Epoch: [679][0/79]	Time 0.435 (0.435)	Data 0.406 (0.406)	Loss 0.3476 (0.3476)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:19

 Epoch: 680	Training Loss 0.1077 	Training Prec@1 96.188 	Training Prec@5 99.970 	Validation Loss 0.4281 	Validation Prec@1 88.040 	Validation Prec@5 99.660 

lr: 0.023915424539975767
TRAINING - Epoch: [680][0/391]	Time 1.275 (1.275)	Data 0.402 (0.402)	Loss 0.0619 (0.0619)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [680][100/391]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.0937 (0.1136)	Prec@1 96.875 (96.001)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [680][200/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.1204 (0.1118)	Prec@1 94.531 (96.035)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [680][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0923 (0.1095)	Prec@1 96.094 (96.190)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [680][0/79]	Time 0.442 (0.442)	Data 0.401 (0.401)	Loss 0.3804 (0.3804)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:30

 Epoch: 681	Training Loss 0.1097 	Training Prec@1 96.210 	Training Prec@5 99.968 	Validation Loss 0.4016 	Validation Prec@1 88.390 	Validation Prec@5 99.650 

lr: 0.02378100632106535
TRAINING - Epoch: [681][0/391]	Time 1.563 (1.563)	Data 0.420 (0.420)	Loss 0.0676 (0.0676)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [681][100/391]	Time 0.115 (0.132)	Data 0.000 (0.004)	Loss 0.0476 (0.1103)	Prec@1 98.438 (96.132)	Prec@5 100.000 (99.961)
TRAINING - Epoch: [681][200/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.0888 (0.1134)	Prec@1 96.875 (95.989)	Prec@5 100.000 (99.953)
TRAINING - Epoch: [681][300/391]	Time 0.112 (0.123)	Data 0.000 (0.002)	Loss 0.0389 (0.1126)	Prec@1 99.219 (96.086)	Prec@5 100.000 (99.956)
EVALUATING - Epoch: [681][0/79]	Time 0.439 (0.439)	Data 0.398 (0.398)	Loss 0.3941 (0.3941)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:41:53

 Epoch: 682	Training Loss 0.1125 	Training Prec@1 96.042 	Training Prec@5 99.958 	Validation Loss 0.3968 	Validation Prec@1 88.670 	Validation Prec@5 99.560 

lr: 0.023646848955690417
TRAINING - Epoch: [682][0/391]	Time 1.222 (1.222)	Data 0.362 (0.362)	Loss 0.0859 (0.0859)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [682][100/391]	Time 0.108 (0.121)	Data 0.000 (0.004)	Loss 0.0785 (0.1026)	Prec@1 96.094 (96.318)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [682][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.1035 (0.1050)	Prec@1 97.656 (96.370)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [682][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1412 (0.1055)	Prec@1 96.094 (96.314)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [682][0/79]	Time 0.436 (0.436)	Data 0.405 (0.405)	Loss 0.2631 (0.2631)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:59

 Epoch: 683	Training Loss 0.1052 	Training Prec@1 96.354 	Training Prec@5 99.984 	Validation Loss 0.4078 	Validation Prec@1 88.880 	Validation Prec@5 99.440 

lr: 0.023512953778586514
TRAINING - Epoch: [683][0/391]	Time 1.266 (1.266)	Data 0.422 (0.422)	Loss 0.1068 (0.1068)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [683][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.0708 (0.0957)	Prec@1 96.875 (96.658)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [683][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0830 (0.1012)	Prec@1 96.094 (96.370)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [683][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.1207 (0.1028)	Prec@1 96.094 (96.314)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [683][0/79]	Time 0.408 (0.408)	Data 0.381 (0.381)	Loss 0.3798 (0.3798)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:35

 Epoch: 684	Training Loss 0.1011 	Training Prec@1 96.368 	Training Prec@5 99.984 	Validation Loss 0.4289 	Validation Prec@1 87.980 	Validation Prec@5 99.580 

lr: 0.023379322121880722
TRAINING - Epoch: [684][0/391]	Time 1.571 (1.571)	Data 0.421 (0.421)	Loss 0.1086 (0.1086)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [684][100/391]	Time 0.117 (0.131)	Data 0.000 (0.004)	Loss 0.0640 (0.0983)	Prec@1 97.656 (96.604)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [684][200/391]	Time 0.114 (0.124)	Data 0.000 (0.002)	Loss 0.0666 (0.0993)	Prec@1 98.438 (96.576)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [684][300/391]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.0430 (0.1028)	Prec@1 100.000 (96.369)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [684][0/79]	Time 0.440 (0.440)	Data 0.404 (0.404)	Loss 0.3099 (0.3099)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:40:00

 Epoch: 685	Training Loss 0.1036 	Training Prec@1 96.338 	Training Prec@5 99.986 	Validation Loss 0.4091 	Validation Prec@1 88.700 	Validation Prec@5 99.590 

lr: 0.023245955315078257
TRAINING - Epoch: [685][0/391]	Time 1.271 (1.271)	Data 0.398 (0.398)	Loss 0.1010 (0.1010)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [685][100/391]	Time 0.117 (0.122)	Data 0.000 (0.004)	Loss 0.0703 (0.1001)	Prec@1 97.656 (96.597)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [685][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.0644 (0.1072)	Prec@1 98.438 (96.292)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [685][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.0603 (0.1074)	Prec@1 98.438 (96.242)	Prec@5 100.000 (99.979)
EVALUATING - Epoch: [685][0/79]	Time 0.424 (0.424)	Data 0.384 (0.384)	Loss 0.3756 (0.3756)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:24:50

 Epoch: 686	Training Loss 0.1058 	Training Prec@1 96.284 	Training Prec@5 99.980 	Validation Loss 0.4333 	Validation Prec@1 88.320 	Validation Prec@5 99.460 

lr: 0.023112854685049405
TRAINING - Epoch: [686][0/391]	Time 1.312 (1.312)	Data 0.452 (0.452)	Loss 0.0775 (0.0775)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [686][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.1048 (0.0968)	Prec@1 95.312 (96.651)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [686][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.1508 (0.0961)	Prec@1 94.531 (96.615)	Prec@5 99.219 (99.992)
TRAINING - Epoch: [686][300/391]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.1476 (0.0978)	Prec@1 95.312 (96.569)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [686][0/79]	Time 0.437 (0.437)	Data 0.389 (0.389)	Loss 0.4036 (0.4036)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:37

 Epoch: 687	Training Loss 0.1003 	Training Prec@1 96.496 	Training Prec@5 99.982 	Validation Loss 0.4490 	Validation Prec@1 87.860 	Validation Prec@5 99.470 

lr: 0.022980021556016205
TRAINING - Epoch: [687][0/391]	Time 1.286 (1.286)	Data 0.413 (0.413)	Loss 0.0474 (0.0474)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [687][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.0655 (0.0934)	Prec@1 96.875 (96.883)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [687][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.1021 (0.0946)	Prec@1 96.875 (96.778)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [687][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.0546 (0.0954)	Prec@1 98.438 (96.696)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [687][0/79]	Time 0.415 (0.415)	Data 0.380 (0.380)	Loss 0.4067 (0.4067)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:25:29

 Epoch: 688	Training Loss 0.0955 	Training Prec@1 96.630 	Training Prec@5 99.986 	Validation Loss 0.4237 	Validation Prec@1 88.100 	Validation Prec@5 99.580 

lr: 0.02284745724953938
TRAINING - Epoch: [688][0/391]	Time 1.280 (1.280)	Data 0.447 (0.447)	Loss 0.0952 (0.0952)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [688][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.1072 (0.0921)	Prec@1 96.875 (96.767)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [688][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1018 (0.0945)	Prec@1 95.312 (96.766)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [688][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0646 (0.0937)	Prec@1 97.656 (96.750)	Prec@5 100.000 (99.974)
EVALUATING - Epoch: [688][0/79]	Time 0.453 (0.453)	Data 0.415 (0.415)	Loss 0.4086 (0.4086)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:12:37

 Epoch: 689	Training Loss 0.0955 	Training Prec@1 96.692 	Training Prec@5 99.976 	Validation Loss 0.4283 	Validation Prec@1 87.890 	Validation Prec@5 99.600 

lr: 0.0227151630845051
TRAINING - Epoch: [689][0/391]	Time 1.336 (1.336)	Data 0.475 (0.475)	Loss 0.0863 (0.0863)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [689][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.0589 (0.0927)	Prec@1 100.000 (96.945)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [689][200/391]	Time 0.121 (0.118)	Data 0.000 (0.003)	Loss 0.0416 (0.0959)	Prec@1 98.438 (96.704)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [689][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0912 (0.0942)	Prec@1 97.656 (96.722)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [689][0/79]	Time 0.438 (0.438)	Data 0.404 (0.404)	Loss 0.3473 (0.3473)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:18

 Epoch: 690	Training Loss 0.0946 	Training Prec@1 96.664 	Training Prec@5 99.986 	Validation Loss 0.4182 	Validation Prec@1 88.630 	Validation Prec@5 99.640 

lr: 0.022583140377111847
TRAINING - Epoch: [690][0/391]	Time 1.275 (1.275)	Data 0.412 (0.412)	Loss 0.0650 (0.0650)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [690][100/391]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.0953 (0.0918)	Prec@1 95.312 (96.604)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [690][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.0625 (0.0963)	Prec@1 98.438 (96.517)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [690][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0690 (0.0955)	Prec@1 98.438 (96.615)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [690][0/79]	Time 0.417 (0.417)	Data 0.377 (0.377)	Loss 0.4517 (0.4517)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:30

 Epoch: 691	Training Loss 0.0972 	Training Prec@1 96.532 	Training Prec@5 99.990 	Validation Loss 0.4268 	Validation Prec@1 88.560 	Validation Prec@5 99.560 

lr: 0.022451390440857397
TRAINING - Epoch: [691][0/391]	Time 1.250 (1.250)	Data 0.410 (0.410)	Loss 0.0716 (0.0716)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [691][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.1035 (0.0898)	Prec@1 96.875 (96.790)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [691][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0656 (0.0920)	Prec@1 97.656 (96.696)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [691][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0359 (0.0934)	Prec@1 100.000 (96.680)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [691][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.4483 (0.4483)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:12:27

 Epoch: 692	Training Loss 0.0946 	Training Prec@1 96.632 	Training Prec@5 99.988 	Validation Loss 0.4128 	Validation Prec@1 88.780 	Validation Prec@5 99.660 

lr: 0.022319914586525765
TRAINING - Epoch: [692][0/391]	Time 1.297 (1.297)	Data 0.426 (0.426)	Loss 0.1213 (0.1213)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [692][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.1708 (0.0932)	Prec@1 91.406 (96.736)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [692][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.0733 (0.0945)	Prec@1 96.875 (96.646)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [692][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1431 (0.0956)	Prec@1 94.531 (96.610)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [692][0/79]	Time 0.423 (0.423)	Data 0.389 (0.389)	Loss 0.3655 (0.3655)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:21

 Epoch: 693	Training Loss 0.0954 	Training Prec@1 96.632 	Training Prec@5 99.980 	Validation Loss 0.3965 	Validation Prec@1 88.950 	Validation Prec@5 99.650 

lr: 0.022188714122174054
TRAINING - Epoch: [693][0/391]	Time 1.276 (1.276)	Data 0.427 (0.427)	Loss 0.1654 (0.1654)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [693][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.0641 (0.0955)	Prec@1 97.656 (96.790)	Prec@5 100.000 (99.954)
TRAINING - Epoch: [693][200/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.0927 (0.0928)	Prec@1 95.312 (96.789)	Prec@5 100.000 (99.973)
TRAINING - Epoch: [693][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.1117 (0.0918)	Prec@1 96.094 (96.797)	Prec@5 100.000 (99.977)
EVALUATING - Epoch: [693][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.3410 (0.3410)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:51

 Epoch: 694	Training Loss 0.0917 	Training Prec@1 96.786 	Training Prec@5 99.980 	Validation Loss 0.3701 	Validation Prec@1 89.630 	Validation Prec@5 99.620 

lr: 0.022057790353119507
TRAINING - Epoch: [694][0/391]	Time 1.303 (1.303)	Data 0.445 (0.445)	Loss 0.1145 (0.1145)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [694][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.1074 (0.0909)	Prec@1 96.875 (96.697)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [694][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.1056 (0.0925)	Prec@1 96.094 (96.615)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [694][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0755 (0.0938)	Prec@1 96.875 (96.628)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [694][0/79]	Time 0.445 (0.445)	Data 0.412 (0.412)	Loss 0.4835 (0.4835)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:37

 Epoch: 695	Training Loss 0.0945 	Training Prec@1 96.610 	Training Prec@5 99.982 	Validation Loss 0.4146 	Validation Prec@1 88.560 	Validation Prec@5 99.600 

lr: 0.021927144581926586
TRAINING - Epoch: [695][0/391]	Time 1.285 (1.285)	Data 0.433 (0.433)	Loss 0.0827 (0.0827)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [695][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.0933 (0.0897)	Prec@1 96.094 (96.759)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [695][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0561 (0.0917)	Prec@1 98.438 (96.716)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [695][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1241 (0.0905)	Prec@1 96.875 (96.802)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [695][0/79]	Time 0.420 (0.420)	Data 0.392 (0.392)	Loss 0.2378 (0.2378)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:37

 Epoch: 696	Training Loss 0.0918 	Training Prec@1 96.736 	Training Prec@5 99.984 	Validation Loss 0.3835 	Validation Prec@1 88.880 	Validation Prec@5 99.570 

lr: 0.021796778108393835
TRAINING - Epoch: [696][0/391]	Time 1.565 (1.565)	Data 0.418 (0.418)	Loss 0.1333 (0.1333)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [696][100/391]	Time 0.117 (0.130)	Data 0.000 (0.004)	Loss 0.1222 (0.0955)	Prec@1 96.875 (96.744)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [696][200/391]	Time 0.112 (0.123)	Data 0.000 (0.002)	Loss 0.1007 (0.0923)	Prec@1 94.531 (96.751)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [696][300/391]	Time 0.111 (0.121)	Data 0.000 (0.002)	Loss 0.0701 (0.0902)	Prec@1 97.656 (96.833)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [696][0/79]	Time 0.436 (0.436)	Data 0.403 (0.403)	Loss 0.3327 (0.3327)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:03

 Epoch: 697	Training Loss 0.0904 	Training Prec@1 96.788 	Training Prec@5 99.982 	Validation Loss 0.3942 	Validation Prec@1 89.060 	Validation Prec@5 99.740 

lr: 0.02166669222954113
TRAINING - Epoch: [697][0/391]	Time 1.272 (1.272)	Data 0.422 (0.422)	Loss 0.0848 (0.0848)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [697][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.1581 (0.0855)	Prec@1 94.531 (96.890)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [697][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0250 (0.0871)	Prec@1 100.000 (96.929)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [697][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0640 (0.0875)	Prec@1 97.656 (96.935)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [697][0/79]	Time 0.447 (0.447)	Data 0.406 (0.406)	Loss 0.4597 (0.4597)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:28

 Epoch: 698	Training Loss 0.0881 	Training Prec@1 96.902 	Training Prec@5 99.988 	Validation Loss 0.4587 	Validation Prec@1 88.050 	Validation Prec@5 99.530 

lr: 0.021536888239596683
TRAINING - Epoch: [698][0/391]	Time 1.268 (1.268)	Data 0.411 (0.411)	Loss 0.0885 (0.0885)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [698][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.0799 (0.0916)	Prec@1 96.875 (96.751)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [698][200/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.1176 (0.0910)	Prec@1 96.094 (96.789)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [698][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.1549 (0.0903)	Prec@1 96.875 (96.810)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [698][0/79]	Time 0.424 (0.424)	Data 0.387 (0.387)	Loss 0.4231 (0.4231)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:17

 Epoch: 699	Training Loss 0.0893 	Training Prec@1 96.846 	Training Prec@5 99.988 	Validation Loss 0.4024 	Validation Prec@1 88.640 	Validation Prec@5 99.650 

lr: 0.02140736742998422
TRAINING - Epoch: [699][0/391]	Time 1.564 (1.564)	Data 0.408 (0.408)	Loss 0.0711 (0.0711)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [699][100/391]	Time 0.111 (0.126)	Data 0.000 (0.004)	Loss 0.0456 (0.0851)	Prec@1 98.438 (97.192)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [699][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.0343 (0.0868)	Prec@1 100.000 (97.046)	Prec@5 100.000 (99.981)
TRAINING - Epoch: [699][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1210 (0.0865)	Prec@1 96.094 (97.002)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [699][0/79]	Time 0.446 (0.446)	Data 0.401 (0.401)	Loss 0.2994 (0.2994)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:09

 Epoch: 700	Training Loss 0.0869 	Training Prec@1 97.000 	Training Prec@5 99.988 	Validation Loss 0.4115 	Validation Prec@1 88.550 	Validation Prec@5 99.380 

lr: 0.021278131089310058
TRAINING - Epoch: [700][0/391]	Time 1.305 (1.305)	Data 0.444 (0.444)	Loss 0.0910 (0.0910)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [700][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.0262 (0.0856)	Prec@1 99.219 (96.921)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [700][200/391]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.0377 (0.0844)	Prec@1 100.000 (96.933)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [700][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0536 (0.0865)	Prec@1 97.656 (96.857)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [700][0/79]	Time 0.453 (0.453)	Data 0.416 (0.416)	Loss 0.2363 (0.2363)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:55

 Epoch: 701	Training Loss 0.0867 	Training Prec@1 96.858 	Training Prec@5 99.994 	Validation Loss 0.4065 	Validation Prec@1 88.820 	Validation Prec@5 99.570 

lr: 0.0211491805033503
TRAINING - Epoch: [701][0/391]	Time 1.344 (1.344)	Data 0.444 (0.444)	Loss 0.0490 (0.0490)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [701][100/391]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.1046 (0.0820)	Prec@1 98.438 (97.123)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [701][200/391]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.1188 (0.0821)	Prec@1 96.094 (97.104)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [701][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0768 (0.0836)	Prec@1 97.656 (97.039)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [701][0/79]	Time 0.453 (0.453)	Data 0.410 (0.410)	Loss 0.3492 (0.3492)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:40

 Epoch: 702	Training Loss 0.0823 	Training Prec@1 97.050 	Training Prec@5 99.992 	Validation Loss 0.3777 	Validation Prec@1 89.230 	Validation Prec@5 99.620 

lr: 0.021020516955038107
TRAINING - Epoch: [702][0/391]	Time 1.321 (1.321)	Data 0.425 (0.425)	Loss 0.0899 (0.0899)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [702][100/391]	Time 0.112 (0.130)	Data 0.000 (0.005)	Loss 0.0750 (0.0815)	Prec@1 96.094 (97.146)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [702][200/391]	Time 0.118 (0.125)	Data 0.000 (0.003)	Loss 0.0288 (0.0826)	Prec@1 99.219 (97.077)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [702][300/391]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.1095 (0.0828)	Prec@1 96.875 (97.041)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [702][0/79]	Time 0.429 (0.429)	Data 0.392 (0.392)	Loss 0.3512 (0.3512)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:40:21

 Epoch: 703	Training Loss 0.0829 	Training Prec@1 97.048 	Training Prec@5 99.990 	Validation Loss 0.3926 	Validation Prec@1 89.230 	Validation Prec@5 99.610 

lr: 0.020892141724450915
TRAINING - Epoch: [703][0/391]	Time 1.326 (1.326)	Data 0.367 (0.367)	Loss 0.1439 (0.1439)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [703][100/391]	Time 0.115 (0.128)	Data 0.000 (0.004)	Loss 0.0527 (0.0770)	Prec@1 98.438 (97.370)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [703][200/391]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.0616 (0.0787)	Prec@1 98.438 (97.268)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [703][300/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.0761 (0.0819)	Prec@1 97.656 (97.179)	Prec@5 100.000 (99.982)
EVALUATING - Epoch: [703][0/79]	Time 0.407 (0.407)	Data 0.381 (0.381)	Loss 0.2910 (0.2910)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:32

 Epoch: 704	Training Loss 0.0822 	Training Prec@1 97.162 	Training Prec@5 99.984 	Validation Loss 0.4169 	Validation Prec@1 89.160 	Validation Prec@5 99.520 

lr: 0.020764056088797635
TRAINING - Epoch: [704][0/391]	Time 1.313 (1.313)	Data 0.427 (0.427)	Loss 0.1073 (0.1073)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [704][100/391]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.0695 (0.0751)	Prec@1 97.656 (97.386)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [704][200/391]	Time 0.109 (0.120)	Data 0.000 (0.003)	Loss 0.0469 (0.0812)	Prec@1 98.438 (97.190)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [704][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.1031 (0.0802)	Prec@1 96.875 (97.189)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [704][0/79]	Time 0.439 (0.439)	Data 0.408 (0.408)	Loss 0.3356 (0.3356)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:51

 Epoch: 705	Training Loss 0.0806 	Training Prec@1 97.176 	Training Prec@5 99.990 	Validation Loss 0.3902 	Validation Prec@1 89.290 	Validation Prec@5 99.680 

lr: 0.02063626132240601
TRAINING - Epoch: [705][0/391]	Time 1.570 (1.570)	Data 0.383 (0.383)	Loss 0.0192 (0.0192)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [705][100/391]	Time 0.114 (0.129)	Data 0.000 (0.004)	Loss 0.1041 (0.0752)	Prec@1 97.656 (97.440)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [705][200/391]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.0670 (0.0764)	Prec@1 96.875 (97.338)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [705][300/391]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.0422 (0.0793)	Prec@1 99.219 (97.251)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [705][0/79]	Time 0.407 (0.407)	Data 0.381 (0.381)	Loss 0.3945 (0.3945)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:28

 Epoch: 706	Training Loss 0.0787 	Training Prec@1 97.242 	Training Prec@5 99.994 	Validation Loss 0.3894 	Validation Prec@1 89.500 	Validation Prec@5 99.560 

lr: 0.020508758696709904
TRAINING - Epoch: [706][0/391]	Time 1.347 (1.347)	Data 0.446 (0.446)	Loss 0.1249 (0.1249)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [706][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.0303 (0.0703)	Prec@1 98.438 (97.548)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [706][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.0708 (0.0744)	Prec@1 97.656 (97.349)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [706][300/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0572 (0.0773)	Prec@1 97.656 (97.238)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [706][0/79]	Time 0.436 (0.436)	Data 0.408 (0.408)	Loss 0.3676 (0.3676)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:54

 Epoch: 707	Training Loss 0.0782 	Training Prec@1 97.208 	Training Prec@5 99.994 	Validation Loss 0.3910 	Validation Prec@1 89.090 	Validation Prec@5 99.530 

lr: 0.020381549480236676
TRAINING - Epoch: [707][0/391]	Time 1.324 (1.324)	Data 0.436 (0.436)	Loss 0.0686 (0.0686)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [707][100/391]	Time 0.111 (0.126)	Data 0.000 (0.005)	Loss 0.0789 (0.0764)	Prec@1 97.656 (97.269)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [707][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.0702 (0.0770)	Prec@1 98.438 (97.268)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [707][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0784 (0.0771)	Prec@1 96.875 (97.202)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [707][0/79]	Time 0.440 (0.440)	Data 0.404 (0.404)	Loss 0.3078 (0.3078)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:01

 Epoch: 708	Training Loss 0.0765 	Training Prec@1 97.254 	Training Prec@5 99.992 	Validation Loss 0.4046 	Validation Prec@1 89.350 	Validation Prec@5 99.630 

lr: 0.020254634938594543
TRAINING - Epoch: [708][0/391]	Time 1.312 (1.312)	Data 0.438 (0.438)	Loss 0.0429 (0.0429)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [708][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.0705 (0.0729)	Prec@1 96.094 (97.463)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [708][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1546 (0.0740)	Prec@1 96.875 (97.404)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [708][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.1045 (0.0738)	Prec@1 96.875 (97.451)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [708][0/79]	Time 0.422 (0.422)	Data 0.390 (0.390)	Loss 0.2751 (0.2751)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:11

 Epoch: 709	Training Loss 0.0735 	Training Prec@1 97.426 	Training Prec@5 99.994 	Validation Loss 0.3928 	Validation Prec@1 89.790 	Validation Prec@5 99.600 

lr: 0.020128016334459972
TRAINING - Epoch: [709][0/391]	Time 1.350 (1.350)	Data 0.412 (0.412)	Loss 0.1127 (0.1127)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [709][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.0935 (0.0754)	Prec@1 97.656 (97.409)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [709][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.0577 (0.0742)	Prec@1 98.438 (97.470)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [709][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0467 (0.0757)	Prec@1 98.438 (97.399)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [709][0/79]	Time 0.414 (0.414)	Data 0.381 (0.381)	Loss 0.3418 (0.3418)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:46

 Epoch: 710	Training Loss 0.0769 	Training Prec@1 97.338 	Training Prec@5 99.992 	Validation Loss 0.3962 	Validation Prec@1 89.350 	Validation Prec@5 99.690 

lr: 0.02000169492756522
TRAINING - Epoch: [710][0/391]	Time 1.322 (1.322)	Data 0.420 (0.420)	Loss 0.0443 (0.0443)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [710][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.0985 (0.0740)	Prec@1 95.312 (97.300)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [710][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0495 (0.0749)	Prec@1 97.656 (97.349)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [710][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1219 (0.0746)	Prec@1 96.094 (97.350)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [710][0/79]	Time 0.458 (0.458)	Data 0.413 (0.413)	Loss 0.2997 (0.2997)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:16

 Epoch: 711	Training Loss 0.0740 	Training Prec@1 97.376 	Training Prec@5 99.988 	Validation Loss 0.3887 	Validation Prec@1 89.760 	Validation Prec@5 99.630 

lr: 0.019875671974685608
TRAINING - Epoch: [711][0/391]	Time 1.613 (1.613)	Data 0.417 (0.417)	Loss 0.0858 (0.0858)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [711][100/391]	Time 0.119 (0.133)	Data 0.000 (0.004)	Loss 0.0491 (0.0693)	Prec@1 98.438 (97.393)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [711][200/391]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.0820 (0.0693)	Prec@1 97.656 (97.466)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [711][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.0482 (0.0701)	Prec@1 98.438 (97.480)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [711][0/79]	Time 0.411 (0.411)	Data 0.383 (0.383)	Loss 0.3749 (0.3749)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:41:10

 Epoch: 712	Training Loss 0.0711 	Training Prec@1 97.462 	Training Prec@5 99.994 	Validation Loss 0.3877 	Validation Prec@1 89.770 	Validation Prec@5 99.550 

lr: 0.019749948729627195
TRAINING - Epoch: [712][0/391]	Time 1.289 (1.289)	Data 0.413 (0.413)	Loss 0.0640 (0.0640)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [712][100/391]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.0386 (0.0729)	Prec@1 98.438 (97.579)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [712][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0465 (0.0742)	Prec@1 97.656 (97.446)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [712][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0604 (0.0750)	Prec@1 98.438 (97.415)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [712][0/79]	Time 0.433 (0.433)	Data 0.394 (0.394)	Loss 0.3674 (0.3674)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:32

 Epoch: 713	Training Loss 0.0726 	Training Prec@1 97.498 	Training Prec@5 99.994 	Validation Loss 0.3911 	Validation Prec@1 89.380 	Validation Prec@5 99.630 

lr: 0.019624526443214215
TRAINING - Epoch: [713][0/391]	Time 1.353 (1.353)	Data 0.368 (0.368)	Loss 0.0657 (0.0657)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [713][100/391]	Time 0.116 (0.128)	Data 0.001 (0.004)	Loss 0.0592 (0.0679)	Prec@1 99.219 (97.502)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [713][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.1017 (0.0688)	Prec@1 95.312 (97.512)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [713][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.0911 (0.0697)	Prec@1 93.750 (97.464)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [713][0/79]	Time 0.412 (0.412)	Data 0.385 (0.385)	Loss 0.2272 (0.2272)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:30

 Epoch: 714	Training Loss 0.0700 	Training Prec@1 97.460 	Training Prec@5 99.992 	Validation Loss 0.3870 	Validation Prec@1 89.810 	Validation Prec@5 99.700 

lr: 0.0194994063632767
TRAINING - Epoch: [714][0/391]	Time 1.305 (1.305)	Data 0.407 (0.407)	Loss 0.1277 (0.1277)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [714][100/391]	Time 0.108 (0.127)	Data 0.000 (0.004)	Loss 0.0637 (0.0666)	Prec@1 96.875 (97.610)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [714][200/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.0510 (0.0671)	Prec@1 98.438 (97.617)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [714][300/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.0621 (0.0676)	Prec@1 97.656 (97.623)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [714][0/79]	Time 0.438 (0.438)	Data 0.401 (0.401)	Loss 0.3748 (0.3748)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:38:20

 Epoch: 715	Training Loss 0.0671 	Training Prec@1 97.624 	Training Prec@5 99.994 	Validation Loss 0.4099 	Validation Prec@1 88.860 	Validation Prec@5 99.650 

lr: 0.019374589734637987
TRAINING - Epoch: [715][0/391]	Time 1.331 (1.331)	Data 0.430 (0.430)	Loss 0.1021 (0.1021)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [715][100/391]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.0660 (0.0693)	Prec@1 96.875 (97.571)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [715][200/391]	Time 0.109 (0.119)	Data 0.000 (0.003)	Loss 0.0326 (0.0685)	Prec@1 99.219 (97.559)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [715][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1090 (0.0699)	Prec@1 94.531 (97.513)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [715][0/79]	Time 0.465 (0.465)	Data 0.422 (0.422)	Loss 0.2754 (0.2754)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:36

 Epoch: 716	Training Loss 0.0695 	Training Prec@1 97.548 	Training Prec@5 99.994 	Validation Loss 0.3844 	Validation Prec@1 89.690 	Validation Prec@5 99.610 

lr: 0.01925007779910231
TRAINING - Epoch: [716][0/391]	Time 1.330 (1.330)	Data 0.393 (0.393)	Loss 0.0489 (0.0489)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [716][100/391]	Time 0.113 (0.125)	Data 0.000 (0.004)	Loss 0.0590 (0.0673)	Prec@1 97.656 (97.463)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [716][200/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.0271 (0.0680)	Prec@1 99.219 (97.505)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [716][300/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0655 (0.0670)	Prec@1 97.656 (97.573)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [716][0/79]	Time 0.403 (0.403)	Data 0.376 (0.376)	Loss 0.2245 (0.2245)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:46

 Epoch: 717	Training Loss 0.0663 	Training Prec@1 97.640 	Training Prec@5 99.996 	Validation Loss 0.3847 	Validation Prec@1 89.900 	Validation Prec@5 99.710 

lr: 0.019125871795442617
TRAINING - Epoch: [717][0/391]	Time 1.353 (1.353)	Data 0.429 (0.429)	Loss 0.0651 (0.0651)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [717][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.1170 (0.0694)	Prec@1 94.531 (97.587)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [717][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.0320 (0.0693)	Prec@1 99.219 (97.610)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [717][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0950 (0.0697)	Prec@1 96.875 (97.571)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [717][0/79]	Time 0.432 (0.432)	Data 0.399 (0.399)	Loss 0.4382 (0.4382)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:48

 Epoch: 718	Training Loss 0.0692 	Training Prec@1 97.560 	Training Prec@5 99.996 	Validation Loss 0.4122 	Validation Prec@1 89.310 	Validation Prec@5 99.550 

lr: 0.019001972959388057
TRAINING - Epoch: [718][0/391]	Time 1.313 (1.313)	Data 0.418 (0.418)	Loss 0.0453 (0.0453)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [718][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.0459 (0.0612)	Prec@1 98.438 (97.873)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [718][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0673 (0.0646)	Prec@1 96.875 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [718][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0342 (0.0660)	Prec@1 99.219 (97.698)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [718][0/79]	Time 0.437 (0.437)	Data 0.397 (0.397)	Loss 0.3280 (0.3280)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:56

 Epoch: 719	Training Loss 0.0660 	Training Prec@1 97.702 	Training Prec@5 99.996 	Validation Loss 0.4061 	Validation Prec@1 89.560 	Validation Prec@5 99.560 

lr: 0.018878382523611775
TRAINING - Epoch: [719][0/391]	Time 1.302 (1.302)	Data 0.413 (0.413)	Loss 0.0639 (0.0639)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [719][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.0196 (0.0668)	Prec@1 100.000 (97.679)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [719][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0552 (0.0670)	Prec@1 98.438 (97.617)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [719][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.0308 (0.0667)	Prec@1 99.219 (97.630)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [719][0/79]	Time 0.423 (0.423)	Data 0.379 (0.379)	Loss 0.3336 (0.3336)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:45

 Epoch: 720	Training Loss 0.0669 	Training Prec@1 97.600 	Training Prec@5 99.994 	Validation Loss 0.3939 	Validation Prec@1 89.510 	Validation Prec@5 99.640 

lr: 0.01875510171771862
TRAINING - Epoch: [720][0/391]	Time 1.306 (1.306)	Data 0.415 (0.415)	Loss 0.1312 (0.1312)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [720][100/391]	Time 0.109 (0.126)	Data 0.000 (0.004)	Loss 0.0270 (0.0658)	Prec@1 98.438 (97.679)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [720][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0676 (0.0650)	Prec@1 96.875 (97.785)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [720][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1199 (0.0659)	Prec@1 91.406 (97.739)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [720][0/79]	Time 0.431 (0.431)	Data 0.402 (0.402)	Loss 0.2442 (0.2442)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:24

 Epoch: 721	Training Loss 0.0663 	Training Prec@1 97.694 	Training Prec@5 99.996 	Validation Loss 0.3913 	Validation Prec@1 89.780 	Validation Prec@5 99.630 

lr: 0.01863213176823298
TRAINING - Epoch: [721][0/391]	Time 1.351 (1.351)	Data 0.422 (0.422)	Loss 0.0398 (0.0398)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [721][100/391]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.1311 (0.0643)	Prec@1 96.094 (97.857)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [721][200/391]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.0461 (0.0638)	Prec@1 99.219 (97.831)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [721][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.0308 (0.0621)	Prec@1 99.219 (97.885)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [721][0/79]	Time 0.418 (0.418)	Data 0.378 (0.378)	Loss 0.3695 (0.3695)	Prec@1 92.188 (92.188)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:50

 Epoch: 722	Training Loss 0.0637 	Training Prec@1 97.808 	Training Prec@5 99.998 	Validation Loss 0.3959 	Validation Prec@1 89.330 	Validation Prec@5 99.390 

lr: 0.018509473898586436
TRAINING - Epoch: [722][0/391]	Time 1.289 (1.289)	Data 0.416 (0.416)	Loss 0.0921 (0.0921)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [722][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.0683 (0.0599)	Prec@1 96.094 (97.904)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [722][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1011 (0.0606)	Prec@1 96.094 (97.932)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [722][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0317 (0.0601)	Prec@1 99.219 (97.960)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [722][0/79]	Time 0.439 (0.439)	Data 0.405 (0.405)	Loss 0.4891 (0.4891)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:25

 Epoch: 723	Training Loss 0.0614 	Training Prec@1 97.906 	Training Prec@5 99.994 	Validation Loss 0.3841 	Validation Prec@1 89.570 	Validation Prec@5 99.610 

lr: 0.018387129329105727
TRAINING - Epoch: [723][0/391]	Time 1.290 (1.290)	Data 0.417 (0.417)	Loss 0.0824 (0.0824)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [723][100/391]	Time 0.117 (0.128)	Data 0.000 (0.005)	Loss 0.0251 (0.0647)	Prec@1 99.219 (97.834)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [723][200/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.0545 (0.0656)	Prec@1 97.656 (97.722)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [723][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0316 (0.0646)	Prec@1 98.438 (97.768)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [723][0/79]	Time 0.431 (0.431)	Data 0.386 (0.386)	Loss 0.2589 (0.2589)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:30

 Epoch: 724	Training Loss 0.0645 	Training Prec@1 97.800 	Training Prec@5 100.000 	Validation Loss 0.3775 	Validation Prec@1 89.860 	Validation Prec@5 99.600 

lr: 0.018265099277000582
TRAINING - Epoch: [724][0/391]	Time 1.299 (1.299)	Data 0.421 (0.421)	Loss 0.0264 (0.0264)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [724][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.0482 (0.0614)	Prec@1 99.219 (97.966)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [724][200/391]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.0329 (0.0638)	Prec@1 99.219 (97.792)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [724][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0611 (0.0643)	Prec@1 96.875 (97.765)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [724][0/79]	Time 0.462 (0.462)	Data 0.415 (0.415)	Loss 0.3739 (0.3739)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:15:22

 Epoch: 725	Training Loss 0.0659 	Training Prec@1 97.720 	Training Prec@5 99.992 	Validation Loss 0.3761 	Validation Prec@1 89.990 	Validation Prec@5 99.620 

lr: 0.018143384956351545
TRAINING - Epoch: [725][0/391]	Time 1.335 (1.335)	Data 0.433 (0.433)	Loss 0.1079 (0.1079)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [725][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.0413 (0.0617)	Prec@1 98.438 (97.958)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [725][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0272 (0.0632)	Prec@1 99.219 (97.862)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [725][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0374 (0.0642)	Prec@1 98.438 (97.799)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [725][0/79]	Time 0.438 (0.438)	Data 0.405 (0.405)	Loss 0.3363 (0.3363)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:53

 Epoch: 726	Training Loss 0.0630 	Training Prec@1 97.836 	Training Prec@5 99.990 	Validation Loss 0.4000 	Validation Prec@1 89.850 	Validation Prec@5 99.660 

lr: 0.018021987578097975
TRAINING - Epoch: [726][0/391]	Time 1.314 (1.314)	Data 0.419 (0.419)	Loss 0.0357 (0.0357)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [726][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.1064 (0.0610)	Prec@1 97.656 (97.881)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [726][200/391]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1286 (0.0633)	Prec@1 96.094 (97.816)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [726][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0677 (0.0653)	Prec@1 98.438 (97.752)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [726][0/79]	Time 0.442 (0.442)	Data 0.401 (0.401)	Loss 0.3144 (0.3144)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:11

 Epoch: 727	Training Loss 0.0646 	Training Prec@1 97.736 	Training Prec@5 100.000 	Validation Loss 0.3785 	Validation Prec@1 89.900 	Validation Prec@5 99.660 

lr: 0.017900908350025897
TRAINING - Epoch: [727][0/391]	Time 1.329 (1.329)	Data 0.408 (0.408)	Loss 0.0117 (0.0117)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [727][100/391]	Time 0.113 (0.124)	Data 0.000 (0.004)	Loss 0.0550 (0.0636)	Prec@1 98.438 (97.819)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [727][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0271 (0.0641)	Prec@1 98.438 (97.753)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [727][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0604 (0.0634)	Prec@1 97.656 (97.773)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [727][0/79]	Time 0.438 (0.438)	Data 0.393 (0.393)	Loss 0.3412 (0.3412)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:21

 Epoch: 728	Training Loss 0.0634 	Training Prec@1 97.760 	Training Prec@5 99.988 	Validation Loss 0.4048 	Validation Prec@1 89.700 	Validation Prec@5 99.680 

lr: 0.01778014847675613
TRAINING - Epoch: [728][0/391]	Time 1.343 (1.343)	Data 0.442 (0.442)	Loss 0.0808 (0.0808)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [728][100/391]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.0350 (0.0570)	Prec@1 99.219 (97.997)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [728][200/391]	Time 0.106 (0.118)	Data 0.000 (0.003)	Loss 0.0865 (0.0598)	Prec@1 96.875 (97.921)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [728][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0278 (0.0609)	Prec@1 99.219 (97.892)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [728][0/79]	Time 0.425 (0.425)	Data 0.393 (0.393)	Loss 0.3187 (0.3187)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:23

 Epoch: 729	Training Loss 0.0594 	Training Prec@1 97.950 	Training Prec@5 100.000 	Validation Loss 0.3799 	Validation Prec@1 89.970 	Validation Prec@5 99.620 

lr: 0.017659709159732185
TRAINING - Epoch: [729][0/391]	Time 1.314 (1.314)	Data 0.417 (0.417)	Loss 0.0432 (0.0432)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [729][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.0322 (0.0581)	Prec@1 100.000 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [729][200/391]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.0785 (0.0576)	Prec@1 97.656 (98.107)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [729][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0233 (0.0585)	Prec@1 99.219 (97.988)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [729][0/79]	Time 0.446 (0.446)	Data 0.404 (0.404)	Loss 0.2398 (0.2398)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:03

 Epoch: 730	Training Loss 0.0577 	Training Prec@1 98.010 	Training Prec@5 99.996 	Validation Loss 0.4095 	Validation Prec@1 90.160 	Validation Prec@5 99.670 

lr: 0.017539591597208345
TRAINING - Epoch: [730][0/391]	Time 1.317 (1.317)	Data 0.425 (0.425)	Loss 0.0258 (0.0258)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [730][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.1086 (0.0596)	Prec@1 96.094 (97.881)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [730][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.0344 (0.0598)	Prec@1 99.219 (97.948)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [730][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0476 (0.0595)	Prec@1 97.656 (97.983)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [730][0/79]	Time 0.437 (0.437)	Data 0.407 (0.407)	Loss 0.3839 (0.3839)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:20

 Epoch: 731	Training Loss 0.0588 	Training Prec@1 97.988 	Training Prec@5 99.990 	Validation Loss 0.3986 	Validation Prec@1 89.850 	Validation Prec@5 99.630 

lr: 0.017419796984237755
TRAINING - Epoch: [731][0/391]	Time 1.328 (1.328)	Data 0.445 (0.445)	Loss 0.0583 (0.0583)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [731][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.0328 (0.0589)	Prec@1 99.219 (97.850)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [731][200/391]	Time 0.110 (0.119)	Data 0.000 (0.003)	Loss 0.0700 (0.0584)	Prec@1 97.656 (97.909)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [731][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0495 (0.0597)	Prec@1 98.438 (97.835)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [731][0/79]	Time 0.450 (0.450)	Data 0.412 (0.412)	Loss 0.3139 (0.3139)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:44

 Epoch: 732	Training Loss 0.0603 	Training Prec@1 97.792 	Training Prec@5 99.998 	Validation Loss 0.3900 	Validation Prec@1 89.870 	Validation Prec@5 99.680 

lr: 0.017300326512660526
TRAINING - Epoch: [732][0/391]	Time 1.341 (1.341)	Data 0.437 (0.437)	Loss 0.0595 (0.0595)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [732][100/391]	Time 0.106 (0.123)	Data 0.000 (0.005)	Loss 0.0283 (0.0573)	Prec@1 98.438 (97.919)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [732][200/391]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.1349 (0.0591)	Prec@1 95.312 (97.944)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [732][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0321 (0.0571)	Prec@1 98.438 (98.020)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [732][0/79]	Time 0.457 (0.457)	Data 0.423 (0.423)	Loss 0.3011 (0.3011)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:10

 Epoch: 733	Training Loss 0.0557 	Training Prec@1 98.058 	Training Prec@5 99.998 	Validation Loss 0.3914 	Validation Prec@1 89.790 	Validation Prec@5 99.640 

lr: 0.017181181371091876
TRAINING - Epoch: [733][0/391]	Time 1.333 (1.333)	Data 0.442 (0.442)	Loss 0.0626 (0.0626)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [733][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0461 (0.0574)	Prec@1 97.656 (98.043)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [733][200/391]	Time 0.113 (0.117)	Data 0.000 (0.003)	Loss 0.0867 (0.0576)	Prec@1 96.875 (98.010)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [733][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.0823 (0.0579)	Prec@1 96.875 (98.027)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [733][0/79]	Time 0.443 (0.443)	Data 0.416 (0.416)	Loss 0.3454 (0.3454)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:21

 Epoch: 734	Training Loss 0.0595 	Training Prec@1 97.904 	Training Prec@5 99.998 	Validation Loss 0.3794 	Validation Prec@1 90.020 	Validation Prec@5 99.570 

lr: 0.017062362744910287
TRAINING - Epoch: [734][0/391]	Time 1.299 (1.299)	Data 0.410 (0.410)	Loss 0.0728 (0.0728)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [734][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.1154 (0.0517)	Prec@1 95.312 (98.229)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [734][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.0853 (0.0517)	Prec@1 95.312 (98.177)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [734][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0344 (0.0540)	Prec@1 98.438 (98.118)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [734][0/79]	Time 0.427 (0.427)	Data 0.397 (0.397)	Loss 0.3080 (0.3080)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:26:41

 Epoch: 735	Training Loss 0.0552 	Training Prec@1 98.078 	Training Prec@5 99.994 	Validation Loss 0.4147 	Validation Prec@1 89.280 	Validation Prec@5 99.560 

lr: 0.016943871816245792
TRAINING - Epoch: [735][0/391]	Time 1.300 (1.300)	Data 0.417 (0.417)	Loss 0.0561 (0.0561)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [735][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.0294 (0.0586)	Prec@1 97.656 (97.942)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [735][200/391]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.0502 (0.0601)	Prec@1 97.656 (97.886)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [735][300/391]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.1060 (0.0603)	Prec@1 94.531 (97.882)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [735][0/79]	Time 0.447 (0.447)	Data 0.403 (0.403)	Loss 0.4021 (0.4021)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:22:25

 Epoch: 736	Training Loss 0.0595 	Training Prec@1 97.918 	Training Prec@5 99.994 	Validation Loss 0.3891 	Validation Prec@1 89.460 	Validation Prec@5 99.720 

lr: 0.016825709763968095
TRAINING - Epoch: [736][0/391]	Time 1.585 (1.585)	Data 0.424 (0.424)	Loss 0.0464 (0.0464)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [736][100/391]	Time 0.111 (0.129)	Data 0.000 (0.004)	Loss 0.0547 (0.0521)	Prec@1 98.438 (98.236)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [736][200/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.0331 (0.0566)	Prec@1 98.438 (98.041)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [736][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.0119 (0.0552)	Prec@1 100.000 (98.079)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [736][0/79]	Time 0.448 (0.448)	Data 0.406 (0.406)	Loss 0.3037 (0.3037)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:56

 Epoch: 737	Training Loss 0.0550 	Training Prec@1 98.092 	Training Prec@5 100.000 	Validation Loss 0.3997 	Validation Prec@1 89.600 	Validation Prec@5 99.700 

lr: 0.01670787776367489
TRAINING - Epoch: [737][0/391]	Time 1.315 (1.315)	Data 0.421 (0.421)	Loss 0.0311 (0.0311)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [737][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.0395 (0.0531)	Prec@1 98.438 (98.175)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [737][200/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.0511 (0.0543)	Prec@1 97.656 (98.076)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [737][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0884 (0.0556)	Prec@1 96.875 (98.053)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [737][0/79]	Time 0.444 (0.444)	Data 0.408 (0.408)	Loss 0.3024 (0.3024)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:32

 Epoch: 738	Training Loss 0.0559 	Training Prec@1 98.046 	Training Prec@5 99.996 	Validation Loss 0.4063 	Validation Prec@1 89.670 	Validation Prec@5 99.700 

lr: 0.016590376987680188
TRAINING - Epoch: [738][0/391]	Time 1.342 (1.342)	Data 0.455 (0.455)	Loss 0.0444 (0.0444)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [738][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.0506 (0.0530)	Prec@1 98.438 (98.120)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [738][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.0342 (0.0573)	Prec@1 99.219 (98.006)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [738][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0783 (0.0578)	Prec@1 96.875 (97.988)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [738][0/79]	Time 0.450 (0.450)	Data 0.409 (0.409)	Loss 0.3371 (0.3371)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:48

 Epoch: 739	Training Loss 0.0578 	Training Prec@1 97.962 	Training Prec@5 99.998 	Validation Loss 0.4016 	Validation Prec@1 89.640 	Validation Prec@5 99.680 

lr: 0.016473208605002686
TRAINING - Epoch: [739][0/391]	Time 1.320 (1.320)	Data 0.442 (0.442)	Loss 0.0777 (0.0777)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [739][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.0396 (0.0533)	Prec@1 99.219 (98.267)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [739][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.0243 (0.0529)	Prec@1 100.000 (98.231)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [739][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0530 (0.0517)	Prec@1 99.219 (98.274)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [739][0/79]	Time 0.431 (0.431)	Data 0.390 (0.390)	Loss 0.3231 (0.3231)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:19

 Epoch: 740	Training Loss 0.0515 	Training Prec@1 98.226 	Training Prec@5 99.996 	Validation Loss 0.4069 	Validation Prec@1 89.750 	Validation Prec@5 99.600 

lr: 0.016356373781354037
TRAINING - Epoch: [740][0/391]	Time 1.608 (1.608)	Data 0.420 (0.420)	Loss 0.0325 (0.0325)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [740][100/391]	Time 0.114 (0.130)	Data 0.000 (0.004)	Loss 0.0225 (0.0501)	Prec@1 99.219 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [740][200/391]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.0593 (0.0514)	Prec@1 98.438 (98.130)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [740][300/391]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.0810 (0.0539)	Prec@1 96.875 (98.066)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [740][0/79]	Time 0.445 (0.445)	Data 0.409 (0.409)	Loss 0.3735 (0.3735)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:38:58

 Epoch: 741	Training Loss 0.0542 	Training Prec@1 98.074 	Training Prec@5 100.000 	Validation Loss 0.3970 	Validation Prec@1 90.020 	Validation Prec@5 99.690 

lr: 0.016239873679127336
TRAINING - Epoch: [741][0/391]	Time 1.336 (1.336)	Data 0.427 (0.427)	Loss 0.1087 (0.1087)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][100/391]	Time 0.105 (0.116)	Data 0.000 (0.004)	Loss 0.0693 (0.0616)	Prec@1 96.875 (97.873)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1528 (0.0562)	Prec@1 95.312 (98.060)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0502 (0.0550)	Prec@1 97.656 (98.105)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [741][0/79]	Time 0.435 (0.435)	Data 0.407 (0.407)	Loss 0.2742 (0.2742)	Prec@1 95.312 (95.312)	Prec@5 99.219 (99.219)
Time cost: 00:45	Time of Finish: 2022-03-24 02:18:42

 Epoch: 742	Training Loss 0.0545 	Training Prec@1 98.090 	Training Prec@5 100.000 	Validation Loss 0.3899 	Validation Prec@1 89.780 	Validation Prec@5 99.640 

lr: 0.01612370945738546
TRAINING - Epoch: [742][0/391]	Time 1.619 (1.619)	Data 0.417 (0.417)	Loss 0.0704 (0.0704)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [742][100/391]	Time 0.112 (0.133)	Data 0.000 (0.004)	Loss 0.0205 (0.0534)	Prec@1 99.219 (98.035)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [742][200/391]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.0885 (0.0563)	Prec@1 97.656 (97.971)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [742][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.0546 (0.0563)	Prec@1 97.656 (97.981)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [742][0/79]	Time 0.457 (0.457)	Data 0.426 (0.426)	Loss 0.4422 (0.4422)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:39:44

 Epoch: 743	Training Loss 0.0566 	Training Prec@1 97.954 	Training Prec@5 99.996 	Validation Loss 0.3837 	Validation Prec@1 89.650 	Validation Prec@5 99.700 

lr: 0.0160078822718497
TRAINING - Epoch: [743][0/391]	Time 1.346 (1.346)	Data 0.433 (0.433)	Loss 0.1005 (0.1005)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [743][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0190 (0.0549)	Prec@1 99.219 (98.058)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [743][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0502 (0.0554)	Prec@1 97.656 (98.022)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [743][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0516 (0.0578)	Prec@1 98.438 (97.952)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [743][0/79]	Time 0.416 (0.416)	Data 0.390 (0.390)	Loss 0.4417 (0.4417)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:27:56

 Epoch: 744	Training Loss 0.0570 	Training Prec@1 98.002 	Training Prec@5 99.994 	Validation Loss 0.4094 	Validation Prec@1 89.970 	Validation Prec@5 99.610 

lr: 0.015892393274888103
TRAINING - Epoch: [744][0/391]	Time 1.368 (1.368)	Data 0.436 (0.436)	Loss 0.0484 (0.0484)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [744][100/391]	Time 0.116 (0.129)	Data 0.000 (0.005)	Loss 0.0408 (0.0520)	Prec@1 98.438 (98.283)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [744][200/391]	Time 0.119 (0.123)	Data 0.000 (0.003)	Loss 0.0367 (0.0527)	Prec@1 98.438 (98.231)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [744][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.0647 (0.0561)	Prec@1 97.656 (98.116)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [744][0/79]	Time 0.434 (0.434)	Data 0.403 (0.403)	Loss 0.3885 (0.3885)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:35:02

 Epoch: 745	Training Loss 0.0566 	Training Prec@1 98.092 	Training Prec@5 100.000 	Validation Loss 0.3929 	Validation Prec@1 90.110 	Validation Prec@5 99.630 

lr: 0.015777243615504054
TRAINING - Epoch: [745][0/391]	Time 1.373 (1.373)	Data 0.433 (0.433)	Loss 0.0431 (0.0431)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [745][100/391]	Time 0.107 (0.126)	Data 0.000 (0.005)	Loss 0.0619 (0.0474)	Prec@1 96.094 (98.414)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [745][200/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0493 (0.0515)	Prec@1 97.656 (98.189)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [745][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0649 (0.0521)	Prec@1 97.656 (98.162)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [745][0/79]	Time 0.428 (0.428)	Data 0.388 (0.388)	Loss 0.3836 (0.3836)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:06

 Epoch: 746	Training Loss 0.0536 	Training Prec@1 98.116 	Training Prec@5 99.994 	Validation Loss 0.3982 	Validation Prec@1 89.840 	Validation Prec@5 99.660 

lr: 0.015662434439324944
TRAINING - Epoch: [746][0/391]	Time 1.305 (1.305)	Data 0.366 (0.366)	Loss 0.0183 (0.0183)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [746][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.0650 (0.0524)	Prec@1 97.656 (98.306)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [746][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1017 (0.0525)	Prec@1 96.094 (98.243)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [746][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0444 (0.0543)	Prec@1 99.219 (98.175)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [746][0/79]	Time 0.444 (0.444)	Data 0.412 (0.412)	Loss 0.3279 (0.3279)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:16

 Epoch: 747	Training Loss 0.0558 	Training Prec@1 98.112 	Training Prec@5 99.996 	Validation Loss 0.3969 	Validation Prec@1 89.840 	Validation Prec@5 99.560 

lr: 0.015547966888590567
TRAINING - Epoch: [747][0/391]	Time 1.281 (1.281)	Data 0.415 (0.415)	Loss 0.0786 (0.0786)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [747][100/391]	Time 0.108 (0.116)	Data 0.000 (0.004)	Loss 0.0259 (0.0510)	Prec@1 98.438 (98.221)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [747][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0954 (0.0518)	Prec@1 95.312 (98.197)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [747][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0102 (0.0520)	Prec@1 100.000 (98.201)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [747][0/79]	Time 0.446 (0.446)	Data 0.408 (0.408)	Loss 0.2818 (0.2818)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:16:14

 Epoch: 748	Training Loss 0.0538 	Training Prec@1 98.098 	Training Prec@5 99.994 	Validation Loss 0.4051 	Validation Prec@1 89.820 	Validation Prec@5 99.620 

lr: 0.015433842102141961
TRAINING - Epoch: [748][0/391]	Time 1.576 (1.576)	Data 0.365 (0.365)	Loss 0.0359 (0.0359)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [748][100/391]	Time 0.111 (0.127)	Data 0.000 (0.004)	Loss 0.0683 (0.0558)	Prec@1 97.656 (98.151)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [748][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0771 (0.0565)	Prec@1 96.875 (98.080)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [748][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0575 (0.0565)	Prec@1 97.656 (98.059)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [748][0/79]	Time 0.484 (0.484)	Data 0.445 (0.445)	Loss 0.4820 (0.4820)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:46

 Epoch: 749	Training Loss 0.0574 	Training Prec@1 98.032 	Training Prec@5 99.998 	Validation Loss 0.3852 	Validation Prec@1 89.870 	Validation Prec@5 99.640 

lr: 0.015320061215409943
TRAINING - Epoch: [749][0/391]	Time 1.302 (1.302)	Data 0.363 (0.363)	Loss 0.0529 (0.0529)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [749][100/391]	Time 0.107 (0.127)	Data 0.000 (0.004)	Loss 0.0414 (0.0539)	Prec@1 98.438 (98.035)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [749][200/391]	Time 0.108 (0.121)	Data 0.000 (0.002)	Loss 0.0331 (0.0543)	Prec@1 99.219 (98.064)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [749][300/391]	Time 0.122 (0.120)	Data 0.001 (0.002)	Loss 0.1014 (0.0555)	Prec@1 96.094 (98.064)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [749][0/79]	Time 0.443 (0.443)	Data 0.406 (0.406)	Loss 0.4012 (0.4012)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:01

 Epoch: 750	Training Loss 0.0545 	Training Prec@1 98.090 	Training Prec@5 99.994 	Validation Loss 0.4056 	Validation Prec@1 90.210 	Validation Prec@5 99.680 

lr: 0.015206625360403925
TRAINING - Epoch: [750][0/391]	Time 1.325 (1.325)	Data 0.421 (0.421)	Loss 0.0545 (0.0545)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [750][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.0653 (0.0494)	Prec@1 96.875 (98.283)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [750][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.1023 (0.0546)	Prec@1 96.875 (98.072)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [750][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.0266 (0.0541)	Prec@1 99.219 (98.090)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [750][0/79]	Time 0.441 (0.441)	Data 0.403 (0.403)	Loss 0.3734 (0.3734)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:31

 Epoch: 751	Training Loss 0.0540 	Training Prec@1 98.084 	Training Prec@5 99.994 	Validation Loss 0.4003 	Validation Prec@1 89.890 	Validation Prec@5 99.680 

lr: 0.015093535665700531
TRAINING - Epoch: [751][0/391]	Time 1.338 (1.338)	Data 0.439 (0.439)	Loss 0.0233 (0.0233)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.0444 (0.0554)	Prec@1 99.219 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0161 (0.0539)	Prec@1 98.438 (98.142)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [751][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0556 (0.0551)	Prec@1 97.656 (98.097)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [751][0/79]	Time 0.453 (0.453)	Data 0.405 (0.405)	Loss 0.3733 (0.3733)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:26:26

 Epoch: 752	Training Loss 0.0542 	Training Prec@1 98.150 	Training Prec@5 100.000 	Validation Loss 0.3860 	Validation Prec@1 89.780 	Validation Prec@5 99.660 

lr: 0.014980793256432458
TRAINING - Epoch: [752][0/391]	Time 1.328 (1.328)	Data 0.418 (0.418)	Loss 0.0792 (0.0792)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [752][100/391]	Time 0.111 (0.125)	Data 0.000 (0.005)	Loss 0.0461 (0.0531)	Prec@1 97.656 (98.105)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [752][200/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.0771 (0.0529)	Prec@1 96.875 (98.060)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [752][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0394 (0.0537)	Prec@1 98.438 (98.072)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [752][0/79]	Time 0.437 (0.437)	Data 0.410 (0.410)	Loss 0.2696 (0.2696)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:49

 Epoch: 753	Training Loss 0.0534 	Training Prec@1 98.102 	Training Prec@5 99.994 	Validation Loss 0.3790 	Validation Prec@1 90.220 	Validation Prec@5 99.590 

lr: 0.014868399254277189
TRAINING - Epoch: [753][0/391]	Time 1.304 (1.304)	Data 0.371 (0.371)	Loss 0.0829 (0.0829)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][100/391]	Time 0.112 (0.127)	Data 0.000 (0.004)	Loss 0.0223 (0.0531)	Prec@1 100.000 (98.113)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][200/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.0196 (0.0527)	Prec@1 100.000 (98.103)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.0513 (0.0529)	Prec@1 96.875 (98.160)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [753][0/79]	Time 0.432 (0.432)	Data 0.398 (0.398)	Loss 0.3520 (0.3520)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:13

 Epoch: 754	Training Loss 0.0524 	Training Prec@1 98.176 	Training Prec@5 99.998 	Validation Loss 0.4256 	Validation Prec@1 89.360 	Validation Prec@5 99.690 

lr: 0.014756354777445987
TRAINING - Epoch: [754][0/391]	Time 1.296 (1.296)	Data 0.416 (0.416)	Loss 0.0692 (0.0692)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [754][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.0300 (0.0574)	Prec@1 98.438 (97.958)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [754][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.0735 (0.0558)	Prec@1 96.094 (97.983)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [754][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.0745 (0.0563)	Prec@1 96.875 (97.975)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [754][0/79]	Time 0.450 (0.450)	Data 0.411 (0.411)	Loss 0.2942 (0.2942)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:00

 Epoch: 755	Training Loss 0.0556 	Training Prec@1 98.036 	Training Prec@5 99.990 	Validation Loss 0.3682 	Validation Prec@1 90.520 	Validation Prec@5 99.610 

lr: 0.014644660940672613
TRAINING - Epoch: [755][0/391]	Time 1.299 (1.299)	Data 0.367 (0.367)	Loss 0.0369 (0.0369)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [755][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.0561 (0.0491)	Prec@1 98.438 (98.236)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [755][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.0483 (0.0501)	Prec@1 97.656 (98.224)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [755][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0653 (0.0513)	Prec@1 97.656 (98.194)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [755][0/79]	Time 0.434 (0.434)	Data 0.400 (0.400)	Loss 0.2686 (0.2686)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:55

 Epoch: 756	Training Loss 0.0509 	Training Prec@1 98.186 	Training Prec@5 99.998 	Validation Loss 0.3910 	Validation Prec@1 89.930 	Validation Prec@5 99.690 

lr: 0.014533318855202308
TRAINING - Epoch: [756][0/391]	Time 1.289 (1.289)	Data 0.376 (0.376)	Loss 0.0542 (0.0542)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [756][100/391]	Time 0.113 (0.127)	Data 0.000 (0.004)	Loss 0.0192 (0.0545)	Prec@1 99.219 (98.175)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [756][200/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.0718 (0.0539)	Prec@1 97.656 (98.150)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [756][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.0488 (0.0539)	Prec@1 98.438 (98.118)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [756][0/79]	Time 0.441 (0.441)	Data 0.405 (0.405)	Loss 0.3437 (0.3437)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:07

 Epoch: 757	Training Loss 0.0543 	Training Prec@1 98.096 	Training Prec@5 99.998 	Validation Loss 0.3945 	Validation Prec@1 90.430 	Validation Prec@5 99.710 

lr: 0.014422329628780784
TRAINING - Epoch: [757][0/391]	Time 1.301 (1.301)	Data 0.426 (0.426)	Loss 0.0405 (0.0405)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [757][100/391]	Time 0.109 (0.125)	Data 0.000 (0.005)	Loss 0.0457 (0.0514)	Prec@1 98.438 (98.391)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [757][200/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.0509 (0.0501)	Prec@1 96.875 (98.336)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [757][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0267 (0.0514)	Prec@1 99.219 (98.261)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [757][0/79]	Time 0.444 (0.444)	Data 0.405 (0.405)	Loss 0.2424 (0.2424)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:37

 Epoch: 758	Training Loss 0.0514 	Training Prec@1 98.270 	Training Prec@5 99.994 	Validation Loss 0.3880 	Validation Prec@1 89.940 	Validation Prec@5 99.610 

lr: 0.014311694365643052
TRAINING - Epoch: [758][0/391]	Time 1.322 (1.322)	Data 0.441 (0.441)	Loss 0.0424 (0.0424)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [758][100/391]	Time 0.111 (0.124)	Data 0.000 (0.005)	Loss 0.0609 (0.0499)	Prec@1 96.875 (98.298)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [758][200/391]	Time 0.120 (0.120)	Data 0.000 (0.003)	Loss 0.0285 (0.0538)	Prec@1 99.219 (98.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [758][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.0404 (0.0524)	Prec@1 98.438 (98.209)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [758][0/79]	Time 0.431 (0.431)	Data 0.398 (0.398)	Loss 0.4417 (0.4417)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:20

 Epoch: 759	Training Loss 0.0525 	Training Prec@1 98.202 	Training Prec@5 100.000 	Validation Loss 0.3975 	Validation Prec@1 90.120 	Validation Prec@5 99.670 

lr: 0.0142014141665026
TRAINING - Epoch: [759][0/391]	Time 1.313 (1.313)	Data 0.412 (0.412)	Loss 0.0330 (0.0330)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [759][100/391]	Time 0.120 (0.126)	Data 0.000 (0.004)	Loss 0.0621 (0.0507)	Prec@1 98.438 (98.159)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [759][200/391]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.0165 (0.0523)	Prec@1 99.219 (98.092)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [759][300/391]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.0604 (0.0524)	Prec@1 96.875 (98.108)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [759][0/79]	Time 0.414 (0.414)	Data 0.387 (0.387)	Loss 0.2973 (0.2973)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:16

 Epoch: 760	Training Loss 0.0511 	Training Prec@1 98.164 	Training Prec@5 100.000 	Validation Loss 0.3787 	Validation Prec@1 89.960 	Validation Prec@5 99.710 

lr: 0.014091490128540345
TRAINING - Epoch: [760][0/391]	Time 1.360 (1.360)	Data 0.453 (0.453)	Loss 0.0306 (0.0306)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [760][100/391]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.0627 (0.0546)	Prec@1 96.094 (98.089)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [760][200/391]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.0558 (0.0534)	Prec@1 98.438 (98.107)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [760][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1324 (0.0543)	Prec@1 96.875 (98.103)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [760][0/79]	Time 0.437 (0.437)	Data 0.400 (0.400)	Loss 0.3585 (0.3585)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:45

 Epoch: 761	Training Loss 0.0532 	Training Prec@1 98.128 	Training Prec@5 99.994 	Validation Loss 0.3824 	Validation Prec@1 90.130 	Validation Prec@5 99.640 

lr: 0.013981923345393787
TRAINING - Epoch: [761][0/391]	Time 1.603 (1.603)	Data 0.414 (0.414)	Loss 0.1125 (0.1125)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][100/391]	Time 0.122 (0.132)	Data 0.000 (0.004)	Loss 0.0235 (0.0527)	Prec@1 98.438 (98.267)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][200/391]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.0433 (0.0539)	Prec@1 98.438 (98.162)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][300/391]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.0522 (0.0537)	Prec@1 99.219 (98.162)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [761][0/79]	Time 0.439 (0.439)	Data 0.392 (0.392)	Loss 0.2930 (0.2930)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:40:15

 Epoch: 762	Training Loss 0.0538 	Training Prec@1 98.140 	Training Prec@5 99.998 	Validation Loss 0.3838 	Validation Prec@1 90.170 	Validation Prec@5 99.740 

lr: 0.013872714907146061
TRAINING - Epoch: [762][0/391]	Time 1.626 (1.626)	Data 0.448 (0.448)	Loss 0.0187 (0.0187)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [762][100/391]	Time 0.121 (0.135)	Data 0.000 (0.005)	Loss 0.1023 (0.0548)	Prec@1 96.094 (98.012)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [762][200/391]	Time 0.120 (0.128)	Data 0.000 (0.003)	Loss 0.0378 (0.0543)	Prec@1 98.438 (98.099)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [762][300/391]	Time 0.113 (0.124)	Data 0.000 (0.002)	Loss 0.0192 (0.0534)	Prec@1 99.219 (98.121)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [762][0/79]	Time 0.437 (0.437)	Data 0.395 (0.395)	Loss 0.3722 (0.3722)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:39:00

 Epoch: 763	Training Loss 0.0534 	Training Prec@1 98.104 	Training Prec@5 99.998 	Validation Loss 0.3774 	Validation Prec@1 90.210 	Validation Prec@5 99.690 

lr: 0.013763865900315081
TRAINING - Epoch: [763][0/391]	Time 1.315 (1.315)	Data 0.419 (0.419)	Loss 0.0526 (0.0526)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.0458 (0.0540)	Prec@1 99.219 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0604 (0.0530)	Prec@1 96.094 (98.134)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [763][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.0138 (0.0533)	Prec@1 100.000 (98.105)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [763][0/79]	Time 0.441 (0.441)	Data 0.392 (0.392)	Loss 0.2515 (0.2515)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:44

 Epoch: 764	Training Loss 0.0531 	Training Prec@1 98.122 	Training Prec@5 99.994 	Validation Loss 0.3955 	Validation Prec@1 89.960 	Validation Prec@5 99.700 

lr: 0.013655377407842801
TRAINING - Epoch: [764][0/391]	Time 1.347 (1.347)	Data 0.448 (0.448)	Loss 0.0397 (0.0397)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [764][100/391]	Time 0.113 (0.132)	Data 0.000 (0.005)	Loss 0.0804 (0.0518)	Prec@1 96.875 (98.151)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [764][200/391]	Time 0.117 (0.123)	Data 0.000 (0.003)	Loss 0.0129 (0.0526)	Prec@1 100.000 (98.165)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [764][300/391]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.0279 (0.0527)	Prec@1 100.000 (98.134)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [764][0/79]	Time 0.458 (0.458)	Data 0.425 (0.425)	Loss 0.3233 (0.3233)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:30

 Epoch: 765	Training Loss 0.0526 	Training Prec@1 98.140 	Training Prec@5 99.998 	Validation Loss 0.3854 	Validation Prec@1 90.070 	Validation Prec@5 99.660 

lr: 0.013547250509084442
TRAINING - Epoch: [765][0/391]	Time 1.294 (1.294)	Data 0.382 (0.382)	Loss 0.0308 (0.0308)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [765][100/391]	Time 0.110 (0.131)	Data 0.000 (0.004)	Loss 0.0471 (0.0526)	Prec@1 98.438 (98.236)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [765][200/391]	Time 0.113 (0.123)	Data 0.000 (0.002)	Loss 0.0544 (0.0532)	Prec@1 98.438 (98.154)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [765][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.0463 (0.0528)	Prec@1 99.219 (98.157)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [765][0/79]	Time 0.440 (0.440)	Data 0.402 (0.402)	Loss 0.3015 (0.3015)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:27

 Epoch: 766	Training Loss 0.0526 	Training Prec@1 98.166 	Training Prec@5 99.998 	Validation Loss 0.3802 	Validation Prec@1 90.110 	Validation Prec@5 99.680 

lr: 0.01343948627979767
TRAINING - Epoch: [766][0/391]	Time 1.595 (1.595)	Data 0.413 (0.413)	Loss 0.0906 (0.0906)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [766][100/391]	Time 0.113 (0.132)	Data 0.000 (0.004)	Loss 0.0331 (0.0565)	Prec@1 98.438 (97.989)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [766][200/391]	Time 0.115 (0.125)	Data 0.000 (0.002)	Loss 0.0303 (0.0551)	Prec@1 98.438 (98.041)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [766][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.0083 (0.0541)	Prec@1 100.000 (98.064)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [766][0/79]	Time 0.466 (0.466)	Data 0.430 (0.430)	Loss 0.2161 (0.2161)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:40:05

 Epoch: 767	Training Loss 0.0543 	Training Prec@1 98.082 	Training Prec@5 99.998 	Validation Loss 0.4000 	Validation Prec@1 89.630 	Validation Prec@5 99.670 

lr: 0.013332085792131954
TRAINING - Epoch: [767][0/391]	Time 1.339 (1.339)	Data 0.420 (0.420)	Loss 0.0484 (0.0484)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][100/391]	Time 0.110 (0.126)	Data 0.000 (0.005)	Loss 0.0484 (0.0503)	Prec@1 98.438 (98.198)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.0456 (0.0517)	Prec@1 97.656 (98.142)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0576 (0.0530)	Prec@1 96.875 (98.087)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [767][0/79]	Time 0.442 (0.442)	Data 0.399 (0.399)	Loss 0.2859 (0.2859)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:19

 Epoch: 768	Training Loss 0.0530 	Training Prec@1 98.138 	Training Prec@5 99.994 	Validation Loss 0.4006 	Validation Prec@1 89.620 	Validation Prec@5 99.670 

lr: 0.013225050114617887
TRAINING - Epoch: [768][0/391]	Time 1.338 (1.338)	Data 0.432 (0.432)	Loss 0.0352 (0.0352)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [768][100/391]	Time 0.111 (0.129)	Data 0.000 (0.005)	Loss 0.1505 (0.0573)	Prec@1 96.094 (98.051)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [768][200/391]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.0636 (0.0546)	Prec@1 97.656 (98.130)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [768][300/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.0663 (0.0562)	Prec@1 96.875 (97.988)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [768][0/79]	Time 0.447 (0.447)	Data 0.408 (0.408)	Loss 0.2576 (0.2576)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:39:46

 Epoch: 769	Training Loss 0.0558 	Training Prec@1 97.984 	Training Prec@5 99.996 	Validation Loss 0.4010 	Validation Prec@1 89.930 	Validation Prec@5 99.610 

lr: 0.013118380312156558
TRAINING - Epoch: [769][0/391]	Time 1.318 (1.318)	Data 0.417 (0.417)	Loss 0.0384 (0.0384)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [769][100/391]	Time 0.116 (0.129)	Data 0.000 (0.005)	Loss 0.0946 (0.0516)	Prec@1 95.312 (98.275)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [769][200/391]	Time 0.114 (0.122)	Data 0.000 (0.003)	Loss 0.0384 (0.0535)	Prec@1 99.219 (98.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [769][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0247 (0.0537)	Prec@1 99.219 (98.188)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [769][0/79]	Time 0.436 (0.436)	Data 0.403 (0.403)	Loss 0.3205 (0.3205)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:19

 Epoch: 770	Training Loss 0.0535 	Training Prec@1 98.190 	Training Prec@5 99.998 	Validation Loss 0.4304 	Validation Prec@1 89.530 	Validation Prec@5 99.610 

lr: 0.013012077446008958
TRAINING - Epoch: [770][0/391]	Time 1.306 (1.306)	Data 0.409 (0.409)	Loss 0.0286 (0.0286)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [770][100/391]	Time 0.117 (0.129)	Data 0.000 (0.004)	Loss 0.0317 (0.0509)	Prec@1 97.656 (98.329)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [770][200/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.0704 (0.0541)	Prec@1 97.656 (98.181)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [770][300/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.0661 (0.0557)	Prec@1 98.438 (98.079)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [770][0/79]	Time 0.493 (0.493)	Data 0.449 (0.449)	Loss 0.3826 (0.3826)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:59

 Epoch: 771	Training Loss 0.0556 	Training Prec@1 98.088 	Training Prec@5 99.998 	Validation Loss 0.4024 	Validation Prec@1 89.950 	Validation Prec@5 99.630 

lr: 0.01290614257378539
TRAINING - Epoch: [771][0/391]	Time 1.356 (1.356)	Data 0.430 (0.430)	Loss 0.0965 (0.0965)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [771][100/391]	Time 0.120 (0.132)	Data 0.000 (0.005)	Loss 0.0343 (0.0521)	Prec@1 99.219 (98.221)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [771][200/391]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.0286 (0.0543)	Prec@1 98.438 (98.154)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [771][300/391]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.0257 (0.0521)	Prec@1 99.219 (98.199)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [771][0/79]	Time 0.451 (0.451)	Data 0.405 (0.405)	Loss 0.4743 (0.4743)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:41:02

 Epoch: 772	Training Loss 0.0526 	Training Prec@1 98.178 	Training Prec@5 99.998 	Validation Loss 0.3804 	Validation Prec@1 90.260 	Validation Prec@5 99.720 

lr: 0.012800576749435057
TRAINING - Epoch: [772][0/391]	Time 1.650 (1.650)	Data 0.448 (0.448)	Loss 0.0435 (0.0435)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][100/391]	Time 0.121 (0.133)	Data 0.000 (0.005)	Loss 0.0296 (0.0505)	Prec@1 99.219 (98.182)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][200/391]	Time 0.117 (0.126)	Data 0.000 (0.003)	Loss 0.0633 (0.0500)	Prec@1 96.875 (98.158)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][300/391]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.0759 (0.0508)	Prec@1 96.875 (98.165)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [772][0/79]	Time 0.426 (0.426)	Data 0.392 (0.392)	Loss 0.3484 (0.3484)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:39:05

 Epoch: 773	Training Loss 0.0510 	Training Prec@1 98.184 	Training Prec@5 99.998 	Validation Loss 0.3842 	Validation Prec@1 90.000 	Validation Prec@5 99.660 

lr: 0.012695381023235376
TRAINING - Epoch: [773][0/391]	Time 1.605 (1.605)	Data 0.406 (0.406)	Loss 0.0629 (0.0629)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [773][100/391]	Time 0.120 (0.133)	Data 0.000 (0.004)	Loss 0.0259 (0.0525)	Prec@1 98.438 (98.182)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [773][200/391]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.1057 (0.0533)	Prec@1 96.094 (98.123)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [773][300/391]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.0426 (0.0539)	Prec@1 98.438 (98.061)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [773][0/79]	Time 0.445 (0.445)	Data 0.411 (0.411)	Loss 0.3754 (0.3754)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:51

 Epoch: 774	Training Loss 0.0541 	Training Prec@1 98.038 	Training Prec@5 100.000 	Validation Loss 0.4157 	Validation Prec@1 89.490 	Validation Prec@5 99.470 

lr: 0.012590556441781725
TRAINING - Epoch: [774][0/391]	Time 1.606 (1.606)	Data 0.420 (0.420)	Loss 0.0844 (0.0844)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [774][100/391]	Time 0.121 (0.133)	Data 0.000 (0.004)	Loss 0.0673 (0.0574)	Prec@1 98.438 (98.089)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [774][200/391]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.0707 (0.0585)	Prec@1 97.656 (98.033)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [774][300/391]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.1197 (0.0565)	Prec@1 97.656 (98.079)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [774][0/79]	Time 0.428 (0.428)	Data 0.381 (0.381)	Loss 0.3872 (0.3872)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:40:30

 Epoch: 775	Training Loss 0.0562 	Training Prec@1 98.080 	Training Prec@5 99.996 	Validation Loss 0.3973 	Validation Prec@1 89.740 	Validation Prec@5 99.740 

lr: 0.012486104047976926
TRAINING - Epoch: [775][0/391]	Time 1.340 (1.340)	Data 0.443 (0.443)	Loss 0.0764 (0.0764)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.0337 (0.0532)	Prec@1 99.219 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][200/391]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.1095 (0.0551)	Prec@1 96.875 (98.092)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0505 (0.0531)	Prec@1 98.438 (98.152)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [775][0/79]	Time 0.441 (0.441)	Data 0.413 (0.413)	Loss 0.4479 (0.4479)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:07

 Epoch: 776	Training Loss 0.0530 	Training Prec@1 98.150 	Training Prec@5 100.000 	Validation Loss 0.4110 	Validation Prec@1 89.740 	Validation Prec@5 99.610 

lr: 0.012382024881020925
TRAINING - Epoch: [776][0/391]	Time 1.582 (1.582)	Data 0.362 (0.362)	Loss 0.0957 (0.0957)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [776][100/391]	Time 0.108 (0.129)	Data 0.000 (0.004)	Loss 0.1428 (0.0508)	Prec@1 93.750 (98.229)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [776][200/391]	Time 0.107 (0.120)	Data 0.000 (0.002)	Loss 0.1021 (0.0522)	Prec@1 98.438 (98.154)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [776][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0174 (0.0528)	Prec@1 100.000 (98.097)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [776][0/79]	Time 0.439 (0.439)	Data 0.411 (0.411)	Loss 0.3271 (0.3271)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:02

 Epoch: 777	Training Loss 0.0529 	Training Prec@1 98.104 	Training Prec@5 99.998 	Validation Loss 0.3844 	Validation Prec@1 90.100 	Validation Prec@5 99.630 

lr: 0.012278319976400397
TRAINING - Epoch: [777][0/391]	Time 1.332 (1.332)	Data 0.440 (0.440)	Loss 0.0331 (0.0331)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.0548 (0.0499)	Prec@1 98.438 (98.167)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][200/391]	Time 0.108 (0.118)	Data 0.000 (0.003)	Loss 0.0471 (0.0513)	Prec@1 97.656 (98.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0430 (0.0507)	Prec@1 99.219 (98.209)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [777][0/79]	Time 0.437 (0.437)	Data 0.408 (0.408)	Loss 0.2921 (0.2921)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:06

 Epoch: 778	Training Loss 0.0523 	Training Prec@1 98.130 	Training Prec@5 99.996 	Validation Loss 0.3886 	Validation Prec@1 89.800 	Validation Prec@5 99.600 

lr: 0.012174990365878435
TRAINING - Epoch: [778][0/391]	Time 1.616 (1.616)	Data 0.416 (0.416)	Loss 0.0588 (0.0588)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [778][100/391]	Time 0.123 (0.134)	Data 0.000 (0.004)	Loss 0.0123 (0.0550)	Prec@1 100.000 (98.120)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [778][200/391]	Time 0.112 (0.126)	Data 0.000 (0.002)	Loss 0.0140 (0.0550)	Prec@1 99.219 (98.095)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [778][300/391]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.0580 (0.0537)	Prec@1 97.656 (98.136)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [778][0/79]	Time 0.419 (0.419)	Data 0.376 (0.376)	Loss 0.4243 (0.4243)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:38:25

 Epoch: 779	Training Loss 0.0538 	Training Prec@1 98.138 	Training Prec@5 99.996 	Validation Loss 0.3850 	Validation Prec@1 90.140 	Validation Prec@5 99.700 

lr: 0.012072037077484405
TRAINING - Epoch: [779][0/391]	Time 1.269 (1.269)	Data 0.417 (0.417)	Loss 0.0509 (0.0509)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [779][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.1212 (0.0550)	Prec@1 95.312 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [779][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.1421 (0.0570)	Prec@1 94.531 (98.018)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [779][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.0284 (0.0564)	Prec@1 100.000 (98.059)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [779][0/79]	Time 0.452 (0.452)	Data 0.412 (0.412)	Loss 0.3816 (0.3816)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:22

 Epoch: 780	Training Loss 0.0564 	Training Prec@1 98.042 	Training Prec@5 99.998 	Validation Loss 0.3772 	Validation Prec@1 89.960 	Validation Prec@5 99.660 

lr: 0.011969461135503562
TRAINING - Epoch: [780][0/391]	Time 1.255 (1.255)	Data 0.355 (0.355)	Loss 0.0147 (0.0147)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [780][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.0735 (0.0525)	Prec@1 96.875 (98.198)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [780][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0429 (0.0533)	Prec@1 98.438 (98.095)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [780][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0412 (0.0533)	Prec@1 98.438 (98.160)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [780][0/79]	Time 0.421 (0.421)	Data 0.381 (0.381)	Loss 0.2416 (0.2416)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:41

 Epoch: 781	Training Loss 0.0526 	Training Prec@1 98.180 	Training Prec@5 99.998 	Validation Loss 0.3810 	Validation Prec@1 90.250 	Validation Prec@5 99.660 

lr: 0.011867263560466957
TRAINING - Epoch: [781][0/391]	Time 1.287 (1.287)	Data 0.429 (0.429)	Loss 0.0222 (0.0222)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [781][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.1052 (0.0521)	Prec@1 96.094 (98.144)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [781][200/391]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.0447 (0.0559)	Prec@1 99.219 (97.998)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [781][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.1092 (0.0553)	Prec@1 93.750 (98.043)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [781][0/79]	Time 0.425 (0.425)	Data 0.388 (0.388)	Loss 0.3208 (0.3208)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:34

 Epoch: 782	Training Loss 0.0541 	Training Prec@1 98.082 	Training Prec@5 99.994 	Validation Loss 0.3842 	Validation Prec@1 90.140 	Validation Prec@5 99.660 

lr: 0.011765445369141248
TRAINING - Epoch: [782][0/391]	Time 1.360 (1.360)	Data 0.472 (0.472)	Loss 0.0595 (0.0595)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [782][100/391]	Time 0.116 (0.128)	Data 0.000 (0.005)	Loss 0.0380 (0.0542)	Prec@1 98.438 (98.035)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [782][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.0233 (0.0538)	Prec@1 99.219 (98.057)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [782][300/391]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.0595 (0.0538)	Prec@1 96.875 (98.082)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [782][0/79]	Time 0.454 (0.454)	Data 0.414 (0.414)	Loss 0.2661 (0.2661)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:31

 Epoch: 783	Training Loss 0.0533 	Training Prec@1 98.084 	Training Prec@5 99.994 	Validation Loss 0.3805 	Validation Prec@1 90.260 	Validation Prec@5 99.680 

lr: 0.011664007574518643
TRAINING - Epoch: [783][0/391]	Time 1.309 (1.309)	Data 0.430 (0.430)	Loss 0.1005 (0.1005)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [783][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.0720 (0.0545)	Prec@1 98.438 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [783][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0606 (0.0544)	Prec@1 98.438 (98.103)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [783][300/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.0661 (0.0552)	Prec@1 97.656 (98.079)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [783][0/79]	Time 0.436 (0.436)	Data 0.407 (0.407)	Loss 0.3935 (0.3935)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:31

 Epoch: 784	Training Loss 0.0553 	Training Prec@1 98.076 	Training Prec@5 99.994 	Validation Loss 0.3845 	Validation Prec@1 90.130 	Validation Prec@5 99.660 

lr: 0.011562951185806676
TRAINING - Epoch: [784][0/391]	Time 1.339 (1.339)	Data 0.418 (0.418)	Loss 0.0244 (0.0244)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.0156 (0.0521)	Prec@1 100.000 (98.252)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][200/391]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.0415 (0.0552)	Prec@1 99.219 (98.099)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0751 (0.0553)	Prec@1 96.875 (98.069)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [784][0/79]	Time 0.444 (0.444)	Data 0.405 (0.405)	Loss 0.2883 (0.2883)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:41

 Epoch: 785	Training Loss 0.0542 	Training Prec@1 98.086 	Training Prec@5 99.994 	Validation Loss 0.3906 	Validation Prec@1 89.970 	Validation Prec@5 99.700 

lr: 0.011462277208418343
TRAINING - Epoch: [785][0/391]	Time 1.357 (1.357)	Data 0.428 (0.428)	Loss 0.0810 (0.0810)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [785][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.0454 (0.0528)	Prec@1 97.656 (98.097)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [785][200/391]	Time 0.108 (0.119)	Data 0.000 (0.003)	Loss 0.0670 (0.0531)	Prec@1 98.438 (98.127)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [785][300/391]	Time 0.124 (0.118)	Data 0.000 (0.002)	Loss 0.0661 (0.0532)	Prec@1 98.438 (98.168)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [785][0/79]	Time 0.431 (0.431)	Data 0.382 (0.382)	Loss 0.2606 (0.2606)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:51

 Epoch: 786	Training Loss 0.0520 	Training Prec@1 98.194 	Training Prec@5 100.000 	Validation Loss 0.3869 	Validation Prec@1 90.550 	Validation Prec@5 99.610 

lr: 0.01136198664396197
TRAINING - Epoch: [786][0/391]	Time 1.335 (1.335)	Data 0.415 (0.415)	Loss 0.0395 (0.0395)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [786][100/391]	Time 0.110 (0.126)	Data 0.000 (0.004)	Loss 0.0299 (0.0491)	Prec@1 98.438 (98.252)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [786][200/391]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.0178 (0.0510)	Prec@1 100.000 (98.173)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [786][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0807 (0.0510)	Prec@1 97.656 (98.201)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [786][0/79]	Time 0.471 (0.471)	Data 0.435 (0.435)	Loss 0.2964 (0.2964)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:59

 Epoch: 787	Training Loss 0.0507 	Training Prec@1 98.212 	Training Prec@5 99.996 	Validation Loss 0.3838 	Validation Prec@1 89.990 	Validation Prec@5 99.630 

lr: 0.011262080490231348
TRAINING - Epoch: [787][0/391]	Time 1.322 (1.322)	Data 0.416 (0.416)	Loss 0.0541 (0.0541)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [787][100/391]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.0272 (0.0528)	Prec@1 99.219 (98.089)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [787][200/391]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.0845 (0.0501)	Prec@1 96.875 (98.278)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [787][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0584 (0.0517)	Prec@1 98.438 (98.214)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [787][0/79]	Time 0.435 (0.435)	Data 0.399 (0.399)	Loss 0.3730 (0.3730)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:28

 Epoch: 788	Training Loss 0.0522 	Training Prec@1 98.198 	Training Prec@5 99.988 	Validation Loss 0.3918 	Validation Prec@1 89.850 	Validation Prec@5 99.580 

lr: 0.011162559741195722
TRAINING - Epoch: [788][0/391]	Time 1.328 (1.328)	Data 0.439 (0.439)	Loss 0.0263 (0.0263)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.0482 (0.0537)	Prec@1 98.438 (98.113)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][200/391]	Time 0.116 (0.117)	Data 0.000 (0.003)	Loss 0.0994 (0.0530)	Prec@1 96.875 (98.127)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [788][300/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.0676 (0.0535)	Prec@1 98.438 (98.139)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [788][0/79]	Time 0.501 (0.501)	Data 0.463 (0.463)	Loss 0.2562 (0.2562)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 789	Training Loss 0.0531 	Training Prec@1 98.144 	Training Prec@5 100.000 	Validation Loss 0.3875 	Validation Prec@1 90.110 	Validation Prec@5 99.650 

lr: 0.011063425386989902
TRAINING - Epoch: [789][0/391]	Time 1.265 (1.265)	Data 0.421 (0.421)	Loss 0.0134 (0.0134)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [789][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.0581 (0.0529)	Prec@1 97.656 (98.167)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [789][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0538 (0.0535)	Prec@1 97.656 (98.173)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [789][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0848 (0.0538)	Prec@1 96.094 (98.131)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [789][0/79]	Time 0.445 (0.445)	Data 0.413 (0.413)	Loss 0.2652 (0.2652)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:19:47

 Epoch: 790	Training Loss 0.0537 	Training Prec@1 98.150 	Training Prec@5 99.994 	Validation Loss 0.4025 	Validation Prec@1 89.960 	Validation Prec@5 99.650 

lr: 0.010964678413904517
TRAINING - Epoch: [790][0/391]	Time 1.342 (1.342)	Data 0.411 (0.411)	Loss 0.0944 (0.0944)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [790][100/391]	Time 0.114 (0.118)	Data 0.000 (0.004)	Loss 0.0111 (0.0491)	Prec@1 100.000 (98.267)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [790][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.0263 (0.0506)	Prec@1 100.000 (98.197)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [790][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0439 (0.0507)	Prec@1 99.219 (98.188)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [790][0/79]	Time 0.434 (0.434)	Data 0.401 (0.401)	Loss 0.3379 (0.3379)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:01

 Epoch: 791	Training Loss 0.0510 	Training Prec@1 98.180 	Training Prec@5 99.994 	Validation Loss 0.3804 	Validation Prec@1 90.410 	Validation Prec@5 99.660 

lr: 0.010866319804376074
TRAINING - Epoch: [791][0/391]	Time 1.346 (1.346)	Data 0.425 (0.425)	Loss 0.0631 (0.0631)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][100/391]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.0548 (0.0548)	Prec@1 98.438 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0778 (0.0544)	Prec@1 98.438 (98.092)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][300/391]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.0524 (0.0544)	Prec@1 98.438 (98.064)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [791][0/79]	Time 0.424 (0.424)	Data 0.396 (0.396)	Loss 0.3325 (0.3325)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:00

 Epoch: 792	Training Loss 0.0540 	Training Prec@1 98.062 	Training Prec@5 100.000 	Validation Loss 0.3719 	Validation Prec@1 90.300 	Validation Prec@5 99.680 

lr: 0.010768350536977268
TRAINING - Epoch: [792][0/391]	Time 1.321 (1.321)	Data 0.442 (0.442)	Loss 0.1118 (0.1118)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [792][100/391]	Time 0.114 (0.130)	Data 0.000 (0.005)	Loss 0.0391 (0.0528)	Prec@1 97.656 (98.105)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [792][200/391]	Time 0.112 (0.122)	Data 0.000 (0.003)	Loss 0.0591 (0.0532)	Prec@1 98.438 (98.041)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [792][300/391]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.0538 (0.0516)	Prec@1 97.656 (98.131)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [792][0/79]	Time 0.432 (0.432)	Data 0.386 (0.386)	Loss 0.4346 (0.4346)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:10

 Epoch: 793	Training Loss 0.0518 	Training Prec@1 98.134 	Training Prec@5 99.994 	Validation Loss 0.3989 	Validation Prec@1 89.920 	Validation Prec@5 99.620 

lr: 0.010670771586407196
TRAINING - Epoch: [793][0/391]	Time 1.370 (1.370)	Data 0.453 (0.453)	Loss 0.0674 (0.0674)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [793][100/391]	Time 0.114 (0.128)	Data 0.000 (0.005)	Loss 0.1052 (0.0547)	Prec@1 96.875 (98.043)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [793][200/391]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.0360 (0.0516)	Prec@1 99.219 (98.208)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [793][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.1594 (0.0546)	Prec@1 96.094 (98.072)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [793][0/79]	Time 0.446 (0.446)	Data 0.411 (0.411)	Loss 0.3481 (0.3481)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:16

 Epoch: 794	Training Loss 0.0541 	Training Prec@1 98.084 	Training Prec@5 99.994 	Validation Loss 0.3835 	Validation Prec@1 90.180 	Validation Prec@5 99.700 

lr: 0.0105735839234817
TRAINING - Epoch: [794][0/391]	Time 1.293 (1.293)	Data 0.435 (0.435)	Loss 0.0527 (0.0527)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [794][100/391]	Time 0.118 (0.130)	Data 0.000 (0.005)	Loss 0.0644 (0.0551)	Prec@1 98.438 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [794][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.0236 (0.0547)	Prec@1 100.000 (98.084)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [794][300/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.0555 (0.0550)	Prec@1 98.438 (98.069)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [794][0/79]	Time 0.453 (0.453)	Data 0.408 (0.408)	Loss 0.3549 (0.3549)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:50

 Epoch: 795	Training Loss 0.0539 	Training Prec@1 98.118 	Training Prec@5 99.996 	Validation Loss 0.3859 	Validation Prec@1 90.000 	Validation Prec@5 99.680 

lr: 0.010476788515123686
TRAINING - Epoch: [795][0/391]	Time 1.589 (1.589)	Data 0.432 (0.432)	Loss 0.0490 (0.0490)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][100/391]	Time 0.124 (0.133)	Data 0.000 (0.005)	Loss 0.0553 (0.0545)	Prec@1 97.656 (98.136)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][200/391]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.0478 (0.0558)	Prec@1 98.438 (98.134)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][300/391]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.0259 (0.0551)	Prec@1 100.000 (98.090)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [795][0/79]	Time 0.433 (0.433)	Data 0.401 (0.401)	Loss 0.3451 (0.3451)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:37:54

 Epoch: 796	Training Loss 0.0547 	Training Prec@1 98.096 	Training Prec@5 99.992 	Validation Loss 0.3854 	Validation Prec@1 90.090 	Validation Prec@5 99.730 

lr: 0.010380386324353497
TRAINING - Epoch: [796][0/391]	Time 1.266 (1.266)	Data 0.413 (0.413)	Loss 0.1232 (0.1232)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [796][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.0380 (0.0555)	Prec@1 98.438 (97.989)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [796][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.1075 (0.0525)	Prec@1 96.094 (98.127)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [796][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.0257 (0.0523)	Prec@1 100.000 (98.139)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [796][0/79]	Time 0.446 (0.446)	Data 0.407 (0.407)	Loss 0.3037 (0.3037)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:58

 Epoch: 797	Training Loss 0.0518 	Training Prec@1 98.162 	Training Prec@5 99.998 	Validation Loss 0.4098 	Validation Prec@1 89.810 	Validation Prec@5 99.640 

lr: 0.010284378310279348
TRAINING - Epoch: [797][0/391]	Time 1.305 (1.305)	Data 0.446 (0.446)	Loss 0.0621 (0.0621)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [797][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.0455 (0.0562)	Prec@1 98.438 (97.888)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [797][200/391]	Time 0.123 (0.119)	Data 0.000 (0.003)	Loss 0.0465 (0.0531)	Prec@1 99.219 (98.025)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [797][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.0561 (0.0543)	Prec@1 98.438 (98.027)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [797][0/79]	Time 0.437 (0.437)	Data 0.406 (0.406)	Loss 0.3956 (0.3956)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:06

 Epoch: 798	Training Loss 0.0539 	Training Prec@1 98.052 	Training Prec@5 99.996 	Validation Loss 0.3992 	Validation Prec@1 89.620 	Validation Prec@5 99.660 

lr: 0.010188765428087805
TRAINING - Epoch: [798][0/391]	Time 1.281 (1.281)	Data 0.376 (0.376)	Loss 0.0282 (0.0282)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][100/391]	Time 0.112 (0.124)	Data 0.000 (0.004)	Loss 0.0517 (0.0567)	Prec@1 98.438 (97.989)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0281 (0.0549)	Prec@1 100.000 (98.057)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][300/391]	Time 0.123 (0.116)	Data 0.000 (0.002)	Loss 0.0094 (0.0537)	Prec@1 100.000 (98.123)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [798][0/79]	Time 0.419 (0.419)	Data 0.383 (0.383)	Loss 0.4011 (0.4011)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:29

 Epoch: 799	Training Loss 0.0536 	Training Prec@1 98.126 	Training Prec@5 99.998 	Validation Loss 0.3716 	Validation Prec@1 90.270 	Validation Prec@5 99.750 

lr: 0.010093548629034206
TRAINING - Epoch: [799][0/391]	Time 1.254 (1.254)	Data 0.371 (0.371)	Loss 0.0460 (0.0460)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [799][100/391]	Time 0.111 (0.124)	Data 0.000 (0.004)	Loss 0.0217 (0.0576)	Prec@1 100.000 (97.904)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [799][200/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0456 (0.0558)	Prec@1 98.438 (98.002)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [799][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0363 (0.0546)	Prec@1 99.219 (98.061)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [799][0/79]	Time 0.427 (0.427)	Data 0.398 (0.398)	Loss 0.3355 (0.3355)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:27

 Epoch: 800	Training Loss 0.0538 	Training Prec@1 98.114 	Training Prec@5 100.000 	Validation Loss 0.3917 	Validation Prec@1 89.960 	Validation Prec@5 99.640 

lr: 0.009998728860433266
TRAINING - Epoch: [800][0/391]	Time 1.234 (1.234)	Data 0.345 (0.345)	Loss 0.0562 (0.0562)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [800][100/391]	Time 0.106 (0.125)	Data 0.000 (0.004)	Loss 0.0300 (0.0558)	Prec@1 99.219 (98.058)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [800][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0461 (0.0539)	Prec@1 96.875 (98.142)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [800][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.0553 (0.0535)	Prec@1 97.656 (98.134)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [800][0/79]	Time 0.416 (0.416)	Data 0.387 (0.387)	Loss 0.2944 (0.2944)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:41

 Epoch: 801	Training Loss 0.0533 	Training Prec@1 98.120 	Training Prec@5 99.994 	Validation Loss 0.3885 	Validation Prec@1 90.170 	Validation Prec@5 99.720 

lr: 0.00990430706564966
TRAINING - Epoch: [801][0/391]	Time 1.284 (1.284)	Data 0.439 (0.439)	Loss 0.0821 (0.0821)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [801][100/391]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.0787 (0.0553)	Prec@1 97.656 (98.066)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [801][200/391]	Time 0.109 (0.118)	Data 0.000 (0.003)	Loss 0.0443 (0.0543)	Prec@1 98.438 (98.111)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [801][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.0551 (0.0554)	Prec@1 96.875 (98.022)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [801][0/79]	Time 0.443 (0.443)	Data 0.405 (0.405)	Loss 0.3534 (0.3534)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:22

 Epoch: 802	Training Loss 0.0554 	Training Prec@1 98.040 	Training Prec@5 99.996 	Validation Loss 0.3888 	Validation Prec@1 90.000 	Validation Prec@5 99.690 

lr: 0.009810284184088582
TRAINING - Epoch: [802][0/391]	Time 1.271 (1.271)	Data 0.418 (0.418)	Loss 0.0645 (0.0645)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [802][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.0597 (0.0579)	Prec@1 99.219 (98.051)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [802][200/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.0805 (0.0582)	Prec@1 96.875 (97.983)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [802][300/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.1276 (0.0566)	Prec@1 95.312 (98.009)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [802][0/79]	Time 0.447 (0.447)	Data 0.403 (0.403)	Loss 0.3832 (0.3832)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:25

 Epoch: 803	Training Loss 0.0571 	Training Prec@1 97.970 	Training Prec@5 99.994 	Validation Loss 0.3829 	Validation Prec@1 90.070 	Validation Prec@5 99.700 

lr: 0.009716661151186447
TRAINING - Epoch: [803][0/391]	Time 1.259 (1.259)	Data 0.372 (0.372)	Loss 0.0795 (0.0795)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [803][100/391]	Time 0.103 (0.120)	Data 0.000 (0.004)	Loss 0.0402 (0.0546)	Prec@1 97.656 (98.105)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [803][200/391]	Time 0.104 (0.112)	Data 0.000 (0.002)	Loss 0.1108 (0.0559)	Prec@1 97.656 (98.053)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [803][300/391]	Time 0.105 (0.110)	Data 0.000 (0.001)	Loss 0.0436 (0.0567)	Prec@1 99.219 (98.040)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [803][0/79]	Time 0.437 (0.437)	Data 0.409 (0.409)	Loss 0.2549 (0.2549)	Prec@1 95.312 (95.312)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:21:05

 Epoch: 804	Training Loss 0.0558 	Training Prec@1 98.046 	Training Prec@5 99.992 	Validation Loss 0.4038 	Validation Prec@1 89.840 	Validation Prec@5 99.710 

lr: 0.0096234388984015
TRAINING - Epoch: [804][0/391]	Time 1.296 (1.296)	Data 0.427 (0.427)	Loss 0.0727 (0.0727)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [804][100/391]	Time 0.120 (0.130)	Data 0.000 (0.005)	Loss 0.0299 (0.0554)	Prec@1 100.000 (98.051)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [804][200/391]	Time 0.111 (0.124)	Data 0.000 (0.003)	Loss 0.0504 (0.0544)	Prec@1 97.656 (98.057)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [804][300/391]	Time 0.111 (0.121)	Data 0.000 (0.002)	Loss 0.0341 (0.0535)	Prec@1 97.656 (98.116)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [804][0/79]	Time 0.433 (0.433)	Data 0.400 (0.400)	Loss 0.2966 (0.2966)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:34

 Epoch: 805	Training Loss 0.0533 	Training Prec@1 98.114 	Training Prec@5 99.998 	Validation Loss 0.4016 	Validation Prec@1 89.710 	Validation Prec@5 99.550 

lr: 0.009530618353204708
TRAINING - Epoch: [805][0/391]	Time 1.275 (1.275)	Data 0.415 (0.415)	Loss 0.0179 (0.0179)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][100/391]	Time 0.120 (0.127)	Data 0.000 (0.004)	Loss 0.0322 (0.0547)	Prec@1 98.438 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][200/391]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.0424 (0.0543)	Prec@1 98.438 (98.072)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][300/391]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.0314 (0.0536)	Prec@1 99.219 (98.131)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [805][0/79]	Time 0.441 (0.441)	Data 0.401 (0.401)	Loss 0.2814 (0.2814)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:29

 Epoch: 806	Training Loss 0.0543 	Training Prec@1 98.078 	Training Prec@5 99.998 	Validation Loss 0.3899 	Validation Prec@1 90.050 	Validation Prec@5 99.620 

lr: 0.009438200439070378
TRAINING - Epoch: [806][0/391]	Time 1.293 (1.293)	Data 0.419 (0.419)	Loss 0.0483 (0.0483)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [806][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.0671 (0.0512)	Prec@1 98.438 (98.275)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [806][200/391]	Time 0.108 (0.119)	Data 0.000 (0.002)	Loss 0.0239 (0.0505)	Prec@1 100.000 (98.266)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [806][300/391]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.1007 (0.0515)	Prec@1 96.094 (98.219)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [806][0/79]	Time 0.443 (0.443)	Data 0.416 (0.416)	Loss 0.3051 (0.3051)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:24

 Epoch: 807	Training Loss 0.0508 	Training Prec@1 98.236 	Training Prec@5 99.998 	Validation Loss 0.3851 	Validation Prec@1 90.170 	Validation Prec@5 99.600 

lr: 0.009346186075467045
TRAINING - Epoch: [807][0/391]	Time 1.257 (1.257)	Data 0.369 (0.369)	Loss 0.1026 (0.1026)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [807][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.0705 (0.0500)	Prec@1 95.312 (98.260)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [807][200/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.0674 (0.0513)	Prec@1 97.656 (98.197)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [807][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0324 (0.0521)	Prec@1 100.000 (98.204)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [807][0/79]	Time 0.438 (0.438)	Data 0.389 (0.389)	Loss 0.4394 (0.4394)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:35

 Epoch: 808	Training Loss 0.0521 	Training Prec@1 98.196 	Training Prec@5 99.996 	Validation Loss 0.4013 	Validation Prec@1 89.360 	Validation Prec@5 99.680 

lr: 0.00925457617784829
TRAINING - Epoch: [808][0/391]	Time 1.496 (1.496)	Data 0.344 (0.344)	Loss 0.0739 (0.0739)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [808][100/391]	Time 0.114 (0.128)	Data 0.000 (0.004)	Loss 0.0299 (0.0526)	Prec@1 98.438 (98.066)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [808][200/391]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.0879 (0.0525)	Prec@1 96.875 (98.107)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [808][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.0621 (0.0533)	Prec@1 97.656 (98.087)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [808][0/79]	Time 0.432 (0.432)	Data 0.403 (0.403)	Loss 0.3398 (0.3398)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:34:20

 Epoch: 809	Training Loss 0.0537 	Training Prec@1 98.080 	Training Prec@5 100.000 	Validation Loss 0.3977 	Validation Prec@1 89.980 	Validation Prec@5 99.600 

lr: 0.009163371657643705
TRAINING - Epoch: [809][0/391]	Time 1.365 (1.365)	Data 0.432 (0.432)	Loss 0.0729 (0.0729)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [809][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.0360 (0.0528)	Prec@1 98.438 (98.190)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [809][200/391]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.0134 (0.0526)	Prec@1 100.000 (98.208)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [809][300/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.0108 (0.0530)	Prec@1 100.000 (98.139)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [809][0/79]	Time 0.433 (0.433)	Data 0.392 (0.392)	Loss 0.3409 (0.3409)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:37

 Epoch: 810	Training Loss 0.0531 	Training Prec@1 98.120 	Training Prec@5 99.996 	Validation Loss 0.3832 	Validation Prec@1 89.860 	Validation Prec@5 99.630 

lr: 0.009072573422249692
TRAINING - Epoch: [810][0/391]	Time 1.262 (1.262)	Data 0.371 (0.371)	Loss 0.0270 (0.0270)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][100/391]	Time 0.109 (0.121)	Data 0.000 (0.004)	Loss 0.0396 (0.0551)	Prec@1 98.438 (98.159)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][200/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.0485 (0.0541)	Prec@1 97.656 (98.181)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.0206 (0.0540)	Prec@1 99.219 (98.157)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [810][0/79]	Time 0.418 (0.418)	Data 0.382 (0.382)	Loss 0.3715 (0.3715)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:27:27

 Epoch: 811	Training Loss 0.0541 	Training Prec@1 98.132 	Training Prec@5 100.000 	Validation Loss 0.3856 	Validation Prec@1 89.920 	Validation Prec@5 99.670 

lr: 0.008982182375020555
TRAINING - Epoch: [811][0/391]	Time 1.312 (1.312)	Data 0.416 (0.416)	Loss 0.0731 (0.0731)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][100/391]	Time 0.112 (0.126)	Data 0.000 (0.004)	Loss 0.0551 (0.0551)	Prec@1 97.656 (98.089)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][200/391]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.0141 (0.0541)	Prec@1 100.000 (98.068)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.0427 (0.0538)	Prec@1 98.438 (98.097)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [811][0/79]	Time 0.447 (0.447)	Data 0.409 (0.409)	Loss 0.3260 (0.3260)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:28

 Epoch: 812	Training Loss 0.0531 	Training Prec@1 98.120 	Training Prec@5 100.000 	Validation Loss 0.4094 	Validation Prec@1 89.800 	Validation Prec@5 99.720 

lr: 0.00889219941525949
TRAINING - Epoch: [812][0/391]	Time 1.251 (1.251)	Data 0.351 (0.351)	Loss 0.0558 (0.0558)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [812][100/391]	Time 0.110 (0.126)	Data 0.000 (0.004)	Loss 0.0396 (0.0508)	Prec@1 98.438 (98.221)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [812][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0964 (0.0516)	Prec@1 96.875 (98.103)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [812][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0151 (0.0537)	Prec@1 99.219 (98.051)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [812][0/79]	Time 0.392 (0.392)	Data 0.353 (0.353)	Loss 0.3408 (0.3408)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:24

 Epoch: 813	Training Loss 0.0539 	Training Prec@1 98.040 	Training Prec@5 99.998 	Validation Loss 0.3922 	Validation Prec@1 89.650 	Validation Prec@5 99.600 

lr: 0.008802625438209585
TRAINING - Epoch: [813][0/391]	Time 1.290 (1.290)	Data 0.426 (0.426)	Loss 0.0422 (0.0422)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [813][100/391]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.0626 (0.0517)	Prec@1 96.875 (98.144)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [813][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0282 (0.0530)	Prec@1 99.219 (98.115)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [813][300/391]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.1654 (0.0530)	Prec@1 95.312 (98.147)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [813][0/79]	Time 0.467 (0.467)	Data 0.427 (0.427)	Loss 0.3294 (0.3294)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:28:09

 Epoch: 814	Training Loss 0.0518 	Training Prec@1 98.164 	Training Prec@5 99.994 	Validation Loss 0.3851 	Validation Prec@1 90.220 	Validation Prec@5 99.720 

lr: 0.008713461335044971
TRAINING - Epoch: [814][0/391]	Time 1.254 (1.254)	Data 0.356 (0.356)	Loss 0.0740 (0.0740)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [814][100/391]	Time 0.118 (0.126)	Data 0.000 (0.004)	Loss 0.0266 (0.0568)	Prec@1 99.219 (98.043)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [814][200/391]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.0934 (0.0539)	Prec@1 95.312 (98.099)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [814][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0511 (0.0541)	Prec@1 97.656 (98.097)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [814][0/79]	Time 0.453 (0.453)	Data 0.414 (0.414)	Loss 0.3393 (0.3393)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:17

 Epoch: 815	Training Loss 0.0542 	Training Prec@1 98.098 	Training Prec@5 99.996 	Validation Loss 0.3896 	Validation Prec@1 90.000 	Validation Prec@5 99.720 

lr: 0.008624707992861887
TRAINING - Epoch: [815][0/391]	Time 1.276 (1.276)	Data 0.426 (0.426)	Loss 0.0281 (0.0281)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [815][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.0145 (0.0494)	Prec@1 99.219 (98.190)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [815][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0877 (0.0544)	Prec@1 96.875 (98.068)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [815][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0347 (0.0544)	Prec@1 97.656 (98.012)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [815][0/79]	Time 0.406 (0.406)	Data 0.379 (0.379)	Loss 0.2743 (0.2743)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:11

 Epoch: 816	Training Loss 0.0540 	Training Prec@1 98.034 	Training Prec@5 99.998 	Validation Loss 0.3993 	Validation Prec@1 90.210 	Validation Prec@5 99.670 

lr: 0.008536366294669969
TRAINING - Epoch: [816][0/391]	Time 1.608 (1.608)	Data 0.461 (0.461)	Loss 0.0499 (0.0499)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [816][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.0665 (0.0560)	Prec@1 97.656 (98.020)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [816][200/391]	Time 0.113 (0.118)	Data 0.000 (0.003)	Loss 0.0521 (0.0540)	Prec@1 97.656 (98.107)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [816][300/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.0641 (0.0555)	Prec@1 98.438 (98.072)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [816][0/79]	Time 0.447 (0.447)	Data 0.406 (0.406)	Loss 0.3246 (0.3246)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:29

 Epoch: 817	Training Loss 0.0544 	Training Prec@1 98.132 	Training Prec@5 99.998 	Validation Loss 0.3950 	Validation Prec@1 89.810 	Validation Prec@5 99.600 

lr: 0.008448437119383341
TRAINING - Epoch: [817][0/391]	Time 1.284 (1.284)	Data 0.379 (0.379)	Loss 0.0371 (0.0371)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.0592 (0.0540)	Prec@1 96.875 (98.082)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0600 (0.0516)	Prec@1 98.438 (98.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [817][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0344 (0.0518)	Prec@1 98.438 (98.152)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [817][0/79]	Time 0.504 (0.504)	Data 0.461 (0.461)	Loss 0.3575 (0.3575)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:12

 Epoch: 818	Training Loss 0.0518 	Training Prec@1 98.150 	Training Prec@5 99.998 	Validation Loss 0.3848 	Validation Prec@1 90.030 	Validation Prec@5 99.730 

lr: 0.008360921341811945
TRAINING - Epoch: [818][0/391]	Time 1.500 (1.500)	Data 0.436 (0.436)	Loss 0.0989 (0.0989)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.0150 (0.0562)	Prec@1 100.000 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][200/391]	Time 0.111 (0.119)	Data 0.000 (0.003)	Loss 0.0425 (0.0546)	Prec@1 98.438 (98.092)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [818][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0726 (0.0531)	Prec@1 96.094 (98.152)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [818][0/79]	Time 0.441 (0.441)	Data 0.406 (0.406)	Loss 0.3544 (0.3544)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:44

 Epoch: 819	Training Loss 0.0536 	Training Prec@1 98.122 	Training Prec@5 99.996 	Validation Loss 0.3818 	Validation Prec@1 90.140 	Validation Prec@5 99.660 

lr: 0.008273819832652813
TRAINING - Epoch: [819][0/391]	Time 1.328 (1.328)	Data 0.449 (0.449)	Loss 0.0189 (0.0189)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [819][100/391]	Time 0.110 (0.125)	Data 0.000 (0.005)	Loss 0.0984 (0.0522)	Prec@1 97.656 (98.066)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [819][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.0604 (0.0522)	Prec@1 97.656 (98.146)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [819][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0270 (0.0538)	Prec@1 99.219 (98.092)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [819][0/79]	Time 0.441 (0.441)	Data 0.399 (0.399)	Loss 0.2917 (0.2917)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:40

 Epoch: 820	Training Loss 0.0547 	Training Prec@1 98.050 	Training Prec@5 99.996 	Validation Loss 0.3898 	Validation Prec@1 89.870 	Validation Prec@5 99.580 

lr: 0.008187133458481407
TRAINING - Epoch: [820][0/391]	Time 1.281 (1.281)	Data 0.411 (0.411)	Loss 0.0288 (0.0288)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [820][100/391]	Time 0.118 (0.123)	Data 0.000 (0.004)	Loss 0.0286 (0.0523)	Prec@1 99.219 (98.113)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [820][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0739 (0.0513)	Prec@1 97.656 (98.197)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [820][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.0525 (0.0516)	Prec@1 97.656 (98.170)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [820][0/79]	Time 0.489 (0.489)	Data 0.447 (0.447)	Loss 0.3618 (0.3618)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 821	Training Loss 0.0518 	Training Prec@1 98.182 	Training Prec@5 99.994 	Validation Loss 0.3898 	Validation Prec@1 90.090 	Validation Prec@5 99.710 

lr: 0.008100863081743
TRAINING - Epoch: [821][0/391]	Time 1.277 (1.277)	Data 0.419 (0.419)	Loss 0.0195 (0.0195)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [821][100/391]	Time 0.106 (0.123)	Data 0.000 (0.004)	Loss 0.0560 (0.0574)	Prec@1 98.438 (97.919)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [821][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0839 (0.0550)	Prec@1 96.875 (98.049)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [821][300/391]	Time 0.103 (0.113)	Data 0.000 (0.002)	Loss 0.0725 (0.0555)	Prec@1 98.438 (98.056)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [821][0/79]	Time 0.443 (0.443)	Data 0.404 (0.404)	Loss 0.2745 (0.2745)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:45	Time of Finish: 2022-03-24 02:25:01

 Epoch: 822	Training Loss 0.0562 	Training Prec@1 98.042 	Training Prec@5 99.998 	Validation Loss 0.3916 	Validation Prec@1 90.570 	Validation Prec@5 99.680 

lr: 0.008015009560744092
TRAINING - Epoch: [822][0/391]	Time 1.296 (1.296)	Data 0.440 (0.440)	Loss 0.0396 (0.0396)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [822][100/391]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.0323 (0.0544)	Prec@1 98.438 (98.120)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [822][200/391]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.0488 (0.0551)	Prec@1 96.875 (98.041)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [822][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.1075 (0.0566)	Prec@1 96.094 (97.975)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [822][0/79]	Time 0.434 (0.434)	Data 0.402 (0.402)	Loss 0.3881 (0.3881)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:27

 Epoch: 823	Training Loss 0.0559 	Training Prec@1 97.990 	Training Prec@5 99.996 	Validation Loss 0.3999 	Validation Prec@1 89.870 	Validation Prec@5 99.620 

lr: 0.007929573749643887
TRAINING - Epoch: [823][0/391]	Time 1.282 (1.282)	Data 0.429 (0.429)	Loss 0.1254 (0.1254)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [823][100/391]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.0803 (0.0538)	Prec@1 96.875 (98.097)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [823][200/391]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.0583 (0.0532)	Prec@1 96.875 (98.115)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [823][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.0230 (0.0525)	Prec@1 99.219 (98.123)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [823][0/79]	Time 0.426 (0.426)	Data 0.387 (0.387)	Loss 0.3596 (0.3596)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:56

 Epoch: 824	Training Loss 0.0535 	Training Prec@1 98.094 	Training Prec@5 100.000 	Validation Loss 0.3790 	Validation Prec@1 90.270 	Validation Prec@5 99.740 

lr: 0.007844556498445777
TRAINING - Epoch: [824][0/391]	Time 1.246 (1.246)	Data 0.346 (0.346)	Loss 0.0603 (0.0603)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [824][100/391]	Time 0.126 (0.136)	Data 0.001 (0.004)	Loss 0.0315 (0.0528)	Prec@1 99.219 (98.260)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [824][200/391]	Time 0.111 (0.129)	Data 0.000 (0.002)	Loss 0.0665 (0.0530)	Prec@1 97.656 (98.181)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [824][300/391]	Time 0.111 (0.124)	Data 0.000 (0.002)	Loss 0.0431 (0.0532)	Prec@1 98.438 (98.170)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [824][0/79]	Time 0.452 (0.452)	Data 0.417 (0.417)	Loss 0.3081 (0.3081)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:37:05

 Epoch: 825	Training Loss 0.0540 	Training Prec@1 98.130 	Training Prec@5 99.994 	Validation Loss 0.3804 	Validation Prec@1 90.260 	Validation Prec@5 99.710 

lr: 0.007759958652988858
TRAINING - Epoch: [825][0/391]	Time 1.296 (1.296)	Data 0.422 (0.422)	Loss 0.0253 (0.0253)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0223 (0.0539)	Prec@1 99.219 (98.120)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0660 (0.0534)	Prec@1 96.094 (98.095)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0734 (0.0537)	Prec@1 96.094 (98.092)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [825][0/79]	Time 0.449 (0.449)	Data 0.414 (0.414)	Loss 0.3648 (0.3648)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:08

 Epoch: 826	Training Loss 0.0542 	Training Prec@1 98.106 	Training Prec@5 100.000 	Validation Loss 0.3883 	Validation Prec@1 90.070 	Validation Prec@5 99.680 

lr: 0.007675781054939574
TRAINING - Epoch: [826][0/391]	Time 1.271 (1.271)	Data 0.422 (0.422)	Loss 0.0250 (0.0250)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [826][100/391]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.0284 (0.0522)	Prec@1 99.219 (98.136)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [826][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.0419 (0.0527)	Prec@1 99.219 (98.080)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [826][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0541 (0.0530)	Prec@1 97.656 (98.059)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [826][0/79]	Time 0.448 (0.448)	Data 0.411 (0.411)	Loss 0.3599 (0.3599)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:31

 Epoch: 827	Training Loss 0.0527 	Training Prec@1 98.100 	Training Prec@5 99.992 	Validation Loss 0.3947 	Validation Prec@1 89.670 	Validation Prec@5 99.680 

lr: 0.007592024541783333
TRAINING - Epoch: [827][0/391]	Time 1.264 (1.264)	Data 0.408 (0.408)	Loss 0.0640 (0.0640)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [827][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.0403 (0.0461)	Prec@1 98.438 (98.422)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [827][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.0866 (0.0482)	Prec@1 97.656 (98.352)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [827][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.0210 (0.0498)	Prec@1 98.438 (98.292)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [827][0/79]	Time 0.440 (0.440)	Data 0.405 (0.405)	Loss 0.3502 (0.3502)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:27:55

 Epoch: 828	Training Loss 0.0492 	Training Prec@1 98.284 	Training Prec@5 99.998 	Validation Loss 0.3927 	Validation Prec@1 89.720 	Validation Prec@5 99.660 

lr: 0.007508689946816117
TRAINING - Epoch: [828][0/391]	Time 1.276 (1.276)	Data 0.421 (0.421)	Loss 0.0721 (0.0721)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [828][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.0859 (0.0510)	Prec@1 96.875 (98.097)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [828][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0824 (0.0507)	Prec@1 96.094 (98.138)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [828][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.0315 (0.0517)	Prec@1 98.438 (98.136)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [828][0/79]	Time 0.450 (0.450)	Data 0.409 (0.409)	Loss 0.3988 (0.3988)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:27:58

 Epoch: 829	Training Loss 0.0531 	Training Prec@1 98.116 	Training Prec@5 99.996 	Validation Loss 0.3780 	Validation Prec@1 90.160 	Validation Prec@5 99.740 

lr: 0.007425778099136271
TRAINING - Epoch: [829][0/391]	Time 1.284 (1.284)	Data 0.420 (0.420)	Loss 0.0203 (0.0203)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [829][100/391]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.0669 (0.0533)	Prec@1 98.438 (98.074)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [829][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.0660 (0.0542)	Prec@1 97.656 (98.080)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [829][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0518 (0.0542)	Prec@1 96.094 (98.090)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [829][0/79]	Time 0.421 (0.421)	Data 0.393 (0.393)	Loss 0.3964 (0.3964)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:41

 Epoch: 830	Training Loss 0.0540 	Training Prec@1 98.072 	Training Prec@5 99.996 	Validation Loss 0.3834 	Validation Prec@1 89.800 	Validation Prec@5 99.700 

lr: 0.007343289823636157
TRAINING - Epoch: [830][0/391]	Time 1.325 (1.325)	Data 0.472 (0.472)	Loss 0.0643 (0.0643)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [830][100/391]	Time 0.112 (0.125)	Data 0.000 (0.005)	Loss 0.0525 (0.0511)	Prec@1 97.656 (98.136)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [830][200/391]	Time 0.110 (0.118)	Data 0.000 (0.003)	Loss 0.0429 (0.0511)	Prec@1 99.219 (98.154)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [830][300/391]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.0355 (0.0508)	Prec@1 98.438 (98.129)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [830][0/79]	Time 0.428 (0.428)	Data 0.393 (0.393)	Loss 0.2840 (0.2840)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:27

 Epoch: 831	Training Loss 0.0520 	Training Prec@1 98.108 	Training Prec@5 99.996 	Validation Loss 0.3813 	Validation Prec@1 89.990 	Validation Prec@5 99.710 

lr: 0.0072612259409940766
TRAINING - Epoch: [831][0/391]	Time 1.270 (1.270)	Data 0.409 (0.409)	Loss 0.0868 (0.0868)	Prec@1 96.094 (96.094)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [831][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.0606 (0.0514)	Prec@1 97.656 (98.105)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [831][200/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.1475 (0.0541)	Prec@1 93.750 (98.088)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [831][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0128 (0.0547)	Prec@1 99.219 (98.072)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [831][0/79]	Time 0.420 (0.420)	Data 0.380 (0.380)	Loss 0.3860 (0.3860)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:31

 Epoch: 832	Training Loss 0.0555 	Training Prec@1 98.062 	Training Prec@5 99.996 	Validation Loss 0.3895 	Validation Prec@1 89.670 	Validation Prec@5 99.720 

lr: 0.007179587267665989
TRAINING - Epoch: [832][0/391]	Time 1.269 (1.269)	Data 0.405 (0.405)	Loss 0.0580 (0.0580)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [832][100/391]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.0252 (0.0541)	Prec@1 99.219 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [832][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.0542 (0.0538)	Prec@1 99.219 (98.049)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [832][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0783 (0.0530)	Prec@1 97.656 (98.165)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [832][0/79]	Time 0.442 (0.442)	Data 0.411 (0.411)	Loss 0.2767 (0.2767)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:31

 Epoch: 833	Training Loss 0.0531 	Training Prec@1 98.164 	Training Prec@5 99.996 	Validation Loss 0.3876 	Validation Prec@1 90.070 	Validation Prec@5 99.690 

lr: 0.007098374615877429
TRAINING - Epoch: [833][0/391]	Time 1.556 (1.556)	Data 0.416 (0.416)	Loss 0.0826 (0.0826)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [833][100/391]	Time 0.119 (0.132)	Data 0.000 (0.004)	Loss 0.0502 (0.0492)	Prec@1 98.438 (98.267)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [833][200/391]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.0804 (0.0519)	Prec@1 96.094 (98.127)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [833][300/391]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.0581 (0.0524)	Prec@1 97.656 (98.097)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [833][0/79]	Time 0.437 (0.437)	Data 0.398 (0.398)	Loss 0.3304 (0.3304)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:36:29

 Epoch: 834	Training Loss 0.0522 	Training Prec@1 98.116 	Training Prec@5 99.996 	Validation Loss 0.3891 	Validation Prec@1 90.110 	Validation Prec@5 99.750 

lr: 0.0070175887936154875
TRAINING - Epoch: [834][0/391]	Time 1.279 (1.279)	Data 0.426 (0.426)	Loss 0.0688 (0.0688)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [834][100/391]	Time 0.112 (0.126)	Data 0.000 (0.005)	Loss 0.0559 (0.0531)	Prec@1 98.438 (98.198)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [834][200/391]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.0239 (0.0529)	Prec@1 100.000 (98.189)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [834][300/391]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.1084 (0.0537)	Prec@1 96.875 (98.157)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [834][0/79]	Time 0.408 (0.408)	Data 0.374 (0.374)	Loss 0.4980 (0.4980)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:57

 Epoch: 835	Training Loss 0.0548 	Training Prec@1 98.086 	Training Prec@5 99.996 	Validation Loss 0.3984 	Validation Prec@1 89.720 	Validation Prec@5 99.620 

lr: 0.006937230604620632
TRAINING - Epoch: [835][0/391]	Time 1.298 (1.298)	Data 0.420 (0.420)	Loss 0.0213 (0.0213)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [835][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0407 (0.0525)	Prec@1 99.219 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [835][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0529 (0.0541)	Prec@1 98.438 (98.029)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [835][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.0431 (0.0523)	Prec@1 98.438 (98.147)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [835][0/79]	Time 0.445 (0.445)	Data 0.395 (0.395)	Loss 0.4019 (0.4019)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:16

 Epoch: 836	Training Loss 0.0524 	Training Prec@1 98.148 	Training Prec@5 99.988 	Validation Loss 0.3928 	Validation Prec@1 89.510 	Validation Prec@5 99.650 

lr: 0.006857300848378856
TRAINING - Epoch: [836][0/391]	Time 1.564 (1.564)	Data 0.422 (0.422)	Loss 0.0217 (0.0217)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [836][100/391]	Time 0.121 (0.136)	Data 0.000 (0.005)	Loss 0.0400 (0.0529)	Prec@1 98.438 (98.113)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [836][200/391]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.0701 (0.0549)	Prec@1 97.656 (98.041)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [836][300/391]	Time 0.109 (0.122)	Data 0.000 (0.002)	Loss 0.1417 (0.0549)	Prec@1 96.875 (98.069)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [836][0/79]	Time 0.444 (0.444)	Data 0.402 (0.402)	Loss 0.4266 (0.4266)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:33:41

 Epoch: 837	Training Loss 0.0537 	Training Prec@1 98.106 	Training Prec@5 99.996 	Validation Loss 0.3781 	Validation Prec@1 90.320 	Validation Prec@5 99.690 

lr: 0.006777800320113631
TRAINING - Epoch: [837][0/391]	Time 1.547 (1.547)	Data 0.427 (0.427)	Loss 0.0375 (0.0375)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.0576 (0.0601)	Prec@1 98.438 (97.850)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][200/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0159 (0.0594)	Prec@1 100.000 (97.827)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [837][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.0445 (0.0572)	Prec@1 99.219 (97.931)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [837][0/79]	Time 0.449 (0.449)	Data 0.410 (0.410)	Loss 0.2533 (0.2533)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:27:36

 Epoch: 838	Training Loss 0.0557 	Training Prec@1 97.990 	Training Prec@5 99.996 	Validation Loss 0.3975 	Validation Prec@1 90.120 	Validation Prec@5 99.620 

lr: 0.0066987298107780546
TRAINING - Epoch: [838][0/391]	Time 1.310 (1.310)	Data 0.449 (0.449)	Loss 0.0253 (0.0253)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [838][100/391]	Time 0.112 (0.128)	Data 0.000 (0.005)	Loss 0.0814 (0.0529)	Prec@1 96.094 (98.128)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [838][200/391]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.0827 (0.0533)	Prec@1 95.312 (98.115)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [838][300/391]	Time 0.108 (0.118)	Data 0.000 (0.002)	Loss 0.0141 (0.0526)	Prec@1 100.000 (98.103)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [838][0/79]	Time 0.459 (0.459)	Data 0.426 (0.426)	Loss 0.2925 (0.2925)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:08

 Epoch: 839	Training Loss 0.0518 	Training Prec@1 98.148 	Training Prec@5 99.996 	Validation Loss 0.3759 	Validation Prec@1 90.080 	Validation Prec@5 99.660 

lr: 0.00662009010704694
TRAINING - Epoch: [839][0/391]	Time 1.276 (1.276)	Data 0.418 (0.418)	Loss 0.0576 (0.0576)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [839][100/391]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.0446 (0.0544)	Prec@1 97.656 (98.082)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [839][200/391]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.0607 (0.0556)	Prec@1 98.438 (98.045)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [839][300/391]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.0619 (0.0552)	Prec@1 97.656 (98.020)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [839][0/79]	Time 0.438 (0.438)	Data 0.389 (0.389)	Loss 0.2861 (0.2861)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:33

 Epoch: 840	Training Loss 0.0565 	Training Prec@1 98.000 	Training Prec@5 99.992 	Validation Loss 0.3887 	Validation Prec@1 90.190 	Validation Prec@5 99.630 

lr: 0.006541881991308992
TRAINING - Epoch: [840][0/391]	Time 1.303 (1.303)	Data 0.445 (0.445)	Loss 0.0149 (0.0149)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][100/391]	Time 0.111 (0.126)	Data 0.000 (0.005)	Loss 0.0191 (0.0506)	Prec@1 100.000 (98.252)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][200/391]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.0362 (0.0531)	Prec@1 98.438 (98.115)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0556 (0.0554)	Prec@1 97.656 (98.009)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [840][0/79]	Time 0.457 (0.457)	Data 0.416 (0.416)	Loss 0.2488 (0.2488)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:17

 Epoch: 841	Training Loss 0.0552 	Training Prec@1 98.022 	Training Prec@5 99.996 	Validation Loss 0.3795 	Validation Prec@1 90.150 	Validation Prec@5 99.720 

lr: 0.0064641062416590424
TRAINING - Epoch: [841][0/391]	Time 1.295 (1.295)	Data 0.377 (0.377)	Loss 0.0787 (0.0787)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [841][100/391]	Time 0.109 (0.121)	Data 0.000 (0.004)	Loss 0.0328 (0.0533)	Prec@1 100.000 (98.113)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [841][200/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.0447 (0.0541)	Prec@1 97.656 (98.092)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [841][300/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.0445 (0.0531)	Prec@1 98.438 (98.121)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [841][0/79]	Time 0.437 (0.437)	Data 0.400 (0.400)	Loss 0.4108 (0.4108)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:27:17

 Epoch: 842	Training Loss 0.0525 	Training Prec@1 98.156 	Training Prec@5 99.998 	Validation Loss 0.3957 	Validation Prec@1 89.760 	Validation Prec@5 99.620 

lr: 0.006386763631890305
TRAINING - Epoch: [842][0/391]	Time 1.573 (1.573)	Data 0.437 (0.437)	Loss 0.0864 (0.0864)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [842][100/391]	Time 0.112 (0.130)	Data 0.000 (0.005)	Loss 0.0602 (0.0596)	Prec@1 97.656 (97.765)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [842][200/391]	Time 0.108 (0.121)	Data 0.000 (0.003)	Loss 0.0232 (0.0587)	Prec@1 100.000 (97.874)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [842][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0833 (0.0598)	Prec@1 97.656 (97.833)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [842][0/79]	Time 0.421 (0.421)	Data 0.383 (0.383)	Loss 0.3361 (0.3361)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:33

 Epoch: 843	Training Loss 0.0576 	Training Prec@1 97.922 	Training Prec@5 99.994 	Validation Loss 0.3862 	Validation Prec@1 90.120 	Validation Prec@5 99.680 

lr: 0.006309854931486667
TRAINING - Epoch: [843][0/391]	Time 1.267 (1.267)	Data 0.414 (0.414)	Loss 0.0217 (0.0217)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [843][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.0238 (0.0551)	Prec@1 99.219 (98.066)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [843][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0251 (0.0554)	Prec@1 99.219 (98.111)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [843][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0374 (0.0555)	Prec@1 99.219 (98.116)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [843][0/79]	Time 0.438 (0.438)	Data 0.407 (0.407)	Loss 0.2971 (0.2971)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:28:42

 Epoch: 844	Training Loss 0.0550 	Training Prec@1 98.140 	Training Prec@5 99.992 	Validation Loss 0.3897 	Validation Prec@1 89.960 	Validation Prec@5 99.680 

lr: 0.006233380905615029
TRAINING - Epoch: [844][0/391]	Time 1.294 (1.294)	Data 0.420 (0.420)	Loss 0.0440 (0.0440)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.1047 (0.0511)	Prec@1 96.875 (98.167)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0559 (0.0528)	Prec@1 97.656 (98.146)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0273 (0.0533)	Prec@1 99.219 (98.121)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [844][0/79]	Time 0.436 (0.436)	Data 0.401 (0.401)	Loss 0.2640 (0.2640)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:13

 Epoch: 845	Training Loss 0.0536 	Training Prec@1 98.100 	Training Prec@5 100.000 	Validation Loss 0.3713 	Validation Prec@1 90.620 	Validation Prec@5 99.600 

lr: 0.006157342315117744
TRAINING - Epoch: [845][0/391]	Time 1.301 (1.301)	Data 0.444 (0.444)	Loss 0.0541 (0.0541)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.0948 (0.0512)	Prec@1 98.438 (98.167)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.0462 (0.0518)	Prec@1 97.656 (98.189)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [845][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0421 (0.0515)	Prec@1 98.438 (98.181)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [845][0/79]	Time 0.454 (0.454)	Data 0.417 (0.417)	Loss 0.2734 (0.2734)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:07

 Epoch: 846	Training Loss 0.0523 	Training Prec@1 98.148 	Training Prec@5 99.994 	Validation Loss 0.3812 	Validation Prec@1 89.900 	Validation Prec@5 99.740 

lr: 0.006081739916504938
TRAINING - Epoch: [846][0/391]	Time 1.300 (1.300)	Data 0.444 (0.444)	Loss 0.0371 (0.0371)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [846][100/391]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.0271 (0.0530)	Prec@1 99.219 (98.198)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [846][200/391]	Time 0.119 (0.119)	Data 0.000 (0.003)	Loss 0.0467 (0.0538)	Prec@1 99.219 (98.162)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [846][300/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0824 (0.0540)	Prec@1 96.875 (98.131)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [846][0/79]	Time 0.429 (0.429)	Data 0.387 (0.387)	Loss 0.3334 (0.3334)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:59

 Epoch: 847	Training Loss 0.0540 	Training Prec@1 98.118 	Training Prec@5 99.996 	Validation Loss 0.3874 	Validation Prec@1 90.020 	Validation Prec@5 99.730 

lr: 0.006006574461947109
TRAINING - Epoch: [847][0/391]	Time 1.298 (1.298)	Data 0.440 (0.440)	Loss 0.0812 (0.0812)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [847][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.0718 (0.0512)	Prec@1 99.219 (98.298)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [847][200/391]	Time 0.110 (0.121)	Data 0.000 (0.003)	Loss 0.0320 (0.0529)	Prec@1 98.438 (98.204)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [847][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.0969 (0.0548)	Prec@1 96.875 (98.118)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [847][0/79]	Time 0.415 (0.415)	Data 0.373 (0.373)	Loss 0.4208 (0.4208)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:57

 Epoch: 848	Training Loss 0.0536 	Training Prec@1 98.148 	Training Prec@5 99.996 	Validation Loss 0.3941 	Validation Prec@1 89.910 	Validation Prec@5 99.660 

lr: 0.0059318466992675485
TRAINING - Epoch: [848][0/391]	Time 1.232 (1.232)	Data 0.369 (0.369)	Loss 0.0817 (0.0817)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [848][100/391]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.0275 (0.0551)	Prec@1 100.000 (98.066)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [848][200/391]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.0961 (0.0517)	Prec@1 96.094 (98.150)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [848][300/391]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.0500 (0.0527)	Prec@1 98.438 (98.170)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [848][0/79]	Time 0.429 (0.429)	Data 0.399 (0.399)	Loss 0.3597 (0.3597)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:55

 Epoch: 849	Training Loss 0.0523 	Training Prec@1 98.178 	Training Prec@5 100.000 	Validation Loss 0.3785 	Validation Prec@1 90.250 	Validation Prec@5 99.620 

lr: 0.005857557371934972
TRAINING - Epoch: [849][0/391]	Time 1.342 (1.342)	Data 0.482 (0.482)	Loss 0.0477 (0.0477)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [849][100/391]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.0418 (0.0557)	Prec@1 97.656 (97.997)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [849][200/391]	Time 0.120 (0.120)	Data 0.000 (0.003)	Loss 0.0931 (0.0579)	Prec@1 96.875 (97.870)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [849][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.0553 (0.0553)	Prec@1 98.438 (97.981)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [849][0/79]	Time 0.430 (0.430)	Data 0.395 (0.395)	Loss 0.2633 (0.2633)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:48

 Epoch: 850	Training Loss 0.0547 	Training Prec@1 98.024 	Training Prec@5 99.996 	Validation Loss 0.3786 	Validation Prec@1 90.200 	Validation Prec@5 99.630 

lr: 0.00578370721905607
TRAINING - Epoch: [850][0/391]	Time 1.312 (1.312)	Data 0.465 (0.465)	Loss 0.0941 (0.0941)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [850][100/391]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.0680 (0.0548)	Prec@1 97.656 (98.113)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [850][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1126 (0.0542)	Prec@1 98.438 (98.177)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [850][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0903 (0.0536)	Prec@1 97.656 (98.134)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [850][0/79]	Time 0.406 (0.406)	Data 0.379 (0.379)	Loss 0.2834 (0.2834)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:47

 Epoch: 851	Training Loss 0.0529 	Training Prec@1 98.184 	Training Prec@5 99.994 	Validation Loss 0.3857 	Validation Prec@1 90.140 	Validation Prec@5 99.660 

lr: 0.005710296975368154
TRAINING - Epoch: [851][0/391]	Time 1.275 (1.275)	Data 0.416 (0.416)	Loss 0.0433 (0.0433)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [851][100/391]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.0353 (0.0587)	Prec@1 98.438 (97.850)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [851][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.0919 (0.0586)	Prec@1 95.312 (97.882)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [851][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0113 (0.0568)	Prec@1 100.000 (97.957)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [851][0/79]	Time 0.445 (0.445)	Data 0.396 (0.396)	Loss 0.2386 (0.2386)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:36

 Epoch: 852	Training Loss 0.0567 	Training Prec@1 97.948 	Training Prec@5 99.996 	Validation Loss 0.3845 	Validation Prec@1 89.960 	Validation Prec@5 99.690 

lr: 0.005637327371231913
TRAINING - Epoch: [852][0/391]	Time 1.269 (1.269)	Data 0.414 (0.414)	Loss 0.1221 (0.1221)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [852][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.0493 (0.0502)	Prec@1 99.219 (98.260)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [852][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0488 (0.0504)	Prec@1 98.438 (98.251)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [852][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0361 (0.0531)	Prec@1 99.219 (98.178)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [852][0/79]	Time 0.423 (0.423)	Data 0.375 (0.375)	Loss 0.4187 (0.4187)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:22:07

 Epoch: 853	Training Loss 0.0538 	Training Prec@1 98.136 	Training Prec@5 99.998 	Validation Loss 0.3766 	Validation Prec@1 90.360 	Validation Prec@5 99.610 

lr: 0.005564799132624058
TRAINING - Epoch: [853][0/391]	Time 1.290 (1.290)	Data 0.432 (0.432)	Loss 0.0427 (0.0427)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [853][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.0461 (0.0534)	Prec@1 97.656 (98.089)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [853][200/391]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.0690 (0.0564)	Prec@1 98.438 (98.022)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [853][300/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0557 (0.0555)	Prec@1 98.438 (98.046)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [853][0/79]	Time 0.451 (0.451)	Data 0.417 (0.417)	Loss 0.2813 (0.2813)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:51

 Epoch: 854	Training Loss 0.0543 	Training Prec@1 98.122 	Training Prec@5 99.992 	Validation Loss 0.3849 	Validation Prec@1 90.120 	Validation Prec@5 99.690 

lr: 0.005492712981130164
TRAINING - Epoch: [854][0/391]	Time 1.321 (1.321)	Data 0.466 (0.466)	Loss 0.0478 (0.0478)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [854][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.0372 (0.0468)	Prec@1 97.656 (98.383)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [854][200/391]	Time 0.104 (0.110)	Data 0.000 (0.003)	Loss 0.1075 (0.0512)	Prec@1 95.312 (98.208)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [854][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0350 (0.0524)	Prec@1 98.438 (98.147)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [854][0/79]	Time 0.434 (0.434)	Data 0.402 (0.402)	Loss 0.2406 (0.2406)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:22:25

 Epoch: 855	Training Loss 0.0538 	Training Prec@1 98.094 	Training Prec@5 99.998 	Validation Loss 0.3859 	Validation Prec@1 89.920 	Validation Prec@5 99.630 

lr: 0.005421069633937463
TRAINING - Epoch: [855][0/391]	Time 1.585 (1.585)	Data 0.443 (0.443)	Loss 0.0721 (0.0721)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [855][100/391]	Time 0.121 (0.132)	Data 0.000 (0.005)	Loss 0.0412 (0.0569)	Prec@1 98.438 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [855][200/391]	Time 0.114 (0.125)	Data 0.000 (0.003)	Loss 0.0609 (0.0576)	Prec@1 97.656 (97.971)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [855][300/391]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.0542 (0.0562)	Prec@1 97.656 (98.001)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [855][0/79]	Time 0.421 (0.421)	Data 0.393 (0.393)	Loss 0.2399 (0.2399)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:35:13

 Epoch: 856	Training Loss 0.0544 	Training Prec@1 98.056 	Training Prec@5 99.992 	Validation Loss 0.3659 	Validation Prec@1 89.960 	Validation Prec@5 99.640 

lr: 0.00534986980382771
TRAINING - Epoch: [856][0/391]	Time 1.273 (1.273)	Data 0.417 (0.417)	Loss 0.0488 (0.0488)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.0444 (0.0576)	Prec@1 98.438 (97.919)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][200/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.0379 (0.0550)	Prec@1 98.438 (98.022)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0394 (0.0537)	Prec@1 98.438 (98.072)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [856][0/79]	Time 0.423 (0.423)	Data 0.383 (0.383)	Loss 0.3253 (0.3253)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:33

 Epoch: 857	Training Loss 0.0555 	Training Prec@1 97.978 	Training Prec@5 99.998 	Validation Loss 0.3837 	Validation Prec@1 90.050 	Validation Prec@5 99.650 

lr: 0.005279114199170097
TRAINING - Epoch: [857][0/391]	Time 1.302 (1.302)	Data 0.440 (0.440)	Loss 0.0391 (0.0391)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [857][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.0391 (0.0550)	Prec@1 98.438 (98.035)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [857][200/391]	Time 0.117 (0.121)	Data 0.000 (0.003)	Loss 0.0169 (0.0533)	Prec@1 100.000 (98.115)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [857][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.1098 (0.0559)	Prec@1 97.656 (97.957)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [857][0/79]	Time 0.446 (0.446)	Data 0.410 (0.410)	Loss 0.3097 (0.3097)	Prec@1 90.625 (90.625)	Prec@5 98.438 (98.438)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:47

 Epoch: 858	Training Loss 0.0564 	Training Prec@1 97.960 	Training Prec@5 99.998 	Validation Loss 0.3965 	Validation Prec@1 89.650 	Validation Prec@5 99.540 

lr: 0.005208803523914206
TRAINING - Epoch: [858][0/391]	Time 1.310 (1.310)	Data 0.442 (0.442)	Loss 0.1000 (0.1000)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [858][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.1381 (0.0558)	Prec@1 95.312 (98.113)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [858][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.0742 (0.0538)	Prec@1 97.656 (98.150)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [858][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0938 (0.0535)	Prec@1 97.656 (98.147)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [858][0/79]	Time 0.434 (0.434)	Data 0.394 (0.394)	Loss 0.2579 (0.2579)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:27

 Epoch: 859	Training Loss 0.0535 	Training Prec@1 98.156 	Training Prec@5 99.998 	Validation Loss 0.3745 	Validation Prec@1 90.210 	Validation Prec@5 99.670 

lr: 0.005138938477582998
TRAINING - Epoch: [859][0/391]	Time 1.303 (1.303)	Data 0.445 (0.445)	Loss 0.0215 (0.0215)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [859][100/391]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.0298 (0.0514)	Prec@1 99.219 (98.128)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [859][200/391]	Time 0.111 (0.119)	Data 0.000 (0.003)	Loss 0.0647 (0.0555)	Prec@1 97.656 (98.022)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [859][300/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.0331 (0.0568)	Prec@1 98.438 (97.983)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [859][0/79]	Time 0.450 (0.450)	Data 0.411 (0.411)	Loss 0.3030 (0.3030)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:55

 Epoch: 860	Training Loss 0.0573 	Training Prec@1 97.976 	Training Prec@5 99.996 	Validation Loss 0.3918 	Validation Prec@1 90.100 	Validation Prec@5 99.570 

lr: 0.005069519755265894
TRAINING - Epoch: [860][0/391]	Time 1.301 (1.301)	Data 0.447 (0.447)	Loss 0.0532 (0.0532)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [860][100/391]	Time 0.118 (0.129)	Data 0.001 (0.005)	Loss 0.0819 (0.0553)	Prec@1 98.438 (98.082)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [860][200/391]	Time 0.117 (0.124)	Data 0.000 (0.003)	Loss 0.0288 (0.0522)	Prec@1 98.438 (98.181)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [860][300/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.0428 (0.0526)	Prec@1 98.438 (98.186)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [860][0/79]	Time 0.410 (0.410)	Data 0.383 (0.383)	Loss 0.3166 (0.3166)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:34:45

 Epoch: 861	Training Loss 0.0524 	Training Prec@1 98.170 	Training Prec@5 99.992 	Validation Loss 0.3695 	Validation Prec@1 90.370 	Validation Prec@5 99.720 

lr: 0.005000548047611758
TRAINING - Epoch: [861][0/391]	Time 1.265 (1.265)	Data 0.419 (0.419)	Loss 0.0792 (0.0792)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [861][100/391]	Time 0.115 (0.128)	Data 0.000 (0.005)	Loss 0.0644 (0.0531)	Prec@1 97.656 (98.151)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [861][200/391]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.0215 (0.0569)	Prec@1 99.219 (98.041)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [861][300/391]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.0120 (0.0553)	Prec@1 100.000 (98.043)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [861][0/79]	Time 0.473 (0.473)	Data 0.434 (0.434)	Loss 0.3507 (0.3507)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:40

 Epoch: 862	Training Loss 0.0552 	Training Prec@1 98.040 	Training Prec@5 100.000 	Validation Loss 0.3796 	Validation Prec@1 90.110 	Validation Prec@5 99.720 

lr: 0.0049320240408221245
TRAINING - Epoch: [862][0/391]	Time 1.250 (1.250)	Data 0.400 (0.400)	Loss 0.1664 (0.1664)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [862][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.0450 (0.0594)	Prec@1 97.656 (97.935)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [862][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0444 (0.0570)	Prec@1 97.656 (97.994)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [862][300/391]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.0607 (0.0574)	Prec@1 96.094 (97.968)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [862][0/79]	Time 0.433 (0.433)	Data 0.399 (0.399)	Loss 0.2304 (0.2304)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:22:35

 Epoch: 863	Training Loss 0.0581 	Training Prec@1 97.938 	Training Prec@5 99.998 	Validation Loss 0.3840 	Validation Prec@1 89.920 	Validation Prec@5 99.720 

lr: 0.004863948416644375
TRAINING - Epoch: [863][0/391]	Time 1.313 (1.313)	Data 0.422 (0.422)	Loss 0.0272 (0.0272)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [863][100/391]	Time 0.114 (0.127)	Data 0.000 (0.005)	Loss 0.0350 (0.0543)	Prec@1 99.219 (98.205)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [863][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.0479 (0.0543)	Prec@1 96.875 (98.142)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [863][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.0609 (0.0527)	Prec@1 96.875 (98.178)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [863][0/79]	Time 0.423 (0.423)	Data 0.377 (0.377)	Loss 0.3079 (0.3079)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:49

 Epoch: 864	Training Loss 0.0533 	Training Prec@1 98.130 	Training Prec@5 99.994 	Validation Loss 0.3676 	Validation Prec@1 90.130 	Validation Prec@5 99.690 

lr: 0.004796321852364871
TRAINING - Epoch: [864][0/391]	Time 1.283 (1.283)	Data 0.423 (0.423)	Loss 0.0721 (0.0721)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [864][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.0930 (0.0529)	Prec@1 97.656 (98.159)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [864][200/391]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.0450 (0.0545)	Prec@1 97.656 (98.072)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [864][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0310 (0.0527)	Prec@1 98.438 (98.131)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [864][0/79]	Time 0.452 (0.452)	Data 0.409 (0.409)	Loss 0.2974 (0.2974)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:14

 Epoch: 865	Training Loss 0.0534 	Training Prec@1 98.080 	Training Prec@5 99.998 	Validation Loss 0.3828 	Validation Prec@1 90.080 	Validation Prec@5 99.650 

lr: 0.004729145020802289
TRAINING - Epoch: [865][0/391]	Time 1.267 (1.267)	Data 0.369 (0.369)	Loss 0.0313 (0.0313)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [865][100/391]	Time 0.110 (0.125)	Data 0.000 (0.004)	Loss 0.0406 (0.0513)	Prec@1 98.438 (98.120)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [865][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.1384 (0.0539)	Prec@1 94.531 (97.998)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [865][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0589 (0.0548)	Prec@1 96.875 (98.007)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [865][0/79]	Time 0.446 (0.446)	Data 0.409 (0.409)	Loss 0.4193 (0.4193)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:02

 Epoch: 866	Training Loss 0.0542 	Training Prec@1 98.052 	Training Prec@5 100.000 	Validation Loss 0.3909 	Validation Prec@1 90.020 	Validation Prec@5 99.690 

lr: 0.004662418590300866
TRAINING - Epoch: [866][0/391]	Time 1.332 (1.332)	Data 0.429 (0.429)	Loss 0.0471 (0.0471)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [866][100/391]	Time 0.113 (0.127)	Data 0.000 (0.005)	Loss 0.1089 (0.0615)	Prec@1 95.312 (97.865)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [866][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.0811 (0.0580)	Prec@1 96.094 (97.998)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [866][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0295 (0.0548)	Prec@1 100.000 (98.116)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [866][0/79]	Time 0.446 (0.446)	Data 0.408 (0.408)	Loss 0.2283 (0.2283)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:37

 Epoch: 867	Training Loss 0.0546 	Training Prec@1 98.090 	Training Prec@5 99.998 	Validation Loss 0.3762 	Validation Prec@1 90.170 	Validation Prec@5 99.730 

lr: 0.004596143224723837
TRAINING - Epoch: [867][0/391]	Time 1.315 (1.315)	Data 0.445 (0.445)	Loss 0.0340 (0.0340)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [867][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.0518 (0.0522)	Prec@1 97.656 (98.221)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [867][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.0416 (0.0521)	Prec@1 98.438 (98.127)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [867][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0191 (0.0528)	Prec@1 100.000 (98.121)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [867][0/79]	Time 0.446 (0.446)	Data 0.410 (0.410)	Loss 0.3045 (0.3045)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:10

 Epoch: 868	Training Loss 0.0529 	Training Prec@1 98.098 	Training Prec@5 99.994 	Validation Loss 0.4000 	Validation Prec@1 89.940 	Validation Prec@5 99.580 

lr: 0.004530319583446741
TRAINING - Epoch: [868][0/391]	Time 1.284 (1.284)	Data 0.422 (0.422)	Loss 0.0630 (0.0630)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [868][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.1075 (0.0502)	Prec@1 95.312 (98.260)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [868][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0280 (0.0497)	Prec@1 99.219 (98.255)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [868][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0594 (0.0503)	Prec@1 97.656 (98.194)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [868][0/79]	Time 0.436 (0.436)	Data 0.399 (0.399)	Loss 0.3538 (0.3538)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:07

 Epoch: 869	Training Loss 0.0508 	Training Prec@1 98.186 	Training Prec@5 99.996 	Validation Loss 0.3735 	Validation Prec@1 90.340 	Validation Prec@5 99.710 

lr: 0.004464948321350921
TRAINING - Epoch: [869][0/391]	Time 1.270 (1.270)	Data 0.418 (0.418)	Loss 0.0973 (0.0973)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.0275 (0.0527)	Prec@1 98.438 (98.159)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0522 (0.0515)	Prec@1 98.438 (98.200)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0640 (0.0513)	Prec@1 96.094 (98.201)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [869][0/79]	Time 0.425 (0.425)	Data 0.385 (0.385)	Loss 0.3742 (0.3742)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:00

 Epoch: 870	Training Loss 0.0520 	Training Prec@1 98.178 	Training Prec@5 99.998 	Validation Loss 0.3752 	Validation Prec@1 90.490 	Validation Prec@5 99.680 

lr: 0.004400030088816965
TRAINING - Epoch: [870][0/391]	Time 1.573 (1.573)	Data 0.420 (0.420)	Loss 0.0474 (0.0474)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][100/391]	Time 0.113 (0.132)	Data 0.000 (0.004)	Loss 0.0258 (0.0550)	Prec@1 99.219 (98.144)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][200/391]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.0697 (0.0542)	Prec@1 96.875 (98.088)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][300/391]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.0380 (0.0545)	Prec@1 98.438 (98.069)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [870][0/79]	Time 0.453 (0.453)	Data 0.403 (0.403)	Loss 0.3037 (0.3037)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:34:50

 Epoch: 871	Training Loss 0.0538 	Training Prec@1 98.082 	Training Prec@5 99.992 	Validation Loss 0.3831 	Validation Prec@1 89.940 	Validation Prec@5 99.680 

lr: 0.00433556553171829
TRAINING - Epoch: [871][0/391]	Time 1.255 (1.255)	Data 0.368 (0.368)	Loss 0.0251 (0.0251)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.0581 (0.0567)	Prec@1 97.656 (97.927)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0402 (0.0565)	Prec@1 97.656 (97.987)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][300/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0462 (0.0570)	Prec@1 98.438 (97.975)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [871][0/79]	Time 0.451 (0.451)	Data 0.404 (0.404)	Loss 0.2814 (0.2814)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:31:02

 Epoch: 872	Training Loss 0.0571 	Training Prec@1 97.952 	Training Prec@5 100.000 	Validation Loss 0.3708 	Validation Prec@1 90.110 	Validation Prec@5 99.680 

lr: 0.004271555291414637
TRAINING - Epoch: [872][0/391]	Time 1.248 (1.248)	Data 0.361 (0.361)	Loss 0.0814 (0.0814)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][100/391]	Time 0.111 (0.126)	Data 0.000 (0.004)	Loss 0.1019 (0.0502)	Prec@1 96.875 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0624 (0.0557)	Prec@1 97.656 (98.006)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0596 (0.0553)	Prec@1 96.875 (98.038)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [872][0/79]	Time 0.459 (0.459)	Data 0.431 (0.431)	Loss 0.4532 (0.4532)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:00

 Epoch: 873	Training Loss 0.0563 	Training Prec@1 97.976 	Training Prec@5 99.998 	Validation Loss 0.3730 	Validation Prec@1 90.380 	Validation Prec@5 99.670 

lr: 0.004208000004745767
TRAINING - Epoch: [873][0/391]	Time 1.296 (1.296)	Data 0.431 (0.431)	Loss 0.0938 (0.0938)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [873][100/391]	Time 0.108 (0.124)	Data 0.000 (0.005)	Loss 0.0274 (0.0496)	Prec@1 98.438 (98.321)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [873][200/391]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.0128 (0.0530)	Prec@1 100.000 (98.208)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [873][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0825 (0.0530)	Prec@1 97.656 (98.147)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [873][0/79]	Time 0.430 (0.430)	Data 0.383 (0.383)	Loss 0.3086 (0.3086)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:56

 Epoch: 874	Training Loss 0.0540 	Training Prec@1 98.102 	Training Prec@5 99.998 	Validation Loss 0.3709 	Validation Prec@1 90.600 	Validation Prec@5 99.610 

lr: 0.004144900304025097
TRAINING - Epoch: [874][0/391]	Time 1.298 (1.298)	Data 0.459 (0.459)	Loss 0.0616 (0.0616)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [874][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.0531 (0.0542)	Prec@1 96.875 (98.012)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [874][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.0875 (0.0535)	Prec@1 96.094 (98.022)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [874][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0449 (0.0554)	Prec@1 98.438 (97.952)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [874][0/79]	Time 0.452 (0.452)	Data 0.411 (0.411)	Loss 0.3419 (0.3419)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:17

 Epoch: 875	Training Loss 0.0556 	Training Prec@1 97.934 	Training Prec@5 99.996 	Validation Loss 0.3924 	Validation Prec@1 90.130 	Validation Prec@5 99.630 

lr: 0.004082256817033387
TRAINING - Epoch: [875][0/391]	Time 1.290 (1.290)	Data 0.422 (0.422)	Loss 0.0532 (0.0532)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [875][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.0485 (0.0513)	Prec@1 97.656 (98.252)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [875][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0644 (0.0518)	Prec@1 98.438 (98.228)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [875][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1220 (0.0535)	Prec@1 94.531 (98.129)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [875][0/79]	Time 0.426 (0.426)	Data 0.393 (0.393)	Loss 0.2636 (0.2636)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:17

 Epoch: 876	Training Loss 0.0532 	Training Prec@1 98.146 	Training Prec@5 99.994 	Validation Loss 0.3845 	Validation Prec@1 90.250 	Validation Prec@5 99.660 

lr: 0.004020070167012536
TRAINING - Epoch: [876][0/391]	Time 1.281 (1.281)	Data 0.431 (0.431)	Loss 0.0863 (0.0863)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.0913 (0.0530)	Prec@1 97.656 (98.028)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][200/391]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.0589 (0.0514)	Prec@1 97.656 (98.123)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.0475 (0.0531)	Prec@1 98.438 (98.072)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [876][0/79]	Time 0.407 (0.407)	Data 0.372 (0.372)	Loss 0.2004 (0.2004)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:28:36

 Epoch: 877	Training Loss 0.0532 	Training Prec@1 98.112 	Training Prec@5 99.996 	Validation Loss 0.3928 	Validation Prec@1 90.220 	Validation Prec@5 99.610 

lr: 0.003958340972659321
TRAINING - Epoch: [877][0/391]	Time 1.264 (1.264)	Data 0.402 (0.402)	Loss 0.0312 (0.0312)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.0391 (0.0561)	Prec@1 98.438 (98.012)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0800 (0.0580)	Prec@1 96.875 (97.956)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [877][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1137 (0.0560)	Prec@1 95.312 (98.038)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [877][0/79]	Time 0.448 (0.448)	Data 0.410 (0.410)	Loss 0.3822 (0.3822)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:40

 Epoch: 878	Training Loss 0.0561 	Training Prec@1 98.016 	Training Prec@5 99.998 	Validation Loss 0.3966 	Validation Prec@1 89.950 	Validation Prec@5 99.730 

lr: 0.0038970698481193182
TRAINING - Epoch: [878][0/391]	Time 1.280 (1.280)	Data 0.414 (0.414)	Loss 0.0249 (0.0249)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [878][100/391]	Time 0.107 (0.121)	Data 0.000 (0.004)	Loss 0.0313 (0.0616)	Prec@1 97.656 (97.757)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [878][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0418 (0.0604)	Prec@1 98.438 (97.886)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [878][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.0296 (0.0590)	Prec@1 99.219 (97.950)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [878][0/79]	Time 0.451 (0.451)	Data 0.411 (0.411)	Loss 0.3326 (0.3326)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:28

 Epoch: 879	Training Loss 0.0578 	Training Prec@1 98.010 	Training Prec@5 99.994 	Validation Loss 0.3707 	Validation Prec@1 90.330 	Validation Prec@5 99.730 

lr: 0.0038362574029807434
TRAINING - Epoch: [879][0/391]	Time 1.284 (1.284)	Data 0.424 (0.424)	Loss 0.0645 (0.0645)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [879][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.0191 (0.0520)	Prec@1 100.000 (98.205)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [879][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0890 (0.0549)	Prec@1 96.875 (98.076)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [879][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0803 (0.0546)	Prec@1 96.875 (98.038)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [879][0/79]	Time 0.435 (0.435)	Data 0.394 (0.394)	Loss 0.3287 (0.3287)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:08

 Epoch: 880	Training Loss 0.0551 	Training Prec@1 98.034 	Training Prec@5 99.998 	Validation Loss 0.3904 	Validation Prec@1 90.010 	Validation Prec@5 99.610 

lr: 0.003775904242268387
TRAINING - Epoch: [880][0/391]	Time 1.266 (1.266)	Data 0.412 (0.412)	Loss 0.0293 (0.0293)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [880][100/391]	Time 0.110 (0.127)	Data 0.000 (0.004)	Loss 0.0701 (0.0524)	Prec@1 96.875 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [880][200/391]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.0428 (0.0525)	Prec@1 98.438 (98.177)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [880][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.0340 (0.0514)	Prec@1 99.219 (98.201)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [880][0/79]	Time 0.433 (0.433)	Data 0.398 (0.398)	Loss 0.3280 (0.3280)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:47

 Epoch: 881	Training Loss 0.0533 	Training Prec@1 98.132 	Training Prec@5 99.998 	Validation Loss 0.3875 	Validation Prec@1 90.170 	Validation Prec@5 99.680 

lr: 0.0037160109664376067
TRAINING - Epoch: [881][0/391]	Time 1.274 (1.274)	Data 0.408 (0.408)	Loss 0.0325 (0.0325)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][100/391]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.0589 (0.0504)	Prec@1 97.656 (98.182)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][200/391]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.0586 (0.0550)	Prec@1 98.438 (98.053)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [881][300/391]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.0486 (0.0558)	Prec@1 97.656 (98.038)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [881][0/79]	Time 0.428 (0.428)	Data 0.380 (0.380)	Loss 0.3022 (0.3022)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:06

 Epoch: 882	Training Loss 0.0564 	Training Prec@1 98.022 	Training Prec@5 99.998 	Validation Loss 0.3854 	Validation Prec@1 90.010 	Validation Prec@5 99.660 

lr: 0.003656578171368365
TRAINING - Epoch: [882][0/391]	Time 1.271 (1.271)	Data 0.419 (0.419)	Loss 0.0240 (0.0240)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [882][100/391]	Time 0.118 (0.128)	Data 0.000 (0.004)	Loss 0.0537 (0.0558)	Prec@1 97.656 (97.997)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [882][200/391]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.0721 (0.0544)	Prec@1 97.656 (98.060)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [882][300/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.0866 (0.0542)	Prec@1 96.094 (98.064)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [882][0/79]	Time 0.475 (0.475)	Data 0.433 (0.433)	Loss 0.3356 (0.3356)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:15

 Epoch: 883	Training Loss 0.0542 	Training Prec@1 98.072 	Training Prec@5 99.996 	Validation Loss 0.3844 	Validation Prec@1 90.000 	Validation Prec@5 99.720 

lr: 0.003597606448359277
TRAINING - Epoch: [883][0/391]	Time 1.289 (1.289)	Data 0.352 (0.352)	Loss 0.0314 (0.0314)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [883][100/391]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.0166 (0.0530)	Prec@1 99.219 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [883][200/391]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.0379 (0.0539)	Prec@1 98.438 (98.107)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [883][300/391]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.0240 (0.0546)	Prec@1 99.219 (98.118)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [883][0/79]	Time 0.447 (0.447)	Data 0.406 (0.406)	Loss 0.3832 (0.3832)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:50	Time of Finish: 2022-03-24 02:35:28

 Epoch: 884	Training Loss 0.0539 	Training Prec@1 98.132 	Training Prec@5 99.998 	Validation Loss 0.3908 	Validation Prec@1 90.000 	Validation Prec@5 99.700 

lr: 0.0035390963841217334
TRAINING - Epoch: [884][0/391]	Time 1.269 (1.269)	Data 0.418 (0.418)	Loss 0.0344 (0.0344)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [884][100/391]	Time 0.113 (0.126)	Data 0.000 (0.005)	Loss 0.0280 (0.0489)	Prec@1 99.219 (98.298)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [884][200/391]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.0717 (0.0530)	Prec@1 98.438 (98.150)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [884][300/391]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.0294 (0.0538)	Prec@1 99.219 (98.103)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [884][0/79]	Time 0.455 (0.455)	Data 0.419 (0.419)	Loss 0.3554 (0.3554)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:53

 Epoch: 885	Training Loss 0.0533 	Training Prec@1 98.102 	Training Prec@5 99.994 	Validation Loss 0.3937 	Validation Prec@1 90.280 	Validation Prec@5 99.690 

lr: 0.003481048560774088
TRAINING - Epoch: [885][0/391]	Time 1.558 (1.558)	Data 0.414 (0.414)	Loss 0.0842 (0.0842)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [885][100/391]	Time 0.121 (0.131)	Data 0.000 (0.004)	Loss 0.0359 (0.0551)	Prec@1 97.656 (97.981)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [885][200/391]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.0771 (0.0553)	Prec@1 96.875 (98.002)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [885][300/391]	Time 0.111 (0.121)	Data 0.000 (0.002)	Loss 0.0301 (0.0551)	Prec@1 99.219 (98.043)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [885][0/79]	Time 0.406 (0.406)	Data 0.379 (0.379)	Loss 0.3520 (0.3520)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:58

 Epoch: 886	Training Loss 0.0548 	Training Prec@1 98.036 	Training Prec@5 99.996 	Validation Loss 0.3744 	Validation Prec@1 90.220 	Validation Prec@5 99.670 

lr: 0.0034234635558358394
TRAINING - Epoch: [886][0/391]	Time 1.299 (1.299)	Data 0.444 (0.444)	Loss 0.0578 (0.0578)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.0867 (0.0514)	Prec@1 96.875 (98.198)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.0437 (0.0506)	Prec@1 98.438 (98.239)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0456 (0.0511)	Prec@1 99.219 (98.186)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [886][0/79]	Time 0.439 (0.439)	Data 0.402 (0.402)	Loss 0.4156 (0.4156)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:21

 Epoch: 887	Training Loss 0.0518 	Training Prec@1 98.152 	Training Prec@5 99.996 	Validation Loss 0.3795 	Validation Prec@1 90.460 	Validation Prec@5 99.630 

lr: 0.0033663419422218645
TRAINING - Epoch: [887][0/391]	Time 1.265 (1.265)	Data 0.413 (0.413)	Loss 0.0720 (0.0720)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][100/391]	Time 0.108 (0.122)	Data 0.000 (0.004)	Loss 0.0502 (0.0572)	Prec@1 99.219 (98.051)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0371 (0.0517)	Prec@1 98.438 (98.251)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.0259 (0.0511)	Prec@1 99.219 (98.271)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [887][0/79]	Time 0.422 (0.422)	Data 0.375 (0.375)	Loss 0.4751 (0.4751)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:20

 Epoch: 888	Training Loss 0.0521 	Training Prec@1 98.224 	Training Prec@5 99.996 	Validation Loss 0.3820 	Validation Prec@1 90.200 	Validation Prec@5 99.650 

lr: 0.003309684288236772
TRAINING - Epoch: [888][0/391]	Time 1.270 (1.270)	Data 0.415 (0.415)	Loss 0.0551 (0.0551)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [888][100/391]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.0807 (0.0474)	Prec@1 96.875 (98.275)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [888][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.0560 (0.0505)	Prec@1 97.656 (98.247)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [888][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0289 (0.0507)	Prec@1 99.219 (98.256)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [888][0/79]	Time 0.434 (0.434)	Data 0.401 (0.401)	Loss 0.3973 (0.3973)	Prec@1 89.844 (89.844)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:06

 Epoch: 889	Training Loss 0.0519 	Training Prec@1 98.210 	Training Prec@5 99.996 	Validation Loss 0.3894 	Validation Prec@1 90.320 	Validation Prec@5 99.680 

lr: 0.0032534911575692405
TRAINING - Epoch: [889][0/391]	Time 1.293 (1.293)	Data 0.419 (0.419)	Loss 0.0552 (0.0552)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [889][100/391]	Time 0.109 (0.124)	Data 0.000 (0.005)	Loss 0.0366 (0.0549)	Prec@1 99.219 (98.128)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [889][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0185 (0.0540)	Prec@1 99.219 (98.173)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [889][300/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.0232 (0.0538)	Prec@1 100.000 (98.183)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [889][0/79]	Time 0.445 (0.445)	Data 0.408 (0.408)	Loss 0.4381 (0.4381)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:19

 Epoch: 890	Training Loss 0.0545 	Training Prec@1 98.154 	Training Prec@5 99.996 	Validation Loss 0.3734 	Validation Prec@1 90.290 	Validation Prec@5 99.630 

lr: 0.003197763109286358
TRAINING - Epoch: [890][0/391]	Time 1.266 (1.266)	Data 0.416 (0.416)	Loss 0.0978 (0.0978)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [890][100/391]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.0321 (0.0570)	Prec@1 98.438 (97.966)	Prec@5 100.000 (99.969)
TRAINING - Epoch: [890][200/391]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.0151 (0.0541)	Prec@1 100.000 (98.130)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [890][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0688 (0.0547)	Prec@1 97.656 (98.131)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [890][0/79]	Time 0.446 (0.446)	Data 0.402 (0.402)	Loss 0.3235 (0.3235)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:09

 Epoch: 891	Training Loss 0.0542 	Training Prec@1 98.116 	Training Prec@5 99.988 	Validation Loss 0.3784 	Validation Prec@1 90.400 	Validation Prec@5 99.660 

lr: 0.0031425006978281177
TRAINING - Epoch: [891][0/391]	Time 1.321 (1.321)	Data 0.461 (0.461)	Loss 0.0417 (0.0417)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [891][100/391]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.1028 (0.0582)	Prec@1 96.875 (97.888)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [891][200/391]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.0413 (0.0587)	Prec@1 97.656 (97.897)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [891][300/391]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.0197 (0.0576)	Prec@1 99.219 (97.988)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [891][0/79]	Time 0.432 (0.432)	Data 0.398 (0.398)	Loss 0.4207 (0.4207)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:03

 Epoch: 892	Training Loss 0.0566 	Training Prec@1 97.996 	Training Prec@5 99.998 	Validation Loss 0.3772 	Validation Prec@1 90.290 	Validation Prec@5 99.680 

lr: 0.0030877044730018475
TRAINING - Epoch: [892][0/391]	Time 1.267 (1.267)	Data 0.365 (0.365)	Loss 0.0710 (0.0710)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [892][100/391]	Time 0.106 (0.124)	Data 0.000 (0.004)	Loss 0.0441 (0.0547)	Prec@1 99.219 (97.973)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [892][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0585 (0.0558)	Prec@1 96.094 (98.010)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [892][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.0911 (0.0562)	Prec@1 97.656 (97.973)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [892][0/79]	Time 0.448 (0.448)	Data 0.409 (0.409)	Loss 0.3463 (0.3463)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:28:54

 Epoch: 893	Training Loss 0.0561 	Training Prec@1 97.982 	Training Prec@5 99.990 	Validation Loss 0.3721 	Validation Prec@1 90.130 	Validation Prec@5 99.700 

lr: 0.0030333749799768073
TRAINING - Epoch: [893][0/391]	Time 1.294 (1.294)	Data 0.416 (0.416)	Loss 0.0656 (0.0656)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [893][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.0748 (0.0569)	Prec@1 96.875 (98.082)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [893][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0489 (0.0552)	Prec@1 98.438 (98.185)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [893][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0938 (0.0533)	Prec@1 96.875 (98.217)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [893][0/79]	Time 0.439 (0.439)	Data 0.389 (0.389)	Loss 0.2365 (0.2365)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:30

 Epoch: 894	Training Loss 0.0543 	Training Prec@1 98.168 	Training Prec@5 99.992 	Validation Loss 0.3866 	Validation Prec@1 90.080 	Validation Prec@5 99.710 

lr: 0.002979512759278715
TRAINING - Epoch: [894][0/391]	Time 1.257 (1.257)	Data 0.372 (0.372)	Loss 0.0516 (0.0516)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.0133 (0.0543)	Prec@1 100.000 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.1290 (0.0525)	Prec@1 93.750 (98.169)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.0811 (0.0529)	Prec@1 97.656 (98.152)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [894][0/79]	Time 0.449 (0.449)	Data 0.409 (0.409)	Loss 0.2641 (0.2641)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:19

 Epoch: 895	Training Loss 0.0533 	Training Prec@1 98.130 	Training Prec@5 100.000 	Validation Loss 0.3991 	Validation Prec@1 90.080 	Validation Prec@5 99.670 

lr: 0.0029261183467843696
TRAINING - Epoch: [895][0/391]	Time 1.303 (1.303)	Data 0.441 (0.441)	Loss 0.1002 (0.1002)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [895][100/391]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.0369 (0.0536)	Prec@1 99.219 (98.151)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [895][200/391]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.0307 (0.0541)	Prec@1 99.219 (98.103)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [895][300/391]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.0288 (0.0536)	Prec@1 99.219 (98.105)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [895][0/79]	Time 0.446 (0.446)	Data 0.410 (0.410)	Loss 0.2992 (0.2992)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:24

 Epoch: 896	Training Loss 0.0532 	Training Prec@1 98.126 	Training Prec@5 99.998 	Validation Loss 0.3848 	Validation Prec@1 90.160 	Validation Prec@5 99.680 

lr: 0.0028731922737163596
TRAINING - Epoch: [896][0/391]	Time 1.288 (1.288)	Data 0.440 (0.440)	Loss 0.0254 (0.0254)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [896][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0712 (0.0599)	Prec@1 98.438 (97.819)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [896][200/391]	Time 0.106 (0.117)	Data 0.000 (0.003)	Loss 0.0882 (0.0564)	Prec@1 96.875 (97.998)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [896][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.0743 (0.0537)	Prec@1 97.656 (98.121)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [896][0/79]	Time 0.436 (0.436)	Data 0.384 (0.384)	Loss 0.3344 (0.3344)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 897	Training Loss 0.0527 	Training Prec@1 98.176 	Training Prec@5 99.998 	Validation Loss 0.3813 	Validation Prec@1 90.400 	Validation Prec@5 99.700 

lr: 0.002820735066637733
TRAINING - Epoch: [897][0/391]	Time 1.283 (1.283)	Data 0.378 (0.378)	Loss 0.0802 (0.0802)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [897][100/391]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.0841 (0.0545)	Prec@1 97.656 (98.159)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [897][200/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.0299 (0.0529)	Prec@1 98.438 (98.123)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [897][300/391]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.0265 (0.0528)	Prec@1 98.438 (98.160)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [897][0/79]	Time 0.438 (0.438)	Data 0.410 (0.410)	Loss 0.2707 (0.2707)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:09

 Epoch: 898	Training Loss 0.0534 	Training Prec@1 98.152 	Training Prec@5 99.996 	Validation Loss 0.3757 	Validation Prec@1 90.410 	Validation Prec@5 99.670 

lr: 0.002768747247446759
TRAINING - Epoch: [898][0/391]	Time 1.233 (1.233)	Data 0.369 (0.369)	Loss 0.0294 (0.0294)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [898][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.0461 (0.0530)	Prec@1 98.438 (98.159)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [898][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0696 (0.0543)	Prec@1 96.875 (98.158)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [898][300/391]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.0576 (0.0544)	Prec@1 96.094 (98.069)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [898][0/79]	Time 0.413 (0.413)	Data 0.383 (0.383)	Loss 0.3103 (0.3103)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:51

 Epoch: 899	Training Loss 0.0555 	Training Prec@1 98.014 	Training Prec@5 99.998 	Validation Loss 0.3768 	Validation Prec@1 90.240 	Validation Prec@5 99.700 

lr: 0.0027172293333717814
TRAINING - Epoch: [899][0/391]	Time 1.260 (1.260)	Data 0.427 (0.427)	Loss 0.0414 (0.0414)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][100/391]	Time 0.113 (0.125)	Data 0.000 (0.005)	Loss 0.0762 (0.0502)	Prec@1 97.656 (98.205)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][200/391]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.0386 (0.0538)	Prec@1 98.438 (98.088)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [899][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0809 (0.0527)	Prec@1 96.875 (98.087)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [899][0/79]	Time 0.451 (0.451)	Data 0.414 (0.414)	Loss 0.3375 (0.3375)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:51

 Epoch: 900	Training Loss 0.0539 	Training Prec@1 98.096 	Training Prec@5 99.998 	Validation Loss 0.3826 	Validation Prec@1 90.180 	Validation Prec@5 99.630 

lr: 0.00266618183696605
TRAINING - Epoch: [900][0/391]	Time 1.318 (1.318)	Data 0.459 (0.459)	Loss 0.0470 (0.0470)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [900][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.0296 (0.0510)	Prec@1 98.438 (98.414)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [900][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.0565 (0.0534)	Prec@1 98.438 (98.212)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [900][300/391]	Time 0.107 (0.115)	Data 0.000 (0.002)	Loss 0.0538 (0.0544)	Prec@1 96.875 (98.139)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [900][0/79]	Time 0.439 (0.439)	Data 0.403 (0.403)	Loss 0.3117 (0.3117)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:43

 Epoch: 901	Training Loss 0.0552 	Training Prec@1 98.080 	Training Prec@5 99.998 	Validation Loss 0.3672 	Validation Prec@1 90.620 	Validation Prec@5 99.640 

lr: 0.0026156052661025857
TRAINING - Epoch: [901][0/391]	Time 1.272 (1.272)	Data 0.414 (0.414)	Loss 0.0762 (0.0762)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [901][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.0237 (0.0552)	Prec@1 99.219 (98.136)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [901][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0286 (0.0548)	Prec@1 99.219 (98.072)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [901][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0665 (0.0549)	Prec@1 99.219 (98.061)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [901][0/79]	Time 0.494 (0.494)	Data 0.455 (0.455)	Loss 0.3382 (0.3382)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:47

 Epoch: 902	Training Loss 0.0539 	Training Prec@1 98.106 	Training Prec@5 99.998 	Validation Loss 0.3739 	Validation Prec@1 90.330 	Validation Prec@5 99.670 

lr: 0.0025655001239691805
TRAINING - Epoch: [902][0/391]	Time 1.282 (1.282)	Data 0.427 (0.427)	Loss 0.0517 (0.0517)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [902][100/391]	Time 0.114 (0.126)	Data 0.000 (0.005)	Loss 0.0703 (0.0527)	Prec@1 97.656 (98.066)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [902][200/391]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.0671 (0.0516)	Prec@1 98.438 (98.138)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [902][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.0671 (0.0513)	Prec@1 98.438 (98.134)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [902][0/79]	Time 0.445 (0.445)	Data 0.407 (0.407)	Loss 0.2729 (0.2729)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:32:10

 Epoch: 903	Training Loss 0.0522 	Training Prec@1 98.148 	Training Prec@5 99.998 	Validation Loss 0.3819 	Validation Prec@1 90.010 	Validation Prec@5 99.670 

lr: 0.002515866909063344
TRAINING - Epoch: [903][0/391]	Time 1.596 (1.596)	Data 0.438 (0.438)	Loss 0.0288 (0.0288)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [903][100/391]	Time 0.119 (0.132)	Data 0.000 (0.005)	Loss 0.0507 (0.0567)	Prec@1 97.656 (98.128)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [903][200/391]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.0417 (0.0559)	Prec@1 97.656 (98.111)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [903][300/391]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1073 (0.0567)	Prec@1 97.656 (98.059)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [903][0/79]	Time 0.477 (0.477)	Data 0.435 (0.435)	Loss 0.2769 (0.2769)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:56

 Epoch: 904	Training Loss 0.0559 	Training Prec@1 98.088 	Training Prec@5 99.996 	Validation Loss 0.3744 	Validation Prec@1 90.330 	Validation Prec@5 99.810 

lr: 0.0024667061151874034
TRAINING - Epoch: [904][0/391]	Time 1.270 (1.270)	Data 0.414 (0.414)	Loss 0.0587 (0.0587)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [904][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.0989 (0.0552)	Prec@1 96.875 (97.997)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [904][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0574 (0.0538)	Prec@1 96.875 (98.076)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [904][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.1117 (0.0544)	Prec@1 96.875 (98.074)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [904][0/79]	Time 0.445 (0.445)	Data 0.403 (0.403)	Loss 0.3954 (0.3954)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:30

 Epoch: 905	Training Loss 0.0539 	Training Prec@1 98.086 	Training Prec@5 99.994 	Validation Loss 0.3858 	Validation Prec@1 89.820 	Validation Prec@5 99.640 

lr: 0.002418018231443528
TRAINING - Epoch: [905][0/391]	Time 1.318 (1.318)	Data 0.451 (0.451)	Loss 0.0639 (0.0639)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [905][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.0754 (0.0545)	Prec@1 96.875 (98.128)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [905][200/391]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.0566 (0.0576)	Prec@1 97.656 (98.018)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [905][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.1024 (0.0575)	Prec@1 96.875 (97.994)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [905][0/79]	Time 0.422 (0.422)	Data 0.379 (0.379)	Loss 0.3093 (0.3093)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:20

 Epoch: 906	Training Loss 0.0565 	Training Prec@1 98.032 	Training Prec@5 99.996 	Validation Loss 0.3862 	Validation Prec@1 90.040 	Validation Prec@5 99.700 

lr: 0.002369803742228891
TRAINING - Epoch: [906][0/391]	Time 1.293 (1.293)	Data 0.416 (0.416)	Loss 0.0242 (0.0242)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][100/391]	Time 0.111 (0.123)	Data 0.000 (0.004)	Loss 0.0635 (0.0546)	Prec@1 96.875 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0578 (0.0565)	Prec@1 96.875 (98.060)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0120 (0.0583)	Prec@1 100.000 (97.926)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [906][0/79]	Time 0.453 (0.453)	Data 0.414 (0.414)	Loss 0.3405 (0.3405)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:39

 Epoch: 907	Training Loss 0.0585 	Training Prec@1 97.906 	Training Prec@5 99.998 	Validation Loss 0.3873 	Validation Prec@1 89.870 	Validation Prec@5 99.640 

lr: 0.0023220631272308757
TRAINING - Epoch: [907][0/391]	Time 1.274 (1.274)	Data 0.413 (0.413)	Loss 0.0947 (0.0947)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.0875 (0.0572)	Prec@1 96.875 (97.989)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][200/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0796 (0.0573)	Prec@1 96.875 (97.971)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.0432 (0.0590)	Prec@1 99.219 (98.001)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [907][0/79]	Time 0.441 (0.441)	Data 0.409 (0.409)	Loss 0.3538 (0.3538)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:15

 Epoch: 908	Training Loss 0.0583 	Training Prec@1 97.960 	Training Prec@5 100.000 	Validation Loss 0.3789 	Validation Prec@1 90.220 	Validation Prec@5 99.750 

lr: 0.002274796861422244
TRAINING - Epoch: [908][0/391]	Time 1.262 (1.262)	Data 0.400 (0.400)	Loss 0.0471 (0.0471)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [908][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.0200 (0.0555)	Prec@1 100.000 (98.113)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [908][200/391]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.0396 (0.0527)	Prec@1 98.438 (98.146)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [908][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0647 (0.0528)	Prec@1 96.875 (98.110)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [908][0/79]	Time 0.426 (0.426)	Data 0.386 (0.386)	Loss 0.3514 (0.3514)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:15

 Epoch: 909	Training Loss 0.0537 	Training Prec@1 98.094 	Training Prec@5 99.994 	Validation Loss 0.3729 	Validation Prec@1 90.100 	Validation Prec@5 99.600 

lr: 0.0022280054150564535
TRAINING - Epoch: [909][0/391]	Time 1.280 (1.280)	Data 0.418 (0.418)	Loss 0.0634 (0.0634)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [909][100/391]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.0543 (0.0516)	Prec@1 97.656 (98.260)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [909][200/391]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.0221 (0.0539)	Prec@1 99.219 (98.134)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [909][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0242 (0.0534)	Prec@1 98.438 (98.108)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [909][0/79]	Time 0.426 (0.426)	Data 0.384 (0.384)	Loss 0.3732 (0.3732)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:04

 Epoch: 910	Training Loss 0.0556 	Training Prec@1 98.040 	Training Prec@5 99.996 	Validation Loss 0.3880 	Validation Prec@1 89.850 	Validation Prec@5 99.610 

lr: 0.0021816892536629753
TRAINING - Epoch: [910][0/391]	Time 1.580 (1.580)	Data 0.417 (0.417)	Loss 0.0310 (0.0310)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [910][100/391]	Time 0.114 (0.134)	Data 0.000 (0.004)	Loss 0.0238 (0.0565)	Prec@1 99.219 (98.035)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [910][200/391]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.0301 (0.0556)	Prec@1 99.219 (98.060)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [910][300/391]	Time 0.109 (0.123)	Data 0.000 (0.002)	Loss 0.0497 (0.0553)	Prec@1 96.875 (98.027)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [910][0/79]	Time 0.403 (0.403)	Data 0.370 (0.370)	Loss 0.3242 (0.3242)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:32:49

 Epoch: 911	Training Loss 0.0545 	Training Prec@1 98.068 	Training Prec@5 99.998 	Validation Loss 0.3922 	Validation Prec@1 90.010 	Validation Prec@5 99.700 

lr: 0.002135848838042668
TRAINING - Epoch: [911][0/391]	Time 1.565 (1.565)	Data 0.431 (0.431)	Loss 0.0502 (0.0502)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [911][100/391]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.0576 (0.0551)	Prec@1 97.656 (98.028)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [911][200/391]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.0899 (0.0565)	Prec@1 96.094 (97.967)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [911][300/391]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.0877 (0.0568)	Prec@1 96.875 (98.004)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [911][0/79]	Time 0.424 (0.424)	Data 0.383 (0.383)	Loss 0.4247 (0.4247)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:47

 Epoch: 912	Training Loss 0.0568 	Training Prec@1 98.034 	Training Prec@5 99.988 	Validation Loss 0.4048 	Validation Prec@1 89.840 	Validation Prec@5 99.590 

lr: 0.002090484624263165
TRAINING - Epoch: [912][0/391]	Time 1.308 (1.308)	Data 0.451 (0.451)	Loss 0.0549 (0.0549)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [912][100/391]	Time 0.116 (0.130)	Data 0.000 (0.005)	Loss 0.0721 (0.0529)	Prec@1 97.656 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [912][200/391]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.0620 (0.0544)	Prec@1 98.438 (98.025)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [912][300/391]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.0485 (0.0550)	Prec@1 99.219 (98.033)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [912][0/79]	Time 0.439 (0.439)	Data 0.408 (0.408)	Loss 0.5123 (0.5123)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:33:47

 Epoch: 913	Training Loss 0.0555 	Training Prec@1 97.988 	Training Prec@5 99.996 	Validation Loss 0.3836 	Validation Prec@1 90.180 	Validation Prec@5 99.690 

lr: 0.00204559706365434
TRAINING - Epoch: [913][0/391]	Time 1.289 (1.289)	Data 0.409 (0.409)	Loss 0.0401 (0.0401)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [913][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.0919 (0.0563)	Prec@1 96.094 (98.082)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [913][200/391]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.0772 (0.0586)	Prec@1 97.656 (97.998)	Prec@5 99.219 (99.992)
TRAINING - Epoch: [913][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0297 (0.0571)	Prec@1 98.438 (98.014)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [913][0/79]	Time 0.428 (0.428)	Data 0.391 (0.391)	Loss 0.3784 (0.3784)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:41

 Epoch: 914	Training Loss 0.0560 	Training Prec@1 98.064 	Training Prec@5 99.994 	Validation Loss 0.3888 	Validation Prec@1 89.880 	Validation Prec@5 99.610 

lr: 0.00200118660280386
TRAINING - Epoch: [914][0/391]	Time 1.262 (1.262)	Data 0.419 (0.419)	Loss 0.0405 (0.0405)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [914][100/391]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.0391 (0.0562)	Prec@1 98.438 (98.066)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [914][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0292 (0.0563)	Prec@1 99.219 (98.111)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [914][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.1115 (0.0581)	Prec@1 95.312 (98.012)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [914][0/79]	Time 0.430 (0.430)	Data 0.400 (0.400)	Loss 0.3251 (0.3251)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:25:45

 Epoch: 915	Training Loss 0.0588 	Training Prec@1 97.960 	Training Prec@5 99.992 	Validation Loss 0.3861 	Validation Prec@1 90.240 	Validation Prec@5 99.670 

lr: 0.0019572536835526996
TRAINING - Epoch: [915][0/391]	Time 1.294 (1.294)	Data 0.442 (0.442)	Loss 0.1277 (0.1277)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][100/391]	Time 0.109 (0.122)	Data 0.000 (0.005)	Loss 0.0358 (0.0536)	Prec@1 98.438 (98.205)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][200/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0776 (0.0556)	Prec@1 96.875 (98.018)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][300/391]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.0700 (0.0559)	Prec@1 96.875 (98.009)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [915][0/79]	Time 0.439 (0.439)	Data 0.406 (0.406)	Loss 0.2544 (0.2544)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:45

 Epoch: 916	Training Loss 0.0563 	Training Prec@1 98.026 	Training Prec@5 99.998 	Validation Loss 0.3875 	Validation Prec@1 90.160 	Validation Prec@5 99.690 

lr: 0.001913798742990762
TRAINING - Epoch: [916][0/391]	Time 1.269 (1.269)	Data 0.367 (0.367)	Loss 0.0268 (0.0268)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [916][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.0779 (0.0535)	Prec@1 98.438 (98.105)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [916][200/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0575 (0.0541)	Prec@1 96.875 (98.064)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [916][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0403 (0.0540)	Prec@1 97.656 (98.072)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [916][0/79]	Time 0.424 (0.424)	Data 0.382 (0.382)	Loss 0.3837 (0.3837)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:23

 Epoch: 917	Training Loss 0.0550 	Training Prec@1 98.074 	Training Prec@5 100.000 	Validation Loss 0.3765 	Validation Prec@1 90.560 	Validation Prec@5 99.670 

lr: 0.0018708222134525153
TRAINING - Epoch: [917][0/391]	Time 1.288 (1.288)	Data 0.434 (0.434)	Loss 0.0753 (0.0753)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][100/391]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.0648 (0.0556)	Prec@1 97.656 (98.004)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][200/391]	Time 0.112 (0.117)	Data 0.000 (0.003)	Loss 0.0260 (0.0576)	Prec@1 99.219 (97.948)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][300/391]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.0608 (0.0575)	Prec@1 96.875 (97.934)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [917][0/79]	Time 0.424 (0.424)	Data 0.378 (0.378)	Loss 0.3646 (0.3646)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:47

 Epoch: 918	Training Loss 0.0562 	Training Prec@1 97.988 	Training Prec@5 100.000 	Validation Loss 0.3952 	Validation Prec@1 90.330 	Validation Prec@5 99.670 

lr: 0.001828324522512713
TRAINING - Epoch: [918][0/391]	Time 1.287 (1.287)	Data 0.370 (0.370)	Loss 0.0680 (0.0680)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [918][100/391]	Time 0.108 (0.123)	Data 0.000 (0.004)	Loss 0.0293 (0.0533)	Prec@1 100.000 (98.136)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [918][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1161 (0.0565)	Prec@1 96.094 (98.053)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [918][300/391]	Time 0.121 (0.116)	Data 0.000 (0.002)	Loss 0.0305 (0.0551)	Prec@1 99.219 (98.069)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [918][0/79]	Time 0.425 (0.425)	Data 0.381 (0.381)	Loss 0.3419 (0.3419)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:57

 Epoch: 919	Training Loss 0.0544 	Training Prec@1 98.074 	Training Prec@5 99.994 	Validation Loss 0.3792 	Validation Prec@1 90.230 	Validation Prec@5 99.680 

lr: 0.001786306092982125
TRAINING - Epoch: [919][0/391]	Time 1.290 (1.290)	Data 0.445 (0.445)	Loss 0.0689 (0.0689)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [919][100/391]	Time 0.110 (0.122)	Data 0.000 (0.005)	Loss 0.0880 (0.0576)	Prec@1 95.312 (97.795)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [919][200/391]	Time 0.111 (0.116)	Data 0.000 (0.003)	Loss 0.0546 (0.0577)	Prec@1 97.656 (97.808)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [919][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.0965 (0.0583)	Prec@1 97.656 (97.817)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [919][0/79]	Time 0.409 (0.409)	Data 0.382 (0.382)	Loss 0.3570 (0.3570)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:30

 Epoch: 920	Training Loss 0.0581 	Training Prec@1 97.856 	Training Prec@5 99.998 	Validation Loss 0.3806 	Validation Prec@1 90.290 	Validation Prec@5 99.640 

lr: 0.0017447673429033348
TRAINING - Epoch: [920][0/391]	Time 1.273 (1.273)	Data 0.362 (0.362)	Loss 0.0794 (0.0794)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [920][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.1248 (0.0548)	Prec@1 96.875 (98.097)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [920][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0459 (0.0533)	Prec@1 98.438 (98.084)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [920][300/391]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.0668 (0.0548)	Prec@1 98.438 (98.082)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [920][0/79]	Time 0.436 (0.436)	Data 0.395 (0.395)	Loss 0.3014 (0.3014)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:26:08

 Epoch: 921	Training Loss 0.0551 	Training Prec@1 98.064 	Training Prec@5 99.994 	Validation Loss 0.3986 	Validation Prec@1 89.980 	Validation Prec@5 99.740 

lr: 0.001703708685546583
TRAINING - Epoch: [921][0/391]	Time 1.269 (1.269)	Data 0.404 (0.404)	Loss 0.0385 (0.0385)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [921][100/391]	Time 0.113 (0.125)	Data 0.000 (0.004)	Loss 0.0855 (0.0567)	Prec@1 97.656 (97.997)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [921][200/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.0526 (0.0552)	Prec@1 96.875 (98.072)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [921][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0839 (0.0559)	Prec@1 97.656 (98.020)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [921][0/79]	Time 0.438 (0.438)	Data 0.399 (0.399)	Loss 0.3426 (0.3426)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:56

 Epoch: 922	Training Loss 0.0557 	Training Prec@1 98.032 	Training Prec@5 100.000 	Validation Loss 0.3850 	Validation Prec@1 90.310 	Validation Prec@5 99.680 

lr: 0.001663130529405664
TRAINING - Epoch: [922][0/391]	Time 1.292 (1.292)	Data 0.438 (0.438)	Loss 0.0305 (0.0305)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [922][100/391]	Time 0.110 (0.123)	Data 0.000 (0.005)	Loss 0.0355 (0.0566)	Prec@1 99.219 (97.919)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [922][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.0507 (0.0548)	Prec@1 98.438 (97.991)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [922][300/391]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.0700 (0.0537)	Prec@1 97.656 (98.066)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [922][0/79]	Time 0.444 (0.444)	Data 0.405 (0.405)	Loss 0.3125 (0.3125)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:26

 Epoch: 923	Training Loss 0.0538 	Training Prec@1 98.062 	Training Prec@5 99.998 	Validation Loss 0.3879 	Validation Prec@1 90.120 	Validation Prec@5 99.660 

lr: 0.0016230332781938237
TRAINING - Epoch: [923][0/391]	Time 1.260 (1.260)	Data 0.409 (0.409)	Loss 0.0648 (0.0648)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.0414 (0.0591)	Prec@1 98.438 (97.757)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0769 (0.0565)	Prec@1 96.094 (97.936)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0835 (0.0581)	Prec@1 97.656 (97.879)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [923][0/79]	Time 0.408 (0.408)	Data 0.375 (0.375)	Loss 0.3721 (0.3721)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:58

 Epoch: 924	Training Loss 0.0581 	Training Prec@1 97.910 	Training Prec@5 99.994 	Validation Loss 0.3850 	Validation Prec@1 90.190 	Validation Prec@5 99.640 

lr: 0.0015834173308398023
TRAINING - Epoch: [924][0/391]	Time 1.329 (1.329)	Data 0.474 (0.474)	Loss 0.0677 (0.0677)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [924][100/391]	Time 0.107 (0.124)	Data 0.000 (0.005)	Loss 0.0500 (0.0530)	Prec@1 98.438 (98.051)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [924][200/391]	Time 0.109 (0.117)	Data 0.000 (0.003)	Loss 0.1113 (0.0551)	Prec@1 96.094 (97.994)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [924][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0398 (0.0554)	Prec@1 98.438 (97.991)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [924][0/79]	Time 0.446 (0.446)	Data 0.407 (0.407)	Loss 0.2967 (0.2967)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:34

 Epoch: 925	Training Loss 0.0550 	Training Prec@1 98.052 	Training Prec@5 99.996 	Validation Loss 0.3990 	Validation Prec@1 89.980 	Validation Prec@5 99.630 

lr: 0.0015442830814838037
TRAINING - Epoch: [925][0/391]	Time 1.278 (1.278)	Data 0.409 (0.409)	Loss 0.0407 (0.0407)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [925][100/391]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.0570 (0.0509)	Prec@1 98.438 (98.321)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [925][200/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0807 (0.0534)	Prec@1 96.875 (98.165)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [925][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.0563 (0.0535)	Prec@1 97.656 (98.162)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [925][0/79]	Time 0.428 (0.428)	Data 0.393 (0.393)	Loss 0.4592 (0.4592)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:00

 Epoch: 926	Training Loss 0.0535 	Training Prec@1 98.156 	Training Prec@5 100.000 	Validation Loss 0.3798 	Validation Prec@1 90.410 	Validation Prec@5 99.680 

lr: 0.0015056309194736372
TRAINING - Epoch: [926][0/391]	Time 1.269 (1.269)	Data 0.412 (0.412)	Loss 0.0177 (0.0177)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [926][100/391]	Time 0.116 (0.130)	Data 0.000 (0.004)	Loss 0.0339 (0.0534)	Prec@1 99.219 (98.151)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [926][200/391]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.0926 (0.0573)	Prec@1 96.875 (97.893)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [926][300/391]	Time 0.113 (0.122)	Data 0.001 (0.002)	Loss 0.0316 (0.0565)	Prec@1 99.219 (97.944)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [926][0/79]	Time 0.445 (0.445)	Data 0.406 (0.406)	Loss 0.3095 (0.3095)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:32:47

 Epoch: 927	Training Loss 0.0570 	Training Prec@1 97.944 	Training Prec@5 99.992 	Validation Loss 0.3768 	Validation Prec@1 90.270 	Validation Prec@5 99.650 

lr: 0.001467461229360788
TRAINING - Epoch: [927][0/391]	Time 1.316 (1.316)	Data 0.464 (0.464)	Loss 0.0697 (0.0697)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [927][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.0258 (0.0487)	Prec@1 98.438 (98.213)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [927][200/391]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.1370 (0.0544)	Prec@1 96.094 (98.119)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [927][300/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0305 (0.0546)	Prec@1 98.438 (98.040)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [927][0/79]	Time 0.437 (0.437)	Data 0.400 (0.400)	Loss 0.3943 (0.3943)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:12

 Epoch: 928	Training Loss 0.0542 	Training Prec@1 98.054 	Training Prec@5 99.996 	Validation Loss 0.3819 	Validation Prec@1 90.100 	Validation Prec@5 99.720 

lr: 0.0014297743908966197
TRAINING - Epoch: [928][0/391]	Time 1.295 (1.295)	Data 0.379 (0.379)	Loss 0.0566 (0.0566)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [928][100/391]	Time 0.109 (0.125)	Data 0.000 (0.004)	Loss 0.0115 (0.0599)	Prec@1 100.000 (97.973)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [928][200/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.0444 (0.0573)	Prec@1 98.438 (98.025)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [928][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0409 (0.0557)	Prec@1 99.219 (98.074)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [928][0/79]	Time 0.459 (0.459)	Data 0.414 (0.414)	Loss 0.2763 (0.2763)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:03

 Epoch: 929	Training Loss 0.0558 	Training Prec@1 98.050 	Training Prec@5 99.998 	Validation Loss 0.3874 	Validation Prec@1 90.190 	Validation Prec@5 99.650 

lr: 0.0013925707790285835
TRAINING - Epoch: [929][0/391]	Time 1.548 (1.548)	Data 0.369 (0.369)	Loss 0.0633 (0.0633)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [929][100/391]	Time 0.116 (0.129)	Data 0.000 (0.004)	Loss 0.0137 (0.0669)	Prec@1 100.000 (97.803)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [929][200/391]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.0519 (0.0633)	Prec@1 97.656 (97.866)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [929][300/391]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.0283 (0.0630)	Prec@1 99.219 (97.807)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [929][0/79]	Time 0.452 (0.452)	Data 0.413 (0.413)	Loss 0.4019 (0.4019)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:50

 Epoch: 930	Training Loss 0.0635 	Training Prec@1 97.788 	Training Prec@5 99.994 	Validation Loss 0.3840 	Validation Prec@1 89.900 	Validation Prec@5 99.720 

lr: 0.0013558507638965144
TRAINING - Epoch: [930][0/391]	Time 1.326 (1.326)	Data 0.428 (0.428)	Loss 0.0567 (0.0567)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [930][100/391]	Time 0.119 (0.128)	Data 0.000 (0.005)	Loss 0.0367 (0.0604)	Prec@1 98.438 (97.850)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [930][200/391]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.0511 (0.0581)	Prec@1 96.875 (97.944)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [930][300/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0276 (0.0582)	Prec@1 99.219 (97.924)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [930][0/79]	Time 0.441 (0.441)	Data 0.406 (0.406)	Loss 0.3671 (0.3671)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:46

 Epoch: 931	Training Loss 0.0581 	Training Prec@1 97.956 	Training Prec@5 99.996 	Validation Loss 0.3851 	Validation Prec@1 90.200 	Validation Prec@5 99.710 

lr: 0.0013196147108289135
TRAINING - Epoch: [931][0/391]	Time 1.235 (1.235)	Data 0.387 (0.387)	Loss 0.0574 (0.0574)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][100/391]	Time 0.107 (0.122)	Data 0.000 (0.004)	Loss 0.1104 (0.0605)	Prec@1 95.312 (97.803)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.0352 (0.0587)	Prec@1 100.000 (97.913)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0681 (0.0579)	Prec@1 97.656 (97.955)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [931][0/79]	Time 0.466 (0.466)	Data 0.423 (0.423)	Loss 0.3936 (0.3936)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:52

 Epoch: 932	Training Loss 0.0584 	Training Prec@1 97.938 	Training Prec@5 99.996 	Validation Loss 0.3688 	Validation Prec@1 90.370 	Validation Prec@5 99.660 

lr: 0.0012838629803393275
TRAINING - Epoch: [932][0/391]	Time 1.330 (1.330)	Data 0.423 (0.423)	Loss 0.0986 (0.0986)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][100/391]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.1322 (0.0593)	Prec@1 95.312 (97.927)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.0924 (0.0589)	Prec@1 98.438 (98.002)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [932][300/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0338 (0.0560)	Prec@1 99.219 (98.103)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [932][0/79]	Time 0.442 (0.442)	Data 0.401 (0.401)	Loss 0.3011 (0.3011)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:43

 Epoch: 933	Training Loss 0.0565 	Training Prec@1 98.056 	Training Prec@5 99.994 	Validation Loss 0.3811 	Validation Prec@1 90.020 	Validation Prec@5 99.780 

lr: 0.0012485959281227854
TRAINING - Epoch: [933][0/391]	Time 1.268 (1.268)	Data 0.413 (0.413)	Loss 0.0715 (0.0715)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [933][100/391]	Time 0.106 (0.122)	Data 0.000 (0.004)	Loss 0.0454 (0.0555)	Prec@1 98.438 (97.997)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [933][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0303 (0.0568)	Prec@1 99.219 (97.936)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [933][300/391]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.0601 (0.0579)	Prec@1 96.875 (97.911)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [933][0/79]	Time 0.431 (0.431)	Data 0.396 (0.396)	Loss 0.3075 (0.3075)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:56

 Epoch: 934	Training Loss 0.0581 	Training Prec@1 97.892 	Training Prec@5 99.992 	Validation Loss 0.3835 	Validation Prec@1 90.000 	Validation Prec@5 99.650 

lr: 0.0012138139050522012
TRAINING - Epoch: [934][0/391]	Time 1.294 (1.294)	Data 0.437 (0.437)	Loss 0.0154 (0.0154)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][100/391]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.0207 (0.0545)	Prec@1 100.000 (98.198)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][200/391]	Time 0.107 (0.117)	Data 0.000 (0.003)	Loss 0.0210 (0.0558)	Prec@1 100.000 (98.095)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0581 (0.0552)	Prec@1 97.656 (98.046)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [934][0/79]	Time 0.463 (0.463)	Data 0.423 (0.423)	Loss 0.3088 (0.3088)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:57

 Epoch: 935	Training Loss 0.0563 	Training Prec@1 98.010 	Training Prec@5 99.998 	Validation Loss 0.3832 	Validation Prec@1 90.110 	Validation Prec@5 99.730 

lr: 0.0011795172571749547
TRAINING - Epoch: [935][0/391]	Time 1.218 (1.218)	Data 0.345 (0.345)	Loss 0.0494 (0.0494)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [935][100/391]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.0572 (0.0554)	Prec@1 96.875 (98.136)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [935][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0705 (0.0541)	Prec@1 98.438 (98.115)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [935][300/391]	Time 0.110 (0.114)	Data 0.000 (0.001)	Loss 0.0493 (0.0548)	Prec@1 98.438 (98.087)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [935][0/79]	Time 0.423 (0.423)	Data 0.393 (0.393)	Loss 0.2681 (0.2681)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:28

 Epoch: 936	Training Loss 0.0547 	Training Prec@1 98.102 	Training Prec@5 99.994 	Validation Loss 0.3935 	Validation Prec@1 90.140 	Validation Prec@5 99.550 

lr: 0.001145706325709388
TRAINING - Epoch: [936][0/391]	Time 1.269 (1.269)	Data 0.369 (0.369)	Loss 0.0180 (0.0180)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.0511 (0.0534)	Prec@1 99.219 (98.120)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][200/391]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.0267 (0.0547)	Prec@1 99.219 (98.049)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [936][300/391]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.0645 (0.0535)	Prec@1 96.875 (98.077)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [936][0/79]	Time 0.450 (0.450)	Data 0.408 (0.408)	Loss 0.3529 (0.3529)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:32:06

 Epoch: 937	Training Loss 0.0529 	Training Prec@1 98.094 	Training Prec@5 99.998 	Validation Loss 0.3643 	Validation Prec@1 90.370 	Validation Prec@5 99.720 

lr: 0.0011123814470414596
TRAINING - Epoch: [937][0/391]	Time 1.254 (1.254)	Data 0.355 (0.355)	Loss 0.0858 (0.0858)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [937][100/391]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.0352 (0.0570)	Prec@1 99.219 (97.958)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [937][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0742 (0.0547)	Prec@1 98.438 (98.064)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [937][300/391]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.0755 (0.0568)	Prec@1 96.875 (98.025)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [937][0/79]	Time 0.430 (0.430)	Data 0.384 (0.384)	Loss 0.3556 (0.3556)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:06

 Epoch: 938	Training Loss 0.0562 	Training Prec@1 98.014 	Training Prec@5 99.998 	Validation Loss 0.3802 	Validation Prec@1 90.240 	Validation Prec@5 99.670 

lr: 0.0010795429527213675
TRAINING - Epoch: [938][0/391]	Time 1.270 (1.270)	Data 0.438 (0.438)	Loss 0.0949 (0.0949)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [938][100/391]	Time 0.104 (0.116)	Data 0.000 (0.005)	Loss 0.0202 (0.0552)	Prec@1 99.219 (97.997)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [938][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0371 (0.0557)	Prec@1 99.219 (98.010)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [938][300/391]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.0518 (0.0562)	Prec@1 97.656 (98.043)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [938][0/79]	Time 0.441 (0.441)	Data 0.396 (0.396)	Loss 0.2864 (0.2864)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:44	Time of Finish: 2022-03-24 02:27:03

 Epoch: 939	Training Loss 0.0561 	Training Prec@1 98.044 	Training Prec@5 99.994 	Validation Loss 0.3733 	Validation Prec@1 90.190 	Validation Prec@5 99.710 

lr: 0.001047191169460231
TRAINING - Epoch: [939][0/391]	Time 1.311 (1.311)	Data 0.440 (0.440)	Loss 0.0618 (0.0618)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [939][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.0921 (0.0651)	Prec@1 97.656 (97.641)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [939][200/391]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.0554 (0.0623)	Prec@1 97.656 (97.715)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [939][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0546 (0.0643)	Prec@1 96.875 (97.635)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [939][0/79]	Time 0.432 (0.432)	Data 0.385 (0.385)	Loss 0.3649 (0.3649)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:14

 Epoch: 940	Training Loss 0.0635 	Training Prec@1 97.690 	Training Prec@5 99.990 	Validation Loss 0.3784 	Validation Prec@1 90.090 	Validation Prec@5 99.730 

lr: 0.0010153264191269042
TRAINING - Epoch: [940][0/391]	Time 1.247 (1.247)	Data 0.358 (0.358)	Loss 0.0142 (0.0142)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [940][100/391]	Time 0.109 (0.122)	Data 0.000 (0.004)	Loss 0.0688 (0.0570)	Prec@1 97.656 (97.834)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [940][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0849 (0.0605)	Prec@1 96.094 (97.730)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [940][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1079 (0.0602)	Prec@1 96.094 (97.768)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [940][0/79]	Time 0.454 (0.454)	Data 0.417 (0.417)	Loss 0.3297 (0.3297)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:33

 Epoch: 941	Training Loss 0.0607 	Training Prec@1 97.784 	Training Prec@5 99.990 	Validation Loss 0.3792 	Validation Prec@1 90.220 	Validation Prec@5 99.700 

lr: 0.0009839490187447165
TRAINING - Epoch: [941][0/391]	Time 1.256 (1.256)	Data 0.356 (0.356)	Loss 0.0622 (0.0622)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [941][100/391]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.0364 (0.0668)	Prec@1 98.438 (97.664)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [941][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0592 (0.0659)	Prec@1 98.438 (97.668)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [941][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1575 (0.0665)	Prec@1 96.094 (97.651)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [941][0/79]	Time 0.441 (0.441)	Data 0.411 (0.411)	Loss 0.3068 (0.3068)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:27

 Epoch: 942	Training Loss 0.0660 	Training Prec@1 97.688 	Training Prec@5 99.994 	Validation Loss 0.3878 	Validation Prec@1 90.060 	Validation Prec@5 99.680 

lr: 0.0009530592804883488
TRAINING - Epoch: [942][0/391]	Time 1.319 (1.319)	Data 0.444 (0.444)	Loss 0.0403 (0.0403)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [942][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.0980 (0.0667)	Prec@1 96.094 (97.664)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [942][200/391]	Time 0.108 (0.117)	Data 0.000 (0.003)	Loss 0.0690 (0.0645)	Prec@1 97.656 (97.687)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [942][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.1916 (0.0656)	Prec@1 93.750 (97.677)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [942][0/79]	Time 0.442 (0.442)	Data 0.406 (0.406)	Loss 0.3626 (0.3626)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:38

 Epoch: 943	Training Loss 0.0652 	Training Prec@1 97.686 	Training Prec@5 99.986 	Validation Loss 0.3868 	Validation Prec@1 90.070 	Validation Prec@5 99.740 

lr: 0.0009226575116807014
TRAINING - Epoch: [943][0/391]	Time 1.275 (1.275)	Data 0.416 (0.416)	Loss 0.0509 (0.0509)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [943][100/391]	Time 0.106 (0.122)	Data 0.000 (0.004)	Loss 0.0266 (0.0606)	Prec@1 99.219 (97.842)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [943][200/391]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.0501 (0.0617)	Prec@1 98.438 (97.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [943][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.0420 (0.0622)	Prec@1 99.219 (97.765)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [943][0/79]	Time 0.429 (0.429)	Data 0.387 (0.387)	Loss 0.3248 (0.3248)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:28

 Epoch: 944	Training Loss 0.0641 	Training Prec@1 97.756 	Training Prec@5 99.996 	Validation Loss 0.3903 	Validation Prec@1 89.990 	Validation Prec@5 99.690 

lr: 0.0008927440147898693
TRAINING - Epoch: [944][0/391]	Time 1.275 (1.275)	Data 0.422 (0.422)	Loss 0.0226 (0.0226)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [944][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.1179 (0.0666)	Prec@1 95.312 (97.579)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [944][200/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0300 (0.0623)	Prec@1 99.219 (97.765)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [944][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0517 (0.0637)	Prec@1 98.438 (97.724)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [944][0/79]	Time 0.424 (0.424)	Data 0.383 (0.383)	Loss 0.3663 (0.3663)	Prec@1 92.969 (92.969)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:50

 Epoch: 945	Training Loss 0.0643 	Training Prec@1 97.690 	Training Prec@5 99.990 	Validation Loss 0.3950 	Validation Prec@1 90.040 	Validation Prec@5 99.540 

lr: 0.0008633190874261002
TRAINING - Epoch: [945][0/391]	Time 1.273 (1.273)	Data 0.417 (0.417)	Loss 0.0638 (0.0638)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [945][100/391]	Time 0.109 (0.121)	Data 0.000 (0.004)	Loss 0.0226 (0.0657)	Prec@1 99.219 (97.471)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [945][200/391]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.1160 (0.0667)	Prec@1 97.656 (97.617)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [945][300/391]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.0855 (0.0650)	Prec@1 96.875 (97.700)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [945][0/79]	Time 0.432 (0.432)	Data 0.402 (0.402)	Loss 0.3535 (0.3535)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:43

 Epoch: 946	Training Loss 0.0653 	Training Prec@1 97.726 	Training Prec@5 99.992 	Validation Loss 0.3950 	Validation Prec@1 90.030 	Validation Prec@5 99.630 

lr: 0.0008343830223388686
TRAINING - Epoch: [946][0/391]	Time 1.281 (1.281)	Data 0.433 (0.433)	Loss 0.0904 (0.0904)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [946][100/391]	Time 0.112 (0.126)	Data 0.000 (0.005)	Loss 0.0772 (0.0610)	Prec@1 96.875 (97.881)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [946][200/391]	Time 0.110 (0.119)	Data 0.000 (0.003)	Loss 0.1205 (0.0641)	Prec@1 94.531 (97.730)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [946][300/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.0258 (0.0637)	Prec@1 99.219 (97.765)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [946][0/79]	Time 0.426 (0.426)	Data 0.382 (0.382)	Loss 0.3986 (0.3986)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:25

 Epoch: 947	Training Loss 0.0640 	Training Prec@1 97.742 	Training Prec@5 99.996 	Validation Loss 0.3802 	Validation Prec@1 90.280 	Validation Prec@5 99.680 

lr: 0.000805936107413923
TRAINING - Epoch: [947][0/391]	Time 1.291 (1.291)	Data 0.441 (0.441)	Loss 0.0673 (0.0673)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][100/391]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.0758 (0.0627)	Prec@1 98.438 (97.765)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][200/391]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.0449 (0.0645)	Prec@1 97.656 (97.707)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][300/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0652 (0.0641)	Prec@1 98.438 (97.703)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [947][0/79]	Time 0.421 (0.421)	Data 0.382 (0.382)	Loss 0.2779 (0.2779)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:21

 Epoch: 948	Training Loss 0.0645 	Training Prec@1 97.696 	Training Prec@5 99.994 	Validation Loss 0.3920 	Validation Prec@1 89.850 	Validation Prec@5 99.610 

lr: 0.000777978625670466
TRAINING - Epoch: [948][0/391]	Time 1.267 (1.267)	Data 0.408 (0.408)	Loss 0.0601 (0.0601)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [948][100/391]	Time 0.113 (0.125)	Data 0.000 (0.004)	Loss 0.0739 (0.0622)	Prec@1 97.656 (97.919)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [948][200/391]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.0543 (0.0608)	Prec@1 97.656 (97.913)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [948][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0487 (0.0611)	Prec@1 96.875 (97.879)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [948][0/79]	Time 0.439 (0.439)	Data 0.404 (0.404)	Loss 0.3463 (0.3463)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:40

 Epoch: 949	Training Loss 0.0602 	Training Prec@1 97.898 	Training Prec@5 99.988 	Validation Loss 0.3855 	Validation Prec@1 90.000 	Validation Prec@5 99.680 

lr: 0.0007505108552582842
TRAINING - Epoch: [949][0/391]	Time 1.272 (1.272)	Data 0.434 (0.434)	Loss 0.0420 (0.0420)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [949][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.0589 (0.0644)	Prec@1 97.656 (97.672)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [949][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0719 (0.0579)	Prec@1 96.875 (97.897)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [949][300/391]	Time 0.103 (0.108)	Data 0.000 (0.002)	Loss 0.0466 (0.0557)	Prec@1 99.219 (98.022)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [949][0/79]	Time 0.413 (0.413)	Data 0.382 (0.382)	Loss 0.2823 (0.2823)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:27:32

 Epoch: 950	Training Loss 0.0565 	Training Prec@1 98.006 	Training Prec@5 99.996 	Validation Loss 0.3694 	Validation Prec@1 90.170 	Validation Prec@5 99.710 

lr: 0.0007235330694550393
TRAINING - Epoch: [950][0/391]	Time 1.273 (1.273)	Data 0.413 (0.413)	Loss 0.0374 (0.0374)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [950][100/391]	Time 0.106 (0.123)	Data 0.000 (0.004)	Loss 0.0920 (0.0614)	Prec@1 96.094 (97.741)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [950][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.0365 (0.0621)	Prec@1 97.656 (97.792)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [950][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.0441 (0.0631)	Prec@1 98.438 (97.729)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [950][0/79]	Time 0.462 (0.462)	Data 0.431 (0.431)	Loss 0.3426 (0.3426)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:57

 Epoch: 951	Training Loss 0.0632 	Training Prec@1 97.762 	Training Prec@5 99.990 	Validation Loss 0.3799 	Validation Prec@1 90.010 	Validation Prec@5 99.670 

lr: 0.0006970455366635145
TRAINING - Epoch: [951][0/391]	Time 1.255 (1.255)	Data 0.374 (0.374)	Loss 0.0456 (0.0456)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [951][100/391]	Time 0.107 (0.123)	Data 0.000 (0.004)	Loss 0.0959 (0.0649)	Prec@1 96.094 (97.618)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [951][200/391]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.1095 (0.0640)	Prec@1 97.656 (97.742)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [951][300/391]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.0906 (0.0639)	Prec@1 96.875 (97.791)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [951][0/79]	Time 0.427 (0.427)	Data 0.383 (0.383)	Loss 0.2830 (0.2830)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:33

 Epoch: 952	Training Loss 0.0638 	Training Prec@1 97.762 	Training Prec@5 99.994 	Validation Loss 0.3929 	Validation Prec@1 89.710 	Validation Prec@5 99.640 

lr: 0.0006710485204089448
TRAINING - Epoch: [952][0/391]	Time 1.272 (1.272)	Data 0.402 (0.402)	Loss 0.1073 (0.1073)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [952][100/391]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.0507 (0.0639)	Prec@1 96.875 (97.649)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [952][200/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.0263 (0.0646)	Prec@1 99.219 (97.637)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [952][300/391]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.0681 (0.0633)	Prec@1 97.656 (97.713)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [952][0/79]	Time 0.429 (0.429)	Data 0.395 (0.395)	Loss 0.2906 (0.2906)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:44

 Epoch: 953	Training Loss 0.0641 	Training Prec@1 97.682 	Training Prec@5 99.996 	Validation Loss 0.3789 	Validation Prec@1 90.150 	Validation Prec@5 99.630 

lr: 0.0006455422793364078
TRAINING - Epoch: [953][0/391]	Time 1.265 (1.265)	Data 0.411 (0.411)	Loss 0.1152 (0.1152)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [953][100/391]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.1071 (0.0606)	Prec@1 97.656 (97.881)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [953][200/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.0134 (0.0616)	Prec@1 100.000 (97.874)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [953][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0611 (0.0621)	Prec@1 96.875 (97.846)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [953][0/79]	Time 0.434 (0.434)	Data 0.405 (0.405)	Loss 0.3630 (0.3630)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:43

 Epoch: 954	Training Loss 0.0624 	Training Prec@1 97.804 	Training Prec@5 99.996 	Validation Loss 0.3901 	Validation Prec@1 89.970 	Validation Prec@5 99.700 

lr: 0.0006205270672082312
TRAINING - Epoch: [954][0/391]	Time 1.297 (1.297)	Data 0.443 (0.443)	Loss 0.0654 (0.0654)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [954][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0529 (0.0637)	Prec@1 98.438 (97.718)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [954][200/391]	Time 0.113 (0.117)	Data 0.000 (0.003)	Loss 0.0975 (0.0618)	Prec@1 96.875 (97.750)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [954][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0469 (0.0606)	Prec@1 99.219 (97.812)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [954][0/79]	Time 0.440 (0.440)	Data 0.401 (0.401)	Loss 0.2339 (0.2339)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:29:49

 Epoch: 955	Training Loss 0.0597 	Training Prec@1 97.864 	Training Prec@5 99.994 	Validation Loss 0.3803 	Validation Prec@1 89.890 	Validation Prec@5 99.760 

lr: 0.0005960031329015063
TRAINING - Epoch: [955][0/391]	Time 1.295 (1.295)	Data 0.445 (0.445)	Loss 0.0556 (0.0556)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [955][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.1146 (0.0604)	Prec@1 96.094 (97.865)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [955][200/391]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.0431 (0.0608)	Prec@1 97.656 (97.886)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [955][300/391]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.0746 (0.0615)	Prec@1 96.875 (97.892)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [955][0/79]	Time 0.409 (0.409)	Data 0.381 (0.381)	Loss 0.3367 (0.3367)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:01

 Epoch: 956	Training Loss 0.0617 	Training Prec@1 97.888 	Training Prec@5 99.992 	Validation Loss 0.3914 	Validation Prec@1 89.850 	Validation Prec@5 99.700 

lr: 0.0005719707204055729
TRAINING - Epoch: [956][0/391]	Time 1.279 (1.279)	Data 0.351 (0.351)	Loss 0.0794 (0.0794)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [956][100/391]	Time 0.108 (0.127)	Data 0.000 (0.004)	Loss 0.0596 (0.0603)	Prec@1 97.656 (97.726)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [956][200/391]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.1005 (0.0630)	Prec@1 96.875 (97.742)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [956][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.1121 (0.0613)	Prec@1 95.312 (97.817)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [956][0/79]	Time 0.442 (0.442)	Data 0.413 (0.413)	Loss 0.3432 (0.3432)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:03

 Epoch: 957	Training Loss 0.0612 	Training Prec@1 97.808 	Training Prec@5 99.998 	Validation Loss 0.3743 	Validation Prec@1 90.070 	Validation Prec@5 99.700 

lr: 0.0005484300688195991
TRAINING - Epoch: [957][0/391]	Time 1.265 (1.265)	Data 0.363 (0.363)	Loss 0.0528 (0.0528)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [957][100/391]	Time 0.104 (0.116)	Data 0.000 (0.004)	Loss 0.0420 (0.0608)	Prec@1 97.656 (97.857)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [957][200/391]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.0385 (0.0607)	Prec@1 98.438 (97.905)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [957][300/391]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.0580 (0.0621)	Prec@1 96.875 (97.869)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [957][0/79]	Time 0.423 (0.423)	Data 0.390 (0.390)	Loss 0.4303 (0.4303)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:44	Time of Finish: 2022-03-24 02:28:08

 Epoch: 958	Training Loss 0.0610 	Training Prec@1 97.892 	Training Prec@5 99.996 	Validation Loss 0.3810 	Validation Prec@1 90.510 	Validation Prec@5 99.610 

lr: 0.000525381412350217
TRAINING - Epoch: [958][0/391]	Time 1.314 (1.314)	Data 0.445 (0.445)	Loss 0.1298 (0.1298)	Prec@1 96.094 (96.094)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [958][100/391]	Time 0.119 (0.130)	Data 0.000 (0.005)	Loss 0.1336 (0.0674)	Prec@1 95.312 (97.687)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [958][200/391]	Time 0.116 (0.122)	Data 0.000 (0.003)	Loss 0.0266 (0.0671)	Prec@1 99.219 (97.726)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [958][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.0414 (0.0657)	Prec@1 98.438 (97.708)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [958][0/79]	Time 0.410 (0.410)	Data 0.370 (0.370)	Loss 0.4235 (0.4235)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:31:07

 Epoch: 959	Training Loss 0.0653 	Training Prec@1 97.706 	Training Prec@5 99.992 	Validation Loss 0.3900 	Validation Prec@1 90.070 	Validation Prec@5 99.570 

lr: 0.000502824980309196
TRAINING - Epoch: [959][0/391]	Time 1.602 (1.602)	Data 0.459 (0.459)	Loss 0.0609 (0.0609)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [959][100/391]	Time 0.121 (0.135)	Data 0.000 (0.005)	Loss 0.0818 (0.0569)	Prec@1 97.656 (97.896)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [959][200/391]	Time 0.120 (0.128)	Data 0.000 (0.003)	Loss 0.0309 (0.0622)	Prec@1 98.438 (97.769)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [959][300/391]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.0378 (0.0616)	Prec@1 98.438 (97.799)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [959][0/79]	Time 0.430 (0.430)	Data 0.394 (0.394)	Loss 0.4652 (0.4652)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:32:11

 Epoch: 960	Training Loss 0.0622 	Training Prec@1 97.774 	Training Prec@5 99.994 	Validation Loss 0.3933 	Validation Prec@1 89.590 	Validation Prec@5 99.660 

lr: 0.00048076099711112316
TRAINING - Epoch: [960][0/391]	Time 1.274 (1.274)	Data 0.413 (0.413)	Loss 0.0256 (0.0256)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [960][100/391]	Time 0.117 (0.127)	Data 0.001 (0.005)	Loss 0.0502 (0.0605)	Prec@1 99.219 (97.927)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [960][200/391]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.0524 (0.0610)	Prec@1 98.438 (97.862)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [960][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0397 (0.0625)	Prec@1 99.219 (97.846)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [960][0/79]	Time 0.434 (0.434)	Data 0.402 (0.402)	Loss 0.3847 (0.3847)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:59

 Epoch: 961	Training Loss 0.0629 	Training Prec@1 97.822 	Training Prec@5 99.992 	Validation Loss 0.3918 	Validation Prec@1 90.010 	Validation Prec@5 99.720 

lr: 0.000459189682271221
TRAINING - Epoch: [961][0/391]	Time 1.296 (1.296)	Data 0.453 (0.453)	Loss 0.0804 (0.0804)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [961][100/391]	Time 0.120 (0.131)	Data 0.000 (0.005)	Loss 0.0342 (0.0617)	Prec@1 98.438 (97.765)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [961][200/391]	Time 0.119 (0.126)	Data 0.000 (0.003)	Loss 0.0302 (0.0632)	Prec@1 99.219 (97.687)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [961][300/391]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.0575 (0.0624)	Prec@1 98.438 (97.703)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [961][0/79]	Time 0.445 (0.445)	Data 0.408 (0.408)	Loss 0.3544 (0.3544)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:31:53

 Epoch: 962	Training Loss 0.0625 	Training Prec@1 97.696 	Training Prec@5 99.996 	Validation Loss 0.3874 	Validation Prec@1 90.010 	Validation Prec@5 99.610 

lr: 0.00043811125040313316
TRAINING - Epoch: [962][0/391]	Time 1.279 (1.279)	Data 0.421 (0.421)	Loss 0.0558 (0.0558)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [962][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.0380 (0.0556)	Prec@1 98.438 (98.074)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [962][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0433 (0.0612)	Prec@1 98.438 (97.831)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [962][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1062 (0.0635)	Prec@1 96.094 (97.721)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [962][0/79]	Time 0.432 (0.432)	Data 0.387 (0.387)	Loss 0.3625 (0.3625)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:11

 Epoch: 963	Training Loss 0.0644 	Training Prec@1 97.666 	Training Prec@5 100.000 	Validation Loss 0.3921 	Validation Prec@1 89.840 	Validation Prec@5 99.740 

lr: 0.0004175259112167868
TRAINING - Epoch: [963][0/391]	Time 1.279 (1.279)	Data 0.435 (0.435)	Loss 0.0739 (0.0739)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [963][100/391]	Time 0.111 (0.126)	Data 0.000 (0.005)	Loss 0.1026 (0.0632)	Prec@1 95.312 (97.865)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [963][200/391]	Time 0.109 (0.121)	Data 0.000 (0.002)	Loss 0.0918 (0.0610)	Prec@1 96.875 (97.889)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [963][300/391]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.0441 (0.0617)	Prec@1 98.438 (97.885)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [963][0/79]	Time 0.431 (0.431)	Data 0.390 (0.390)	Loss 0.3913 (0.3913)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:49	Time of Finish: 2022-03-24 02:31:31

 Epoch: 964	Training Loss 0.0633 	Training Prec@1 97.836 	Training Prec@5 99.992 	Validation Loss 0.3899 	Validation Prec@1 89.680 	Validation Prec@5 99.630 

lr: 0.00039743386951633886
TRAINING - Epoch: [964][0/391]	Time 1.277 (1.277)	Data 0.417 (0.417)	Loss 0.0520 (0.0520)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [964][100/391]	Time 0.118 (0.127)	Data 0.000 (0.004)	Loss 0.0292 (0.0651)	Prec@1 98.438 (97.772)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [964][200/391]	Time 0.108 (0.119)	Data 0.000 (0.002)	Loss 0.0487 (0.0652)	Prec@1 98.438 (97.699)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [964][300/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0405 (0.0638)	Prec@1 98.438 (97.719)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [964][0/79]	Time 0.442 (0.442)	Data 0.402 (0.402)	Loss 0.4654 (0.4654)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:18

 Epoch: 965	Training Loss 0.0649 	Training Prec@1 97.700 	Training Prec@5 99.992 	Validation Loss 0.4041 	Validation Prec@1 89.840 	Validation Prec@5 99.630 

lr: 0.0003778353251980833
TRAINING - Epoch: [965][0/391]	Time 1.281 (1.281)	Data 0.425 (0.425)	Loss 0.0391 (0.0391)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][100/391]	Time 0.111 (0.123)	Data 0.000 (0.005)	Loss 0.0530 (0.0630)	Prec@1 98.438 (97.811)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.0949 (0.0632)	Prec@1 96.875 (97.792)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][300/391]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.0701 (0.0639)	Prec@1 98.438 (97.781)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [965][0/79]	Time 0.433 (0.433)	Data 0.390 (0.390)	Loss 0.4652 (0.4652)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:05

 Epoch: 966	Training Loss 0.0646 	Training Prec@1 97.738 	Training Prec@5 99.998 	Validation Loss 0.3914 	Validation Prec@1 89.560 	Validation Prec@5 99.640 

lr: 0.0003587304732485248
TRAINING - Epoch: [966][0/391]	Time 1.263 (1.263)	Data 0.415 (0.415)	Loss 0.0697 (0.0697)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [966][100/391]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.0693 (0.0624)	Prec@1 97.656 (97.881)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [966][200/391]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.0195 (0.0635)	Prec@1 100.000 (97.831)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [966][300/391]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.0315 (0.0648)	Prec@1 98.438 (97.747)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [966][0/79]	Time 0.416 (0.416)	Data 0.380 (0.380)	Loss 0.4206 (0.4206)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:53

 Epoch: 967	Training Loss 0.0663 	Training Prec@1 97.666 	Training Prec@5 99.992 	Validation Loss 0.3973 	Validation Prec@1 89.750 	Validation Prec@5 99.600 

lr: 0.00034011950374238613
TRAINING - Epoch: [967][0/391]	Time 1.284 (1.284)	Data 0.430 (0.430)	Loss 0.0951 (0.0951)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [967][100/391]	Time 0.106 (0.122)	Data 0.000 (0.005)	Loss 0.0949 (0.0659)	Prec@1 96.875 (97.687)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [967][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0686 (0.0657)	Prec@1 96.875 (97.656)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [967][300/391]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.0419 (0.0636)	Prec@1 97.656 (97.719)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [967][0/79]	Time 0.422 (0.422)	Data 0.389 (0.389)	Loss 0.3535 (0.3535)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:29:56

 Epoch: 968	Training Loss 0.0633 	Training Prec@1 97.746 	Training Prec@5 99.996 	Validation Loss 0.3969 	Validation Prec@1 89.800 	Validation Prec@5 99.690 

lr: 0.00032200260184075366
TRAINING - Epoch: [968][0/391]	Time 1.328 (1.328)	Data 0.484 (0.484)	Loss 0.0407 (0.0407)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [968][100/391]	Time 0.108 (0.123)	Data 0.000 (0.005)	Loss 0.0684 (0.0653)	Prec@1 98.438 (97.780)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [968][200/391]	Time 0.119 (0.118)	Data 0.000 (0.003)	Loss 0.0548 (0.0656)	Prec@1 98.438 (97.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [968][300/391]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.0416 (0.0664)	Prec@1 99.219 (97.630)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [968][0/79]	Time 0.454 (0.454)	Data 0.411 (0.411)	Loss 0.3126 (0.3126)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:32

 Epoch: 969	Training Loss 0.0660 	Training Prec@1 97.660 	Training Prec@5 99.996 	Validation Loss 0.3939 	Validation Prec@1 89.910 	Validation Prec@5 99.640 

lr: 0.0003043799477892125
TRAINING - Epoch: [969][0/391]	Time 1.584 (1.584)	Data 0.438 (0.438)	Loss 0.0984 (0.0984)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [969][100/391]	Time 0.116 (0.131)	Data 0.000 (0.005)	Loss 0.0560 (0.0614)	Prec@1 97.656 (97.788)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [969][200/391]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.0285 (0.0629)	Prec@1 99.219 (97.742)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [969][300/391]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.0074 (0.0621)	Prec@1 100.000 (97.791)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [969][0/79]	Time 0.434 (0.434)	Data 0.401 (0.401)	Loss 0.3530 (0.3530)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:31:42

 Epoch: 970	Training Loss 0.0634 	Training Prec@1 97.736 	Training Prec@5 99.992 	Validation Loss 0.3936 	Validation Prec@1 89.580 	Validation Prec@5 99.720 

lr: 0.000287251716916059
TRAINING - Epoch: [970][0/391]	Time 1.296 (1.296)	Data 0.439 (0.439)	Loss 0.0744 (0.0744)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.0230 (0.0571)	Prec@1 100.000 (97.981)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][200/391]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.0770 (0.0564)	Prec@1 98.438 (97.991)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][300/391]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.0713 (0.0594)	Prec@1 96.094 (97.879)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [970][0/79]	Time 0.442 (0.442)	Data 0.407 (0.407)	Loss 0.3238 (0.3238)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:46	Time of Finish: 2022-03-24 02:30:01

 Epoch: 971	Training Loss 0.0618 	Training Prec@1 97.796 	Training Prec@5 99.996 	Validation Loss 0.3910 	Validation Prec@1 89.460 	Validation Prec@5 99.660 

lr: 0.0002706180796305687
TRAINING - Epoch: [971][0/391]	Time 1.568 (1.568)	Data 0.423 (0.423)	Loss 0.0930 (0.0930)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [971][100/391]	Time 0.120 (0.130)	Data 0.000 (0.004)	Loss 0.0529 (0.0670)	Prec@1 98.438 (97.540)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [971][200/391]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.1262 (0.0667)	Prec@1 95.312 (97.664)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [971][300/391]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.1057 (0.0664)	Prec@1 96.094 (97.628)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [971][0/79]	Time 0.450 (0.450)	Data 0.407 (0.407)	Loss 0.4036 (0.4036)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:31:03

 Epoch: 972	Training Loss 0.0662 	Training Prec@1 97.588 	Training Prec@5 99.990 	Validation Loss 0.3871 	Validation Prec@1 89.770 	Validation Prec@5 99.660 

lr: 0.00025447920142128677
TRAINING - Epoch: [972][0/391]	Time 1.288 (1.288)	Data 0.430 (0.430)	Loss 0.0810 (0.0810)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [972][100/391]	Time 0.107 (0.123)	Data 0.000 (0.005)	Loss 0.0337 (0.0686)	Prec@1 98.438 (97.517)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [972][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0318 (0.0677)	Prec@1 98.438 (97.613)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [972][300/391]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.0359 (0.0656)	Prec@1 99.219 (97.706)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [972][0/79]	Time 0.453 (0.453)	Data 0.409 (0.409)	Loss 0.4114 (0.4114)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:11

 Epoch: 973	Training Loss 0.0641 	Training Prec@1 97.766 	Training Prec@5 99.996 	Validation Loss 0.3806 	Validation Prec@1 90.140 	Validation Prec@5 99.670 

lr: 0.0002388352428543791
TRAINING - Epoch: [973][0/391]	Time 1.279 (1.279)	Data 0.412 (0.412)	Loss 0.0570 (0.0570)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [973][100/391]	Time 0.112 (0.123)	Data 0.000 (0.004)	Loss 0.1554 (0.0640)	Prec@1 95.312 (97.703)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [973][200/391]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.0336 (0.0617)	Prec@1 99.219 (97.819)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [973][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0329 (0.0647)	Prec@1 98.438 (97.726)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [973][0/79]	Time 0.432 (0.432)	Data 0.381 (0.381)	Loss 0.3162 (0.3162)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:13

 Epoch: 974	Training Loss 0.0656 	Training Prec@1 97.686 	Training Prec@5 99.992 	Validation Loss 0.3855 	Validation Prec@1 90.170 	Validation Prec@5 99.630 

lr: 0.0002236863595720559
TRAINING - Epoch: [974][0/391]	Time 1.267 (1.267)	Data 0.410 (0.410)	Loss 0.0207 (0.0207)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.1521 (0.0636)	Prec@1 93.750 (97.741)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.1145 (0.0669)	Prec@1 96.094 (97.680)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [974][300/391]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.0340 (0.0658)	Prec@1 98.438 (97.664)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [974][0/79]	Time 0.437 (0.437)	Data 0.398 (0.398)	Loss 0.2650 (0.2650)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:45

 Epoch: 975	Training Loss 0.0638 	Training Prec@1 97.722 	Training Prec@5 99.994 	Validation Loss 0.3929 	Validation Prec@1 89.940 	Validation Prec@5 99.660 

lr: 0.00020903270229098966
TRAINING - Epoch: [975][0/391]	Time 1.280 (1.280)	Data 0.416 (0.416)	Loss 0.0715 (0.0715)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [975][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.0994 (0.0556)	Prec@1 96.094 (98.151)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [975][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0298 (0.0596)	Prec@1 98.438 (97.956)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [975][300/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.0905 (0.0613)	Prec@1 96.094 (97.861)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [975][0/79]	Time 0.418 (0.418)	Data 0.386 (0.386)	Loss 0.2648 (0.2648)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:33

 Epoch: 976	Training Loss 0.0597 	Training Prec@1 97.900 	Training Prec@5 99.996 	Validation Loss 0.3920 	Validation Prec@1 89.940 	Validation Prec@5 99.730 

lr: 0.00019487441680084958
TRAINING - Epoch: [976][0/391]	Time 1.360 (1.360)	Data 0.455 (0.455)	Loss 0.0593 (0.0593)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [976][100/391]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.1062 (0.0621)	Prec@1 96.875 (97.819)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [976][200/391]	Time 0.110 (0.117)	Data 0.000 (0.003)	Loss 0.0633 (0.0608)	Prec@1 98.438 (97.870)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [976][300/391]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.0519 (0.0615)	Prec@1 97.656 (97.804)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [976][0/79]	Time 0.414 (0.414)	Data 0.384 (0.384)	Loss 0.3315 (0.3315)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:10

 Epoch: 977	Training Loss 0.0618 	Training Prec@1 97.820 	Training Prec@5 100.000 	Validation Loss 0.3893 	Validation Prec@1 90.080 	Validation Prec@5 99.700 

lr: 0.00018121164396283615
TRAINING - Epoch: [977][0/391]	Time 1.291 (1.291)	Data 0.452 (0.452)	Loss 0.0417 (0.0417)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [977][100/391]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.0344 (0.0596)	Prec@1 99.219 (97.834)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [977][200/391]	Time 0.107 (0.116)	Data 0.000 (0.003)	Loss 0.0483 (0.0635)	Prec@1 96.875 (97.715)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [977][300/391]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.0504 (0.0619)	Prec@1 97.656 (97.799)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [977][0/79]	Time 0.425 (0.425)	Data 0.393 (0.393)	Loss 0.3865 (0.3865)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:30:04

 Epoch: 978	Training Loss 0.0637 	Training Prec@1 97.764 	Training Prec@5 99.998 	Validation Loss 0.3940 	Validation Prec@1 90.250 	Validation Prec@5 99.640 

lr: 0.00016804451970827672
TRAINING - Epoch: [978][0/391]	Time 1.269 (1.269)	Data 0.406 (0.406)	Loss 0.0196 (0.0196)	Prec@1 100.000 (100.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][100/391]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.0438 (0.0543)	Prec@1 98.438 (98.144)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][200/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0330 (0.0583)	Prec@1 99.219 (98.022)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][300/391]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.0862 (0.0588)	Prec@1 96.875 (97.978)	Prec@5 100.000 (100.000)
EVALUATING - Epoch: [978][0/79]	Time 0.442 (0.442)	Data 0.410 (0.410)	Loss 0.3707 (0.3707)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:41

 Epoch: 979	Training Loss 0.0595 	Training Prec@1 97.952 	Training Prec@5 100.000 	Validation Loss 0.3838 	Validation Prec@1 89.600 	Validation Prec@5 99.650 

lr: 0.0001553731750372709
TRAINING - Epoch: [979][0/391]	Time 1.277 (1.277)	Data 0.417 (0.417)	Loss 0.0621 (0.0621)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [979][100/391]	Time 0.119 (0.132)	Data 0.000 (0.004)	Loss 0.0812 (0.0616)	Prec@1 96.094 (97.842)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [979][200/391]	Time 0.114 (0.124)	Data 0.000 (0.002)	Loss 0.0846 (0.0625)	Prec@1 96.875 (97.812)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [979][300/391]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.0312 (0.0601)	Prec@1 99.219 (97.872)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [979][0/79]	Time 0.431 (0.431)	Data 0.398 (0.398)	Loss 0.3848 (0.3848)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:49	Time of Finish: 2022-03-24 02:30:57

 Epoch: 980	Training Loss 0.0601 	Training Prec@1 97.848 	Training Prec@5 99.994 	Validation Loss 0.3942 	Validation Prec@1 89.560 	Validation Prec@5 99.700 

lr: 0.0001431977360173973
TRAINING - Epoch: [980][0/391]	Time 1.268 (1.268)	Data 0.418 (0.418)	Loss 0.0515 (0.0515)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [980][100/391]	Time 0.109 (0.123)	Data 0.000 (0.004)	Loss 0.0763 (0.0632)	Prec@1 98.438 (97.788)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [980][200/391]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.1622 (0.0623)	Prec@1 95.312 (97.886)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [980][300/391]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.0403 (0.0633)	Prec@1 98.438 (97.828)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [980][0/79]	Time 0.409 (0.409)	Data 0.383 (0.383)	Loss 0.3946 (0.3946)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:20

 Epoch: 981	Training Loss 0.0625 	Training Prec@1 97.848 	Training Prec@5 99.992 	Validation Loss 0.3885 	Validation Prec@1 90.010 	Validation Prec@5 99.670 

lr: 0.00013151832378245892
TRAINING - Epoch: [981][0/391]	Time 1.498 (1.498)	Data 0.372 (0.372)	Loss 0.0536 (0.0536)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [981][100/391]	Time 0.110 (0.128)	Data 0.000 (0.004)	Loss 0.0253 (0.0576)	Prec@1 99.219 (98.028)	Prec@5 100.000 (99.977)
TRAINING - Epoch: [981][200/391]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.0634 (0.0592)	Prec@1 96.094 (97.952)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [981][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0282 (0.0594)	Prec@1 99.219 (97.908)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [981][0/79]	Time 0.443 (0.443)	Data 0.407 (0.407)	Loss 0.4057 (0.4057)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:20

 Epoch: 982	Training Loss 0.0597 	Training Prec@1 97.866 	Training Prec@5 99.992 	Validation Loss 0.3980 	Validation Prec@1 90.110 	Validation Prec@5 99.630 

lr: 0.00012033505453127298
TRAINING - Epoch: [982][0/391]	Time 1.296 (1.296)	Data 0.432 (0.432)	Loss 0.0467 (0.0467)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [982][100/391]	Time 0.113 (0.123)	Data 0.000 (0.005)	Loss 0.0883 (0.0606)	Prec@1 97.656 (98.004)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [982][200/391]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.0491 (0.0601)	Prec@1 98.438 (97.987)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [982][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0599 (0.0588)	Prec@1 97.656 (97.955)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [982][0/79]	Time 0.450 (0.450)	Data 0.414 (0.414)	Loss 0.3047 (0.3047)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:13

 Epoch: 983	Training Loss 0.0596 	Training Prec@1 97.932 	Training Prec@5 99.994 	Validation Loss 0.3966 	Validation Prec@1 89.650 	Validation Prec@5 99.650 

lr: 0.00010964803952649967
TRAINING - Epoch: [983][0/391]	Time 1.311 (1.311)	Data 0.463 (0.463)	Loss 0.0678 (0.0678)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [983][100/391]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.1038 (0.0630)	Prec@1 95.312 (97.703)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [983][200/391]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.0575 (0.0608)	Prec@1 97.656 (97.882)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [983][300/391]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.1822 (0.0618)	Prec@1 94.531 (97.828)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [983][0/79]	Time 0.415 (0.415)	Data 0.378 (0.378)	Loss 0.3518 (0.3518)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:29

 Epoch: 984	Training Loss 0.0620 	Training Prec@1 97.824 	Training Prec@5 99.994 	Validation Loss 0.3880 	Validation Prec@1 90.110 	Validation Prec@5 99.560 

lr: 9.945738509358191e-05
TRAINING - Epoch: [984][0/391]	Time 1.308 (1.308)	Data 0.459 (0.459)	Loss 0.0474 (0.0474)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [984][100/391]	Time 0.112 (0.124)	Data 0.000 (0.005)	Loss 0.1068 (0.0581)	Prec@1 96.875 (97.973)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [984][200/391]	Time 0.120 (0.120)	Data 0.000 (0.003)	Loss 0.0648 (0.0580)	Prec@1 97.656 (97.959)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [984][300/391]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.0392 (0.0574)	Prec@1 98.438 (98.017)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [984][0/79]	Time 0.435 (0.435)	Data 0.404 (0.404)	Loss 0.3506 (0.3506)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:42

 Epoch: 985	Training Loss 0.0584 	Training Prec@1 97.958 	Training Prec@5 99.996 	Validation Loss 0.3992 	Validation Prec@1 89.800 	Validation Prec@5 99.660 

lr: 8.976319261962395e-05
TRAINING - Epoch: [985][0/391]	Time 1.283 (1.283)	Data 0.427 (0.427)	Loss 0.0527 (0.0527)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [985][100/391]	Time 0.106 (0.126)	Data 0.000 (0.005)	Loss 0.0505 (0.0586)	Prec@1 99.219 (97.950)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [985][200/391]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.0505 (0.0577)	Prec@1 97.656 (97.921)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [985][300/391]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.0491 (0.0598)	Prec@1 98.438 (97.882)	Prec@5 100.000 (99.987)
EVALUATING - Epoch: [985][0/79]	Time 0.429 (0.429)	Data 0.387 (0.387)	Loss 0.3337 (0.3337)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:28

 Epoch: 986	Training Loss 0.0581 	Training Prec@1 97.972 	Training Prec@5 99.990 	Validation Loss 0.3845 	Validation Prec@1 89.910 	Validation Prec@5 99.670 

lr: 8.056555855243664e-05
TRAINING - Epoch: [986][0/391]	Time 1.268 (1.268)	Data 0.403 (0.403)	Loss 0.1114 (0.1114)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [986][100/391]	Time 0.113 (0.123)	Data 0.000 (0.004)	Loss 0.0369 (0.0582)	Prec@1 98.438 (97.942)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [986][200/391]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.0547 (0.0587)	Prec@1 98.438 (97.913)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [986][300/391]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.0574 (0.0585)	Prec@1 98.438 (97.981)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [986][0/79]	Time 0.425 (0.425)	Data 0.387 (0.387)	Loss 0.3704 (0.3704)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:25

 Epoch: 987	Training Loss 0.0583 	Training Prec@1 97.994 	Training Prec@5 99.992 	Validation Loss 0.3855 	Validation Prec@1 90.140 	Validation Prec@5 99.660 

lr: 7.186457439954932e-05
TRAINING - Epoch: [987][0/391]	Time 1.549 (1.549)	Data 0.410 (0.410)	Loss 0.0275 (0.0275)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [987][100/391]	Time 0.115 (0.132)	Data 0.000 (0.004)	Loss 0.0861 (0.0567)	Prec@1 96.094 (97.888)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [987][200/391]	Time 0.117 (0.125)	Data 0.000 (0.002)	Loss 0.0359 (0.0597)	Prec@1 99.219 (97.788)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [987][300/391]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.0533 (0.0585)	Prec@1 98.438 (97.830)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [987][0/79]	Time 0.447 (0.447)	Data 0.406 (0.406)	Loss 0.4064 (0.4064)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:50	Time of Finish: 2022-03-24 02:30:57

 Epoch: 988	Training Loss 0.0591 	Training Prec@1 97.844 	Training Prec@5 99.994 	Validation Loss 0.3952 	Validation Prec@1 90.140 	Validation Prec@5 99.600 

lr: 6.366032672731051e-05
TRAINING - Epoch: [988][0/391]	Time 1.293 (1.293)	Data 0.439 (0.439)	Loss 0.0283 (0.0283)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [988][100/391]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.0579 (0.0556)	Prec@1 98.438 (98.035)	Prec@5 100.000 (99.985)
TRAINING - Epoch: [988][200/391]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.0535 (0.0562)	Prec@1 97.656 (98.018)	Prec@5 100.000 (99.984)
TRAINING - Epoch: [988][300/391]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.0651 (0.0580)	Prec@1 96.875 (97.913)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [988][0/79]	Time 0.419 (0.419)	Data 0.383 (0.383)	Loss 0.4380 (0.4380)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:34

 Epoch: 989	Training Loss 0.0571 	Training Prec@1 97.968 	Training Prec@5 99.992 	Validation Loss 0.3952 	Validation Prec@1 89.950 	Validation Prec@5 99.680 

lr: 5.595289716001644e-05
TRAINING - Epoch: [989][0/391]	Time 1.280 (1.280)	Data 0.432 (0.432)	Loss 0.1088 (0.1088)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [989][100/391]	Time 0.109 (0.123)	Data 0.000 (0.005)	Loss 0.0439 (0.0561)	Prec@1 99.219 (98.074)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [989][200/391]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.0508 (0.0585)	Prec@1 98.438 (97.971)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [989][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0344 (0.0577)	Prec@1 98.438 (97.963)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [989][0/79]	Time 0.442 (0.442)	Data 0.400 (0.400)	Loss 0.3953 (0.3953)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:22

 Epoch: 990	Training Loss 0.0582 	Training Prec@1 97.942 	Training Prec@5 99.992 	Validation Loss 0.4006 	Validation Prec@1 89.940 	Validation Prec@5 99.720 

lr: 4.874236237911717e-05
TRAINING - Epoch: [990][0/391]	Time 1.297 (1.297)	Data 0.448 (0.448)	Loss 0.0492 (0.0492)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][100/391]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.0938 (0.0614)	Prec@1 96.875 (97.850)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][200/391]	Time 0.111 (0.116)	Data 0.000 (0.003)	Loss 0.0162 (0.0607)	Prec@1 100.000 (97.870)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][300/391]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.0314 (0.0583)	Prec@1 98.438 (97.965)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [990][0/79]	Time 0.409 (0.409)	Data 0.380 (0.380)	Loss 0.3688 (0.3688)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:30:20

 Epoch: 991	Training Loss 0.0565 	Training Prec@1 98.040 	Training Prec@5 99.996 	Validation Loss 0.3853 	Validation Prec@1 89.960 	Validation Prec@5 99.640 

lr: 4.202879412242284e-05
TRAINING - Epoch: [991][0/391]	Time 1.281 (1.281)	Data 0.412 (0.412)	Loss 0.0558 (0.0558)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [991][100/391]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.0580 (0.0584)	Prec@1 98.438 (97.935)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [991][200/391]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1111 (0.0586)	Prec@1 96.875 (97.917)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [991][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0418 (0.0595)	Prec@1 99.219 (97.864)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [991][0/79]	Time 0.427 (0.427)	Data 0.391 (0.391)	Loss 0.3303 (0.3303)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:22

 Epoch: 992	Training Loss 0.0609 	Training Prec@1 97.818 	Training Prec@5 99.996 	Validation Loss 0.4012 	Validation Prec@1 89.820 	Validation Prec@5 99.640 

lr: 3.581225918342642e-05
TRAINING - Epoch: [992][0/391]	Time 1.278 (1.278)	Data 0.416 (0.416)	Loss 0.0268 (0.0268)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [992][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.0340 (0.0572)	Prec@1 97.656 (97.966)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [992][200/391]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.0783 (0.0581)	Prec@1 96.875 (97.940)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [992][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0764 (0.0568)	Prec@1 95.312 (97.986)	Prec@5 100.000 (99.992)
EVALUATING - Epoch: [992][0/79]	Time 0.442 (0.442)	Data 0.400 (0.400)	Loss 0.4613 (0.4613)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:24

 Epoch: 993	Training Loss 0.0559 	Training Prec@1 98.018 	Training Prec@5 99.992 	Validation Loss 0.3987 	Validation Prec@1 89.670 	Validation Prec@5 99.630 

lr: 3.009281941062089e-05
TRAINING - Epoch: [993][0/391]	Time 1.283 (1.283)	Data 0.417 (0.417)	Loss 0.0423 (0.0423)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [993][100/391]	Time 0.117 (0.127)	Data 0.000 (0.004)	Loss 0.0115 (0.0546)	Prec@1 100.000 (98.175)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [993][200/391]	Time 0.108 (0.120)	Data 0.000 (0.002)	Loss 0.0549 (0.0566)	Prec@1 97.656 (98.025)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [993][300/391]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.0534 (0.0567)	Prec@1 97.656 (97.983)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [993][0/79]	Time 0.439 (0.439)	Data 0.409 (0.409)	Loss 0.3692 (0.3692)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:28

 Epoch: 994	Training Loss 0.0563 	Training Prec@1 98.012 	Training Prec@5 99.996 	Validation Loss 0.3888 	Validation Prec@1 90.180 	Validation Prec@5 99.650 

lr: 2.487053170686646e-05
TRAINING - Epoch: [994][0/391]	Time 1.274 (1.274)	Data 0.419 (0.419)	Loss 0.0562 (0.0562)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][100/391]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.0239 (0.0592)	Prec@1 99.219 (97.958)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0455 (0.0587)	Prec@1 98.438 (97.967)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][300/391]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.0594 (0.0590)	Prec@1 96.875 (97.918)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [994][0/79]	Time 0.444 (0.444)	Data 0.403 (0.403)	Loss 0.3840 (0.3840)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:24

 Epoch: 995	Training Loss 0.0593 	Training Prec@1 97.922 	Training Prec@5 99.996 	Validation Loss 0.4002 	Validation Prec@1 89.740 	Validation Prec@5 99.660 

lr: 2.0145448028874282e-05
TRAINING - Epoch: [995][0/391]	Time 1.276 (1.276)	Data 0.413 (0.413)	Loss 0.0723 (0.0723)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [995][100/391]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.0420 (0.0628)	Prec@1 97.656 (97.772)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [995][200/391]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.0532 (0.0605)	Prec@1 97.656 (97.812)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [995][300/391]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.0623 (0.0590)	Prec@1 96.875 (97.885)	Prec@5 100.000 (99.984)
EVALUATING - Epoch: [995][0/79]	Time 0.429 (0.429)	Data 0.388 (0.388)	Loss 0.3625 (0.3625)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:46	Time of Finish: 2022-03-24 02:30:22

 Epoch: 996	Training Loss 0.0594 	Training Prec@1 97.848 	Training Prec@5 99.988 	Validation Loss 0.4042 	Validation Prec@1 89.860 	Validation Prec@5 99.640 

lr: 1.5917615386623604e-05
TRAINING - Epoch: [996][0/391]	Time 1.307 (1.307)	Data 0.447 (0.447)	Loss 0.0705 (0.0705)	Prec@1 96.875 (96.875)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [996][100/391]	Time 0.116 (0.127)	Data 0.000 (0.005)	Loss 0.1427 (0.0600)	Prec@1 94.531 (97.811)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [996][200/391]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.0139 (0.0607)	Prec@1 99.219 (97.788)	Prec@5 100.000 (99.988)
TRAINING - Epoch: [996][300/391]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.0934 (0.0578)	Prec@1 96.875 (97.950)	Prec@5 100.000 (99.990)
EVALUATING - Epoch: [996][0/79]	Time 0.441 (0.441)	Data 0.403 (0.403)	Loss 0.3453 (0.3453)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:30

 Epoch: 997	Training Loss 0.0574 	Training Prec@1 97.978 	Training Prec@5 99.992 	Validation Loss 0.3984 	Validation Prec@1 90.110 	Validation Prec@5 99.630 

lr: 1.2187075842956519e-05
TRAINING - Epoch: [997][0/391]	Time 1.299 (1.299)	Data 0.438 (0.438)	Loss 0.0646 (0.0646)	Prec@1 97.656 (97.656)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][100/391]	Time 0.115 (0.129)	Data 0.000 (0.005)	Loss 0.0204 (0.0536)	Prec@1 100.000 (98.190)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][200/391]	Time 0.114 (0.123)	Data 0.000 (0.003)	Loss 0.0322 (0.0556)	Prec@1 100.000 (98.115)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][300/391]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.0623 (0.0574)	Prec@1 96.875 (98.017)	Prec@5 100.000 (99.997)
EVALUATING - Epoch: [997][0/79]	Time 0.406 (0.406)	Data 0.379 (0.379)	Loss 0.3499 (0.3499)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:48	Time of Finish: 2022-03-24 02:30:29

 Epoch: 998	Training Loss 0.0585 	Training Prec@1 97.944 	Training Prec@5 99.996 	Validation Loss 0.4033 	Validation Prec@1 89.730 	Validation Prec@5 99.620 

lr: 8.95386651311169e-06
TRAINING - Epoch: [998][0/391]	Time 1.287 (1.287)	Data 0.430 (0.430)	Loss 0.0362 (0.0362)	Prec@1 99.219 (99.219)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [998][100/391]	Time 0.110 (0.124)	Data 0.000 (0.005)	Loss 0.0617 (0.0534)	Prec@1 97.656 (98.105)	Prec@5 100.000 (99.992)
TRAINING - Epoch: [998][200/391]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.0454 (0.0546)	Prec@1 99.219 (98.092)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [998][300/391]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.0237 (0.0554)	Prec@1 98.438 (98.069)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [998][0/79]	Time 0.443 (0.443)	Data 0.412 (0.412)	Loss 0.3462 (0.3462)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:27

 Epoch: 999	Training Loss 0.0558 	Training Prec@1 98.022 	Training Prec@5 99.994 	Validation Loss 0.3868 	Validation Prec@1 90.210 	Validation Prec@5 99.670 

lr: 6.218019564391271e-06
TRAINING - Epoch: [999][0/391]	Time 1.268 (1.268)	Data 0.419 (0.419)	Loss 0.0369 (0.0369)	Prec@1 98.438 (98.438)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [999][100/391]	Time 0.110 (0.123)	Data 0.000 (0.004)	Loss 0.0240 (0.0551)	Prec@1 99.219 (98.035)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [999][200/391]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.0563 (0.0565)	Prec@1 97.656 (97.998)	Prec@5 100.000 (99.996)
TRAINING - Epoch: [999][300/391]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.0331 (0.0573)	Prec@1 98.438 (97.994)	Prec@5 100.000 (99.995)
EVALUATING - Epoch: [999][0/79]	Time 0.462 (0.462)	Data 0.427 (0.427)	Loss 0.4674 (0.4674)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:47	Time of Finish: 2022-03-24 02:30:27

 Epoch: 1000	Training Loss 0.0561 	Training Prec@1 98.024 	Training Prec@5 99.996 	Validation Loss 0.3921 	Validation Prec@1 89.910 	Validation Prec@5 99.670 

**************************************************DONE**************************************************

 Best_Epoch: 845	Best_Prec1 90.6200 	Best_Loss 0.371 	
